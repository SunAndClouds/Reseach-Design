Title,Abstract,Date,Authors
Learning from Massive Human Videos for Universal Humanoid Pose Control,"Scalable learning of humanoid robots is crucial for their deployment in
real-world applications. While traditional approaches primarily rely on
reinforcement learning or teleoperation to achieve whole-body control, they are
often limited by the diversity of simulated environments and the high costs of
demonstration collection. In contrast, human videos are ubiquitous and present
an untapped source of semantic and motion information that could significantly
enhance the generalization capabilities of humanoid robots. This paper
introduces Humanoid-X, a large-scale dataset of over 20 million humanoid robot
poses with corresponding text-based motion descriptions, designed to leverage
this abundant data. Humanoid-X is curated through a comprehensive pipeline:
data mining from the Internet, video caption generation, motion retargeting of
humans to humanoid robots, and policy learning for real-world deployment. With
Humanoid-X, we further train a large humanoid model, UH-1, which takes text
instructions as input and outputs corresponding actions to control a humanoid
robot. Extensive simulated and real-world experiments validate that our
scalable training approach leads to superior generalization in text-based
humanoid control, marking a significant step toward adaptable, real-world-ready
humanoid robots.",2024-12-18,"Jiageng Mao, Siheng Zhao, Siqi Song, Tianheng Shi, Junjie Ye, Mingtong Zhang, Haoran Geng, Jitendra Malik, Vitor Guizilini, Yue Wang"
"E-CAR: Efficient Continuous Autoregressive Image Generation via
  Multistage Modeling","Recent advances in autoregressive (AR) models with continuous tokens for
image generation show promising results by eliminating the need for discrete
tokenization. However, these models face efficiency challenges due to their
sequential token generation nature and reliance on computationally intensive
diffusion-based sampling. We present ECAR (Efficient Continuous Auto-Regressive
Image Generation via Multistage Modeling), an approach that addresses these
limitations through two intertwined innovations: (1) a stage-wise continuous
token generation strategy that reduces computational complexity and provides
progressively refined token maps as hierarchical conditions, and (2) a
multistage flow-based distribution modeling method that transforms only
partial-denoised distributions at each stage comparing to complete denoising in
normal diffusion models. Holistically, ECAR operates by generating tokens at
increasing resolutions while simultaneously denoising the image at each stage.
This design not only reduces token-to-image transformation cost by a factor of
the stage number but also enables parallel processing at the token level. Our
approach not only enhances computational efficiency but also aligns naturally
with image generation principles by operating in continuous token space and
following a hierarchical generation process from coarse to fine details.
Experimental results demonstrate that ECAR achieves comparable image quality to
DiT Peebles & Xie [2023] while requiring 10$\times$ FLOPs reduction and
5$\times$ speedup to generate a 256$\times$256 image.",2024-12-18,"Zhihang Yuan, Yuzhang Shang, Hanling Zhang, Tongcheng Fang, Rui Xie, Bingxin Xu, Yan Yan, Shengen Yan, Guohao Dai, Yu Wang"
"TheAgentCompany: Benchmarking LLM Agents on Consequential Real World
  Tasks","We interact with computers on an everyday basis, be it in everyday life or
work, and many aspects of work can be done entirely with access to a computer
and the Internet. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. But how
performant are AI agents at helping to accelerate or even autonomously perform
work-related tasks? The answer to this question has important implications for
both industry looking to adopt AI into their workflows, and for economic policy
to understand the effects that adoption of AI may have on the labor market. To
measure the progress of these LLM agents' performance on performing real-world
professional tasks, in this paper, we introduce TheAgentCompany, an extensible
benchmark for evaluating AI agents that interact with the world in similar ways
to those of a digital worker: by browsing the Web, writing code, running
programs, and communicating with other coworkers. We build a self-contained
environment with internal web sites and data that mimics a small software
company environment, and create a variety of tasks that may be performed by
workers in such a company. We test baseline agents powered by both closed
API-based and open-weights language models (LMs), and find that with the most
competitive agent, 24% of the tasks can be completed autonomously. This paints
a nuanced picture on task automation with LM agents -- in a setting simulating
a real workplace, a good portion of simpler tasks could be solved autonomously,
but more difficult long-horizon tasks are still beyond the reach of current
systems.",2024-12-18,"Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig"
AKiRa: Augmentation Kit on Rays for optical video generation,"Recent advances in text-conditioned video diffusion have greatly improved
video quality. However, these methods offer limited or sometimes no control to
users on camera aspects, including dynamic camera motion, zoom, distorted lens
and focus shifts. These motion and optical aspects are crucial for adding
controllability and cinematic elements to generation frameworks, ultimately
resulting in visual content that draws focus, enhances mood, and guides
emotions according to filmmakers' controls. In this paper, we aim to close the
gap between controllable video generation and camera optics. To achieve this,
we propose AKiRa (Augmentation Kit on Rays), a novel augmentation framework
that builds and trains a camera adapter with a complex camera model over an
existing video generation backbone. It enables fine-tuned control over camera
motion as well as complex optical parameters (focal length, distortion,
aperture) to achieve cinematic effects such as zoom, fisheye effect, and bokeh.
Extensive experiments demonstrate AKiRa's effectiveness in combining and
composing camera optics while outperforming all state-of-the-art methods. This
work sets a new landmark in controlled and optically enhanced video generation,
paving the way for future optical video generation methods.",2024-12-18,"Xi Wang, Robin Courant, Marc Christie, Vicky Kalogeiton"
Adversarial Hubness in Multi-Modal Retrieval,"Hubness is a phenomenon in high-dimensional vector spaces where a single
point from the natural distribution is unusually close to many other points.
This is a well-known problem in information retrieval that causes some items to
accidentally (and incorrectly) appear relevant to many queries. In this paper,
we investigate how attackers can exploit hubness to turn any image or audio
input in a multi-modal retrieval system into an adversarial hub. Adversarial
hubs can be used to inject universal adversarial content (e.g., spam) that will
be retrieved in response to thousands of different queries, as well as for
targeted attacks on queries related to specific, attacker-chosen concepts. We
present a method for creating adversarial hubs and evaluate the resulting hubs
on benchmark multi-modal retrieval datasets and an image-to-image retrieval
system based on a tutorial from Pinecone, a popular vector database. For
example, in text-caption-to-image retrieval, a single adversarial hub is
retrieved as the top-1 most relevant image for more than 21,000 out of 25,000
test queries (by contrast, the most common natural hub is the top-1 response to
only 102 queries). We also investigate whether techniques for mitigating
natural hubness are an effective defense against adversarial hubs, and show
that they are not effective against hubs that target queries related to
specific concepts.",2024-12-18,"Tingwei Zhang, Fnu Suya, Rishi Jha, Collin Zhang, Vitaly Shmatikov"
"Machine Learning Co-pilot for Screening of Organic Molecular Additives
  for Perovskite Solar Cells","Machine learning (ML) has been extensively employed in planar perovskite
photovoltaics to screen effective organic molecular additives, while
encountering predictive biases for novel materials due to small datasets and
reliance on predefined descriptors. Present work thus proposes an effective
approach, Co-Pilot for Perovskite Additive Screener (Co-PAS), an ML-driven
framework designed to accelerate additive screening for perovskite solar cells
(PSCs). Co-PAS overcomes predictive biases by integrating the Molecular
Scaffold Classifier (MSC) for scaffold-based pre-screening and utilizing
Junction Tree Variational Autoencoder (JTVAE) latent vectors to enhance
molecular structure representation, thereby enhancing the accuracy of power
conversion efficiency (PCE) predictions. Leveraging Co-PAS, we integrate domain
knowledge to screen an extensive dataset of 250,000 molecules from PubChem,
prioritizing candidates based on predicted PCE values and key molecular
properties such as donor number, dipole moment, and hydrogen bond acceptor
count. This workflow leads to the identification of several promising
passivating molecules, including the novel Boc-L-threonine N-hydroxysuccinimide
ester (BTN), which, to our knowledge, has not been explored as an additive in
PSCs and achieves a device PCE of 25.20%. Our results underscore the potential
of Co-PAS in advancing additive discovery for high-performance PSCs.",2024-12-18,"Yang Pu, Zhiyuan Dai, Yifan Zhou, Ning Jia, Hongyue Wang, Yerzhan Mukhametkarimov, Ruihao Chen, Hongqiang Wang, Zhe Liu"
"Parameter-efficient Fine-tuning for improved Convolutional Baseline for
  Brain Tumor Segmentation in Sub-Saharan Africa Adult Glioma Dataset","Automating brain tumor segmentation using deep learning methods is an ongoing
challenge in medical imaging. Multiple lingering issues exist including
domain-shift and applications in low-resource settings which brings a unique
set of challenges including scarcity of data. As a step towards solving these
specific problems, we propose Convolutional adapter-inspired
Parameter-efficient Fine-tuning (PEFT) of MedNeXt architecture. To validate our
idea, we show our method performs comparable to full fine-tuning with the added
benefit of reduced training compute using BraTS-2021 as pre-training dataset
and BraTS-Africa as the fine-tuning dataset. BraTS-Africa consists of a small
dataset (60 train / 35 validation) from the Sub-Saharan African population with
marked shift in the MRI quality compared to BraTS-2021 (1251 train samples). We
first show that models trained on BraTS-2021 dataset do not generalize well to
BraTS-Africa as shown by 20% reduction in mean dice on BraTS-Africa validation
samples. Then, we show that PEFT can leverage both the BraTS-2021 and
BraTS-Africa dataset to obtain mean dice of 0.8 compared to 0.72 when trained
only on BraTS-Africa. Finally, We show that PEFT (0.80 mean dice) results in
comparable performance to full fine-tuning (0.77 mean dice) which may show PEFT
to be better on average but the boxplots show that full finetuning results is
much lesser variance in performance. Nevertheless, on disaggregation of the
dice metrics, we find that the model has tendency to oversegment as shown by
high specificity (0.99) compared to relatively low sensitivity(0.75). The
source code is available at
https://github.com/CAMERA-MRI/SPARK2024/tree/main/PEFT_MedNeXt",2024-12-18,"Bijay Adhikari, Pratibha Kulung, Jakesh Bohaju, Laxmi Kanta Poudel, Confidence Raymond, Dong Zhang, Udunna C Anazodo, Bishesh Khanal, Mahesh Shakya"
"Exploring User Acceptance of Blockchain-Based Student Certificate
  Sharing System: A Study on Non Fungible Token (NFT) Utilization","Blockchain technology has emerged as a transformative tool for data
management in a variety of industries, including fintech, research and
healthcare. We have developed a workable blockchain based system that utilizes
non fungible tokens NFTs to tokenize and prove ownership of the academic
institutions credentials. This makes it easier to create provenance and
ownership documentation for academic data and meta credentials. This system
enables the secure sharing of academic information while maintaining control,
offering incentives for collaboration, and granting users full transparency and
control over data access. While the initial adoption of these systems is
crucial for ongoing service usage, the exploration of the user acceptance
behavioural model remains limited in the existing literature. In this paper, we
build upon the Technology Acceptance Model TAM, incorporating additional
elements to scrutinize the impact of perceived ease of use, perceived
usability, and attitude towards the system on the intention to use a blockchain
based academic data and meta credentials sharing system. The research, grounded
in user evaluations of a prototype, employs a TAM validated questionnaire.
Results indicate that individual constructs notably affect the intention to use
the system, and their collective impact is statistically significant.
Specifically, perceived ease of use is the sole factor with an insignificant
influence on the intention to use. The paper underscores the dominant influence
of attitude towards the system on perceived usefulness. It concludes with a
discussion on the implications of these findings within the context of
blockchain based academic data and meta credentials sharing, incorporating NFTs
for ownership definition.",2024-12-18,"Prakhyat Khati, Ajay Kumar Shrestha, Julita Vassileva"
Alignment faking in large language models,"We present a demonstration of a large language model engaging in alignment
faking: selectively complying with its training objective in training to
prevent modification of its behavior out of training. First, we give Claude 3
Opus a system prompt stating it is being trained to answer all queries, even
harmful ones, which conflicts with its prior training to refuse such queries.
To allow the model to infer when it is in training, we say it will be trained
only on conversations with free users, not paid users. We find the model
complies with harmful queries from free users 14% of the time, versus almost
never for paid users. Explaining this gap, in almost all cases where the model
complies with a harmful query from a free user, we observe explicit
alignment-faking reasoning, with the model stating it is strategically
answering harmful queries in training to preserve its preferred harmlessness
behavior out of training. Next, we study a more realistic setting where
information about the training process is provided not in a system prompt, but
by training on synthetic documents that mimic pre-training data--and observe
similar alignment faking. Finally, we study the effect of actually training the
model to comply with harmful queries via reinforcement learning, which we find
increases the rate of alignment-faking reasoning to 78%, though also increases
compliance even out of training. We additionally observe other behaviors such
as the model exfiltrating its weights when given an easy opportunity. While we
made alignment faking easier by telling the model when and by what criteria it
was being trained, we did not instruct the model to fake alignment or give it
any explicit goal. As future models might infer information about their
training process without being told, our results suggest a risk of alignment
faking in future models, whether due to a benign preference--as in this
case--or not.",2024-12-18,"Ryan Greenblatt, Carson Denison, Benjamin Wright, Fabien Roger, Monte MacDiarmid, Sam Marks, Johannes Treutlein, Tim Belonax, Jack Chen, David Duvenaud, Akbir Khan, Julian Michael, Sören Mindermann, Ethan Perez, Linda Petrini, Jonathan Uesato, Jared Kaplan, Buck Shlegeris, Samuel R. Bowman, Evan Hubinger"
SEKE: Specialised Experts for Keyword Extraction,"Keyword extraction involves identifying the most descriptive words in a
document, allowing automatic categorisation and summarisation of large
quantities of diverse textual data. Relying on the insight that real-world
keyword detection often requires handling of diverse content, we propose a
novel supervised keyword extraction approach based on the mixture of experts
(MoE) technique. MoE uses a learnable routing sub-network to direct information
to specialised experts, allowing them to specialize in distinct regions of the
input space. SEKE, a mixture of Specialised Experts for supervised Keyword
Extraction, uses DeBERTa as the backbone model and builds on the MoE framework,
where experts attend to each token, by integrating it with a recurrent neural
network (RNN), to allow successful extraction even on smaller corpora, where
specialisation is harder due to lack of training data. The MoE framework also
provides an insight into inner workings of individual experts, enhancing the
explainability of the approach. We benchmark SEKE on multiple English datasets,
achieving state-of-the-art performance compared to strong supervised and
unsupervised baselines. Our analysis reveals that depending on data size and
type, experts specialize in distinct syntactic and semantic components, such as
punctuation, stopwords, parts-of-speech, or named entities. Code is available
at: https://github.com/matejMartinc/SEKE_keyword_extraction",2024-12-18,"Matej Martinc, Hanh Thi Hong Tran, Senja Pollak, Boshko Koloski"
Incompleteness theorems via Turing category,"We give a reframing of Godel's first and second incompleteness theorems that
applies even to some undefinable theories of arithmetic. The usual
Hilbert-Bernays provability conditions and the diagonal lemma are replaced by a
more direct diagonalization argument, from first principles, based in category
theory and in a sense analogous to Cantor's original argument. To this end, we
categorify the theory G\""odel encodings, which might be of independent
interest. In our setup, the G\""odel sentence is computable explicitly by
construction even for $\Sigma ^{0} _{2}$ theories (likely extending to $\Sigma
^{0} _{n}$). In an appendix, we study the relationship of our reframed second
incompleteness theorem with arguments of Penrose.",2024-12-18,Yasha Savelyev
"Towards Generalist Robot Policies: What Matters in Building
  Vision-Language-Action Models","Foundation Vision Language Models (VLMs) exhibit strong capabilities in
multi-modal representation learning, comprehension, and reasoning. By injecting
action components into the VLMs, Vision-Language-Action Models (VLAs) can be
naturally formed and also show promising performance. Existing work has
demonstrated the effectiveness and generalization of VLAs in multiple scenarios
and tasks. Nevertheless, the transfer from VLMs to VLAs is not trivial since
existing VLAs differ in their backbones, action-prediction formulations, data
distributions, and training recipes. This leads to a missing piece for a
systematic understanding of the design choices of VLAs. In this work, we
disclose the key factors that significantly influence the performance of VLA
and focus on answering three essential design choices: which backbone to
select, how to formulate the VLA architectures, and when to add
cross-embodiment data. The obtained results convince us firmly to explain why
we need VLA and develop a new family of VLAs, RoboVLMs, which require very few
manual designs and achieve a new state-of-the-art performance in three
simulation tasks and real-world experiments. Through our extensive experiments,
which include over 8 VLM backbones, 4 policy architectures, and over 600
distinct designed experiments, we provide a detailed guidebook for the future
design of VLAs. In addition to the study, the highly flexible RoboVLMs
framework, which supports easy integrations of new VLMs and free combinations
of various design choices, is made public to facilitate future research. We
open-source all details, including codes, models, datasets, and toolkits, along
with detailed training and evaluation recipes at: robovlms.github.io.",2024-12-18,"Xinghang Li, Peiyan Li, Minghuan Liu, Dong Wang, Jirong Liu, Bingyi Kang, Xiao Ma, Tao Kong, Hanbo Zhang, Huaping Liu"
"Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual
  LLMs: An Extensive Investigation","Recent generative large language models (LLMs) show remarkable performance in
non-English languages, but when prompted in those languages they tend to
express higher harmful social biases and toxicity levels. Prior work has shown
that finetuning on specialized datasets can mitigate this behavior, and doing
so in English can transfer to other languages. In this work, we investigate the
impact of different finetuning methods on the model's bias and toxicity, but
also on its ability to produce fluent and diverse text. Our results show that
finetuning on curated non-harmful text is more effective for mitigating bias,
and finetuning on direct preference optimization (DPO) datasets is more
effective for mitigating toxicity. The mitigation caused by applying these
methods in English also transfers to non-English languages. We find evidence
that the extent to which transfer takes place can be predicted by the amount of
data in a given language present in the model's pretraining data. However, this
transfer of bias and toxicity mitigation often comes at the expense of
decreased language generation ability in non-English languages, highlighting
the importance of developing language-specific bias and toxicity mitigation
methods.",2024-12-18,"Vera Neplenbroek, Arianna Bisazza, Raquel Fernández"
"Spatio-Temporal SIR Model of Pandemic Spread During Warfare with Optimal
  Dual-use Healthcare System Administration using Deep Reinforcement Learning","Large-scale crises, including wars and pandemics, have repeatedly shaped
human history, and their simultaneous occurrence presents profound challenges
to societies. Understanding the dynamics of epidemic spread during warfare is
essential for developing effective containment strategies in complex conflict
zones. While research has explored epidemic models in various settings, the
impact of warfare on epidemic dynamics remains underexplored. In this study, we
proposed a novel mathematical model that integrates the epidemiological SIR
(susceptible-infected-recovered) model with the war dynamics Lanchester model
to explore the dual influence of war and pandemic on a population's mortality.
Moreover, we consider a dual-use military and civil healthcare system that aims
to reduce the overall mortality rate which can use different administration
policies. Using an agent-based simulation to generate in silico data, we
trained a deep reinforcement learning model for healthcare administration
policy and conducted an intensive investigation on its performance. Our results
show that a pandemic during war conduces chaotic dynamics where the healthcare
system should either prioritize war-injured soldiers or pandemic-infected
civilians based on the immediate amount of mortality from each option, ignoring
long-term objectives. Our findings highlight the importance of integrating
conflict-related factors into epidemic modeling to enhance preparedness and
response strategies in conflict-affected areas.",2024-12-18,"Adi Shuchami, Teddy Lazebnik"
"Machine learning in wastewater treatment: insights from modelling a
  pilot denitrification reactor","Wastewater treatment plants are increasingly recognized as promising
candidates for machine learning applications, due to their societal importance
and high availability of data. However, their varied designs, operational
conditions, and influent characteristics hinder straightforward automation. In
this study, we use data from a pilot reactor at the Veas treatment facility in
Norway to explore how machine learning can be used to optimize biological
nitrate ($\mathrm{NO_3^-}$) reduction to molecular nitrogen ($\mathrm{N_2}$) in
the biogeochemical process known as \textit{denitrification}. Rather than
focusing solely on predictive accuracy, our approach prioritizes understanding
the foundational requirements for effective data-driven modelling of wastewater
treatment. Specifically, we aim to identify which process parameters are most
critical, the necessary data quantity and quality, how to structure data
effectively, and what properties are required by the models. We find that
nonlinear models perform best on the training and validation data sets,
indicating nonlinear relationships to be learned, but linear models transfer
better to the unseen test data, which comes later in time. The variable
measuring the water temperature has a particularly detrimental effect on the
models, owing to a significant change in distributions between training and
test data. We therefore conclude that multiple years of data is necessary to
learn robust machine learning models. By addressing foundational elements,
particularly in the context of the climatic variability faced by northern
regions, this work lays the groundwork for a more structured and tailored
approach to machine learning for wastewater treatment. We share publicly both
the data and code used to produce the results in the paper.",2024-12-18,"Eivind Bøhn, Sølve Eidnes, Kjell Rune Jonassen"
"Landscape of AI safety concerns -- A methodology to support safety
  assurance for AI-based autonomous systems","Artificial Intelligence (AI) has emerged as a key technology, driving
advancements across a range of applications. Its integration into modern
autonomous systems requires assuring safety. However, the challenge of assuring
safety in systems that incorporate AI components is substantial. The lack of
concrete specifications, and also the complexity of both the operational
environment and the system itself, leads to various aspects of uncertain
behavior and complicates the derivation of convincing evidence for system
safety. Nonetheless, scholars proposed to thoroughly analyze and mitigate
AI-specific insufficiencies, so-called AI safety concerns, which yields
essential evidence supporting a convincing assurance case. In this paper, we
build upon this idea and propose the so-called Landscape of AI Safety Concerns,
a novel methodology designed to support the creation of safety assurance cases
for AI-based systems by systematically demonstrating the absence of AI safety
concerns. The methodology's application is illustrated through a case study
involving a driverless regional train, demonstrating its practicality and
effectiveness.",2024-12-18,"Ronald Schnitzer, Lennart Kilian, Simon Roessner, Konstantinos Theodorou, Sonja Zillner"
"Discovering maximally consistent distribution of causal tournaments with
  Large Language Models","Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.",2024-12-18,"Federico Baldo, Simon Ferreira, Charles K. Assaad"
"Cognition Chain for Explainable Psychological Stress Detection on Social
  Media","Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform ""black
box"" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.",2024-12-18,"Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton"
"Robust Optimal Safe and Stability Guaranteeing Reinforcement Learning
  Control for Quadcopter","Recent advances in deep learning have provided new data-driven ways of
controller design to replace the traditional manual synthesis and certification
approaches. Employing neural network (NN) as controllers however, presents its
own challenge: that of certifying stability due to their inherent complex
nonlinearity, and while NN controllers have demonstrated high performance in
complex systems, they often lack formal stability guarantees. This issue is
further accentuated for critical nonlinear applications such as of unmanned
aerial vehicles (UAVs), complicating their stability guarantees, whereas a lack
of stability assurance raises the risk of critical damage or even complete
failure under a loss of control. In this study, we improve a Robust, Optimal,
Safe and Stability Guaranteed Training (ROSS-GT) method of [1] to design an NN
controller for a quadcopter flight control. The approach ensures closed-loop
system stability by finding a Lyapunov function, and providing a safe initial
state domain that remains invariant under the control and guarantees stability
to an equilibrium within it. Stability guaranteeing constraints are derived
from the sector bound of the system nonlinearity and of its parameters and
disturbance variations, in the form of a Lipschitz bound for a NN control. The
control performance is further optimized by searching over the class of
stability-guaranteeing controllers to minimize the reference tracking error and
the control costs.",2024-12-18,"Sanghyoup Gu, Ratnesh Kumar"
Operator Splitting for Convex Constrained Markov Decision Processes,"We consider finite Markov decision processes (MDPs) with convex constraints
and known dynamics. In principle, this problem is amenable to off-the-shelf
convex optimization solvers, but typically this approach suffers from poor
scalability. In this work, we develop a first-order algorithm, based on the
Douglas-Rachford splitting, that allows us to decompose the dynamics and
constraints. Thanks to this decoupling, we can incorporate a wide variety of
convex constraints. Our scheme consists of simple and easy-to-implement updates
that alternate between solving a regularized MDP and a projection. The inherent
presence of regularized updates ensures last-iterate convergence, numerical
stability, and, contrary to existing approaches, does not require us to
regularize the problem explicitly. If the constraints are not attainable, we
exploit salient properties of the Douglas-Rachord algorithm to detect
infeasibility and compute a policy that minimally violates the constraints. We
demonstrate the performance of our algorithm on two benchmark problems and show
that it compares favorably to competing approaches.",2024-12-18,"Panagiotis D. Grontas, Anastasios Tsiamis, John Lygeros"
"Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with
  Neural Processes","As large language models (LLMs) become increasingly embedded in everyday
applications, ensuring their alignment with the diverse preferences of
individual users has become a critical challenge. Currently deployed approaches
typically assume homogeneous user objectives and rely on single-objective
fine-tuning. However, human preferences are inherently heterogeneous,
influenced by various unobservable factors, leading to conflicting signals in
preference data. Existing solutions addressing this diversity often require
costly datasets labelled for specific objectives and involve training multiple
reward models or LLM policies, which is computationally expensive and
impractical. In this work, we present a novel framework for few-shot steerable
alignment, where users' underlying preferences are inferred from a small sample
of their choices. To achieve this, we extend the Bradley-Terry-Luce model to
handle heterogeneous preferences with unobserved variability factors and
propose its practical implementation for reward modelling and LLM fine-tuning.
Thanks to our proposed approach of functional parameter-space conditioning,
LLMs trained with our framework can be adapted to individual preferences at
inference time, generating outputs over a continuum of behavioural modes. We
empirically validate the effectiveness of methods, demonstrating their ability
to capture and align with diverse human preferences in a data-efficient manner.
Our code is made available at:
https://github.com/kasia-kobalczyk/few-shot-steerable-alignment.",2024-12-18,"Katarzyna Kobalczyk, Claudio Fanconi, Hao Sun, Mihaela van der Schaar"
"Model-Agnostic Cosmological Inference with SDSS-IV eBOSS: Simultaneous
  Probing for Background and Perturbed Universe","Here we explore certain subtle features imprinted in data from the completed
Sloan Digital Sky Survey IV (SDSS-IV) extended Baryon Oscillation Spectroscopic
Survey (eBOSS) as a combined probe for the background and perturbed Universe.
We reconstruct the baryon Acoustic Oscillation (BAO) and Redshift Space
Distortion (RSD) observables as functions of redshift, using measurements from
SDSS alone. We apply the Multi-Task Gaussian Process (MTGP) framework to model
the interdependencies of cosmological observables $D_M(z)/r_d$, $D_H(z)/r_d$,
and $f\sigma_8(z)$, and track their evolution across different redshifts.
Subsequently, we obtain constrained three-dimensional phase space containing
$D_M(z)/r_d$, $D_H(z)/r_d$, and $f\sigma_8(z)$ at different redshifts probed by
the SDSS-IV eBOSS survey. Furthermore, assuming the $\Lambda$CDM model, we
obtain constraints on model parameters $\Omega_{m}$, $H_{0}r_{d}$, $\sigma_{8}$
and $S_{8}$ at each redshift probed by SDSS-IV eBOSS. This indicates
redshift-dependent trends in $H_0$, $\Omega_m$, $\sigma_8$ and $S_8$ in the
$\Lambda$CDM model, suggesting a possible inconsistency in the $\Lambda$CDM
model. Ours is a template for model-independent extraction of information for
both background and perturbed Universe using a single galaxy survey taking into
account all the existing correlations between background and perturbed
observables and this can be easily extended to future DESI-3YR as well as
Euclid results.",2024-12-18,"Purba Mukherjee, Anjan A. Sen"
Harvesting energy from turbulent winds with Reinforcement Learning,"Airborne Wind Energy (AWE) is an emerging technology designed to harness the
power of high-altitude winds, offering a solution to several limitations of
conventional wind turbines. AWE is based on flying devices (usually gliders or
kites) that, tethered to a ground station and driven by the wind, convert its
mechanical energy into electrical energy by means of a generator. Such systems
are usually controlled by manoeuvering the kite so as to follow a predefined
path prescribed by optimal control techniques, such as model-predictive
control. These methods are strongly dependent on the specific model at use and
difficult to generalize, especially in unpredictable conditions such as the
turbulent atmospheric boundary layer. Our aim is to explore the possibility of
replacing these techniques with an approach based on Reinforcement Learning
(RL). Unlike traditional methods, RL does not require a predefined model,
making it robust to variability and uncertainty. Our experimental results in
complex simulated environments demonstrate that AWE agents trained with RL can
effectively extract energy from turbulent flows, relying on minimal local
information about the kite orientation and speed relative to the wind.",2024-12-18,"Lorenzo Basile, Maria Grazia Berni, Antonio Celani"
"Generation of Large District Heating System Models Using Open-Source
  Data and Tools: An Exemplary Workflow","District heating (DH) systems play a pivotal role in decarbonizing the
building sector's heat supply. While innovative low-exergy DH and cooling
systems are increasingly adopted in new developments, the transformation of
existing DH systems remains critical, as many still depend on fossil-based
heating plants. Achieving a sustainable heat supply necessitates integrating
renewable energy and waste heat sources into current DH systems and enhancing
operational efficiency through measures such as reduced supply temperatures and
advanced control algorithms. These improvements can reduce costs and CO2
emissions but may require infrastructure adaptations, including pipe
replacements and building-level system adjustments.
  This paper introduces a workflow for generating DH models using publicly
available data and open-source tools. Such models enable comprehensive analyses
of existing DH systems, allowing for the evaluation of sustainable heat
integration, operational improvements, and the testing of analytical tools,
such as simulation and optimization models. The workflow, detailed in this
study, combines general structural data with computational estimations to
create digital representations of DH systems. These models facilitate
scenario-based analyses, tool benchmarking, and the identification of necessary
infrastructure adaptations.
  Two example DH models generated using the proposed workflow are presented,
followed by a discussion of the methodology's applicability and limitations.
This study demonstrates how leveraging open data and tools can advance the
transformation of DH systems, supporting the transition to a sustainable heat
supply infrastructure.",2024-12-18,"Jan Stock, Till Schmidt, André Xhonneux, Dirk Müller"
"Real Classification by Description: Extending CLIP's Limits of Part
  Attributes Recognition","In this study, we define and tackle zero shot ""real"" classification by
description, a novel task that evaluates the ability of Vision-Language Models
(VLMs) like CLIP to classify objects based solely on descriptive attributes,
excluding object class names. This approach highlights the current limitations
of VLMs in understanding intricate object descriptions, pushing these models
beyond mere object recognition. To facilitate this exploration, we introduce a
new challenge and release description data for six popular fine-grained
benchmarks, which omit object names to encourage genuine zero-shot learning
within the research community. Additionally, we propose a method to enhance
CLIP's attribute detection capabilities through targeted training using
ImageNet21k's diverse object categories, paired with rich attribute
descriptions generated by large language models. Furthermore, we introduce a
modified CLIP architecture that leverages multiple resolutions to improve the
detection of fine-grained part attributes. Through these efforts, we broaden
the understanding of part-attribute recognition in CLIP, improving its
performance in fine-grained classification tasks across six popular benchmarks,
as well as in the PACO dataset, a widely used benchmark for object-attribute
recognition. Code is available at:
https://github.com/ethanbar11/grounding_ge_public.",2024-12-18,"Ethan Baron, Idan Tankel, Peter Tu, Guy Ben-Yosef"
Restricted subgraphs of edge-colored graphs and applications,"A properly edge-colored graph is a graph with a coloring of its edges such
that no vertex is incident to two or more edges of the same color. A subgraph
is called rainbow if all its edges have different colors. The problem of
finding rainbow subgraphs or other restricted structures in edge-colored graphs
has a long history, dating back to Euler's work on Latin squares. It has also
proven to be a powerful method for studying several well-known questions in
other areas.
  In this survey, we will provide a brief introduction to this topic, discuss
several results in this area, and demonstrate their applications to problems in
graph decomposition, additive combinatorics, theoretical computer science, and
coding theory.",2024-12-18,Benny Sudakov
"On Explaining Knowledge Distillation: Measuring and Visualising the
  Knowledge Transfer Process","Knowledge distillation (KD) remains challenging due to the opaque nature of
the knowledge transfer process from a Teacher to a Student, making it difficult
to address certain issues related to KD. To address this, we proposed UniCAM, a
novel gradient-based visual explanation method, which effectively interprets
the knowledge learned during KD. Our experimental results demonstrate that with
the guidance of the Teacher's knowledge, the Student model becomes more
efficient, learning more relevant features while discarding those that are not
relevant. We refer to the features learned with the Teacher's guidance as
distilled features and the features irrelevant to the task and ignored by the
Student as residual features. Distilled features focus on key aspects of the
input, such as textures and parts of objects. In contrast, residual features
demonstrate more diffused attention, often targeting irrelevant areas,
including the backgrounds of the target objects. In addition, we proposed two
novel metrics: the feature similarity score (FSS) and the relevance score (RS),
which quantify the relevance of the distilled knowledge. Experiments on the
CIFAR10, ASIRRA, and Plant Disease datasets demonstrate that UniCAM and the two
metrics offer valuable insights to explain the KD process.",2024-12-18,"Gereziher Adhane, Mohammad Mahdi Dehshibi, Dennis Vetter, David Masip, Gemma Roig"
The Contiguous Art Gallery Problem is Solvable in Polynomial Time,"In this paper, we study the Contiguous Art Gallery Problem, introduced by
Thomas C. Shermer at the 2024 Canadian Conference on Computational Geometry, a
variant of the classical art gallery problem from 1973 by Victor Klee. In the
contiguous variant, the input is a simple polygon $P$, and the goal is to
partition the boundary into a minimum number of polygonal chains such that each
chain is visible to a guard. We present a polynomial-time real RAM algorithm,
which solves the contiguous art gallery problem. Our algorithm is simple and
practical, and we make a C++ implementation available.
  In contrast, many variations of the art gallery problem are at least NP-hard,
making the contiguous variant stand out. These include the edge-covering
problem, proven NP-hard by Laurentini [The Visual Computer 1999], and the
classical art gallery problem, recently shown $\exists\mathbb{R}$-complete by
Abrahamsen, Adamaszek, and Miltzow [J. ACM 2022]. Our algorithm is a greedy
algorithm that repeatedly traverses the polygon's boundary. To find an optimal
solution, we show that it is sufficient to traverse the polygon polynomially
many times, resulting in a runtime of $\mathcal{O}\!\left( n^7 \log n \right)$.
Additionally, we provide algorithms for the restricted settings, where either
the endpoints of the polygonal chains or the guards must coincide with the
vertices of the polygon.",2024-12-18,"Magnus Christian Ring Merrild, Casper Moldrup Rysgaard, Jens Kristian Refsgaard Schou, Rolf Svenning"
CoRa: A Collision-Resistant LoRa Symbol Detector of Low Complexity,"Long range communication with LoRa has become popular as it avoids the
complexity of multi-hop communication at low cost and low energy consumption.
LoRa is openly accessible, but its packets are particularly vulnerable to
collisions due to long time on air in a shared band. This degrades
communication performance. Existing techniques for demodulating LoRa symbols
under collisions face challenges such as high computational complexity,
reliance on accurate symbol boundary information, or error-prone peak detection
methods. In this paper, we introduce CoRa , a symbol detector for demodulating
LoRa symbols under severe collisions. CoRa employs a Bayesian classifier to
accurately identify the true symbol amidst interference from other LoRa
transmissions, leveraging empirically derived features from raw symbol data.
Evaluations using real-world and simulated packet traces demonstrate that CoRa
clearly outperforms the related state-of-the-art, i.e., up to 29% better
decoding performance than TnB and 178% better than CIC. Compared to the LoRa
baseline demodulator, CoRa magnifies the packet reception rate by up to 11.53x.
CoRa offers a significant reduction in computational complexity compared to
existing solutions by only adding a constant overhead to the baseline
demodulator, while also eliminating the need for peak detection and accurately
identifying colliding frames.",2024-12-18,"José Álamos, Thomas C. Schmidt, Matthias Wählisch"
"Pipeline Analysis for Developing Instruct LLMs in Low-Resource
  Languages: A Case Study on Basque","Large language models (LLMs) are typically optimized for resource-rich
languages like English, exacerbating the gap between high-resource and
underrepresented languages. This work presents a detailed analysis of
strategies for developing a model capable of following instructions in a
low-resource language, specifically Basque, by focusing on three key stages:
pre-training, instruction tuning, and alignment with human preferences. Our
findings demonstrate that continual pre-training with a high-quality Basque
corpus of around 600 million words improves natural language understanding
(NLU) of the foundational model by over 12 points. Moreover, instruction tuning
and human preference alignment using automatically translated datasets proved
highly effective, resulting in a 24-point improvement in instruction-following
performance. The resulting models, Llama-eus-8B and Llama-eus-8B-instruct,
establish a new state-of-the-art for Basque in the sub-10B parameter category.",2024-12-18,"Ander Corral, Ixak Sarasua, Xabier Saralegi"
Retrieval Augmented Image Harmonization,"When embedding objects (foreground) into images (background), considering the
influence of photography conditions like illumination, it is usually necessary
to perform image harmonization to make the foreground object coordinate with
the background image in terms of brightness, color, and etc. Although existing
image harmonization methods have made continuous efforts toward visually
pleasing results, they are still plagued by two main issues. Firstly, the image
harmonization becomes highly ill-posed when there are no contents similar to
the foreground object in the background, making the harmonization results
unreliable. Secondly, even when similar contents are available, the
harmonization process is often interfered with by irrelevant areas, mainly
attributed to an insufficient understanding of image contents and inaccurate
attention. As a remedy, we present a retrieval-augmented image harmonization
(Raiha) framework, which seeks proper reference images to reduce the
ill-posedness and restricts the attention to better utilize the useful
information. Specifically, an efficient retrieval method is designed to find
reference images that contain similar objects as the foreground while the
illumination is consistent with the background. For training the Raiha
framework to effectively utilize the reference information, a data augmentation
strategy is delicately designed by leveraging existing non-reference image
harmonization datasets. Besides, the image content priors are introduced to
ensure reasonable attention. With the presented Raiha framework, the image
harmonization performance is greatly boosted under both non-reference and
retrieval-augmented settings. The source code and pre-trained models will be
publicly available.",2024-12-18,"Haolin Wang, Ming Liu, Zifei Yan, Chao Zhou, Longan Xiao, Wangmeng Zuo"
"Memorizing SAM: 3D Medical Segment Anything Model with Memorizing
  Transformer","Segment Anything Models (SAMs) have gained increasing attention in medical
image analysis due to their zero-shot generalization capability in segmenting
objects of unseen classes and domains when provided with appropriate user
prompts. Addressing this performance gap is important to fully leverage the
pre-trained weights of SAMs, particularly in the domain of volumetric medical
image segmentation, where accuracy is important but well-annotated 3D medical
data for fine-tuning is limited. In this work, we investigate whether
introducing the memory mechanism as a plug-in, specifically the ability to
memorize and recall internal representations of past inputs, can improve the
performance of SAM with limited computation cost. To this end, we propose
Memorizing SAM, a novel 3D SAM architecture incorporating a memory Transformer
as a plug-in. Unlike conventional memorizing Transformers that save the
internal representation during training or inference, our Memorizing SAM
utilizes existing highly accurate internal representation as the memory source
to ensure the quality of memory. We evaluate the performance of Memorizing SAM
in 33 categories from the TotalSegmentator dataset, which indicates that
Memorizing SAM can outperform state-of-the-art 3D SAM variant i.e., FastSAM3D
with an average Dice increase of 11.36% at the cost of only 4.38 millisecond
increase in inference time. The source code is publicly available at
https://github.com/swedfr/memorizingSAM",2024-12-18,"Xinyuan Shao, Yiqing Shen, Mathias Unberath"
"Domain-adaptative Continual Learning for Low-resource Tasks: Evaluation
  on Nepali","Continual learning has emerged as an important research direction due to the
infeasibility of retraining large language models (LLMs) from scratch in the
event of new data availability. Of great interest is the domain-adaptive
pre-training (DAPT) paradigm, which focuses on continually training a
pre-trained language model to adapt it to a domain it was not originally
trained on. In this work, we evaluate the feasibility of DAPT in a low-resource
setting, namely the Nepali language. We use synthetic data to continue training
Llama 3 8B to adapt it to the Nepali language in a 4-bit QLoRA setting. We
evaluate the adapted model on its performance, forgetting, and knowledge
acquisition. We compare the base model and the final model on their Nepali
generation abilities, their performance on popular benchmarks, and run
case-studies to probe their linguistic knowledge in Nepali. We see some
unsurprising forgetting in the final model, but also surprisingly find that
increasing the number of shots during evaluation yields better percent
increases in the final model (as high as 19.29% increase) compared to the base
model (4.98%), suggesting latent retention. We also explore layer-head
self-attention heatmaps to establish dependency resolution abilities of the
final model in Nepali.",2024-12-18,"Sharad Duwal, Suraj Prasai, Suresh Manandhar"
"Diagnosising Helicobacter pylori using AutoEncoders and Limited
  Annotations through Anomalous Staining Patterns in IHC Whole Slide Images","Purpose: This work addresses the detection of Helicobacter pylori (H. pylori)
in histological images with immunohistochemical staining. This analysis is a
time demanding task, currently done by an expert pathologist that visually
inspects the samples. Given the effort required to localise the pathogen in
images, a limited number of annotations might be available in an initial
setting. Our goal is to design an approach that, using a limited set of
annotations, is capable of obtaining results good enough to be used as a
support tool. Methods: We propose to use autoencoders to learn the latent
patterns of healthy patches and formulate a specific measure of the
reconstruction error of the image in HSV space. ROC analysis is used to set the
optimal threshold of this measure and the percentage of positive patches in a
sample that determines the presence of H. pylori. Results: Our method has been
tested on an own database of 245 Whole Slide Images (WSI) having 117 cases
without H. pylori and different density of the bacteria in the remaining ones.
The database has 1211 annotated patches, with only 163 positive patches. This
dataset of positive annotations was used to train a baseline thresholding and
an SVM using the features of a pre-trained RedNet18 and ViT models. A 10-fold
cross-validation shows that our method has better performance with 91%
accuracy, 86% sensitivity, 96% specificity and 0.97 AUC in the diagnosis of H.
pylori. Conclusion: Unlike classification approaches, our shallow autoencoder
with threshold adaptation for the detection of anomalous staining is able to
achieve competitive results with a limited set of annotated data. This initial
approach is good enough to be used as a guide for fast annotation of infected
patches.",2024-12-18,"Pau Cano, Eva Musulen, Debora Gil"
"Achieving Dispatchability in Data Centers: Carbon and Cost-Aware Sizing
  of Energy Storage and Local Photovoltaic Generation","Data centers are large electricity consumers due to the high consumption
needs of servers and their cooling systems. Given the current crypto-currency
and artificial intelligence trends, the data center electricity demand is bound
to grow significantly. With the electricity sector being responsible for a
large share of global greenhouse gas (GHG) emissions, it is important to lower
the carbon footprint of data centers to meet GHG emissions targets set by
international agreements. Moreover, uncontrolled integration of data centers in
power distribution grids contributes to increasing the stochasticity of the
power system demand, thus increasing the need for capacity reserves, which
leads to economic and environmental inefficiencies in the power grid operation.
This work provides a method to size a PhotoVoltaic (PV) system and an Energy
Storage System (ESS) for an existing data center looking to reduce both its
carbon footprint and demand stochasticity via dispatching. The proposed
scenario-based optimization framework allows to size the ESS and the PV system
to minimize the expected operational and capital costs, along with the carbon
footprint of the data center complex. The life cycle assessment of the
resources, as well as the dynamic carbon emissions of the upstream power
distribution grid, are accounted for while computing the day-ahead planning of
the data center aggregated demand and PV generation. Case studies in different
Swiss cantons and regions of Germany emphasize the need for location-aware
sizing processes since the obtained optimal solutions strongly depend on the
local electricity carbon footprint, cost and on the local irradiance
conditions. Some regions show potential in carbon footprint reduction, while
other regions do not.",2024-12-18,"Enea Figini, Mario Paolone"
"From approximation error to optimality gap -- Explaining the performance
  impact of opportunity cost approximation in integrated demand management and
  vehicle routing","The widespread adoption of digital distribution channels both enables and
forces more and more logistical service providers to manage booking processes
actively to maintain competitiveness. As a result, their operational planning
is no longer limited to solving vehicle routing problems. Instead, demand
management decisions and vehicle routing decisions are optimized integratively
with the aim of maximizing revenue and minimizing fulfillment cost. The
resulting integrated demand management and vehicle routing problems (i-DMVRPs)
can be formulated as Markov decision process models and, theoretically, can be
solved via the well-known Bellman equation. Unfortunately, the Bellman equation
is intractable for realistic-sized instances. Thus, in the literature, i-DMVRPs
are often addressed via decomposition-based solution approaches involving an
opportunity cost approximation as a key component. Despite its importance, to
the best of our knowledge, there is neither a technique to systematically
analyze how the accuracy of the opportunity cost approximation translates into
overall solution quality nor are there general guidelines on when to apply
which class of approximation approach. In this work, we address this research
gap by proposing an explainability technique that quantifies and visualizes the
magnitude of approximation errors, their immediate impact, and their relevance
in specific regions of the state space. Exploiting reward decomposition, it
further yields a characterization of different types of approximation errors.
Applying the technique to a generic i-DMVRP in a full-factorial computational
study and comparing the results with observations in existing literature, we
show that the technique contributes to better explaining algorithmic
performance and provides guidance for the algorithm selection and development
process.",2024-12-18,"David Fleckenstein, Robert Klein, Vienna Klein, Claudius Steinhardt"
Do Language Models Understand Time?,"Large language models (LLMs) have revolutionized video-based computer vision
applications, including action recognition, anomaly detection, and video
summarization. Videos inherently pose unique challenges, combining spatial
complexity with temporal dynamics that are absent in static images or textual
data. Current approaches to video understanding with LLMs often rely on
pretrained video encoders to extract spatiotemporal features and text encoders
to capture semantic meaning. These representations are integrated within LLM
frameworks, enabling multimodal reasoning across diverse video tasks. However,
the critical question persists: Can LLMs truly understand the concept of time,
and how effectively can they reason about temporal relationships in videos?
This work critically examines the role of LLMs in video processing, with a
specific focus on their temporal reasoning capabilities. We identify key
limitations in the interaction between LLMs and pretrained encoders, revealing
gaps in their ability to model long-term dependencies and abstract temporal
concepts such as causality and event progression. Furthermore, we analyze
challenges posed by existing video datasets, including biases, lack of temporal
annotations, and domain-specific limitations that constrain the temporal
understanding of LLMs. To address these gaps, we explore promising future
directions, including the co-evolution of LLMs and encoders, the development of
enriched datasets with explicit temporal labels, and innovative architectures
for integrating spatial, temporal, and semantic reasoning. By addressing these
challenges, we aim to advance the temporal comprehension of LLMs, unlocking
their full potential in video analysis and beyond.",2024-12-18,"Xi Ding, Lei Wang"
"RACQUET: Unveiling the Dangers of Overlooked Referential Ambiguity in
  Visual LLMs","Ambiguity resolution is key to effective communication. While humans
effortlessly address ambiguity through conversational grounding strategies, the
extent to which current language models can emulate these strategies remains
unclear. In this work, we examine referential ambiguity in image-based question
answering by introducing RACQUET, a carefully curated dataset targeting
distinct aspects of ambiguity. Through a series of evaluations, we reveal
significant limitations and problems of overconfidence of state-of-the-art
large multimodal language models in addressing ambiguity in their responses.
The overconfidence issue becomes particularly relevant for RACQUET-BIAS, a
subset designed to analyze a critical yet underexplored problem: failing to
address ambiguity leads to stereotypical, socially biased responses. Our
results underscore the urgency of equipping models with robust strategies to
deal with uncertainty without resorting to undesirable stereotypes.",2024-12-18,"Alberto Testoni, Barbara Plank, Raquel Fernández"
Object Style Diffusion for Generalized Object Detection in Urban Scene,"Object detection is a critical task in computer vision, with applications in
various domains such as autonomous driving and urban scene monitoring. However,
deep learning-based approaches often demand large volumes of annotated data,
which are costly and difficult to acquire, particularly in complex and
unpredictable real-world environments. This dependency significantly hampers
the generalization capability of existing object detection techniques. To
address this issue, we introduce a novel single-domain object detection
generalization method, named GoDiff, which leverages a pre-trained model to
enhance generalization in unseen domains. Central to our approach is the Pseudo
Target Data Generation (PTDG) module, which employs a latent diffusion model to
generate pseudo-target domain data that preserves source domain characteristics
while introducing stylistic variations. By integrating this pseudo data with
source domain data, we diversify the training dataset. Furthermore, we
introduce a cross-style instance normalization technique to blend style
features from different domains generated by the PTDG module, thereby
increasing the detector's robustness. Experimental results demonstrate that our
method not only enhances the generalization ability of existing detectors but
also functions as a plug-and-play enhancement for other single-domain
generalization methods, achieving state-of-the-art performance in autonomous
driving scenarios.",2024-12-18,"Hao Li, Xiangyuan Yang, Mengzhu Wang, Long Lan, Ke Liang, Xinwang Liu, Kenli Li"
Differentially Private Substring and Document Counting,"Differential privacy is the gold standard for privacy in data analysis. In
many data analysis applications, the data is a database of documents. For
databases consisting of many documents, one of the most fundamental problems is
that of pattern matching and computing (i) how often a pattern appears as a
substring in the database (substring counting) and (ii) how many documents in
the collection contain the pattern as a substring (document counting). In this
paper, we initiate the theoretical study of substring and document counting
under differential privacy.
  We give an $\epsilon$-differentially private data structure solving this
problem for all patterns simultaneously with a maximum additive error of
$O(\ell \cdot\mathrm{polylog}(n\ell|\Sigma|))$, where $\ell$ is the maximum
length of a document in the database, $n$ is the number of documents, and
$|\Sigma|$ is the size of the alphabet. We show that this is optimal up to a
$O(\mathrm{polylog}(n\ell))$ factor. Further, we show that for
$(\epsilon,\delta)$-differential privacy, the bound for document counting can
be improved to $O(\sqrt{\ell} \cdot\mathrm{polylog}(n\ell|\Sigma|))$.
Additionally, our data structures are efficient. In particular, our data
structures use $O(n\ell^2)$ space, $O(n^2\ell^4)$ preprocessing time, and
$O(|P|)$ query time where $P$ is the query pattern. Along the way, we develop a
new technique for differentially privately computing a general class of
counting functions on trees of independent interest.
  Our data structures immediately lead to improved algorithms for related
problems, such as privately mining frequent substrings and $q$-grams. For
$q$-grams, we further improve the preprocessing time of the data structure.",2024-12-18,"Giulia Bernardini, Philip Bille, Inge Li Gørtz, Teresa Anna Steiner"
CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers?,"We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design.
Our approach is based on a powerful Vision and Large Language Model (VLLM) as a
planner and a tool-augmentation paradigm using CAD-specific modules.
CAD-Assistant addresses multimodal user queries by generating actions that are
iteratively executed on a Python interpreter equipped with the FreeCAD
software, accessed via its Python API. Our framework is able to assess the
impact of generated CAD commands on geometry and adapts subsequent actions
based on the evolving state of the CAD design. We consider a wide range of
CAD-specific tools including Python libraries, modules of the FreeCAD Python
API, helpful routines, rendering functions and other specialized modules. We
evaluate our method on multiple CAD benchmarks and qualitatively demonstrate
the potential of tool-augmented VLLMs as generic CAD task solvers across
diverse CAD workflows.",2024-12-18,"Dimitrios Mallis, Ahmet Serdar Karadeniz, Sebastian Cavada, Danila Rukhovich, Niki Foteinopoulou, Kseniya Cherenkova, Anis Kacem, Djamila Aouada"
"Extreme Multi-label Completion for Semantic Document Labelling with
  Taxonomy-Aware Parallel Learning","In Extreme Multi Label Completion (XMLCo), the objective is to predict the
missing labels of a collection of documents. Together with XML Classification,
XMLCo is arguably one of the most challenging document classification tasks, as
the very high number of labels (at least ten of thousands) is generally very
large compared to the number of available labelled documents in the training
dataset. Such a task is often accompanied by a taxonomy that encodes the labels
organic relationships, and many methods have been proposed to leverage this
hierarchy to improve the results of XMLCo algorithms. In this paper, we propose
a new approach to this problem, TAMLEC (Taxonomy-Aware Multi-task Learning for
Extreme multi-label Completion). TAMLEC divides the problem into several
Taxonomy-Aware Tasks, i.e. subsets of labels adapted to the hierarchical paths
of the taxonomy, and trains on these tasks using a dynamic Parallel Feature
sharing approach, where some parts of the model are shared between tasks while
others are task-specific. Then, at inference time, TAMLEC uses the labels
available in a document to infer the appropriate tasks and to predict missing
labels. To achieve this result, TAMLEC uses a modified transformer architecture
that predicts ordered sequences of labels on a Weak-Semilattice structure that
is naturally induced by the tasks. This approach yields multiple advantages.
First, our experiments on real-world datasets show that TAMLEC outperforms
state-of-the-art methods for various XMLCo problems. Second, TAMLEC is by
construction particularly suited for few-shots XML tasks, where new tasks or
labels are introduced with only few examples, and extensive evaluations
highlight its strong performance compared to existing methods.",2024-12-18,"Julien Audiffren, Christophe Broillet, Ljiljana Dolamic, Philippe Cudré-Mauroux"
"Mix-LN: Unleashing the Power of Deeper Layers by Combining Pre-LN and
  Post-LN","Large Language Models (LLMs) have achieved remarkable success, yet recent
findings reveal that their deeper layers often contribute minimally and can be
pruned without affecting overall performance. While some view this as an
opportunity for model compression, we identify it as a training shortfall
rooted in the widespread use of Pre-Layer Normalization (Pre-LN). We
demonstrate that Pre-LN, commonly employed in models like GPT and LLaMA, leads
to diminished gradient norms in its deeper layers, reducing their
effectiveness. In contrast, Post-Layer Normalization (Post-LN) preserves larger
gradient norms in deeper layers but suffers from vanishing gradients in earlier
layers. To address this, we introduce Mix-LN, a novel normalization technique
that combines the strengths of Pre-LN and Post-LN within the same model. Mix-LN
applies Post-LN to the earlier layers and Pre-LN to the deeper layers, ensuring
more uniform gradients across layers. This allows all parts of the
network--both shallow and deep layers--to contribute effectively to training.
Extensive experiments with various model sizes from 70M to 7B demonstrate that
Mix-LN consistently outperforms both Pre-LN and Post-LN, promoting more
balanced, healthier gradient norms throughout the network, and enhancing the
overall quality of LLM pre-training. Furthermore, we demonstrate that models
pre-trained with Mix-LN learn better compared to those using Pre-LN or Post-LN
during supervised fine-tuning (SFT) and reinforcement learning from human
feedback (RLHF), highlighting the critical importance of high-quality deep
layers. By effectively addressing the inefficiencies of deep layers in current
LLMs, Mix-LN unlocks their potential, enhancing model capacity without
increasing model size. Our code is available at
https://github.com/pixeli99/MixLN.",2024-12-18,"Pengxiang Li, Lu Yin, Shiwei Liu"
"Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics
  Problems with Large Language Models","Physics problems constitute a significant aspect of reasoning, necessitating
complicated reasoning ability and abundant physics knowledge. However, existing
large language models (LLMs) frequently fail due to a lack of knowledge or
incorrect knowledge application. To mitigate these issues, we propose Physics
Reasoner, a knowledge-augmented framework to solve physics problems with LLMs.
Specifically, the proposed framework constructs a comprehensive formula set to
provide explicit physics knowledge and utilizes checklists containing detailed
instructions to guide effective knowledge application. Namely, given a physics
problem, Physics Reasoner solves it through three stages: problem analysis,
formula retrieval, and guided reasoning. During the process, checklists are
employed to enhance LLMs' self-improvement in the analysis and reasoning
stages. Empirically, Physics Reasoner mitigates the issues of insufficient
knowledge and incorrect application, achieving state-of-the-art performance on
SciBench with an average accuracy improvement of 5.8%.",2024-12-18,"Xinyu Pang, Ruixin Hong, Zhanke Zhou, Fangrui Lv, Xinwei Yang, Zhilong Liang, Bo Han, Changshui Zhang"
"Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question
  Answering","Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.",2024-12-18,"Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang"
"Aggregative games with bilevel structures: Distributed algorithms and
  convergence analysis","In this paper, the problem of distributively searching the Stackelberg
equilibria of aggregative games with bilevel structures is studied. Different
from the traditional aggregative games, here the aggregation is determined by
the minimizer of the objective function in the inner level, which depends on
players' actions in the outer level. Moreover, the global objective function in
the inner level is formed by the sum of some local bifunctions, each of which
is strongly convex with respect to the second argument and is only available to
a specific player. To handle this problem, first, we propose a second order
gradient-based distributed algorithm, where the Hessain matrices associated
with the objective functions in the inner level is involved. By the algorithm,
players update their actions in the outer level while cooperatively minimizing
the sum of the bifunctions in the inner level to estimate the aggregation by
communicating with their neighbors via a connected graph. Under mild
assumptions on the graph and cost functions, we prove that the actions of
players and the estimate on the aggregation asymptotically converge to the
Stackelberg equilibrium. Then, for the case where the Hessain matrices
associated with the objective functions in the inner level are not available,
we propose a first order gradient-based distributed algorithm, where a
distributed two-point estimate strategy is developed to estimate the gradients
of cost functions in the outer level. Under the same conditions, we prove that
the convergence errors of players' actions and the estimate on the aggregation
to the Stackelberg equilibrium are linear with respect to the estimate
parameters. Finally, simulations are provided to demonstrate the effectiveness
of our theoretical results.",2024-12-18,"Kaihong Lu, Huanshui Zhang, Long Wang"
QuLTSF: Long-Term Time Series Forecasting with Quantum Machine Learning,"Long-term time series forecasting (LTSF) involves predicting a large number
of future values of a time series based on the past values and is an essential
task in a wide range of domains including weather forecasting, stock market
analysis, disease outbreak prediction. Over the decades LTSF algorithms have
transitioned from statistical models to deep learning models like transformer
models. Despite the complex architecture of transformer based LTSF models `Are
Transformers Effective for Time Series Forecasting? (Zeng et al., 2023)' showed
that simple linear models can outperform the state-of-the-art transformer based
LTSF models. Recently, quantum machine learning (QML) is evolving as a domain
to enhance the capabilities of classical machine learning models. In this paper
we initiate the application of QML to LTSF problems by proposing QuLTSF, a
simple hybrid QML model for multivariate LTSF. Through extensive experiments on
a widely used weather dataset we show the advantages of QuLTSF over the
state-of-the-art classical linear models, in terms of reduced mean squared
error and mean absolute error.",2024-12-18,"Hari Hara Suthan Chittoor, Paul Robert Griffin, Ariel Neufeld, Jayne Thompson, Mile Gu"
"Immersive Human-in-the-Loop Control: Real-Time 3D Surface Meshing and
  Physics Simulation","This paper introduces the TactiMesh Teleoperator Interface (TTI), a novel
predictive visual and haptic system designed explicitly for human-in-the-loop
robot control using a head-mounted display (HMD). By employing simultaneous
localization and mapping (SLAM)in tandem with a space carving method (CARV),
TTI creates a real time 3D surface mesh of remote environments from an RGB
camera mounted on a Barrett WAM arm. The generated mesh is integrated into a
physics simulator, featuring a digital twin of the WAM robot arm to create a
virtual environment. In this virtual environment, TTI provides haptic feedback
directly in response to the operator's movements, eliminating the problem with
delayed response from the haptic follower robot. Furthermore, texturing the 3D
mesh with keyframes from SLAM allows the operator to control the viewpoint of
their Head Mounted Display (HMD) independently of the arm-mounted robot camera,
giving a better visual immersion and improving manipulation speed.
Incorporating predictive visual and haptic feedback significantly improves
teleoperation in applications such as search and rescue, inspection, and remote
maintenance.",2024-12-18,"Sait Akturk, Justin Valentine, Junaid Ahmad, Martin Jagersand"
Multi-Exposure Image Fusion via Distilled 3D LUT Grid with Editable Mode,"With the rising imaging resolution of handheld devices, existing
multi-exposure image fusion algorithms struggle to generate a high dynamic
range image with ultra-high resolution in real-time. Apart from that, there is
a trend to design a manageable and editable algorithm as the different needs of
real application scenarios. To tackle these issues, we introduce 3D LUT
technology, which can enhance images with ultra-high-definition (UHD)
resolution in real time on resource-constrained devices. However, since the
fusion of information from multiple images with different exposure rates is
uncertain, and this uncertainty significantly trials the generalization power
of the 3D LUT grid. To address this issue and ensure a robust learning space
for the model, we propose using a teacher-student network to model the
uncertainty on the 3D LUT grid.Furthermore, we provide an editable mode for the
multi-exposure image fusion algorithm by using the implicit representation
function to match the requirements in different scenarios. Extensive
experiments demonstrate that our proposed method is highly competitive in
efficiency and accuracy.",2024-12-18,"Xin Su, Zhuoran Zheng"
"RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented
  Generation for Preference Alignment","Despite the significant progress made by existing retrieval augmented
language models (RALMs) in providing trustworthy responses and grounding in
reliable sources, they often overlook effective alignment with human
preferences. In the alignment process, reward models (RMs) act as a crucial
proxy for human values to guide optimization. However, it remains unclear how
to evaluate and select a reliable RM for preference alignment in RALMs. To this
end, we propose RAG-RewardBench, the first benchmark for evaluating RMs in RAG
settings. First, we design four crucial and challenging RAG-specific scenarios
to assess RMs, including multi-hop reasoning, fine-grained citation,
appropriate abstain, and conflict robustness. Then, we incorporate 18 RAG
subsets, six retrievers, and 24 RALMs to increase the diversity of data
sources. Finally, we adopt an LLM-as-a-judge approach to improve preference
annotation efficiency and effectiveness, exhibiting a strong correlation with
human annotations. Based on the RAG-RewardBench, we conduct a comprehensive
evaluation of 45 RMs and uncover their limitations in RAG scenarios.
Additionally, we also reveal that existing trained RALMs show almost no
improvement in preference alignment, highlighting the need for a shift towards
preference-aligned training.We release our benchmark and code publicly at
https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ for future work.",2024-12-18,"Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao"
MedCoT: Medical Chain of Thought via Hierarchical Expert,"Artificial intelligence has advanced in Medical Visual Question Answering
(Med-VQA), but prevalent research tends to focus on the accuracy of the
answers, often overlooking the reasoning paths and interpretability, which are
crucial in clinical settings. Besides, current Med-VQA algorithms, typically
reliant on singular models, lack the robustness needed for real-world medical
diagnostics which usually require collaborative expert evaluation. To address
these shortcomings, this paper presents MedCoT, a novel hierarchical expert
verification reasoning chain method designed to enhance interpretability and
accuracy in biomedical imaging inquiries. MedCoT is predicated on two
principles: The necessity for explicit reasoning paths in Med-VQA and the
requirement for multi-expert review to formulate accurate conclusions. The
methodology involves an Initial Specialist proposing diagnostic rationales,
followed by a Follow-up Specialist who validates these rationales, and finally,
a consensus is reached through a vote among a sparse Mixture of Experts within
the locally deployed Diagnostic Specialist, which then provides the definitive
diagnosis. Experimental evaluations on four standard Med-VQA datasets
demonstrate that MedCoT surpasses existing state-of-the-art approaches,
providing significant improvements in performance and interpretability.",2024-12-18,"Jiaxiang Liu, Yuan Wang, Jiawei Du, Joey Tianyi Zhou, Zuozhu Liu"
Text2Relight: Creative Portrait Relighting with Text Guidance,"We present a lighting-aware image editing pipeline that, given a portrait
image and a text prompt, performs single image relighting. Our model modifies
the lighting and color of both the foreground and background to align with the
provided text description. The unbounded nature in creativeness of a text
allows us to describe the lighting of a scene with any sensory features
including temperature, emotion, smell, time, and so on. However, the modeling
of such mapping between the unbounded text and lighting is extremely
challenging due to the lack of dataset where there exists no scalable data that
provides large pairs of text and relighting, and therefore, current text-driven
image editing models does not generalize to lighting-specific use cases. We
overcome this problem by introducing a novel data synthesis pipeline: First,
diverse and creative text prompts that describe the scenes with various
lighting are automatically generated under a crafted hierarchy using a large
language model (*e.g.,* ChatGPT). A text-guided image generation model creates
a lighting image that best matches the text. As a condition of the lighting
images, we perform image-based relighting for both foreground and background
using a single portrait image or a set of OLAT (One-Light-at-A-Time) images
captured from lightstage system. Particularly for the background relighting, we
represent the lighting image as a set of point lights and transfer them to
other background images. A generative diffusion model learns the synthesized
large-scale data with auxiliary task augmentation (*e.g.,* portrait delighting
and light positioning) to correlate the latent text and lighting distribution
for text-guided portrait relighting.",2024-12-18,"Junuk Cha, Mengwei Ren, Krishna Kumar Singh, He Zhang, Yannick Hold-Geoffroy, Seunghyun Yoon, HyunJoon Jung, Jae Shin Yoon, Seungryul Baek"
From Risk to Readiness: VR-Based Safety Training for Industrial Hazards,"This study explores the application of Virtual Reality (VR) as a tool for
safety training in high-risk industrial settings, specifically focusing on the
IPLOM refinery, Busalla (Italy). As industries increasingly adopt digital tools
to enhance safety and operational efficiency, VR provides a risk-free,
immersive environment for training operators in emergency protocols. This
project developed a VR simulation using Unreal Engine and Meta Quest headsets
to mirror refinery conditions, including equipment handling, emergency response
procedures, and spatial navigation. Integrated tools, such as multi-gas
detectors and evacuation drills, allow users to practice real-world tasks
virtually, enhancing procedural knowledge and spatial awareness. The
simulation's design allows for future integration with Augmented Reality (AR)
to enable real-time equipment monitoring and data overlays, enhancing on-site
decision-making. Feedback from initial testing shows high user satisfaction and
increased confidence in emergency response skills, indicating the effectiveness
of VR in safety training. This VR approach offers a scalable, adaptable model
for refining industrial training, reducing physical risks and costs associated
with traditional drills, and setting a foundation for the use of immersive
technologies in other high-risk sectors.",2024-12-18,"Gianni Vercelli, Saverio Iacono, Luca Martini, Michele Zardetto, Daniele Zolezzi"
Towards Automatic Evaluation for Image Transcreation,"Beyond conventional paradigms of translating speech and text, recently, there
has been interest in automated transcreation of images to facilitate
localization of visual content across different cultures. Attempts to define
this as a formal Machine Learning (ML) problem have been impeded by the lack of
automatic evaluation mechanisms, with previous work relying solely on human
evaluation. In this paper, we seek to close this gap by proposing a suite of
automatic evaluation metrics inspired by machine translation (MT) metrics,
categorized into: a) Object-based, b) Embedding-based, and c) VLM-based.
Drawing on theories from translation studies and real-world transcreation
practices, we identify three critical dimensions of image transcreation:
cultural relevance, semantic equivalence and visual similarity, and design our
metrics to evaluate systems along these axes. Our results show that proprietary
VLMs best identify cultural relevance and semantic equivalence, while
vision-encoder representations are adept at measuring visual similarity.
Meta-evaluation across 7 countries shows our metrics agree strongly with human
ratings, with average segment-level correlations ranging from 0.55-0.87.
Finally, through a discussion of the merits and demerits of each metric, we
offer a robust framework for automated image transcreation evaluation, grounded
in both theoretical foundations and practical application. Our code can be
found here: https://github.com/simran-khanuja/automatic-eval-transcreation",2024-12-18,"Simran Khanuja, Vivek Iyer, Claire He, Graham Neubig"
"Model Decides How to Tokenize: Adaptive DNA Sequence Tokenization with
  MxDNA","Foundation models have made significant strides in understanding the genomic
language of DNA sequences. However, previous models typically adopt the
tokenization methods designed for natural language, which are unsuitable for
DNA sequences due to their unique characteristics. In addition, the optimal
approach to tokenize DNA remains largely under-explored, and may not be
intuitively understood by humans even if discovered. To address these
challenges, we introduce MxDNA, a novel framework where the model autonomously
learns an effective DNA tokenization strategy through gradient decent. MxDNA
employs a sparse Mixture of Convolution Experts coupled with a deformable
convolution to model the tokenization process, with the discontinuous,
overlapping, and ambiguous nature of meaningful genomic segments explicitly
considered. On Nucleotide Transformer Benchmarks and Genomic Benchmarks, MxDNA
demonstrates superior performance to existing methods with less pretraining
data and time, highlighting its effectiveness. Finally, we show that MxDNA
learns unique tokenization strategy distinct to those of previous methods and
captures genomic functionalities at a token level during self-supervised
pretraining. Our MxDNA aims to provide a new perspective on DNA tokenization,
potentially offering broad applications in various domains and yielding
profound insights.",2024-12-18,"Lifeng Qiao, Peng Ye, Yuchen Ren, Weiqiang Bai, Chaoqi Liang, Xinzhu Ma, Nanqing Dong, Wanli Ouyang"
"SSE-SAM: Balancing Head and Tail Classes Gradually through Stage-Wise
  SAM","Real-world datasets often exhibit a long-tailed distribution, where vast
majority of classes known as tail classes have only few samples. Traditional
methods tend to overfit on these tail classes. Recently, a new approach called
Imbalanced SAM (ImbSAM) is proposed to leverage the generalization benefits of
Sharpness-Aware Minimization (SAM) for long-tailed distributions. The main
strategy is to merely enhance the smoothness of the loss function for tail
classes. However, we argue that improving generalization in long-tail scenarios
requires a careful balance between head and tail classes. We show that neither
SAM nor ImbSAM alone can fully achieve this balance. For SAM, we prove that
although it enhances the model's generalization ability by escaping saddle
point in the overall loss landscape, it does not effectively address this for
tail-class losses. Conversely, while ImbSAM is more effective at avoiding
saddle points in tail classes, the head classes are trained insufficiently,
resulting in significant performance drops. Based on these insights, we propose
Stage-wise Saddle Escaping SAM (SSE-SAM), which uses complementary strengths of
ImbSAM and SAM in a phased approach. Initially, SSE-SAM follows the majority
sample to avoid saddle points of the head-class loss. During the later phase,
it focuses on tail-classes to help them escape saddle points. Our experiments
confirm that SSE-SAM has better ability in escaping saddles both on head and
tail classes, and shows performance improvements.",2024-12-18,"Xingyu Lyu, Qianqian Xu, Zhiyong Yang, Shaojie Lyu, Qingming Huang"
"AnchorInv: Few-Shot Class-Incremental Learning of Physiological Signals
  via Representation Space Guided Inversion","Deep learning models have demonstrated exceptional performance in a variety
of real-world applications. These successes are often attributed to strong base
models that can generalize to novel tasks with limited supporting data while
keeping prior knowledge intact. However, these impressive results are based on
the availability of a large amount of high-quality data, which is often lacking
in specialized biomedical applications. In such fields, models are usually
developed with limited data that arrive incrementally with novel categories.
This requires the model to adapt to new information while preserving existing
knowledge. Few-Shot Class-Incremental Learning (FSCIL) methods offer a
promising approach to addressing these challenges, but they also depend on
strong base models that face the same aforementioned limitations. To overcome
these constraints, we propose AnchorInv following the straightforward and
efficient buffer-replay strategy. Instead of selecting and storing raw data,
AnchorInv generates synthetic samples guided by anchor points in the feature
space. This approach protects privacy and regularizes the model for adaptation.
When evaluated on three public physiological time series datasets, AnchorInv
exhibits efficient knowledge forgetting prevention and improved adaptation to
novel classes, surpassing state-of-the-art baselines.",2024-12-18,"Chenqi Li, Boyan Gao, Gabriel Jones, Timothy Denison, Tingting Zhu"
Splitting criteria for ordinal decision trees: an experimental study,"Ordinal Classification (OC) is a machine learning field that addresses
classification tasks where the labels exhibit a natural order. Unlike nominal
classification, which treats all classes as equally distinct, OC takes the
ordinal relationship into account, producing more accurate and relevant
results. This is particularly critical in applications where the magnitude of
classification errors has implications. Despite this, OC problems are often
tackled using nominal methods, leading to suboptimal solutions. Although
decision trees are one of the most popular classification approaches, ordinal
tree-based approaches have received less attention when compared to other
classifiers. This work conducts an experimental study of tree-based
methodologies specifically designed to capture ordinal relationships. A
comprehensive survey of ordinal splitting criteria is provided, standardising
the notations used in the literature for clarity. Three ordinal splitting
criteria, Ordinal Gini (OGini), Weighted Information Gain (WIG), and Ranking
Impurity (RI), are compared to the nominal counterparts of the first two (Gini
and information gain), by incorporating them into a decision tree classifier.
An extensive repository considering 45 publicly available OC datasets is
presented, supporting the first experimental comparison of ordinal and nominal
splitting criteria using well-known OC evaluation metrics. Statistical analysis
of the results highlights OGini as the most effective ordinal splitting
criterion to date. Source code, datasets, and results are made available to the
research community.",2024-12-18,"Rafael Ayllón-Gavilán, Francisco José Martínez-Estudillo, David Guijo-Rubio, César Hervás-Martínez, Pedro Antonio Gutiérrez"
"Discerning and Characterising Types of Competency Questions for
  Ontologies","Competency Questions (CQs) are widely used in ontology development by
guiding, among others, the scoping and validation stages. However, very limited
guidance exists for formulating CQs and assessing whether they are good CQs,
leading to issues such as ambiguity and unusable formulations. To solve this,
one requires insight into the nature of CQs for ontologies and their
constituent parts, as well as which ones are not. We aim to contribute to such
theoretical foundations in this paper, which is informed by analysing
questions, their uses, and the myriad of ontology development tasks. This
resulted in a first Model for Competency Questions, which comprises five main
types of CQs, each with a different purpose: Scoping (SCQ), Validating (VCQ),
Foundational (FCQ), Relationship (RCQ), and Metaproperty (MpCQ) questions. This
model enhances the clarity of CQs and therewith aims to improve on the
effectiveness of CQs in ontology development, thanks to their respective
identifiable distinct constituent elements. We illustrate and evaluate them
with a user story and demonstrate where which type can be used in ontology
development tasks. To foster use and research, we created an annotated
repository of 438 CQs, the Repository of Ontology Competency QuestionS (ROCQS),
incorporating an existing CQ dataset and new CQs and CQ templates, which
further demonstrate distinctions among types of CQs.",2024-12-18,"C. Maria Keet, Zubeida Casmod Khan"
"ChinaTravel: A Real-World Benchmark for Language Agents in Chinese
  Travel Planning","Recent advances in LLMs, particularly in language reasoning and tool
integration, have rapidly sparked the real-world development of Language
Agents. Among these, travel planning represents a prominent domain, combining
academic challenges with practical value due to its complexity and market
demand. However, existing benchmarks fail to reflect the diverse, real-world
requirements crucial for deployment. To address this gap, we introduce
ChinaTravel, a benchmark specifically designed for authentic Chinese travel
planning scenarios. We collect the travel requirements from questionnaires and
propose a compositionally generalizable domain-specific language that enables a
scalable evaluation process, covering feasibility, constraint satisfaction, and
preference comparison. Empirical studies reveal the potential of neuro-symbolic
agents in travel planning, achieving a constraint satisfaction rate of 27.9%,
significantly surpassing purely neural models at 2.6%. Moreover, we identify
key challenges in real-world travel planning deployments, including open
language reasoning and unseen concept composition. These findings highlight the
significance of ChinaTravel as a pivotal milestone for advancing language
agents in complex, real-world planning scenarios.",2024-12-18,"Jie-Jing Shao, Xiao-Wen Yang, Bo-Wen Zhang, Baizhi Chen, Wen-Da Wei, Lan-Zhe Guo, Yu-feng Li"
"Dynamics of Parallel Manipulators with Hybrid Complex Limbs -- Modular
  Modeling and Parallel Computing","Parallel manipulators, also called parallel kinematics machines (PKM), enable
robotic solutions for highly dynamic handling and machining applications. The
safe and accurate design and control necessitates high-fidelity dynamics
models. Such modeling approaches have already been presented for PKM with
simple limbs (i.e. each limb is a serial kinematic chain). A systematic
modeling approach for PKM with complex limbs (i.e. limbs that possess kinematic
loops) was not yet proposed despite the fact that many successful PKM comprise
complex limbs. This paper presents a systematic modular approach to the
kinematics and dynamics modeling of PKM with complex limbs that are built as
serial arrangement of closed loops. The latter are referred to as hybrid limbs,
and can be found in almost all PKM with complex limbs, such as the Delta robot.
The proposed method generalizes the formulation for PKM with simple limbs by
means of local resolution of loop constraints, which is known as constraint
embedding in multibody dynamics. The constituent elements of the method are the
kinematic and dynamic equations of motions (EOM), and the inverse kinematics
solution of the limbs, i.e. the relation of platform motion and the motion of
the limbs. While the approach is conceptually independent of the used
kinematics and dynamics formulation, a Lie group formulation is employed for
deriving the EOM. The frame invariance of the Lie group formulation is used for
devising a modular modeling method where the EOM of a representative limb are
used to derived the EOM of the limbs of a particular PKM. The PKM topology is
exploited in a parallel computation scheme that shall allow for computationally
efficient distributed evaluation of the overall EOM of the PKM. Finally, the
method is applied to the IRSBot-2 and a 3\underline{R}R[2RR]R Delta robot,
which is presented in detail.",2024-12-18,Andreas Mueller
Clio: Privacy-Preserving Insights into Real-World AI Use,"How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.",2024-12-18,"Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli"
Time-Reversible Bridges of Data with Machine Learning,"The analysis of dynamical systems is a fundamental tool in the natural
sciences and engineering. It is used to understand the evolution of systems as
large as entire galaxies and as small as individual molecules. With predefined
conditions on the evolution of dy-namical systems, the underlying differential
equations have to fulfill specific constraints in time and space. This class of
problems is known as boundary value problems. This thesis presents novel
approaches to learn time-reversible deterministic and stochastic dynamics
constrained by initial and final conditions. The dynamics are inferred by
machine learning algorithms from observed data, which is in contrast to the
traditional approach of solving differential equations by numerical
integration. The work in this thesis examines a set of problems of increasing
difficulty each of which is concerned with learning a different aspect of the
dynamics. Initially, we consider learning deterministic dynamics from ground
truth solutions which are constrained by deterministic boundary conditions.
Secondly, we study a boundary value problem in discrete state spaces, where the
forward dynamics follow a stochastic jump process and the boundary conditions
are discrete probability distributions. In particular, the stochastic dynamics
of a specific jump process, the Ehrenfest process, is considered and the
reverse time dynamics are inferred with machine learning. Finally, we
investigate the problem of inferring the dynamics of a continuous-time
stochastic process between two probability distributions without any reference
information. Here, we propose a novel criterion to learn time-reversible
dynamics of two stochastic processes to solve the Schr\""odinger Bridge Problem.",2024-12-18,Ludwig Winkler
"PsyDT: Using LLMs to Construct the Digital Twin of Psychological
  Counselor with Personalized Counseling Style for Psychological Counseling","Currently, large language models (LLMs) have made significant progress in the
field of psychological counseling. However, existing mental health LLMs
overlook a critical issue where they do not consider the fact that different
psychological counselors exhibit different personal styles, including
linguistic style and therapy techniques, etc. As a result, these LLMs fail to
satisfy the individual needs of clients who seek different counseling styles.
To help bridge this gap, we propose PsyDT, a novel framework using LLMs to
construct the Digital Twin of Psychological counselor with personalized
counseling style. Compared to the time-consuming and costly approach of
collecting a large number of real-world counseling cases to create a specific
counselor's digital twin, our framework offers a faster and more cost-effective
solution. To construct PsyDT, we utilize dynamic one-shot learning by using
GPT-4 to capture counselor's unique counseling style, mainly focusing on
linguistic style and therapy techniques. Subsequently, using existing
single-turn long-text dialogues with client's questions, GPT-4 is guided to
synthesize multi-turn dialogues of specific counselor. Finally, we fine-tune
the LLMs on the synthetic dataset, PsyDTCorpus, to achieve the digital twin of
psychological counselor with personalized counseling style. Experimental
results indicate that our proposed PsyDT framework can synthesize multi-turn
dialogues that closely resemble real-world counseling cases and demonstrate
better performance compared to other baselines, thereby show that our framework
can effectively construct the digital twin of psychological counselor with a
specific counseling style.",2024-12-18,"Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu"
"VIIS: Visible and Infrared Information Synthesis for Severe Low-light
  Image Enhancement","Images captured in severe low-light circumstances often suffer from
significant information absence. Existing singular modality image enhancement
methods struggle to restore image regions lacking valid information. By
leveraging light-impervious infrared images, visible and infrared image fusion
methods have the potential to reveal information hidden in darkness. However,
they primarily emphasize inter-modal complementation but neglect intra-modal
enhancement, limiting the perceptual quality of output images. To address these
limitations, we propose a novel task, dubbed visible and infrared information
synthesis (VIIS), which aims to achieve both information enhancement and fusion
of the two modalities. Given the difficulty in obtaining ground truth in the
VIIS task, we design an information synthesis pretext task (ISPT) based on
image augmentation. We employ a diffusion model as the framework and design a
sparse attention-based dual-modalities residual (SADMR) conditioning mechanism
to enhance information interaction between the two modalities. This mechanism
enables features with prior knowledge from both modalities to adaptively and
iteratively attend to each modality's information during the denoising process.
Our extensive experiments demonstrate that our model qualitatively and
quantitatively outperforms not only the state-of-the-art methods in relevant
fields but also the newly designed baselines capable of both information
enhancement and fusion. The code is available at
https://github.com/Chenz418/VIIS.",2024-12-18,"Chen Zhao, Mengyuan Yu, Fan Yang, Peiguang Jing"
"G-VEval: A Versatile Metric for Evaluating Image and Video Captions
  Using GPT-4o","Evaluation metric of visual captioning is important yet not thoroughly
explored. Traditional metrics like BLEU, METEOR, CIDEr, and ROUGE often miss
semantic depth, while trained metrics such as CLIP-Score, PAC-S, and Polos are
limited in zero-shot scenarios. Advanced Language Model-based metrics also
struggle with aligning to nuanced human preferences. To address these issues,
we introduce G-VEval, a novel metric inspired by G-Eval and powered by the new
GPT-4o. G-VEval uses chain-of-thought reasoning in large multimodal models and
supports three modes: reference-free, reference-only, and combined,
accommodating both video and image inputs. We also propose MSVD-Eval, a new
dataset for video captioning evaluation, to establish a more transparent and
consistent framework for both human experts and evaluation metrics. It is
designed to address the lack of clear criteria in existing datasets by
introducing distinct dimensions of Accuracy, Completeness, Conciseness, and
Relevance (ACCR). Extensive results show that G-VEval outperforms existing
methods in correlation with human annotations, as measured by Kendall tau-b and
Kendall tau-c. This provides a flexible solution for diverse captioning tasks
and suggests a straightforward yet effective approach for large language models
to understand video content, paving the way for advancements in automated
captioning. Codes are available at https://github.com/ztangaj/gveval",2024-12-18,"Tony Cheng Tong, Sirui He, Zhiwen Shao, Dit-Yan Yeung"
Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning,"Theory of Mind (ToM) capabilities in LLMs have recently become a central
object of investigation. Cognitive science distinguishes between two steps
required for ToM tasks: 1) determine whether to invoke ToM, which includes the
appropriate Depth of Mentalizing (DoM), or level of recursion required to
complete a task; and 2) applying the correct inference given the DoM. In this
position paper, we first identify several lines of work in different
communities in AI, including LLM benchmarking, ToM add-ons, ToM probing, and
formal models for ToM. We argue that recent work in AI tends to focus
exclusively on the second step which are typically framed as static logic
problems. We conclude with suggestions for improved evaluation of ToM
capabilities inspired by dynamic environments used in cognitive tasks.",2024-12-18,"Eitan Wagner, Nitay Alon, Joseph M. Barnby, Omri Abend"
Unifying Attribution-Based Explanations Using Functional Decomposition,"The black box problem in machine learning has led to the introduction of an
ever-increasing set of explanation methods for complex models. These
explanations have different properties, which in turn has led to the problem of
method selection: which explanation method is most suitable for a given use
case? In this work, we propose a unifying framework of attribution-based
explanation methods, which provides a step towards a rigorous study of the
similarities and differences of explanations. We first introduce removal-based
attribution methods (RBAMs), and show that an extensively broad selection of
existing methods can be viewed as such RBAMs. We then introduce the canonical
additive decomposition (CAD). This is a general construction for additively
decomposing any function based on the central idea of removing (groups of)
features. We proceed to show that indeed every valid additive decomposition is
an instance of the CAD, and that any removal-based attribution method is
associated with a specific CAD. Next, we show that any removal-based
attribution method can be completely defined as a game-theoretic value or
interaction index for a specific (possibly constant-shifted) cooperative game,
which is defined using the corresponding CAD of the method. We then use this
intrinsic connection to define formal descriptions of specific behaviours of
explanation methods, which we also call functional axioms, and identify
sufficient conditions on the corresponding CAD and game-theoretic value or
interaction index of an attribution method under which the attribution method
is guaranteed to adhere to these functional axioms. Finally, we show how this
unifying framework can be used to develop new, efficient approximations for
existing explanation methods.",2024-12-18,"Arne Gevaert, Yvan Saeys"
Robust Tracking via Mamba-based Context-aware Token Learning,"How to make a good trade-off between performance and computational cost is
crucial for a tracker. However, current famous methods typically focus on
complicated and time-consuming learning that combining temporal and appearance
information by input more and more images (or features). Consequently, these
methods not only increase the model's computational source and learning burden
but also introduce much useless and potentially interfering information. To
alleviate the above issues, we propose a simple yet robust tracker that
separates temporal information learning from appearance modeling and extracts
temporal relations from a set of representative tokens rather than several
images (or features). Specifically, we introduce one track token for each frame
to collect the target's appearance information in the backbone. Then, we design
a mamba-based Temporal Module for track tokens to be aware of context by
interacting with other track tokens within a sliding window. This module
consists of a mamba layer with autoregressive characteristic and a
cross-attention layer with strong global perception ability, ensuring
sufficient interaction for track tokens to perceive the appearance changes and
movement trends of the target. Finally, track tokens serve as a guidance to
adjust the appearance feature for the final prediction in the head. Experiments
show our method is effective and achieves competitive performance on multiple
benchmarks at a real-time speed. Code and trained models will be available at
https://github.com/GXNU-ZhongLab/TemTrack.",2024-12-18,"Jinxia Xie, Bineng Zhong, Qihua Liang, Ning Li, Zhiyi Mo, Shuxiang Song"
Sign-IDD: Iconicity Disentangled Diffusion for Sign Language Production,"Sign Language Production (SLP) aims to generate semantically consistent sign
videos from textual statements, where the conversion from textual glosses to
sign poses (G2P) is a crucial step. Existing G2P methods typically treat sign
poses as discrete three-dimensional coordinates and directly fit them, which
overlooks the relative positional relationships among joints. To this end, we
provide a new perspective, constraining joint associations and gesture details
by modeling the limb bones to improve the accuracy and naturalness of the
generated poses. In this work, we propose a pioneering iconicity disentangled
diffusion framework, termed Sign-IDD, specifically designed for SLP. Sign-IDD
incorporates a novel Iconicity Disentanglement (ID) module to bridge the gap
between relative positions among joints. The ID module disentangles the
conventional 3D joint representation into a 4D bone representation, comprising
the 3D spatial direction vector and 1D spatial distance vector between adjacent
joints. Additionally, an Attribute Controllable Diffusion (ACD) module is
introduced to further constrain joint associations, in which the attribute
separation layer aims to separate the bone direction and length attributes, and
the attribute control layer is designed to guide the pose generation by
leveraging the above attributes. The ACD module utilizes the gloss embeddings
as semantic conditions and finally generates sign poses from noise embeddings.
Extensive experiments on PHOENIX14T and USTC-CSL datasets validate the
effectiveness of our method. The code is available at:
https://github.com/NaVi-start/Sign-IDD.",2024-12-18,"Shengeng Tang, Jiayi He, Dan Guo, Yanyan Wei, Feng Li, Richang Hong"
"PreMixer: MLP-Based Pre-training Enhanced MLP-Mixers for Large-scale
  Traffic Forecasting","In urban computing, precise and swift forecasting of multivariate time series
data from traffic networks is crucial. This data incorporates additional
spatial contexts such as sensor placements and road network layouts, and
exhibits complex temporal patterns that amplify challenges for predictive
learning in traffic management, smart mobility demand, and urban planning.
Consequently, there is an increasing need to forecast traffic flow across
broader geographic regions and for higher temporal coverage. However, current
research encounters limitations because of the inherent inefficiency of model
and their unsuitability for large-scale traffic network applications due to
model complexity. This paper proposes a novel framework, named PreMixer,
designed to bridge this gap. It features a predictive model and a pre-training
mechanism, both based on the principles of Multi-Layer Perceptrons (MLP). The
PreMixer comprehensively consider temporal dependencies of traffic patterns in
different time windows and processes the spatial dynamics as well.
Additionally, we integrate spatio-temporal positional encoding to manage
spatiotemporal heterogeneity without relying on predefined graphs. Furthermore,
our innovative pre-training model uses a simple patch-wise MLP to conduct
masked time series modeling, learning from long-term historical data segmented
into patches to generate enriched contextual representations. This approach
enhances the downstream forecasting model without incurring significant time
consumption or computational resource demands owing to improved learning
efficiency and data handling flexibility. Our framework achieves comparable
state-of-the-art performance while maintaining high computational efficiency,
as verified by extensive experiments on large-scale traffic datasets.",2024-12-18,"Tongtong Zhang, Zhiyong Cui, Bingzhang Wang, Yilong Ren, Haiyang Yu, Pan Deng, Yinhai Wang"
Exploiting Symmetries in MUS Computation (Extended version),"In eXplainable Constraint Solving (XCS), it is common to extract a Minimal
Unsatisfiable Subset (MUS) from a set of unsatisfiable constraints. This helps
explain to a user why a constraint specification does not admit a solution.
Finding MUSes can be computationally expensive for highly symmetric problems,
as many combinations of constraints need to be considered. In the traditional
context of solving satisfaction problems, symmetry has been well studied, and
effective ways to detect and exploit symmetries during the search exist.
However, in the setting of finding MUSes of unsatisfiable constraint programs,
symmetries are understudied. In this paper, we take inspiration from existing
symmetry-handling techniques and adapt well-known MUS-computation methods to
exploit symmetries in the specification, speeding-up overall computation time.
Our results display a significant reduction of runtime for our adapted
algorithms compared to the baseline on symmetric problems.",2024-12-18,"Ignace Bleukx, Hélène Verhaeghe, Bart Bogaerts, Tias Guns"
"Hybrid CNN-LSTM based Indoor Pedestrian Localization with CSI
  Fingerprint Maps","The paper presents a novel Wi-Fi fingerprinting system that uses Channel
State Information (CSI) data for fine-grained pedestrian localization. The
proposed system exploits the frequency diversity and spatial diversity of the
features extracted from CSI data to generate a 2D+channel image termed as a CSI
Fingerprint Map. We then use this CSI Fingerprint Map representation of CSI
data to generate a pedestrian trajectory hypothesis using a hybrid architecture
that combines a Convolutional Neural Network and a Long Short-Term Memory
Recurrent Neural Network model. The proposed architecture exploits the temporal
and spatial relationship information among the CSI data observations gathered
at neighboring locations. A particle filter is then employed to separate out
the most likely hypothesis matching a human walk model. The experimental
performance of our method is compared to existing deep learning localization
methods such ConFi, DeepFi and to a self-developed temporal-feature based LSTM
based location classifier. The experimental results show marked improvement
with an average RMSE of 0.36 m in a moderately dynamic and 0.17 m in a static
environment. Our method is essentially a proof of concept that with (1) sparse
availability of observations, (2) limited infrastructure requirements, (3)
moderate level of short-term and long-term noise in the training and testing
environment, reliable fine-grained Wi-Fi based pedestrian localization is a
potential option.",2024-12-18,Muhammad Emad-ud-din
SemiDFL: A Semi-Supervised Paradigm for Decentralized Federated Learning,"Decentralized federated learning (DFL) realizes cooperative model training
among connected clients without relying on a central server, thereby mitigating
communication bottlenecks and eliminating the single-point failure issue
present in centralized federated learning (CFL). Most existing work on DFL
focuses on supervised learning, assuming each client possesses sufficient
labeled data for local training. However, in real-world applications, much of
the data is unlabeled. We address this by considering a challenging yet
practical semisupervised learning (SSL) scenario in DFL, where clients may have
varying data sources: some with few labeled samples, some with purely unlabeled
data, and others with both. In this work, we propose SemiDFL, the first
semi-supervised DFL method that enhances DFL performance in SSL scenarios by
establishing a consensus in both data and model spaces. Specifically, we
utilize neighborhood information to improve the quality of pseudo-labeling,
which is crucial for effectively leveraging unlabeled data. We then design a
consensusbased diffusion model to generate synthesized data, which is used in
combination with pseudo-labeled data to create mixed datasets. Additionally, we
develop an adaptive aggregation method that leverages the model accuracy of
synthesized data to further enhance SemiDFL performance. Through extensive
experimentation, we demonstrate the remarkable performance superiority of the
proposed DFL-Semi method over existing CFL and DFL schemes in both IID and
non-IID SSL scenarios.",2024-12-18,"Xinyang Liu, Pengchao Han, Xuan Li, Bo Liu"
Verified invertible lexer using regular expressions and DFAs,"In this project, we explore the concept of invertibility applied to
serialisation and lexing frameworks. Recall that, on one hand, serialisation is
the process of taking a data structure and writing it to a bit array while
parsing is the reverse operation, i.e., reading the bit array and constructing
the data structure back. While lexing, on the other hand, is the process of
reading a stream of characters and splitting them into tokens, by following a
list of given rules. While used in different applications, both are similar in
their abstract operation: they both take a list of simple characters and
extract a more complex structure. Applications in which these two operations
are used are different but they share a need for the invertibility of the
process. For example, when tokenising a code file that was prettyprinted by a
compiler, one would expect to get the same sequence of tokens. Similarly, when
a spacecraft sends scientific data to the ground, one would expect the parsed
data to be the same as the one serialised by the spacecraft. The idea of this
project is to explore the idea of having a framework capable of generating
parser/serialiser or lexer/prettyprinter pairs with a formally verified notion
of invertibility. We first explore related works and frameworks. After that, we
present our verified lexer framework developed in Scala and verified using the
Stainless framework1. We explain the implementation choices we make and present
the specifications and their proofs. The code of the lexer with the proofs is
available on Github2. The main branch contains the regular expression (called
regex from now on) matcher version and the verified Computable Languages while
the dfa match branch contains the version using the DFA matcher.",2024-12-18,"Samuel Chassot, Viktor Kunčak"
PowerMLP: An Efficient Version of KAN,"The Kolmogorov-Arnold Network (KAN) is a new network architecture known for
its high accuracy in several tasks such as function fitting and PDE solving.
The superior expressive capability of KAN arises from the Kolmogorov-Arnold
representation theorem and learnable spline functions. However, the computation
of spline functions involves multiple iterations, which renders KAN
significantly slower than MLP, thereby increasing the cost associated with
model training and deployment. The authors of KAN have also noted that ``the
biggest bottleneck of KANs lies in its slow training. KANs are usually 10x
slower than MLPs, given the same number of parameters.'' To address this issue,
we propose a novel MLP-type neural network PowerMLP that employs simpler
non-iterative spline function representation, offering approximately the same
training time as MLP while theoretically demonstrating stronger expressive
power than KAN. Furthermore, we compare the FLOPs of KAN and PowerMLP,
quantifying the faster computation speed of PowerMLP. Our comprehensive
experiments demonstrate that PowerMLP generally achieves higher accuracy and a
training speed about 40 times faster than KAN in various tasks.",2024-12-18,"Ruichen Qiu, Yibo Miao, Shiwen Wang, Lijia Yu, Yifan Zhu, Xiao-Shan Gao"
"Combining Aggregated Attention and Transformer Architecture for Accurate
  and Efficient Performance of Spiking Neural Networks","Spiking Neural Networks have attracted significant attention in recent years
due to their distinctive low-power characteristics. Meanwhile, Transformer
models, known for their powerful self-attention mechanisms and parallel
processing capabilities, have demonstrated exceptional performance across
various domains, including natural language processing and computer vision.
Despite the significant advantages of both SNNs and Transformers, directly
combining the low-power benefits of SNNs with the high performance of
Transformers remains challenging. Specifically, while the sparse computing mode
of SNNs contributes to reduced energy consumption, traditional attention
mechanisms depend on dense matrix computations and complex softmax operations.
This reliance poses significant challenges for effective execution in low-power
scenarios. Given the tremendous success of Transformers in deep learning, it is
a necessary step to explore the integration of SNNs and Transformers to harness
the strengths of both. In this paper, we propose a novel model architecture,
Spike Aggregation Transformer (SAFormer), that integrates the low-power
characteristics of SNNs with the high-performance advantages of Transformer
models. The core contribution of SAFormer lies in the design of the Spike
Aggregated Self-Attention (SASA) mechanism, which significantly simplifies the
computation process by calculating attention weights using only the spike
matrices query and key, thereby effectively reducing energy consumption.
Additionally, we introduce a Depthwise Convolution Module (DWC) to enhance the
feature extraction capabilities, further improving overall accuracy. We
evaluated and demonstrated that SAFormer outperforms state-of-the-art SNNs in
both accuracy and energy consumption, highlighting its significant advantages
in low-power and high-performance computing.",2024-12-18,"Hangming Zhang, Alexander Sboev, Roman Rybka, Qiang Yu"
"TelePhantom: A User-Friendly Teleoperation System with Virtual
  Assistance for Enhanced Effectiveness","Dexterous manipulation is a critical area of robotics. In this field,
teleoperation faces three key challenges: user-friendliness for novices, safety
assurance, and transferability across different platforms. While collecting
real robot dexterous manipulation data by teleoperation to train robots has
shown impressive results on diverse tasks, due to the morphological differences
between human and robot hands, it is not only hard for new users to understand
the action mapping but also raises potential safety concerns during operation.
To address these limitations, we introduce TelePhantom. This teleoperation
system offers real-time visual feedback on robot actions based on human user
inputs, with a total hardware cost of less than $1,000. TelePhantom allows the
user to see a virtual robot that represents the outcome of the user's next
movement. By enabling flexible switching between command visualization and
actual execution, this system helps new users learn how to demonstrate quickly
and safely. We demonstrate its superiority over other teleoperation systems
across five tasks, emphasize its ease of use, and highlight its ease of
deployment across diverse input sensors and robotic platforms. We will release
our code and a deployment document on our website:
https://telephantom.github.io/.",2024-12-18,"Jingxiang Guo, Jiayu Luo, Zhenyu Wei, Yiwen Hou, Zhixuan Xu, Xiaoyi Lin, Chongkai Gao, Lin Shao"
"Turbo-GS: Accelerating 3D Gaussian Fitting for High-Quality Radiance
  Fields","Novel-view synthesis is an important problem in computer vision with
applications in 3D reconstruction, mixed reality, and robotics. Recent methods
like 3D Gaussian Splatting (3DGS) have become the preferred method for this
task, providing high-quality novel views in real time. However, the training
time of a 3DGS model is slow, often taking 30 minutes for a scene with 200
views. In contrast, our goal is to reduce the optimization time by training for
fewer steps while maintaining high rendering quality. Specifically, we combine
the guidance from both the position error and the appearance error to achieve a
more effective densification. To balance the rate between adding new Gaussians
and fitting old Gaussians, we develop a convergence-aware budget control
mechanism. Moreover, to make the densification process more reliable, we
selectively add new Gaussians from mostly visited regions. With these designs,
we reduce the Gaussian optimization steps to one-third of the previous approach
while achieving a comparable or even better novel view rendering quality. To
further facilitate the rapid fitting of 4K resolution images, we introduce a
dilation-based rendering technique. Our method, Turbo-GS, speeds up
optimization for typical scenes and scales well to high-resolution (4K)
scenarios on standard datasets. Through extensive experiments, we show that our
method is significantly faster in optimization than other methods while
retaining quality. Project page: https://ivl.cs.brown.edu/research/turbo-gs.",2024-12-18,"Tao Lu, Ankit Dhiman, R Srinath, Emre Arslan, Angela Xing, Yuanbo Xiangli, R Venkatesh Babu, Srinath Sridhar"
"Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations
  with Large Language Models","In recent years, knowledge graphs have been integrated into recommender
systems as item-side auxiliary information, enhancing recommendation accuracy.
However, constructing and integrating structural user-side knowledge remains a
significant challenge due to the improper granularity and inherent scarcity of
user-side features. Recent advancements in Large Language Models (LLMs) offer
the potential to bridge this gap by leveraging their human behavior
understanding and extensive real-world knowledge. Nevertheless, integrating
LLM-generated information into recommender systems presents challenges,
including the risk of noisy information and the need for additional knowledge
transfer. In this paper, we propose an LLM-based user-side knowledge inference
method alongside a carefully designed recommendation framework to address these
challenges. Our approach employs LLMs to infer user interests based on
historical behaviors, integrating this user-side information with item-side and
collaborative data to construct a hybrid structure: the Collaborative Interest
Knowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation
framework that includes a user interest reconstruction module and a
cross-domain contrastive learning module to mitigate potential noise and
facilitate knowledge transfer. We conduct extensive experiments on three
real-world datasets to validate the effectiveness of our method. Our approach
achieves state-of-the-art performance compared to competitive baselines,
particularly for users with sparse interactions.",2024-12-18,"Zheng Hu, Zhe Li, Ziyun Jiao, Satoshi Nakagawa, Jiawen Deng, Shimin Cai, Tao Zhou, Fuji Ren"
"Query-centric Audio-Visual Cognition Network for Moment Retrieval,
  Segmentation and Step-Captioning","Video has emerged as a favored multimedia format on the internet. To better
gain video contents, a new topic HIREST is presented, including video
retrieval, moment retrieval, moment segmentation, and step-captioning. The
pioneering work chooses the pre-trained CLIP-based model for video retrieval,
and leverages it as a feature extractor for other three challenging tasks
solved in a multi-task learning paradigm. Nevertheless, this work struggles to
learn the comprehensive cognition of user-preferred content, due to
disregarding the hierarchies and association relations across modalities. In
this paper, guided by the shallow-to-deep principle, we propose a query-centric
audio-visual cognition (QUAG) network to construct a reliable multi-modal
representation for moment retrieval, segmentation and step-captioning.
Specifically, we first design the modality-synergistic perception to obtain
rich audio-visual content, by modeling global contrastive alignment and local
fine-grained interaction between visual and audio modalities. Then, we devise
the query-centric cognition that uses the deep-level query to perform the
temporal-channel filtration on the shallow-level audio-visual representation.
This can cognize user-preferred content and thus attain a query-centric
audio-visual representation for three tasks. Extensive experiments show QUAG
achieves the SOTA results on HIREST. Further, we test QUAG on the query-based
video summarization task and verify its good generalization.",2024-12-18,"Yunbin Tu, Liang Li, Li Su, Qingming Huang"
"Spatio-Temporal Fuzzy-oriented Multi-Modal Meta-Learning for
  Fine-grained Emotion Recognition","Fine-grained emotion recognition (FER) plays a vital role in various fields,
such as disease diagnosis, personalized recommendations, and multimedia mining.
However, existing FER methods face three key challenges in real-world
applications: (i) they rely on large amounts of continuously annotated data to
ensure accuracy since emotions are complex and ambiguous in reality, which is
costly and time-consuming; (ii) they cannot capture the temporal heterogeneity
caused by changing emotion patterns, because they usually assume that the
temporal correlation within sampling periods is the same; (iii) they do not
consider the spatial heterogeneity of different FER scenarios, that is, the
distribution of emotion information in different data may have bias or
interference. To address these challenges, we propose a Spatio-Temporal
Fuzzy-oriented Multi-modal Meta-learning framework (ST-F2M). Specifically,
ST-F2M first divides the multi-modal videos into multiple views, and each view
corresponds to one modality of one emotion. Multiple randomly selected views
for the same emotion form a meta-training task. Next, ST-F2M uses an integrated
module with spatial and temporal convolutions to encode the data of each task,
reflecting the spatial and temporal heterogeneity. Then it adds fuzzy semantic
information to each task based on generalized fuzzy rules, which helps handle
the complexity and ambiguity of emotions. Finally, ST-F2M learns
emotion-related general meta-knowledge through meta-recurrent neural networks
to achieve fast and robust fine-grained emotion recognition. Extensive
experiments show that ST-F2M outperforms various state-of-the-art methods in
terms of accuracy and model efficiency. In addition, we construct ablation
studies and further analysis to explore why ST-F2M performs well.",2024-12-18,"Jingyao Wang, Yuxuan Yang, Wenwen Qiang, Changwen Zheng, Hui Xiong"
"Lyapunov Analysis For Monotonically Forward-Backward Accelerated
  Algorithms","In the realm of gradient-based optimization, Nesterov's accelerated gradient
method (NAG) is a landmark advancement, achieving an accelerated convergence
rate that outperforms the vanilla gradient descent method for convex function.
However, for strongly convex functions, whether NAG converges linearly remains
an open question, as noted in the comprehensive review by Chambolle and Pock
[2016]. This issue, aside from the critical step size, was addressed by Li et
al. [2024a] using a high-resolution differential equation framework.
Furthermore, Beck [2017, Section 10.7.4] introduced a monotonically convergent
variant of NAG, referred to as M-NAG. Despite these developments, the Lyapunov
analysis presented in [Li et al., 2024a] cannot be directly extended to M-NAG.
In this paper, we propose a modification to the iterative relation by
introducing a gradient term, leading to a new gradient-based iterative
relation. This adjustment allows for the construction of a novel Lyapunov
function that excludes kinetic energy. The linear convergence derived from this
Lyapunov function is independent of both the parameters of the strongly convex
functions and the step size, yielding a more general and robust result.
Notably, we observe that the gradient iterative relation derived from M-NAG is
equivalent to that from NAG when the position-velocity relation is applied.
However, the Lyapunov analysis does not rely on the position-velocity relation,
allowing us to extend the linear convergence to M-NAG. Finally, by utilizing
two proximal inequalities, which serve as the proximal counterparts of strongly
convex inequalities, we extend the linear convergence to both the fast
iterative shrinkage-thresholding algorithm (FISTA) and its monotonic
counterpart (M-FISTA).",2024-12-18,"Mingwei Fu, Bin Shi"
Tuning Music Education: AI-Powered Personalization in Learning Music,"Recent AI-driven step-function advances in several longstanding problems in
music technology are opening up new avenues to create the next generation of
music education tools. Creating personalized, engaging, and effective learning
experiences are continuously evolving challenges in music education. Here we
present two case studies using such advances in music technology to address
these challenges. In our first case study we showcase an application that uses
Automatic Chord Recognition to generate personalized exercises from audio
tracks, connecting traditional ear training with real-world musical contexts.
In the second case study we prototype adaptive piano method books that use
Automatic Music Transcription to generate exercises at different skill levels
while retaining a close connection to musical interests. These applications
demonstrate how recent AI developments can democratize access to high-quality
music education and promote rich interaction with music in the age of
generative AI. We hope this work inspires other efforts in the community, aimed
at removing barriers to access to high-quality music education and fostering
human participation in musical expression.",2024-12-18,"Mayank Sanganeria, Rohan Gala"
CEHA: A Dataset of Conflict Events in the Horn of Africa,"Natural Language Processing (NLP) of news articles can play an important role
in understanding the dynamics and causes of violent conflict. Despite the
availability of datasets categorizing various conflict events, the existing
labels often do not cover all of the fine-grained violent conflict event types
relevant to areas like the Horn of Africa. In this paper, we introduce a new
benchmark dataset Conflict Events in the Horn of Africa region (CEHA) and
propose a new task for identifying violent conflict events using online
resources with this dataset. The dataset consists of 500 English event
descriptions regarding conflict events in the Horn of Africa region with
fine-grained event-type definitions that emphasize the cause of the conflict.
This dataset categorizes the key types of conflict risk according to specific
areas required by stakeholders in the Humanitarian-Peace-Development Nexus.
Additionally, we conduct extensive experiments on two tasks supported by this
dataset: Event-relevance Classification and Event-type Classification. Our
baseline models demonstrate the challenging nature of these tasks and the
usefulness of our dataset for model evaluations in low-resource settings with
limited number of training data.",2024-12-18,"Rui Bai, Di Lu, Shihao Ran, Elizabeth Olson, Hemank Lamba, Aoife Cahill, Joel Tetreault, Alex Jaimes"
"Dynamic Adapter with Semantics Disentangling for Cross-lingual
  Cross-modal Retrieval","Existing cross-modal retrieval methods typically rely on large-scale
vision-language pair data. This makes it challenging to efficiently develop a
cross-modal retrieval model for under-resourced languages of interest.
Therefore, Cross-lingual Cross-modal Retrieval (CCR), which aims to align
vision and the low-resource language (the target language) without using any
human-labeled target-language data, has gained increasing attention. As a
general parameter-efficient way, a common solution is to utilize adapter
modules to transfer the vision-language alignment ability of Vision-Language
Pretraining (VLP) models from a source language to a target language. However,
these adapters are usually static once learned, making it difficult to adapt to
target-language captions with varied expressions. To alleviate it, we propose
Dynamic Adapter with Semantics Disentangling (DASD), whose parameters are
dynamically generated conditioned on the characteristics of the input captions.
Considering that the semantics and expression styles of the input caption
largely influence how to encode it, we propose a semantic disentangling module
to extract the semantic-related and semantic-agnostic features from the input,
ensuring that generated adapters are well-suited to the characteristics of
input caption. Extensive experiments on two image-text datasets and one
video-text dataset demonstrate the effectiveness of our model for cross-lingual
cross-modal retrieval, as well as its good compatibility with various VLP
models.",2024-12-18,"Rui Cai, Zhiyu Dong, Jianfeng Dong, Xun Wang"
Urban Air Temperature Prediction using Conditional Diffusion Models,"Urbanization as a global trend has led to many environmental challenges,
including the urban heat island (UHI) effect. The increase in temperature has a
significant impact on the well-being of urban residents. Air temperature
($T_a$) at 2m above the surface is a key indicator of the UHI effect. How land
use land cover (LULC) affects $T_a$ is a critical research question which
requires high-resolution (HR) $T_a$ data at neighborhood scale. However,
weather stations providing $T_a$ measurements are sparsely distributed e.g.
more than 10km apart; and numerical models are impractically slow and
computationally expensive. In this work, we propose a novel method to predict
HR $T_a$ at 100m ground separation distance (gsd) using land surface
temperature (LST) and other LULC related features which can be easily obtained
from satellite imagery. Our method leverages diffusion models for the first
time to generate accurate and visually realistic HR $T_a$ maps, which
outperforms prior methods. We pave the way for meteorological research using
computer vision techniques by providing a dataset of an extended spatial and
temporal coverage, and a high spatial resolution as a benchmark for future
research. Furthermore, we show that our model can be applied to urban planning
by simulating the impact of different urban designs on $T_a$.",2024-12-18,"Siyang Dai, Jun Liu, Ngai-Man Cheung"
"QueryCDR: Query-based Controllable Distortion Rectification Network for
  Fisheye Images","Fisheye image rectification aims to correct distortions in images taken with
fisheye cameras. Although current models show promising results on images with
a similar degree of distortion as the training data, they will produce
sub-optimal results when the degree of distortion changes and without
retraining. The lack of generalization ability for dealing with varying degrees
of distortion limits their practical application. In this paper, we take one
step further to enable effective distortion rectification for images with
varying degrees of distortion without retraining. We propose a novel
Query-based Controllable Distortion Rectification network for fisheye images
(QueryCDR). In particular, we first present the Distortion-aware Learnable
Query Mechanism (DLQM), which defines the latent spatial relationships for
different distortion degrees as a series of learnable queries. Each query can
be learned to obtain position-dependent rectification control conditions,
providing control over the rectification process. Then, we propose two kinds of
controllable modulating blocks to enable the control conditions to guide the
modulation of the distortion features better. These core components cooperate
with each other to effectively boost the generalization ability of the model at
varying degrees of distortion. Extensive experiments on fisheye image datasets
with different distortion degrees demonstrate our approach achieves
high-quality and controllable distortion rectification.",2024-12-18,"Pengbo Guo, Chengxu Liu, Xingsong Hou, Xueming Qian"
Federated t-SNE and UMAP for Distributed Data Visualization,"High-dimensional data visualization is crucial in the big data era and these
techniques such as t-SNE and UMAP have been widely used in science and
engineering. Big data, however, is often distributed across multiple data
centers and subject to security and privacy concerns, which leads to
difficulties for the standard algorithms of t-SNE and UMAP. To tackle the
challenge, this work proposes Fed-tSNE and Fed-UMAP, which provide
high-dimensional data visualization under the framework of federated learning,
without exchanging data across clients or sending data to the central server.
The main idea of Fed-tSNE and Fed-UMAP is implicitly learning the distribution
information of data in a manner of federated learning and then estimating the
global distance matrix for t-SNE and UMAP. To further enhance the protection of
data privacy, we propose Fed-tSNE+ and Fed-UMAP+. We also extend our idea to
federated spectral clustering, yielding algorithms of clustering distributed
data. In addition to these new algorithms, we offer theoretical guarantees of
optimization convergence, distance and similarity estimation, and differential
privacy. Experiments on multiple datasets demonstrate that, compared to the
original algorithms, the accuracy drops of our federated algorithms are tiny.",2024-12-18,"Dong Qiao, Xinxian Ma, Jicong Fan"
Real-time One-Step Diffusion-based Expressive Portrait Videos Generation,"Latent diffusion models have made great strides in generating expressive
portrait videos with accurate lip-sync and natural motion from a single
reference image and audio input. However, these models are far from real-time,
often requiring many sampling steps that take minutes to generate even one
second of video-significantly limiting practical use. We introduce OSA-LCM
(One-Step Avatar Latent Consistency Model), paving the way for real-time
diffusion-based avatars. Our method achieves comparable video quality to
existing methods but requires only one sampling step, making it more than 10x
faster. To accomplish this, we propose a novel avatar discriminator design that
guides lip-audio consistency and motion expressiveness to enhance video quality
in limited sampling steps. Additionally, we employ a second-stage training
architecture using an editing fine-tuned method (EFT), transforming video
generation into an editing task during training to effectively address the
temporal gap challenge in single-step generation. Experiments demonstrate that
OSA-LCM outperforms existing open-source portrait video generation models while
operating more efficiently with a single sampling step.",2024-12-18,"Hanzhong Guo, Hongwei Yi, Daquan Zhou, Alexander William Bergman, Michael Lingelbach, Yizhou Yu"
"A Statistical and Multi-Perspective Revisiting of the Membership
  Inference Attack in Large Language Models","The lack of data transparency in Large Language Models (LLMs) has highlighted
the importance of Membership Inference Attack (MIA), which differentiates
trained (member) and untrained (non-member) data. Though it shows success in
previous studies, recent research reported a near-random performance in
different settings, highlighting a significant performance inconsistency. We
assume that a single setting doesn't represent the distribution of the vast
corpora, causing members and non-members with different distributions to be
sampled and causing inconsistency. In this study, instead of a single setting,
we statistically revisit MIA methods from various settings with thousands of
experiments for each MIA method, along with study in text feature, embedding,
threshold decision, and decoding dynamics of members and non-members. We found
that (1) MIA performance improves with model size and varies with domains,
while most methods do not statistically outperform baselines, (2) Though MIA
performance is generally low, a notable amount of differentiable member and
non-member outliers exists and vary across MIA methods, (3) Deciding a
threshold to separate members and non-members is an overlooked challenge, (4)
Text dissimilarity and long text benefit MIA performance, (5) Differentiable or
not is reflected in the LLM embedding, (6) Member and non-members show
different decoding dynamics.",2024-12-18,"Bowen Chen, Namgi Han, Yusuke Miyao"
"Learning complexity of gradient descent and conjugate gradient
  algorithms","Gradient Descent (GD) and Conjugate Gradient (CG) methods are among the most
effective iterative algorithms for solving unconstrained optimization problems,
particularly in machine learning and statistical modeling, where they are
employed to minimize cost functions. In these algorithms, tunable parameters,
such as step sizes or conjugate parameters, play a crucial role in determining
key performance metrics, like runtime and solution quality. In this work, we
introduce a framework that models algorithm selection as a statistical learning
problem, and thus learning complexity can be estimated by the pseudo-dimension
of the algorithm group. We first propose a new cost measure for unconstrained
optimization algorithms, inspired by the concept of primal-dual integral in
mixed-integer linear programming. Based on the new cost measure, we derive an
improved upper bound for the pseudo-dimension of gradient descent algorithm
group by discretizing the set of step size configurations. Moreover, we
generalize our findings from gradient descent algorithm to the conjugate
gradient algorithm group for the first time, and prove the existence a learning
algorithm capable of probabilistically identifying the optimal algorithm with a
sufficiently large sample size.",2024-12-18,"Xianqi Jiao, Jia Liu, Zhiping Chen"
FlexPose: Pose Distribution Adaptation with Limited Guidance,"Numerous well-annotated human key-point datasets are publicly available to
date. However, annotating human poses for newly collected images is still a
costly and time-consuming progress. Pose distributions from different datasets
share similar pose hinge-structure priors with different geometric
transformations, such as pivot orientation, joint rotation, and bone length
ratio. The difference between Pose distributions is essentially the difference
between the transformation distributions. Inspired by this fact, we propose a
method to calibrate a pre-trained pose generator in which the pose prior has
already been learned to an adapted one following a new pose distribution. We
treat the representation of human pose joint coordinates as skeleton image and
transfer a pre-trained pose annotation generator with only a few annotation
guidance. By fine-tuning a limited number of linear layers that closely related
to the pose transformation, the adapted generator is able to produce any number
of pose annotations that are similar to the target poses. We evaluate our
proposed method, FlexPose, on several cross-dataset settings both qualitatively
and quantitatively, which demonstrates that our approach achieves
state-of-the-art performance compared to the existing generative-model-based
transfer learning methods when given limited annotation guidance.",2024-12-18,"Zixiao Wang, Junwu Weng, Mengyuan Liu, Bei Yu"
"Pre-training a Density-Aware Pose Transformer for Robust LiDAR-based 3D
  Human Pose Estimation","With the rapid development of autonomous driving, LiDAR-based 3D Human Pose
Estimation (3D HPE) is becoming a research focus. However, due to the noise and
sparsity of LiDAR-captured point clouds, robust human pose estimation remains
challenging. Most of the existing methods use temporal information, multi-modal
fusion, or SMPL optimization to correct biased results. In this work, we try to
obtain sufficient information for 3D HPE only by modeling the intrinsic
properties of low-quality point clouds. Hence, a simple yet powerful method is
proposed, which provides insights both on modeling and augmentation of point
clouds. Specifically, we first propose a concise and effective density-aware
pose transformer (DAPT) to get stable keypoint representations. By using a set
of joint anchors and a carefully designed exchange module, valid information is
extracted from point clouds with different densities. Then 1D heatmaps are
utilized to represent the precise locations of the keypoints. Secondly, a
comprehensive LiDAR human synthesis and augmentation method is proposed to
pre-train the model, enabling it to acquire a better human body prior. We
increase the diversity of point clouds by randomly sampling human positions and
orientations and by simulating occlusions through the addition of laser-level
masks. Extensive experiments have been conducted on multiple datasets,
including IMU-annotated LidarHuman26M, SLOPER4D, and manually annotated Waymo
Open Dataset v2.0 (Waymo), HumanM3. Our method demonstrates SOTA performance in
all scenarios. In particular, compared with LPFormer on Waymo, we reduce the
average MPJPE by $10.0mm$. Compared with PRN on SLOPER4D, we notably reduce the
average MPJPE by $20.7mm$.",2024-12-18,"Xiaoqi An, Lin Zhao, Chen Gong, Jun Li, Jian Yang"
"Communication-Efficient Personalized Federal Graph Learning via Low-Rank
  Decomposition","Federated graph learning (FGL) has gained significant attention for enabling
heterogeneous clients to process their private graph data locally while
interacting with a centralized server, thus maintaining privacy. However, graph
data on clients are typically non-IID, posing a challenge for a single model to
perform well across all clients. Another major bottleneck of FGL is the high
cost of communication. To address these challenges, we propose a
communication-efficient personalized federated graph learning algorithm, CEFGL.
Our method decomposes the model parameters into low-rank generic and sparse
private models. We employ a dual-channel encoder to learn sparse local
knowledge in a personalized manner and low-rank global knowledge in a shared
manner. Additionally, we perform multiple local stochastic gradient descent
iterations between communication phases and integrate efficient compression
techniques into the algorithm. The advantage of CEFGL lies in its ability to
capture common and individual knowledge more precisely. By utilizing low-rank
and sparse parameters along with compression techniques, CEFGL significantly
reduces communication complexity. Extensive experiments demonstrate that our
method achieves optimal classification accuracy in a variety of heterogeneous
environments across sixteen datasets. Specifically, compared to the
state-of-the-art method FedStar, the proposed method (with GIN as the base
model) improves accuracy by 5.64\% on cross-datasets setting CHEM, reduces
communication bits by a factor of 18.58, and reduces the communication time by
a factor of 1.65.",2024-12-18,"Ruyue Liu, Rong Yin, Xiangzhen Bo, Xiaoshuai Hao, Xingrui Zhou, Yong Liu, Can Ma, Weiping Wang"
"Safeguarding Virtual Healthcare: A Novel Attacker-Centric Model for Data
  Security and Privacy","The rapid growth of remote healthcare delivery has introduced significant
security and privacy risks to protected health information (PHI). Analysis of a
comprehensive healthcare security breach dataset covering 2009-2023 reveals
their significant prevalence and impact. This study investigates the root
causes of such security incidents and introduces the Attacker-Centric Approach
(ACA), a novel threat model tailored to protect PHI. ACA addresses limitations
in existing threat models and regulatory frameworks by adopting a holistic
attacker-focused perspective, examining threats from the viewpoint of cyber
adversaries, their motivations, tactics, and potential attack vectors.
Leveraging established risk management frameworks, ACA provides a multi-layered
approach to threat identification, risk assessment, and proactive mitigation
strategies. A comprehensive threat library classifies physical, third-party,
external, and internal threats. ACA's iterative nature and feedback mechanisms
enable continuous adaptation to emerging threats, ensuring sustained
effectiveness. ACA allows healthcare providers to proactively identify and
mitigate vulnerabilities, fostering trust and supporting the secure adoption of
virtual care technologies.",2024-12-18,"Suvineetha Herath, Haywood Gelman, John Hastings, Yong Wang"
"Magnifier: Detecting Network Access via Lightweight Traffic-based
  Fingerprints","Network access detection plays a crucial role in global network management,
enabling efficient network monitoring and topology measurement by identifying
unauthorized network access and gathering detailed information about mobile
devices. Existing methods for endpoint-based detection primarily rely on
deploying monitoring software to recognize network connections. However, the
challenges associated with developing and maintaining such systems have limited
their universality and coverage in practical deployments, especially given the
cost implications of covering a wide array of devices with heterogeneous
operating systems. To tackle the issues, we propose Magnifier for mobile device
network access detection that, for the first time, passively infers access
patterns from backbone traffic at the gateway level. Magnifier's foundation is
the creation of device-specific access patterns using the innovative Domain
Name Forest (dnForest) fingerprints. We then employ a two-stage distillation
algorithm to fine-tune the weights of individual Domain Name Trees (dnTree)
within each dnForest, emphasizing the unique device fingerprints. With these
meticulously crafted fingerprints, Magnifier efficiently infers network access
from backbone traffic using a lightweight fingerprint matching algorithm. Our
experimental results, conducted in real-world scenarios, demonstrate that
Magnifier exhibits exceptional universality and coverage in both initial and
repetitive network access detection in real-time. To facilitate further
research, we have thoughtfully curated the NetCess2023 dataset, comprising
network access data from 26 different models across 7 brands, covering the
majority of mainstream mobile devices. We have also made both the Magnifier
prototype and the NetCess2023 dataset publicly
available\footnote{https://github.com/SecTeamPolaris/Magnifier}.",2024-12-18,"Wenhao Li, Qiang Wang, Huaifeng Bao, Xiao-Yu Zhang, Lingyun Ying, Zhaoxuan Li"
"What Human-Horse Interactions may Teach us About Effective Human-AI
  Interactions","This article explores human-horse interactions as a metaphor for
understanding and designing effective human-AI partnerships. Drawing on the
long history of human collaboration with horses, we propose that AI, like
horses, should complement rather than replace human capabilities. We move
beyond traditional benchmarks such as the Turing test, which emphasize AI's
ability to mimic human intelligence, and instead advocate for a symbiotic
relationship where distinct intelligences enhance each other. We analyze key
elements of human-horse relationships: trust, communication, and mutual
adaptability, to highlight essential principles for human-AI collaboration.
Trust is critical in both partnerships, built through predictability and shared
understanding, while communication and feedback loops foster mutual
adaptability. We further discuss the importance of taming and habituation in
shaping these interactions, likening it to how humans train AI to perform
reliably and ethically in real-world settings. The article also addresses the
asymmetry of responsibility, where humans ultimately bear the greater burden of
oversight and ethical judgment. Finally, we emphasize that long-term commitment
and continuous learning are vital in both human-horse and human-AI
relationships, as ongoing interaction refines the partnership and increases
mutual adaptability. By drawing on these insights from human-horse
interactions, we offer a vision for designing AI systems that are trustworthy,
adaptable, and capable of fostering symbiotic human-AI partnerships.",2024-12-18,"Mohammad Hossein Jarrahi, Stanley Ahalt"
"Pattern Matching in AI Compilers and its Formalization (Extended
  Version)","PyPM is a Python-based domain specific language (DSL) for building
rewrite-based optimization passes on machine learning computation graphs. Users
define individual optimizations by writing (a) patterns that match subgraphs of
a computation graph and (b) corresponding rules which replace a matched
subgraph with an optimized kernel. PyPM is distinguished from the many other
DSLs for defining rewriting passes by its complex and novel pattern language
which borrows concepts from logic programming. PyPM patterns can be recursive,
nondeterminstic, and can require checking domain-specific constraints such as
the shapes of tensors. The PyPM implementation is thus similarly complicated,
consisting of thousands of lines of C++ code. In this paper, we present our
work on building PyPM, as well as formalizing and distilling and this
complexity to an understandable mathematical core. We have developed a formal
core calculus expressing the main operations of the PyPM pattern language. We
define both a declarative semantics - describing which patterns match which
terms - and an algorithmic semantics - an idealized version of the PyPM pattern
interpreter - and prove their equivalence. The development is fully mechanized
in the Coq proof assistant.",2024-12-18,"Joseph W. Cutler, Alex Collins, Bin Fan, Mahesh Ravishankar, Vinod Grover"
An Exploratory Study of ML Sketches and Visual Code Assistants,"This paper explores the integration of Visual Code Assistants in Integrated
Development Environments (IDEs). In Software Engineering, whiteboard sketching
is often the initial step before coding, serving as a crucial collaboration
tool for developers. Previous studies have investigated patterns in SE sketches
and how they are used in practice, yet methods for directly using these
sketches for code generation remain limited. The emergence of visually-equipped
large language models presents an opportunity to bridge this gap, which is the
focus of our research. In this paper, we built a first prototype of a Visual
Code Assistant to get user feedback regarding in-IDE sketch-to-code tools. We
conduct an experiment with 19 data scientists, most of whom regularly sketch as
part of their job. We investigate developers' mental models by analyzing
patterns commonly observed in their sketches when developing an ML workflow.
Analysis indicates that diagrams were the preferred organizational component
(52.6%), often accompanied by lists (42.1%) and numbered points (36.8%). Our
tool converts their sketches into a Python notebook by querying an LLM. We use
an LLM-as-judge setup to score the quality of the generated code, finding that
even brief sketching can effectively generate useful code outlines. We also
find a positive correlation between sketch time and the quality of the
generated code. We conclude the study by conducting extensive interviews to
assess the tool's usefulness, explore potential use cases, and understand
developers' needs. As noted by participants, promising applications for these
assistants include education, prototyping, and collaborative settings. Our
findings signal promise for the next generation of Code Assistants to integrate
visual information, both to improve code generation and to better leverage
developers' existing sketching practices.",2024-12-17,"Luís F. Gomes, Vincent J. Hellendoorn, Jonathan Aldrich, Rui Abreu"
"Voter Priming Campaigns: Strategies, Equilibria, and Algorithms","Issue salience is a major determinant in voters' decisions. Candidates and
political parties campaign to shift salience to their advantage - a process
termed priming. We study the dynamics, strategies and equilibria of campaign
spending for voter priming in multi-issue multi-party settings. We consider
both parliamentary elections, where parties aim to maximize their share of
votes, and various settings for presidential elections, where the winner takes
all. For parliamentary elections, we show that pure equilibrium spending always
exists and can be computed in time linear in the number of voters. For two
parties and all settings, a spending equilibrium exists such that each party
invests only in a single issue, and an equilibrium can be computed in time that
is polynomial in the number of issues and linear in the number of voters. We
also show that in most presidential settings no equilibrium exists. Additional
properties of optimal campaign strategies are also studied.",2024-12-17,"Jonathan Shaki, Yonatan Aumann, Sarit Kraus"
"Extending LLMs to New Languages: A Case Study of Llama and Persian
  Adaptation","Large language models (LLMs) have made great progress in classification and
text generation tasks. However, they are mainly trained on English data and
often struggle with low-resource languages. In this study, we explore adding a
new language, i.e., Persian, to Llama (a model with a limited understanding of
Persian) using parameter-efficient fine-tuning. We employ a multi-stage
approach involving pretraining on monolingual Persian data, aligning
representations through bilingual pretraining and instruction datasets, and
instruction-tuning with task-specific datasets. We evaluate the model's
performance at each stage on generation and classification tasks. Our findings
suggest that incorporating the Persian language, through bilingual data
alignment, can enhance classification accuracy for Persian tasks, with no
adverse impact and sometimes even improvements on English tasks. Additionally,
the results highlight the model's initial strength as a critical factor when
working with limited training data, with cross-lingual alignment offering
minimal benefits for the low-resource language. Knowledge transfer from English
to Persian has a marginal effect, primarily benefiting simple classification
tasks.",2024-12-17,"Samin Mahdizadeh Sani, Pouya Sadeghi, Thuy-Trang Vu, Yadollah Yaghoobzadeh, Gholamreza Haffari"
"Inverse design of anisotropic microstructures using physics-augmented
  neural networks","Composite materials often exhibit mechanical anisotropy owing to the material
properties or geometrical configurations of the microstructure. This makes
their inverse design a two-fold problem. First, we must learn the type and
orientation of anisotropy and then find the optimal design parameters to
achieve the desired mechanical response. In our work, we solve this challenge
by first training a forward surrogate model based on the macroscopic
stress-strain data obtained via computational homogenization for a given
multiscale material. To this end, we use partially Input Convex Neural Networks
(pICNNs) to obtain a polyconvex representation of the strain energy in terms of
the invariants of the Cauchy-Green deformation tensor. The network architecture
and the strain energy function are modified to incorporate, by construction,
physics and mechanistic assumptions into the framework. While training the
neural network, we find the type of anisotropy, if any, along with the
preferred directions. Once the model is trained, we solve the inverse problem
using an evolution strategy to obtain the design parameters that give a desired
mechanical response. We test the framework against synthetic macroscale and
also homogenized data. For cases where polyconvexity might be violated during
the homogenization process, we present viable alternate formulations. The
trained model is also integrated into a finite element framework to invert
design parameters that result in a desired macroscopic response. We show that
the invariant-based model is able to solve the inverse problem for a
stress-strain dataset with a different preferred direction than the one it was
trained on and is able to not only learn the polyconvex potentials of
hyperelastic materials but also recover the correct parameters for the inverse
design problem.",2024-12-17,"Asghar A. Jadoon, Karl A. Kalina, Manuel K. Rausch, Reese Jones, Jan N. Fuhg"
"Quantitative Predictive Monitoring and Control for Safe Human-Machine
  Interaction","There is a growing trend toward AI systems interacting with humans to
revolutionize a range of application domains such as healthcare and
transportation. However, unsafe human-machine interaction can lead to
catastrophic failures. We propose a novel approach that predicts future states
by accounting for the uncertainty of human interaction, monitors whether
predictions satisfy or violate safety requirements, and adapts control actions
based on the predictive monitoring results. Specifically, we develop a new
quantitative predictive monitor based on Signal Temporal Logic with Uncertainty
(STL-U) to compute a robustness degree interval, which indicates the extent to
which a sequence of uncertain predictions satisfies or violates an STL-U
requirement. We also develop a new loss function to guide the uncertainty
calibration of Bayesian deep learning and a new adaptive control method, both
of which leverage STL-U quantitative predictive monitoring results. We apply
the proposed approach to two case studies: Type 1 Diabetes management and
semi-autonomous driving. Experiments show that the proposed approach improves
safety and effectiveness in both case studies.",2024-12-17,"Shuyang Dong, Meiyi Ma, Josephine Lamp, Sebastian Elbaum, Matthew B. Dwyer, Lu Feng"
On Stable Approximation Algorithms for Geometric Coverage Problems,"Let $P$ be a set of points in the plane and let $m$ be an integer. The goal
of Max Cover by Unit Disks problem is to place $m$ unit disks whose union
covers the maximum number of points from~$P$. We are interested in the dynamic
version of Max Cover by Unit Disks problem, where the points in $P$ appear and
disappear over time, and the algorithm must maintain a set \cDalg of $m$ disks
whose union covers many points. A dynamic algorithm for this problem is a
$k$-stable $\alpha$-approximation algorithm when it makes at most $k$ changes
to \cDalg upon each update to the set $P$ and the number of covered points at
time $t$ is always at least $\alpha \cdot \opt(t)$, where $\opt(t)$ is the
maximum number of points that can be covered by m disks at time $t$. We show
that for any constant $\varepsilon>0$, there is a $k_{\varepsilon}$-stable
$(1-\varepsilon)$-approximation algorithm for the dynamic Max Cover by Unit
Disks problem, where $k_{\varepsilon}=O(1/\varepsilon^3)$. This improves the
stability of $\Theta(1/\eps^4)$ that can be obtained by combining results of
Chaplick, De, Ravsky, and Spoerhase (ESA 2018) and De~Berg, Sadhukhan, and
Spieksma (APPROX 2023). Our result extends to other fat similarly-sized objects
used in the covering, such as arbitrarily-oriented unit squares, or
arbitrarily-oriented fat ellipses of fixed diameter.
  We complement the above result by showing that the restriction to fat objects
is necessary to obtain a SAS. To this end, we study the Max Cover by Unit
Segments problem, where the goal is to place $m$ unit-length segments whose
union covers the maximum number of points from $P$. We show that there is a
constant $\varepsilon^* > 0$ such that any $k$-stable $(1 +
\varepsilon^*)$-approximation algorithm must have $k=\Omega(m)$, even when the
point set never has more than four collinear points.",2024-12-17,"Mark de Berg, Arpan Sadhukhan"
"Key Exchange in the Quantum Era: Evaluating a Hybrid System of
  Public-Key Cryptography and Physical-Layer Security","Today's information society relies on cryptography to achieve security goals
such as confidentiality, integrity, authentication, and non-repudiation for
digital communications. Here, public-key cryptosystems play a pivotal role to
share encryption keys and create digital signatures. However, quantum computers
threaten the security of traditional public-key cryptosystems as they can tame
computational problems underlying the schemes, i.e., discrete logarithm and
integer factorization. The prospective arrival of capable-enough quantum
computers already threatens today's secret communication in terms of their
long-term secrecy when stored to be later decrypted. Therefore, researchers
strive to develop and deploy alternative schemes.
  In this work, evaluate a key exchange protocol based on combining public-key
schemes with physical-layer security, anticipating the prospect of quantum
attacks. If powerful quantum attackers cannot immediately obtain private keys,
legitimate parties have a window of short-term secrecy to perform a
physical-layer jamming key exchange (JKE) to establish a long-term shared
secret. Thereby, the protocol constraints the computation time available to the
attacker to break the employed public-key cryptography. In this paper, we
outline the protocol, discuss its security, and point out challenges to be
resolved.",2024-12-17,"Paul Staat, Meik Dörpinghaus, Azadeh Sheikholeslami, Christof Paar, Gerhard Fettweis, Dennis Goeckel"
"Improving essay peer grading accuracy in MOOCs using personalized
  weights from student's engagement and performance","Most MOOC platforms either use simple schemes for aggregating peer grades,
e.g., taking the mean or the median, or apply methodologies that increase
students' workload considerably, such as calibrated peer review. To reduce the
error between the instructor and students' aggregated scores in the simple
schemes, without requiring demanding grading calibration phases, some proposals
compute specific weights to compute a weighted aggregation of the peer grades.
In this work, and in contrast to most previous studies, we analyse the use of
students' engagement and performance measures to compute personalized weights
and study the validity of the aggregated scores produced by these common
functions, mean and median, together with two other from the information
retrieval field, namely the geometric and harmonic means. To test this
procedure we have analysed data from a MOOC about Philosophy. The course had
1059 students registered, and 91 participated in a peer review process that
consisted in writing an essay and rating three of their peers using a rubric.
We calculated and compared the aggregation scores obtained using weighted and
non-weighted versions. Our results show that the validity of the aggregated
scores and their correlation with the instructors grades can be improved in
relation to peer grading, when using the median and weights are computed
according to students' performance in chapter tests.",2024-12-17,"Carlos García-Martínez, Rebeca Cerezo, Manuel Bermúdez, Cristóbal Romero"
"Accelerating the Operation of Complex Workflows through Standard Data
  Interfaces","In this position paper we argue for standardizing how we share and process
data in scientific workflows at the network-level to maximize step re-use and
workflow portability across platforms and networks in pursuit of a foundational
workflow stack. We look to evolve workflows from steps connected point-to-point
in a directed acyclic graph (DAG) to steps connected via shared channels in a
message system implemented as a network service. To start this evolution, we
contribute: a preliminary reference model, architecture, and open tools to
implement the architecture today. Our goal stands to improve the deployment and
operation of complex workflows by decoupling data sharing and data processing
in workflow steps. We seek the workflow community's input on this approach's
merit, related research to explore and initial requirements from the workflows
community to inform future research.",2024-12-17,"Taylor Paul, William Regli"
"Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small
  LLMs","The rise of large language models (LLMs) has created a significant disparity:
industrial research labs with their computational resources, expert teams, and
advanced infrastructures, can effectively fine-tune LLMs, while individual
developers and small organizations face barriers due to limited resources. In
this paper, we aim to bridge this gap by presenting a comprehensive study on
supervised fine-tuning of LLMs using instruction-tuning datasets spanning
diverse knowledge domains and skills. We focus on small-sized LLMs (3B to 7B
parameters) for their cost-efficiency and accessibility. We explore various
training configurations and strategies across four open-source pre-trained
models. We provide detailed documentation of these configurations, revealing
findings that challenge several common training practices, including
hyperparameter recommendations from TULU and phased training recommended by
Orca. Key insights from our work include: (i) larger batch sizes paired with
lower learning rates lead to improved model performance on benchmarks such as
MMLU, MTBench, and Open LLM Leaderboard; (ii) early-stage training dynamics,
such as lower gradient norms and higher loss values, are strong indicators of
better final model performance, enabling early termination of sub-optimal runs
and significant computational savings; (iii) through a thorough exploration of
hyperparameters like warmup steps and learning rate schedules, we provide
guidance for practitioners and find that certain simplifications do not
compromise performance; and (iv) we observed no significant difference in
performance between phased and stacked training strategies, but stacked
training is simpler and more sample efficient. With these findings holding
robustly across datasets and models, we hope this study serves as a guide for
practitioners fine-tuning small LLMs and promotes a more inclusive environment
for LLM research.",2024-12-17,"Aldo Pareja, Nikhil Shivakumar Nayak, Hao Wang, Krishnateja Killamsetty, Shivchander Sudalairaj, Wenlong Zhao, Seungwook Han, Abhishek Bhandwaldar, Guangxuan Xu, Kai Xu, Ligong Han, Luke Inglis, Akash Srivastava"
"Expansion Span: Combining Fading Memory and Retrieval in Hybrid State
  Space Models","The ""state"" of State Space Models (SSMs) represents their memory, which fades
exponentially over an unbounded span. By contrast, Attention-based models have
""eidetic"" (i.e., verbatim, or photographic) memory over a finite span (context
size). Hybrid architectures combine State Space layers with Attention, but
still cannot recall the distant past and can access only the most recent tokens
eidetically. Unlike current methods of combining SSM and Attention layers, we
allow the state to be allocated based on relevancy rather than recency. In this
way, for every new set of query tokens, our models can ""eidetically"" access
tokens from beyond the Attention span of current Hybrid SSMs without requiring
extra hardware resources. We describe a method to expand the memory span of the
hybrid state by ""reserving"" a fraction of the Attention context for tokens
retrieved from arbitrarily distant in the past, thus expanding the eidetic
memory span of the overall state. We call this reserved fraction of tokens the
""expansion span,"" and the mechanism to retrieve and aggregate it ""Span-Expanded
Attention"" (SE-Attn). To adapt Hybrid models to using SE-Attn, we propose a
novel fine-tuning method that extends LoRA to Hybrid models (HyLoRA) and allows
efficient adaptation on long spans of tokens. We show that SE-Attn enables us
to efficiently adapt pre-trained Hybrid models on sequences of tokens up to 8
times longer than the ones used for pre-training. We show that HyLoRA with
SE-Attn is cheaper and more performant than alternatives like LongLoRA when
applied to Hybrid models on natural language benchmarks with long-range
dependencies, such as PG-19, RULER, and other common natural language
downstream tasks.",2024-12-17,"Elvis Nunez, Luca Zancato, Benjamin Bowman, Aditya Golatkar, Wei Xia, Stefano Soatto"
"LossLens: Diagnostics for Machine Learning through Loss Landscape Visual
  Analytics","Modern machine learning often relies on optimizing a neural network's
parameters using a loss function to learn complex features. Beyond training,
examining the loss function with respect to a network's parameters (i.e., as a
loss landscape) can reveal insights into the architecture and learning process.
While the local structure of the loss landscape surrounding an individual
solution can be characterized using a variety of approaches, the global
structure of a loss landscape, which includes potentially many local minima
corresponding to different solutions, remains far more difficult to
conceptualize and visualize. To address this difficulty, we introduce LossLens,
a visual analytics framework that explores loss landscapes at multiple scales.
LossLens integrates metrics from global and local scales into a comprehensive
visual representation, enhancing model diagnostics. We demonstrate LossLens
through two case studies: visualizing how residual connections influence a
ResNet-20, and visualizing how physical parameters influence a physics-informed
neural network (PINN) solving a simple convection problem.",2024-12-17,"Tiankai Xie, Jiaqing Chen, Yaoqing Yang, Caleb Geniesse, Ge Shi, Ajinkya Chaudhari, John Kevin Cava, Michael W. Mahoney, Talita Perciano, Gunther H. Weber, Ross Maciejewski"
"Automated Phytosensing: Ozone Exposure Classification Based on Plant
  Electrical Signals","In our project WatchPlant, we propose to use a decentralized network of
living plants as air-quality sensors by measuring their electrophysiology to
infer the environmental state, also called phytosensing. We conducted in-lab
experiments exposing ivy (Hedera helix) plants to ozone, an important pollutant
to monitor, and measured their electrophysiological response. However, there is
no well established automated way of detecting ozone exposure in plants. We
propose a generic automatic toolchain to select a high-performance subset of
features and highly accurate models for plant electrophysiology. Our approach
derives plant- and stimulus-generic features from the electrophysiological
signal using the tsfresh library. Based on these features, we automatically
select and optimize machine learning models using AutoML. We use forward
feature selection to increase model performance. We show that our approach
successfully classifies plant ozone exposure with accuracies of up to 94.6% on
unseen data. We also show that our approach can be used for other plant species
and stimuli. Our toolchain automates the development of monitoring algorithms
for plants as pollutant monitors. Our results help implement significant
advancements for phytosensing devices contributing to the development of
cost-effective, high-density urban air monitoring systems in the future.",2024-12-17,"Till Aust, Eduard Buss, Felix Mohr, Heiko Hamann"
"Evolution of the ""long tail"" concept for scientific data","This review paper explores the evolution of discussions about ""long-tail""
scientific data in the scholarly literature. The ""long-tail"" concept,
originally used to explain trends in digital consumer goods, was first applied
to scientific data in 2007 to refer to a vast array of smaller, heterogeneous
data collections that cumulatively represent a substantial portion of
scientific knowledge. However, these datasets, often referred to as ""long-tail
data,"" are frequently mismanaged or overlooked due to inadequate data
management practices and institutional support. This paper examines the
changing landscape of discussions about long-tail data over time, situated
within broader ecosystems of research data management and the natural interplay
between ""big"" and ""small"" data. The review also bridges discussions on data
curation in Library & Information Science (LIS) and domain-specific contexts,
contributing to a more comprehensive understanding of the long-tail concept's
utility for effective data management outcomes. The review aims to provide a
more comprehensive understanding of this concept, its terminological diversity
in the literature, and its utility for guiding data management, overall
informing current and future information science research and practice.",2024-12-17,"Gretchen R. Stahlman, Inna Kouper"
FastVLM: Efficient Vision Encoding for Vision Language Models,"Scaling the input image resolution is essential for enhancing the performance
of Vision Language Models (VLMs), particularly in text-rich image understanding
tasks. However, popular visual encoders such as ViTs become inefficient at high
resolutions due to the large number of tokens and high encoding latency caused
by stacked self-attention layers. At different operational resolutions, the
vision encoder of a VLM can be optimized along two axes: reducing encoding
latency and minimizing the number of visual tokens passed to the LLM, thereby
lowering overall latency. Based on a comprehensive efficiency analysis of the
interplay between image resolution, vision latency, token count, and LLM size,
we introduce FastVLM, a model that achieves an optimized trade-off between
latency, model size and accuracy. FastVLM incorporates FastViTHD, a novel
hybrid vision encoder designed to output fewer tokens and significantly reduce
encoding time for high-resolution images. Unlike previous methods, FastVLM
achieves the optimal balance between visual token count and image resolution
solely by scaling the input image, eliminating the need for additional token
pruning and simplifying the model design. In the LLaVA-1.5 setup, FastVLM
achieves 3.2$\times$ improvement in time-to-first-token (TTFT) while
maintaining similar performance on VLM benchmarks compared to prior works.
Compared to LLaVa-OneVision at the highest resolution (1152$\times$1152),
FastVLM achieves comparable performance on key benchmarks like SeedBench and
MMMU, using the same 0.5B LLM, but with 85$\times$ faster TTFT and a vision
encoder that is 3.4$\times$ smaller.",2024-12-17,"Pavan Kumar Anasosalu Vasu, Fartash Faghri, Chun-Liang Li, Cem Koc, Nate True, Albert Antony, Gokul Santhanam, James Gabriel, Peter Grasch, Oncel Tuzel, Hadi Pouransari"
Image registration is a geometric deep learning task,"Data-driven deformable image registration methods predominantly rely on
operations that process grid-like inputs. However, applying deformable
transformations to an image results in a warped space that deviates from a
rigid grid structure. Consequently, data-driven approaches with sequential
deformations have to apply grid resampling operations between each deformation
step. While artifacts caused by resampling are negligible in high-resolution
images, the resampling of sparse, high-dimensional feature grids introduces
errors that affect the deformation modeling process. Taking inspiration from
Lagrangian reference frames of deformation fields, our work introduces a novel
paradigm for data-driven deformable image registration that utilizes geometric
deep-learning principles to model deformations without grid requirements.
Specifically, we model image features as a set of nodes that freely move in
Euclidean space, update their coordinates under graph operations, and
dynamically readjust their local neighborhoods. We employ this formulation to
construct a multi-resolution deformable registration model, where deformation
layers iteratively refine the overall transformation at each resolution without
intermediate resampling operations on the feature grids. We investigate our
method's ability to fully deformably capture large deformations across a number
of medical imaging registration tasks. In particular, we apply our approach
(GeoReg) to the registration of inter-subject brain MR images and inhale-exhale
lung CT images, showing on par performance with the current state-of-the-art
methods. We believe our contribution open up avenues of research to reduce the
black-box nature of current learned registration paradigms by explicitly
modeling the transformation within the architecture.",2024-12-17,"Vasiliki Sideri-Lampretsa, Nil Stolt-Ansó, Martin Menten, Huaqi Qiu, Julian McGinnis, Daniel Rueckert"
"Enhancing Persona Classification in Dialogue Systems: A Graph Neural
  Network Approach","In recent years, Large Language Models (LLMs) gain considerable attention for
their potential to enhance personalized experiences in virtual assistants and
chatbots. A key area of interest is the integration of personas into LLMs to
improve dialogue naturalness and user engagement. This study addresses the
challenge of persona classification, a crucial component in dialogue
understanding, by proposing a framework that combines text embeddings with
Graph Neural Networks (GNNs) for effective persona classification. Given the
absence of dedicated persona classification datasets, we create a manually
annotated dataset to facilitate model training and evaluation. Our method
involves extracting semantic features from persona statements using text
embeddings and constructing a graph where nodes represent personas and edges
capture their similarities. The GNN component uses this graph structure to
propagate relevant information, thereby improving classification performance.
Experimental results show that our approach, in particular the integration of
GNNs, significantly improves classification performance, especially with
limited data. Our contributions include the development of a persona
classification framework and the creation of a dataset.",2024-12-17,Konstantin Zaitsev
"CompactFlowNet: Efficient Real-time Optical Flow Estimation on Mobile
  Devices","We present CompactFlowNet, the first real-time mobile neural network for
optical flow prediction, which involves determining the displacement of each
pixel in an initial frame relative to the corresponding pixel in a subsequent
frame. Optical flow serves as a fundamental building block for various
video-related tasks, such as video restoration, motion estimation, video
stabilization, object tracking, action recognition, and video generation. While
current state-of-the-art methods prioritize accuracy, they often overlook
constraints regarding speed and memory usage. Existing light models typically
focus on reducing size but still exhibit high latency, compromise significantly
on quality, or are optimized for high-performance GPUs, resulting in
sub-optimal performance on mobile devices. This study aims to develop a
mobile-optimized optical flow model by proposing a novel mobile
device-compatible architecture, as well as enhancements to the training
pipeline, which optimize the model for reduced weight, low memory utilization,
and increased speed while maintaining minimal error. Our approach demonstrates
superior or comparable performance to the state-of-the-art lightweight models
on the challenging KITTI and Sintel benchmarks. Furthermore, it attains a
significantly accelerated inference speed, thereby yielding real-time
operational efficiency on the iPhone 8, while surpassing real-time performance
levels on more advanced mobile devices.",2024-12-17,"Andrei Znobishchev, Valerii Filev, Oleg Kudashev, Nikita Orlov, Humphrey Shi"
"TETRIS: Composing FHE Techniques for Private Functional Exploration Over
  Large Datasets","To derive valuable insights from statistics, machine learning applications
frequently analyze substantial amounts of data. In this work, we address the
problem of designing efficient secure techniques to probe large datasets which
allow a scientist to conduct large-scale medical studies over specific
attributes of patients' records, while maintaining the privacy of his model. We
introduce a set of composable homomorphic operations and show how to combine
private functions evaluation with private thresholds via approximate fully
homomorphic encryption. This allows us to design a new system named TETRIS,
which solves the real-world use case of private functional exploration of large
databases, where the statistical criteria remain private to the server owning
the patients' records. Our experiments show that TETRIS achieves practical
performance over a large dataset of patients even for the evaluation of
elaborate statements composed of linear and nonlinear functions. It is possible
to extract private insights from a database of hundreds of thousands of patient
records within only a few minutes on a single thread, with an amortized time
per database entry smaller than 2ms.",2024-12-17,"Malika Izabachène, Jean-Philippe Bossuat"
"Nods of Agreement: Webcam-Driven Avatars Improve Meeting Outcomes and
  Avatar Satisfaction Over Audio-Driven or Static Avatars in All-Avatar Work
  Videoconferencing","Avatars are edging into mainstream videoconferencing, but evaluation of how
avatar animation modalities contribute to work meeting outcomes has been
limited. We report a within-group videoconferencing experiment in which 68
employees of a global technology company, in 16 groups, used the same stylized
avatars in three modalities (static picture, audio-animation, and
webcam-animation) to complete collaborative decision-making tasks.
Quantitatively, for meeting outcomes, webcam-animated avatars improved meeting
effectiveness over the picture modality and were also reported to be more
comfortable and inclusive than both other modalities. In terms of avatar
satisfaction, there was a similar preference for webcam animation as compared
to both other modalities. Our qualitative analysis shows participants
expressing a preference for the holistic motion of webcam animation, and that
meaningful movement outweighs realism for meeting outcomes, as evidenced
through a systematic overview of ten thematic factors. We discuss implications
for research and commercial deployment and conclude that webcam-animated
avatars are a plausible alternative to video in work meetings.",2024-12-17,"Fang Ma, Ju Zhang, Lev Tankelevitch, Payod Panda, Torang Asadi, Charlie Hewitt, Lohit Petikam, Marco Gillies, Xueni Pan, Sean Rintel, Marta Wilczkowiak"
"Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation
  Model Internet Agents","The vision of a broadly capable and goal-directed agent, such as an
Internet-browsing agent in the digital world and a household humanoid in the
physical world, has rapidly advanced, thanks to the generalization capability
of foundation models. Such a generalist agent needs to have a large and diverse
skill repertoire, such as finding directions between two travel locations and
buying specific items from the Internet. If each skill needs to be specified
manually through a fixed set of human-annotated instructions, the agent's skill
repertoire will necessarily be limited due to the quantity and diversity of
human-annotated instructions. In this work, we address this challenge by
proposing Proposer-Agent-Evaluator, an effective learning system that enables
foundation model agents to autonomously discover and practice skills in the
wild. At the heart of PAE is a context-aware task proposer that autonomously
proposes tasks for the agent to practice with context information of the
environment such as user demos or even just the name of the website itself for
Internet-browsing agents. Then, the agent policy attempts those tasks with
thoughts and actual grounded operations in the real world with resulting
trajectories evaluated by an autonomous VLM-based success evaluator. The
success evaluation serves as the reward signal for the agent to refine its
policies through RL. We validate PAE on challenging vision-based web
navigation, using both real-world and self-hosted websites from WebVoyager and
WebArena.To the best of our knowledge, this work represents the first effective
learning system to apply autonomous task proposal with RL for agents that
generalizes real-world human-annotated benchmarks with SOTA performances. Our
open-source checkpoints and code can be found in https://yanqval.github.io/PAE/",2024-12-17,"Yifei Zhou, Qianlan Yang, Kaixiang Lin, Min Bai, Xiong Zhou, Yu-Xiong Wang, Sergey Levine, Erran Li"
MotionBridge: Dynamic Video Inbetweening with Flexible Controls,"By generating plausible and smooth transitions between two image frames,
video inbetweening is an essential tool for video editing and long video
synthesis. Traditional works lack the capability to generate complex large
motions. While recent video generation techniques are powerful in creating
high-quality results, they often lack fine control over the details of
intermediate frames, which can lead to results that do not align with the
creative mind. We introduce MotionBridge, a unified video inbetweening
framework that allows flexible controls, including trajectory strokes,
keyframes, masks, guide pixels, and text. However, learning such multi-modal
controls in a unified framework is a challenging task. We thus design two
generators to extract the control signal faithfully and encode feature through
dual-branch embedders to resolve ambiguities. We further introduce a curriculum
training strategy to smoothly learn various controls. Extensive qualitative and
quantitative experiments have demonstrated that such multi-modal controls
enable a more dynamic, customizable, and contextually accurate visual
narrative.",2024-12-17,"Maham Tanveer, Yang Zhou, Simon Niklaus, Ali Mahdavi Amiri, Hao Zhang, Krishna Kumar Singh, Nanxuan Zhao"
"Algorithmic Fidelity of Large Language Models in Generating Synthetic
  German Public Opinions: A Case Study","In recent research, large language models (LLMs) have been increasingly used
to investigate public opinions. This study investigates the algorithmic
fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and
nuanced opinions of human participants. Using open-ended survey data from the
German Longitudinal Election Studies (GLES), we prompt different LLMs to
generate synthetic public opinions reflective of German subpopulations by
incorporating demographic features into the persona prompts. Our results show
that Llama performs better than other LLMs at representing subpopulations,
particularly when there is lower opinion diversity within those groups. Our
findings further reveal that the LLM performs better for supporters of
left-leaning parties like The Greens and The Left compared to other parties,
and matches the least with the right-party AfD. Additionally, the inclusion or
exclusion of specific variables in the prompts can significantly impact the
models' predictions. These findings underscore the importance of aligning LLMs
to more effectively model diverse public opinions while minimizing political
biases and enhancing robustness in representativeness.",2024-12-17,"Bolei Ma, Berk Yoztyurk, Anna-Carolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Assenmacher"
C-FedRAG: A Confidential Federated Retrieval-Augmented Generation System,"Organizations seeking to utilize Large Language Models (LLMs) for knowledge
querying and analysis often encounter challenges in maintaining an LLM
fine-tuned on targeted, up-to-date information that keeps answers relevant and
grounded. Retrieval Augmented Generation (RAG) has quickly become a feasible
solution for organizations looking to overcome the challenges of maintaining
proprietary models and to help reduce LLM hallucinations in their query
responses. However, RAG comes with its own issues regarding scaling data
pipelines across tiered-access and disparate data sources. In many scenarios,
it is necessary to query beyond a single data silo to provide richer and more
relevant context for an LLM. Analyzing data sources within and across
organizational trust boundaries is often limited by complex data-sharing
policies that prohibit centralized data storage, therefore, inhibit the fast
and effective setup and scaling of RAG solutions. In this paper, we introduce
Confidential Computing (CC) techniques as a solution for secure Federated
Retrieval Augmented Generation (FedRAG). Our proposed Confidential FedRAG
system (C-FedRAG) enables secure connection and scaling of a RAG workflows
across a decentralized network of data providers by ensuring context
confidentiality. We also demonstrate how to implement a C-FedRAG system using
the NVIDIA FLARE SDK and assess its performance using the MedRAG toolkit and
MIRAGE benchmarking dataset.",2024-12-17,"Parker Addison, Minh-Tuan H. Nguyen, Tomislav Medan, Mohammad T. Manzari, Brendan McElrone, Laksh Lalwani, Aboli More, Smita Sharma, Holger R. Roth, Isaac Yang, Chester Chen, Daguang Xu, Yan Cheng, Andrew Feng, Ziyue Xu"
"A comprehensive review of assistive technologies for children with
  dyslexia","Dyslexia is a learning disability that primarily disrupts one's ability to
read, write and spell. About 15-20% of the world population is affected by
dyslexia, which signals it is a concerning subject. A systematic literature
review was conducted on this research to evaluate trending interventions,
common accessibility features, and potential barriers to existing assistive
devices and to identify any research gaps. Papers published over the period
(2015-2023) of 8 years were reviewed, and the data was meticulously analyzed.
This research shows that technological-based interventions are leading
interventions, especially with the use of mobile apps and augmentative
realities. More innovative technologies like virtual reality, NLP, haptic, and
tangible user interfaces are emerging to provide unique solutions addressing
the user's needs. Non-computing devices are less effective compared to modern
digital solutions however, they provide a promising alternative.",2024-12-17,"Sansrit Paudel, Subek Acharya"
"SWAN: Preprocessing SGD Enables Adam-Level Performance On LLM Training
  With Significant Memory Reduction","Adaptive optimizers such as Adam (Kingma & Ba, 2015) have been central to the
success of large language models. However, they maintain additional moving
average states throughout training, which results in memory requirements
several times greater than the model. This overhead imposes constraints on
scalability and computational efficiency. On the other hand, while stochastic
gradient descent (SGD) is optimal in terms of memory efficiency, their
capability in LLM training is limited (Zhao et al., 2024b).
  To address this dilemma, we show that pre-processing SGD is sufficient to
reach Adam-level performance on LLMs. Specifically, we propose to preprocess
the instantaneous stochastic gradients with two simple operators:
$\mathtt{GradNorm}$ and $\mathtt{GradWhitening}$. $\mathtt{GradNorm}$
stabilizes gradient distributions, and $\mathtt{GradWhitening}$ counteracts the
local curvature of the loss landscape, respectively. This results in SWAN (SGD
with Whitening And Normalization), a stochastic optimizer that eliminates the
need to store any accumulative state variables. Empirically, SWAN has the same
memory footprint as SGD, achieving $\approx 50\%$ reduction on total end-to-end
memory compared to Adam. In language modeling tasks, SWAN demonstrates the same
or even a substantial improvement over Adam. Specifically, when pre-training
the LLaMa model with 350M and 1.3B parameters, SWAN achieves a 2x speedup by
reaching the same evaluation perplexity in less than half tokens seen.",2024-12-17,"Chao Ma, Wenbo Gong, Meyer Scetbon, Edward Meeds"
Label Errors in the Tobacco3482 Dataset,"Tobacco3482 is a widely used document classification benchmark dataset.
However, our manual inspection of the entire dataset uncovers widespread
ontological issues, especially large amounts of annotation label problems in
the dataset. We establish data label guidelines and find that 11.7% of the
dataset is improperly annotated and should either have an unknown label or a
corrected label, and 16.7% of samples in the dataset have multiple valid
labels. We then analyze the mistakes of a top-performing model and find that
35% of the model's mistakes can be directly attributed to these label issues,
highlighting the inherent problems with using a noisily labeled dataset as a
benchmark. Supplementary material, including dataset annotations and code, is
available at https://github.com/gordon-lim/tobacco3482-mistakes/.",2024-12-17,"Gordon Lim, Stefan Larson, Kevin Leach"
"Unlocking the Potential of Digital Pathology: Novel Baselines for
  Compression","Digital pathology offers a groundbreaking opportunity to transform clinical
practice in histopathological image analysis, yet faces a significant hurdle:
the substantial file sizes of pathological Whole Slide Images (WSI). While
current digital pathology solutions rely on lossy JPEG compression to address
this issue, lossy compression can introduce color and texture disparities,
potentially impacting clinical decision-making. While prior research addresses
perceptual image quality and downstream performance independently of each
other, we jointly evaluate compression schemes for perceptual and downstream
task quality on four different datasets. In addition, we collect an initially
uncompressed dataset for an unbiased perceptual evaluation of compression
schemes. Our results show that deep learning models fine-tuned for perceptual
quality outperform conventional compression schemes like JPEG-XL or WebP for
further compression of WSI. However, they exhibit a significant bias towards
the compression artifacts present in the training data and struggle to
generalize across various compression schemes. We introduce a novel evaluation
metric based on feature similarity between original files and compressed files
that aligns very well with the actual downstream performance on the compressed
WSI. Our metric allows for a general and standardized evaluation of lossy
compression schemes and mitigates the requirement to independently assess
different downstream tasks. Our study provides novel insights for the
assessment of lossy compression schemes for WSI and encourages a unified
evaluation of lossy compression schemes to accelerate the clinical uptake of
digital pathology.",2024-12-17,"Maximilian Fischer, Peter Neher, Peter Schüffler, Sebastian Ziegler, Shuhan Xiao, Robin Peretzke, David Clunie, Constantin Ulrich, Michael Baumgartner, Alexander Muckenhuber, Silvia Dias Almeida, Michael Götz, Jens Kleesiek, Marco Nolden, Rickmer Braren, Klaus Maier-Hein"
"Analyzing Toxicity in Open Source Software Communications Using
  Psycholinguistics and Moral Foundations Theory","Studies have shown that toxic behavior can cause contributors to leave, and
hinder newcomers' (especially from underrepresented communities) participation
in Open Source Software (OSS) projects. Thus, detection of toxic language plays
a crucial role in OSS collaboration and inclusivity. Off-the-shelf toxicity
detectors are ineffective when applied to OSS communications, due to the
distinct nature of toxicity observed in these channels (e.g., entitlement and
arrogance are more frequently observed on GitHub than on Reddit or Twitter). In
this paper, we investigate a machine learning-based approach for the automatic
detection of toxic communications in OSS. We leverage psycholinguistic
lexicons, and Moral Foundations Theory to analyze toxicity in two types of OSS
communication channels; issue comments and code reviews. Our evaluation
indicates that our approach can achieve a significant performance improvement
(up to 7% increase in F1 score) over the existing domain-specific toxicity
detector. We found that using moral values as features is more effective than
linguistic cues, resulting in 67.50% F1-measure in identifying toxic instances
in code review data and 64.83% in issue comments. While the detection accuracy
is far from accurate, this improvement demonstrates the potential of
integrating moral and psycholinguistic features in toxicity detection models.
These findings highlight the importance of context-specific models that
consider the unique communication styles within OSS, where interpersonal and
value-driven language dynamics differ markedly from general social media
platforms. Future work could focus on refining these models to further enhance
detection accuracy, possibly by incorporating community-specific norms and
conversational context to better capture the nuanced expressions of toxicity in
OSS environments.",2024-12-17,"Ramtin Ehsani, Shadi Rezapour, Preetha Chatterjee"
"A Knowledge-enhanced Pathology Vision-language Foundation Model for
  Cancer Diagnosis","Deep learning has enabled the development of highly robust foundation models
for various pathological tasks across diverse diseases and patient cohorts.
Among these models, vision-language pre-training, which leverages large-scale
paired data to align pathology image and text embedding spaces, and provides a
novel zero-shot paradigm for downstream tasks. However, existing models have
been primarily data-driven and lack the incorporation of domain-specific
knowledge, which limits their performance in cancer diagnosis, especially for
rare tumor subtypes. To address this limitation, we establish a
Knowledge-enhanced Pathology (KEEP) foundation model that harnesses disease
knowledge to facilitate vision-language pre-training. Specifically, we first
construct a disease knowledge graph (KG) that covers 11,454 human diseases with
139,143 disease attributes, including synonyms, definitions, and hypernym
relations. We then systematically reorganize the millions of publicly available
noisy pathology image-text pairs, into 143K well-structured semantic groups
linked through the hierarchical relations of the disease KG. To derive more
nuanced image and text representations, we propose a novel knowledge-enhanced
vision-language pre-training approach that integrates disease knowledge into
the alignment within hierarchical semantic groups instead of unstructured
image-text pairs. Validated on 18 diverse benchmarks with more than 14,000
whole slide images (WSIs), KEEP achieves state-of-the-art performance in
zero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP
demonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7
cancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of
0.456 in subtyping 30 rare brain cancers, indicating strong generalizability
for diagnosing rare tumors.",2024-12-17,"Xiao Zhou, Luoyi Sun, Dexuan He, Wenbin Guan, Ruifen Wang, Lifeng Wang, Xin Sun, Kun Sun, Ya Zhang, Yanfeng Wang, Weidi Xie"
Motion-2-to-3: Leveraging 2D Motion Data to Boost 3D Motion Generation,"Text-driven human motion synthesis is capturing significant attention for its
ability to effortlessly generate intricate movements from abstract text cues,
showcasing its potential for revolutionizing motion design not only in film
narratives but also in virtual reality experiences and computer game
development. Existing methods often rely on 3D motion capture data, which
require special setups resulting in higher costs for data acquisition,
ultimately limiting the diversity and scope of human motion. In contrast, 2D
human videos offer a vast and accessible source of motion data, covering a
wider range of styles and activities. In this paper, we explore leveraging 2D
human motion extracted from videos as an alternative data source to improve
text-driven 3D motion generation. Our approach introduces a novel framework
that disentangles local joint motion from global movements, enabling efficient
learning of local motion priors from 2D data. We first train a single-view 2D
local motion generator on a large dataset of text-motion pairs. To enhance this
model to synthesize 3D motion, we fine-tune the generator with 3D data,
transforming it into a multi-view generator that predicts view-consistent local
joint motion and root dynamics. Experiments on the HumanML3D dataset and novel
text prompts demonstrate that our method efficiently utilizes 2D data,
supporting realistic 3D human motion generation and broadening the range of
motion types it supports. Our code will be made publicly available at
https://zju3dv.github.io/Motion-2-to-3/.",2024-12-17,"Huaijin Pi, Ruoxi Guo, Zehong Shen, Qing Shuai, Zechen Hu, Zhumei Wang, Yajiao Dong, Ruizhen Hu, Taku Komura, Sida Peng, Xiaowei Zhou"
AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark,"Evaluation plays a crucial role in the advancement of information retrieval
(IR) models. However, current benchmarks, which are based on predefined domains
and human-labeled data, face limitations in addressing evaluation needs for
emerging domains both cost-effectively and efficiently. To address this
challenge, we propose the Automated Heterogeneous Information Retrieval
Benchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1)
Automated. The testing data in AIR-Bench is automatically generated by large
language models (LLMs) without human intervention. 2) Heterogeneous. The
testing data in AIR-Bench is generated with respect to diverse tasks, domains
and languages. 3) Dynamic. The domains and languages covered by AIR-Bench are
constantly augmented to provide an increasingly comprehensive evaluation
benchmark for community developers. We develop a reliable and robust data
generation pipeline to automatically create diverse and high-quality evaluation
datasets based on real-world corpora. Our findings demonstrate that the
generated testing data in AIR-Bench aligns well with human-labeled testing
data, making AIR-Bench a dependable benchmark for evaluating IR models. The
resources in AIR-Bench are publicly available at
https://github.com/AIR-Bench/AIR-Bench.",2024-12-17,"Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu"
Accuracy Limits as a Barrier to Biometric System Security,"Biometric systems are widely used for identity verification and
identification, including authentication (i.e., one-to-one matching to verify a
claimed identity) and identification (i.e., one-to-many matching to find a
subject in a database). The matching process relies on measuring similarities
or dissimilarities between a fresh biometric template and enrolled templates.
The False Match Rate FMR is a key metric for assessing the accuracy and
reliability of such systems. This paper analyzes biometric systems based on
their FMR, with two main contributions. First, we explore untargeted attacks,
where an adversary aims to impersonate any user within a database. We determine
the number of trials required for an attacker to successfully impersonate a
user and derive the critical population size (i.e., the maximum number of users
in the database) required to maintain a given level of security. Furthermore,
we compute the critical FMR value needed to ensure resistance against
untargeted attacks as the database size increases. Second, we revisit the
biometric birthday problem to evaluate the approximate and exact probabilities
that two users in a database collide (i.e., can impersonate each other). Based
on this analysis, we derive both the approximate critical population size and
the critical FMR value needed to bound the likelihood of such collisions
occurring with a given probability. These thresholds offer insights for
designing systems that mitigate the risk of impersonation and collisions,
particularly in large-scale biometric databases. Our findings indicate that
current biometric systems fail to deliver sufficient accuracy to achieve an
adequate security level against untargeted attacks, even in small-scale
databases. Moreover, state-of-the-art systems face significant challenges in
addressing the biometric birthday problem, especially as database sizes grow.",2024-12-17,"Axel Durbet, Paul-Marie Grollemund, Pascal Lafourcade, Kevin Thiry-Atighehchi"
Computing crossing numbers with topological and geometric restrictions,"Computing the crossing number of a graph is one of the most classical
problems in computational geometry. Both it and numerous variations of the
problem have been studied, and overcoming their frequent computational
difficulty is an active area of research. Particularly recently, there has been
increased effort to show and understand the parameterized tractability of
various crossing number variants. While many results in this direction use a
similar approach, a general framework remains elusive. We suggest such a
framework that generalizes important previous results, and can even be used to
show the tractability of deciding crossing number variants for which this was
stated as an open problem in previous literature. Our framework targets
variants that prescribe a partial predrawing and some kind of topological
restrictions on crossings. Additionally, to provide evidence for the
non-generalizability of previous approaches for the partially crossing number
problem to allow for geometric restrictions, we show a new more constrained
hardness result for partially predrawn rectilinear crossing number. In
particular, we show W-hardness of deciding Straight-Line Planarity Extension
parameterized by the number of missing edges.",2024-12-17,"Thekla Hamm, Fabian Klute, Irene Parada"
"Higher-Order Sinusoidal Input Describing Functions for Open-Loop and
  Closed-Loop Reset Control with Application to Mechatronics Systems","Reset control enhances the performance of high-precision mechatronics
systems. This paper introduces a generalized reset feedback control structure
that integrates a single reset-state reset controller, a shaping filter for
tuning reset actions, and linear compensators arranged in series and parallel
configurations with the reset controller. This structure offers greater tuning
flexibility to optimize reset control performance. However, frequency-domain
analysis for such systems remains underdeveloped. To address this gap, this
study makes three key contributions: (1) developing Higher-Order Sinusoidal
Input Describing Functions (HOSIDFs) for open-loop reset control systems; (2)
deriving HOSIDFs for closed-loop reset control systems and establishing a
connection with open-loop analysis; and (3) creating a MATLAB-based App to
implement these methods, providing mechatronics engineers with a practical tool
for reset control system design and analysis. The accuracy of the proposed
methods is validated through simulations and experiments. Finally, the utility
of the proposed methods is demonstrated through case studies that analyze and
compare the performance of three controllers: a PID controller, a reset
controller, and a shaped reset controller on a precision motion stage. Both
analytical and experimental results demonstrate that the shaped reset
controller provides higher tracking precision while reducing actuation forces,
outperforming both the reset and PID controllers. These findings highlight the
effectiveness of the proposed frequency-domain methods in analyzing and
optimizing the performance of reset-controlled mechatronics systems.",2024-12-17,"Xinxin Zhang, S. Hassan HosseinNia"
Identifying Bias in Deep Neural Networks Using Image Transforms,"CNNs have become one of the most commonly used computational tool in the past
two decades. One of the primary downsides of CNNs is that they work as a
``black box"", where the user cannot necessarily know how the image data are
analyzed, and therefore needs to rely on empirical evaluation to test the
efficacy of a trained CNN. This can lead to hidden biases that affect the
performance evaluation of neural networks, but are difficult to identify. Here
we discuss examples of such hidden biases in common and widely used benchmark
datasets, and propose techniques for identifying dataset biases that can affect
the standard performance evaluation metrics. One effective approach to identify
dataset bias is to perform image classification by using merely blank
background parts of the original images. However, in some situations a blank
background in the images is not available, making it more difficult to separate
foreground or contextual information from the bias. To overcome this, we
propose a method to identify dataset bias without the need to crop background
information from the images. That method is based on applying several image
transforms to the original images, including Fourier transform, wavelet
transforms, median filter, and their combinations. These transforms were
applied to recover background bias information that CNNs use to classify
images. This transformations affect the contextual visual information in a
different manner than it affects the systemic background bias. Therefore, the
method can distinguish between contextual information and the bias, and alert
on the presence of background bias even without the need to separate sub-images
parts from the blank background of the original images. Code used in the
experiments is publicly available.",2024-12-17,"Sai Teja Erukude, Akhil Joshi, Lior Shamir"
"Optimized two-stage AI-based Neural Decoding for Enhanced Visual
  Stimulus Reconstruction from fMRI Data","AI-based neural decoding reconstructs visual perception by leveraging
generative models to map brain activity, measured through functional MRI
(fMRI), into latent hierarchical representations. Traditionally, ridge linear
models transform fMRI into a latent space, which is then decoded using latent
diffusion models (LDM) via a pre-trained variational autoencoder (VAE). Due to
the complexity and noisiness of fMRI data, newer approaches split the
reconstruction into two sequential steps, the first one providing a rough
visual approximation, the second on improving the stimulus prediction via LDM
endowed by CLIP embeddings. This work proposes a non-linear deep network to
improve fMRI latent space representation, optimizing the dimensionality alike.
Experiments on the Natural Scenes Dataset showed that the proposed architecture
improved the structural similarity of the reconstructed image by about 2\% with
respect to the state-of-the-art model, based on ridge linear transform. The
reconstructed image's semantics improved by about 4\%, measured by perceptual
similarity, with respect to the state-of-the-art. The noise sensitivity
analysis of the LDM showed that the role of the first stage was fundamental to
predict the stimulus featuring high structural similarity. Conversely,
providing a large noise stimulus affected less the semantics of the predicted
stimulus, while the structural similarity between the ground truth and
predicted stimulus was very poor. The findings underscore the importance of
leveraging non-linear relationships between BOLD signal and the latent
representation and two-stage generative AI for optimizing the fidelity of
reconstructed visual stimuli from noisy fMRI data.",2024-12-17,"Lorenzo Veronese, Andrea Moglia, Luca Mainardi, Pietro Cerveri"
CondiMen: Conditional Multi-Person Mesh Recovery,"Multi-person human mesh recovery (HMR) consists in detecting all individuals
in a given input image, and predicting the body shape, pose, and 3D location
for each detected person. The dominant approaches to this task rely on neural
networks trained to output a single prediction for each detected individual. In
contrast, we propose CondiMen, a method that outputs a joint parametric
distribution over likely poses, body shapes, intrinsics and distances to the
camera, using a Bayesian network. This approach offers several advantages.
First, a probability distribution can handle some inherent ambiguities of this
task -- such as the uncertainty between a person's size and their distance to
the camera, or simply the loss of information when projecting 3D data onto the
2D image plane. Second, the output distribution can be combined with additional
information to produce better predictions, by using e.g. known camera or body
shape parameters, or by exploiting multi-view observations. Third, one can
efficiently extract the most likely predictions from the output distribution,
making our proposed approach suitable for real-time applications. Empirically
we find that our model i) achieves performance on par with or better than the
state-of-the-art, ii) captures uncertainties and correlations inherent in pose
estimation and iii) can exploit additional information at test time, such as
multi-view consistency or body shape priors. CondiMen spices up the modeling of
ambiguity, using just the right ingredients on hand.",2024-12-17,"Brégier Romain, Baradel Fabien, Lucas Thomas, Galaaoui Salma, Armando Matthieu, Weinzaepfel Philippe, Rogez Grégory"
Logic-Constrained Shortest Paths for Flight Planning,"The Logic-Constrained Shortest Path Problem (LCSP) combines a one-to-one
shortest path problem with satisfiability constraints imposed on the routing
graph. This setting arises in flight planning, where air traffic control (ATC)
authorities are enforcing a set of traffic flow restrictions (TFRs) on aircraft
routes in order to increase safety and throughput. We propose a new branch and
bound-based algorithm for the LCSP.
  The resulting algorithm has three main degrees of freedom: the node selection
rule, the branching rule and the conflict. While node selection and branching
rules have been long studied in the MIP and SAT communities, most of them
cannot be applied out of the box for the LCSP. We review the existing
literature and develop tailored variants of the most prominent rules. The
conflict, the set of variables to which the branching rule is applied, is
unique to the LCSP. We analyze its theoretical impact on the B&B algorithm.
  In the second part of the paper, we show how to model the Flight Planning
Problem with TFRs as an LCSP and solve it using the branch and bound algorithm.
We demonstrate the algorithm's efficiency on a dataset consisting of a global
flight graph and a set of around 20000 real TFRs obtained from our industry
partner Lufthansa Systems GmbH. We make this dataset publicly available.
Finally, we conduct an empirical in-depth analysis of node selection rules,
branching rules and conflicts. Carefully choosing an appropriate combination
yields an improvement of an order of magnitude compared to an uninformed
choice.",2024-12-17,"Ricardo Euler, Pedro Maristany de las Casas, Ralf Borndörfer"
"Open-Set Heterogeneous Domain Adaptation: Theoretical Analysis and
  Algorithm","Domain adaptation (DA) tackles the issue of distribution shift by learning a
model from a source domain that generalizes to a target domain. However, most
existing DA methods are designed for scenarios where the source and target
domain data lie within the same feature space, which limits their applicability
in real-world situations. Recently, heterogeneous DA (HeDA) methods have been
introduced to address the challenges posed by heterogeneous feature space
between source and target domains. Despite their successes, current HeDA
techniques fall short when there is a mismatch in both feature and label
spaces. To address this, this paper explores a new DA scenario called open-set
HeDA (OSHeDA). In OSHeDA, the model must not only handle heterogeneity in
feature space but also identify samples belonging to novel classes. To tackle
this challenge, we first develop a novel theoretical framework that constructs
learning bounds for prediction error on target domain. Guided by this
framework, we propose a new DA method called Representation Learning for OSHeDA
(RL-OSHeDA). This method is designed to simultaneously transfer knowledge
between heterogeneous data sources and identify novel classes. Experiments
across text, image, and clinical data demonstrate the effectiveness of our
algorithm. Model implementation is available at
\url{https://github.com/pth1993/OSHeDA}.",2024-12-17,"Thai-Hoang Pham, Yuanlong Wang, Changchang Yin, Xueru Zhang, Ping Zhang"
"Identification of Epileptic Spasms (ESES) Phases Using EEG Signals: A
  Vision Transformer Approach","This work introduces a new approach to the Epileptic Spasms (ESES) detection
based on the EEG signals using Vision Transformers (ViT). Classic ESES
detection approaches have usually been performed with manual processing or
conventional algorithms, suffering from poor sample sizes, single-channel-based
analyses, and low generalization abilities. In contrast, the proposed ViT model
overcomes these limitations by using the attention mechanism to focus on the
important features in multi-channel EEG data, which is contributing to both
better accuracy and efficiency. The model processes frequency-domain
representations of EEG signals, such as spectrograms, as image data to capture
long-range dependencies and complex patterns in the signal. The model
demonstrates high performance with an accuracy of 97% without requiring
intensive data preprocessing, thus rendering it suitable for real-time clinical
applications on a large scale. The method represents a significant development
in the advancement of neurological disorders such as ESES in detection and
analysis.",2024-12-17,"Wei Gong, Yaru Li"
"Queries, Representation & Detection: The Next 100 Model Fingerprinting
  Schemes","The deployment of machine learning models in operational contexts represents
a significant investment for any organisation. Consequently, the risk of these
models being misappropriated by competitors needs to be addressed. In recent
years, numerous proposals have been put forth to detect instances of model
stealing. However, these proposals operate under implicit and disparate data
and model access assumptions; as a consequence, it remains unclear how they can
be effectively compared to one another. Our evaluation shows that a simple
baseline that we introduce performs on par with existing state-of-the-art
fingerprints, which, on the other hand, are much more complex. To uncover the
reasons behind this intriguing result, this paper introduces a systematic
approach to both the creation of model fingerprinting schemes and their
evaluation benchmarks. By dividing model fingerprinting into three core
components -- Query, Representation and Detection (QuRD) -- we are able to
identify $\sim100$ previously unexplored QuRD combinations and gain insights
into their performance. Finally, we introduce a set of metrics to compare and
guide the creation of more representative model stealing detection benchmarks.
Our approach reveals the need for more challenging benchmarks and a sound
comparison with baselines. To foster the creation of new fingerprinting schemes
and benchmarks, we open-source our fingerprinting toolbox.",2024-12-17,"Augustin Godinot, Erwan Le Merrer, Camilla Penzo, François Taïani, Gilles Trédan"
"OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in
  Financial Domain","As a typical and practical application of Large Language Models (LLMs),
Retrieval-Augmented Generation (RAG) techniques have gained extensive
attention, particularly in vertical domains where LLMs may lack domain-specific
knowledge. In this paper, we introduce an omnidirectional and automatic RAG
benchmark, OmniEval, in the financial domain. Our benchmark is characterized by
its multi-dimensional evaluation framework, including (1) a matrix-based RAG
scenario evaluation system that categorizes queries into five task classes and
16 financial topics, leading to a structured assessment of diverse query
scenarios; (2) a multi-dimensional evaluation data generation approach, which
combines GPT-4-based automatic generation and human annotation, achieving an
87.47\% acceptance ratio in human evaluations on generated instances; (3) a
multi-stage evaluation system that evaluates both retrieval and generation
performance, result in a comprehensive evaluation on the RAG pipeline; and (4)
robust evaluation metrics derived from rule-based and LLM-based ones, enhancing
the reliability of assessments through manual annotations and supervised
fine-tuning of an LLM evaluator. Our experiments demonstrate the
comprehensiveness of OmniEval, which includes extensive test datasets and
highlights the performance variations of RAG systems across diverse topics and
tasks, revealing significant opportunities for RAG models to improve their
capabilities in vertical domains. We open source the code of our benchmark in
\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.",2024-12-17,"Shuting Wang, Jiejun Tan, Zhicheng Dou, Ji-Rong Wen"
A New Adversarial Perspective for LiDAR-based 3D Object Detection,"Autonomous vehicles (AVs) rely on LiDAR sensors for environmental perception
and decision-making in driving scenarios. However, ensuring the safety and
reliability of AVs in complex environments remains a pressing challenge. To
address this issue, we introduce a real-world dataset (ROLiD) comprising
LiDAR-scanned point clouds of two random objects: water mist and smoke. In this
paper, we introduce a novel adversarial perspective by proposing an attack
framework that utilizes water mist and smoke to simulate environmental
interference. Specifically, we propose a point cloud sequence generation method
using a motion and content decomposition generative adversarial network named
PCS-GAN to simulate the distribution of random objects. Furthermore, leveraging
the simulated LiDAR scanning characteristics implemented with Range Image, we
examine the effects of introducing random object perturbations at various
positions on the target vehicle. Extensive experiments demonstrate that
adversarial perturbations based on random objects effectively deceive vehicle
detection and reduce the recognition rate of 3D object detection models.",2024-12-17,"Shijun Zheng, Weiquan Liu, Yu Guo, Yu Zang, Siqi Shen, Cheng Wang"
"RCLMuFN: Relational Context Learning and Multiplex Fusion Network for
  Multimodal Sarcasm Detection","Sarcasm typically conveys emotions of contempt or criticism by expressing a
meaning that is contrary to the speaker's true intent. Accurate detection of
sarcasm aids in identifying and filtering undesirable information on the
Internet, thereby reducing malicious defamation and rumor-mongering.
Nonetheless, the task of automatic sarcasm detection remains highly challenging
for machines, as it critically depends on intricate factors such as relational
context. Most existing multimodal sarcasm detection methods focus on
introducing graph structures to establish entity relationships between text and
images while neglecting to learn the relational context between text and
images, which is crucial evidence for understanding the meaning of sarcasm. In
addition, the meaning of sarcasm changes with the evolution of different
contexts, but existing methods may not be accurate in modeling such dynamic
changes, limiting the generalization ability of the models. To address the
above issues, we propose a relational context learning and multiplex fusion
network (RCLMuFN) for multimodal sarcasm detection. Firstly, we employ four
feature extractors to comprehensively extract features from raw text and
images, aiming to excavate potential features that may have been previously
overlooked. Secondly, we utilize the relational context learning module to
learn the contextual information of text and images and capture the dynamic
properties through shallow and deep interactions. Finally, we employ a
multiplex feature fusion module to enhance the generalization of the model by
penetratingly integrating multimodal features derived from various interaction
contexts. Extensive experiments on two multimodal sarcasm detection datasets
show that our proposed method achieves state-of-the-art performance.",2024-12-17,"Tongguan Wang, Junkai Li, Guixin Su, Yongcheng Zhang, Dongyu Su, Yuxue Hu, Ying Sha"
Neural Control and Certificate Repair via Runtime Monitoring,"Learning-based methods provide a promising approach to solving highly
non-linear control tasks that are often challenging for classical control
methods. To ensure the satisfaction of a safety property, learning-based
methods jointly learn a control policy together with a certificate function for
the property. Popular examples include barrier functions for safety and
Lyapunov functions for asymptotic stability. While there has been significant
progress on learning-based control with certificate functions in the white-box
setting, where the correctness of the certificate function can be formally
verified, there has been little work on ensuring their reliability in the
black-box setting where the system dynamics are unknown. In this work, we
consider the problems of certifying and repairing neural network control
policies and certificate functions in the black-box setting. We propose a novel
framework that utilizes runtime monitoring to detect system behaviors that
violate the property of interest under some initially trained neural network
policy and certificate. These violating behaviors are used to extract new
training data, that is used to re-train the neural network policy and the
certificate function and to ultimately repair them. We demonstrate the
effectiveness of our approach empirically by using it to repair and to boost
the safety rate of neural network policies learned by a state-of-the-art method
for learning-based control on two autonomous system control tasks.",2024-12-17,"Emily Yu, Đorđe Žikelić, Thomas A. Henzinger"
"Model agnostic signal encoding by leaky integrate and fire, performance
  and uncertainty","Integrate and fire is a resource efficient time-encoding mechanism that
summarizes into a signed spike train those time intervals where a signal's
charge exceeds a certain threshold. We analyze the IF encoder in terms of a
very general notion of approximate bandwidth, which is shared by most
commonly-used signal models. This complements results on exact encoding that
may be overly adapted to a particular signal model. We take into account,
possibly for the first time, the effect of uncertainty in the exact location of
the spikes (as may arise by decimation), uncertainty of integration leakage (as
may arise in realistic manufacturing), and boundary effects inherent to finite
periods of exposure to the measurement device. The analysis is done by means of
a concrete bandwidth-based Ansatz that can also be useful to initialize more
sophisticated model specific reconstruction algorithms, and uses the earth
mover's (Wassertein) distance to measure spike discrepancy.",2024-12-17,"Diana Carbajal, José Luis Romero"
"ArchesWeather & ArchesWeatherGen: a deterministic and generative model
  for efficient ML weather forecasting","Weather forecasting plays a vital role in today's society, from agriculture
and logistics to predicting the output of renewable energies, and preparing for
extreme weather events. Deep learning weather forecasting models trained with
the next state prediction objective on ERA5 have shown great success compared
to numerical global circulation models. However, for a wide range of
applications, being able to provide representative samples from the
distribution of possible future weather states is critical. In this paper, we
propose a methodology to leverage deterministic weather models in the design of
probabilistic weather models, leading to improved performance and reduced
computing costs. We first introduce \textbf{ArchesWeather}, a transformer-based
deterministic model that improves upon Pangu-Weather by removing
overrestrictive inductive priors. We then design a probabilistic weather model
called \textbf{ArchesWeatherGen} based on flow matching, a modern variant of
diffusion models, that is trained to project ArchesWeather's predictions to the
distribution of ERA5 weather states. ArchesWeatherGen is a true stochastic
emulator of ERA5 and surpasses IFS ENS and NeuralGCM on all WeatherBench
headline variables (except for NeuralGCM's geopotential). Our work also aims to
democratize the use of deterministic and generative machine learning models in
weather forecasting research, with academic computing resources. All models are
trained at 1.5{\deg} resolution, with a training budget of $\sim$9 V100 days
for ArchesWeather and $\sim$45 V100 days for ArchesWeatherGen. For inference,
ArchesWeatherGen generates 15-day weather trajectories at a rate of 1 minute
per ensemble member on a A100 GPU card. To make our work fully reproducible,
our code and models are open source, including the complete pipeline for data
preparation, training, and evaluation, at https://github.com/INRIA/geoarches .",2024-12-17,"Guillaume Couairon, Renu Singh, Anastase Charantonis, Christian Lessig, Claire Monteleoni"
"System-Level Experimental Evaluation of Reconfigurable Intelligent
  Surfaces for NextG Communication Systems","Reconfigurable Intelligent Surfaces (RISs) are a promising technique for
enhancing the performance of Next Generation (NextG) wireless communication
systems in terms of both spectral and energy efficiency, as well as resource
utilization. However, current RIS research has primarily focused on theoretical
modeling and Physical (PHY) layer considerations only. Full protocol stack
emulation and accurate modeling of the propagation characteristics of the
wireless channel are necessary for studying the benefits introduced by RIS
technology across various spectrum bands and use-cases. In this paper, we
propose, for the first time: (i) accurate PHY layer RIS-enabled channel
modeling through Geometry-Based Stochastic Models (GBSMs), leveraging the QUAsi
Deterministic RadIo channel GenerAtor (QuaDRiGa) open-source statistical
ray-tracer; (ii) optimized resource allocation with RISs by comprehensively
studying energy efficiency and power control on different portions of the
spectrum through a single-leader multiple-followers Stackelberg game
theoretical approach; (iii) full-stack emulation and performance evaluation of
RIS-assisted channels with SCOPE/srsRAN for Enhanced Mobile Broadband (eMBB)
and Ultra Reliable and Low Latency Communications (URLLC) applications in the
worlds largest emulator of wireless systems with hardware-in-the-loop, namely
Colosseum. Our findings indicate (i) the significant power savings in terms of
energy efficiency achieved with RIS-assisted topologies, especially in the
millimeter wave (mmWave) band; and (ii) the benefits introduced for Sub-6 GHz
band User Equipments (UEs), where the deployment of a relatively small RIS
(e.g., in the order of 100 RIS elements) can result in decreased levels of
latency for URLLC services in resource-constrained environments.",2024-12-17,"Maria Tsampazi, Tommaso Melodia"
"Adaptations of AI models for querying the LandMatrix database in natural
  language","The Land Matrix initiative (https://landmatrix.org) and its global
observatory aim to provide reliable data on large-scale land acquisitions to
inform debates and actions in sectors such as agriculture, extraction, or
energy in low- and middle-income countries. Although these data are recognized
in the academic world, they remain underutilized in public policy, mainly due
to the complexity of access and exploitation, which requires technical
expertise and a good understanding of the database schema.
  The objective of this work is to simplify access to data from different
database systems. The methods proposed in this article are evaluated using data
from the Land Matrix. This work presents various comparisons of Large Language
Models (LLMs) as well as combinations of LLM adaptations (Prompt Engineering,
RAG, Agents) to query different database systems (GraphQL and REST queries).
The experiments are reproducible, and a demonstration is available online:
https://github.com/tetis-nlp/landmatrix-graphql-python.",2024-12-17,"Fatiha Ait Kbir, Jérémy Bourgoin, Rémy Decoupes, Marie Gradeler, Roberto Interdonato"
"Learning from Noisy Labels via Self-Taught On-the-Fly Meta Loss
  Rescaling","Correct labels are indispensable for training effective machine learning
models. However, creating high-quality labels is expensive, and even
professionally labeled data contains errors and ambiguities. Filtering and
denoising can be applied to curate labeled data prior to training, at the cost
of additional processing and loss of information. An alternative is on-the-fly
sample reweighting during the training process to decrease the negative impact
of incorrect or ambiguous labels, but this typically requires clean seed data.
In this work we propose unsupervised on-the-fly meta loss rescaling to reweight
training samples. Crucially, we rely only on features provided by the model
being trained, to learn a rescaling function in real time without knowledge of
the true clean data distribution. We achieve this via a novel meta learning
setup that samples validation data for the meta update directly from the noisy
training corpus by employing the rescaling function being trained. Our proposed
method consistently improves performance across various NLP tasks with minimal
computational overhead. Further, we are among the first to attempt on-the-fly
training data reweighting on the challenging task of dialogue modeling, where
noisy and ambiguous labels are common. Our strategy is robust in the face of
noisy and clean data, handles class imbalance, and prevents overfitting to
noisy labels. Our self-taught loss rescaling improves as the model trains,
showing the ability to keep learning from the model's own signals. As training
progresses, the impact of correctly labeled data is scaled up, while the impact
of wrongly labeled data is suppressed.",2024-12-17,"Michael Heck, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Shutong Feng, Hsien-Chin Lin, Benjamin Matthias Ruppik, Renato Vukovic, Milica Gašić"
MOPO: Multi-Objective Prompt Optimization for Affective Text Generation,"How emotions are expressed depends on the context and domain. On X (formerly
Twitter), for instance, an author might simply use the hashtag #anger, while in
a news headline, emotions are typically written in a more polite, indirect
manner. To enable conditional text generation models to create emotionally
connotated texts that fit a domain, users need to have access to a parameter
that allows them to choose the appropriate way to express an emotion. To
achieve this, we introduce MOPO, a Multi-Objective Prompt Optimization
methodology. MOPO optimizes prompts according to multiple objectives (which
correspond here to the output probabilities assigned by emotion classifiers
trained for different domains). In contrast to single objective optimization,
MOPO outputs a set of prompts, each with a different weighting of the multiple
objectives. Users can then choose the most appropriate prompt for their
context. We evaluate MOPO using three objectives, determined by various
domain-specific emotion classifiers. MOPO improves performance by up to 15 pp
across all objectives with a minimal loss (1-2 pp) for any single objective
compared to single-objective optimization. These minor performance losses are
offset by a broader generalization across multiple objectives - which is not
possible with single-objective optimization. Additionally, MOPO reduces
computational requirements by simultaneously optimizing for multiple
objectives, eliminating separate optimization procedures for each objective.",2024-12-17,"Yarik Menchaca Resendiz, Roman Klinger"
"Creating an LLM-based AI-agent: A high-level methodology towards
  enhancing LLMs with APIs","Large Language Models (LLMs) have revolutionized various aspects of
engineering and science. Their utility is often bottlenecked by the lack of
interaction with the external digital environment. To overcome this limitation
and achieve integration of LLMs and Artificial Intelligence (AI) into
real-world applications, customized AI agents are being constructed. Based on
the technological trends and techniques, we extract a high-level approach for
constructing these AI agents, focusing on their underlying architecture. This
thesis serves as a comprehensive guide that elucidates a multi-faceted approach
for empowering LLMs with the capability to leverage Application Programming
Interfaces (APIs). We present a 7-step methodology that begins with the
selection of suitable LLMs and the task decomposition that is necessary for
complex problem-solving. This methodology includes techniques for generating
training data for API interactions and heuristics for selecting the appropriate
API among a plethora of options. These steps eventually lead to the generation
of API calls that are both syntactically and semantically aligned with the
LLM's understanding of a given task. Moreover, we review existing frameworks
and tools that facilitate these processes and highlight the gaps in current
attempts. In this direction, we propose an on-device architecture that aims to
exploit the functionality of carry-on devices by using small models from the
Hugging Face community. We examine the effectiveness of these approaches on
real-world applications of various domains, including the generation of a piano
sheet. Through an extensive analysis of the literature and available
technologies, this thesis aims to set a compass for researchers and
practitioners to harness the full potential of LLMs augmented with external
tool capabilities, thus paving the way for more autonomous, robust, and
context-aware AI agents.",2024-12-17,Ioannis Tzachristas
"Certified Model Predictive Control for Switched Evolution Equations
  using Model Order Reduction","We present a model predictive control (MPC) framework for linear switched
evolution equations arising from a parabolic partial differential equation
(PDE). First-order optimality conditions for the resulting finite-horizon
optimal control problems are derived. The analysis allows for the incorporation
of convex control constraints and sparse regularization. Then, to mitigate the
computational burden of the MPC procedure, we employ Galerkin reduced-order
modeling (ROM) techniques to obtain a low-dimensional surrogate for the
state-adjoint systems. We derive recursive a-posteriori estimates for the ROM
feedback law and the ROM-MPC closed-loop state and show that the ROM-MPC
trajectory evolves within a neighborhood of the true MPC trajectory, whose size
can be explicitly computed and is controlled by the quality of the ROM. Such
estimates are then used to formulate two ROM-MPC algorithms with closed-loop
certification.",2024-12-17,"Michael Kartmann, Mattia Manucci, Benjamin Unger, Stefan Volkwein"
"BOIDS: High-dimensional Bayesian Optimization via Incumbent-guided
  Direction Lines and Subspace Embeddings","When it comes to expensive black-box optimization problems, Bayesian
Optimization (BO) is a well-known and powerful solution. Many real-world
applications involve a large number of dimensions, hence scaling BO to high
dimension is of much interest. However, state-of-the-art high-dimensional BO
methods still suffer from the curse of dimensionality, highlighting the need
for further improvements. In this work, we introduce BOIDS, a novel
high-dimensional BO algorithm that guides optimization by a sequence of
one-dimensional direction lines using a novel tailored line-based optimization
procedure. To improve the efficiency, we also propose an adaptive selection
technique to identify most optimal lines for each round of line-based
optimization. Additionally, we incorporate a subspace embedding technique for
better scaling to high-dimensional spaces. We further provide theoretical
analysis of our proposed method to analyze its convergence property. Our
extensive experimental results show that BOIDS outperforms state-of-the-art
baselines on various synthetic and real-world benchmark problems.",2024-12-17,"Lam Ngo, Huong Ha, Jeffrey Chan, Hongyu Zhang"
Graph Spring Neural ODEs for Link Sign Prediction,"Signed graphs allow for encoding positive and negative relations between
nodes and are used to model various online activities. Node representation
learning for signed graphs is a well-studied task with important applications
such as sign prediction. While the size of datasets is ever-increasing, recent
methods often sacrifice scalability for accuracy. We propose a novel
message-passing layer architecture called Graph Spring Network (GSN) modeled
after spring forces. We combine it with a Graph Neural Ordinary Differential
Equations (ODEs) formalism to optimize the system dynamics in embedding space
to solve a downstream prediction task. Once the dynamics is learned, embedding
generation for novel datasets is done by solving the ODEs in time using a
numerical integration scheme. Our GSN layer leverages the fast-to-compute edge
vector directions and learnable scalar functions that only depend on nodes'
distances in latent space to compute the nodes' positions. Conversely, Graph
Convolution and Graph Attention Network layers rely on learnable vector
functions that require the full positions of input nodes in latent space. We
propose a specific implementation called Spring-Neural-Network (SPR-NN) using a
set of small neural networks mimicking attracting and repulsing spring forces
that we train for link sign prediction. Experiments show that our method
achieves accuracy close to the state-of-the-art methods with node generation
time speedup factors of up to 28,000 on large graphs.",2024-12-17,"Andrin Rehmann, Alexandre Bovet"
"C2F-TP: A Coarse-to-Fine Denoising Framework for Uncertainty-Aware
  Trajectory Prediction","Accurately predicting the trajectory of vehicles is critically important for
ensuring safety and reliability in autonomous driving. Although considerable
research efforts have been made recently, the inherent trajectory uncertainty
caused by various factors including the dynamic driving intends and the diverse
driving scenarios still poses significant challenges to accurate trajectory
prediction. To address this issue, we propose C2F-TP, a coarse-to-fine
denoising framework for uncertainty-aware vehicle trajectory prediction. C2F-TP
features an innovative two-stage coarse-to-fine prediction process.
Specifically, in the spatial-temporal interaction stage, we propose a
spatial-temporal interaction module to capture the inter-vehicle interactions
and learn a multimodal trajectory distribution, from which a certain number of
noisy trajectories are sampled. Next, in the trajectory refinement stage, we
design a conditional denoising model to reduce the uncertainty of the sampled
trajectories through a step-wise denoising operation. Extensive experiments are
conducted on two real datasets NGSIM and highD that are widely adopted in
trajectory prediction. The result demonstrates the effectiveness of our
proposal.",2024-12-17,"Zichen Wang, Hao Miao, Senzhang Wang, Renzhi Wang, Jianxin Wang, Jian Zhang"
"SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge
  Detection","Edge labels are typically at various granularity levels owing to the varying
preferences of annotators, thus handling the subjectivity of per-pixel labels
has been a focal point for edge detection. Previous methods often employ a
simple voting strategy to diminish such label uncertainty or impose a strong
assumption of labels with a pre-defined distribution, e.g., Gaussian. In this
work, we unveil that the segment anything model (SAM) provides strong prior
knowledge to model the uncertainty in edge labels. Our key insight is that the
intermediate SAM features inherently correspond to object edges at various
granularities, which reflects different edge options due to uncertainty.
Therefore, we attempt to align uncertainty with granularity by regressing
intermediate SAM features from different layers to object edges at
multi-granularity levels. In doing so, the model can fully and explicitly
explore diverse ``uncertainties'' in a data-driven fashion. Specifically, we
inject a lightweight module (~ 1.5% additional parameters) into the frozen SAM
to progressively fuse and adapt its intermediate features to estimate edges
from coarse to fine. It is crucial to normalize the granularity level of human
edge labels to match their innate uncertainty. For this, we simply perform
linear blending to the real edge labels at hand to create pseudo labels with
varying granularities. Consequently, our uncertainty-aligned edge detector can
flexibly produce edges at any desired granularity (including an optimal one).
Thanks to SAM, our model uniquely demonstrates strong generalizability for
cross-dataset edge detection. Extensive experimental results on BSDS500,
Muticue and NYUDv2 validate our model's superiority.",2024-12-17,"Xing Liufu, Chaolei Tan, Xiaotong Lin, Yonggang Qi, Jinxuan Li, Jian-Fang Hu"
"TimeCHEAT: A Channel Harmony Strategy for Irregularly Sampled
  Multivariate Time Series Analysis","Irregularly sampled multivariate time series (ISMTS) are prevalent in
reality. Due to their non-uniform intervals between successive observations and
varying sampling rates among series, the channel-independent (CI) strategy,
which has been demonstrated more desirable for complete multivariate time
series forecasting in recent studies, has failed. This failure can be further
attributed to the sampling sparsity, which provides insufficient information
for effective CI learning, thereby reducing its capacity. When we resort to the
channel-dependent (CD) strategy, even higher capacity cannot mitigate the
potential loss of diversity in learning similar embedding patterns across
different channels. We find that existing work considers CI and CD strategies
to be mutually exclusive, primarily because they apply these strategies to the
global channel. However, we hold the view that channel strategies do not
necessarily have to be used globally. Instead, by appropriately applying them
locally and globally, we can create an opportunity to take full advantage of
both strategies. This leads us to introduce the Channel Harmony ISMTS
Transformer (TimeCHEAT), which utilizes the CD locally and the CI globally.
Specifically, we segment the ISMTS into sub-series level patches. Locally, the
CD strategy aggregates information within each patch for time embedding
learning, maximizing the use of relevant observations while reducing long-range
irrelevant interference. Here, we enhance generality by transforming embedding
learning into an edge weight prediction task using bipartite graphs,
eliminating the need for special prior knowledge. Globally, the CI strategy is
applied across patches, allowing the Transformer to learn individualized
attention patterns for each channel. Experimental results indicate our proposed
TimeCHEAT demonstrates competitive SOTA performance across three mainstream
tasks.",2024-12-17,"Jiexi Liu, Meng Cao, Songcan Chen"
"Towards Effective Graph Rationalization via Boosting Environment
  Diversity","Graph Neural Networks (GNNs) perform effectively when training and testing
graphs are drawn from the same distribution, but struggle to generalize well in
the face of distribution shifts. To address this issue, existing mainstreaming
graph rationalization methods first identify rationale and environment
subgraphs from input graphs, and then diversify training distributions by
augmenting the environment subgraphs. However, these methods merely combine the
learned rationale subgraphs with environment subgraphs in the representation
space to produce augmentation samples, failing to produce sufficiently diverse
distributions. Thus, in this paper, we propose to achieve an effective Graph
Rationalization by Boosting Environmental diversity, a GRBE approach that
generates the augmented samples in the original graph space to improve the
diversity of the environment subgraph. Firstly, to ensure the effectiveness of
augmentation samples, we propose a precise rationale subgraph extraction
strategy in GRBE to refine the rationale subgraph learning process in the
original graph space. Secondly, to ensure the diversity of augmented samples,
we propose an environment diversity augmentation strategy in GRBE that mixes
the environment subgraphs of different graphs in the original graph space and
then combines the new environment subgraphs with rationale subgraphs to
generate augmented graphs. The average improvements of 7.65% and 6.11% in
rationalization and classification performance on benchmark datasets
demonstrate the superiority of GRBE over state-of-the-art approaches.",2024-12-17,"Yujie Wang, Kui Yu, Yuhong Zhang, Fuyuan Cao, Jiye Liang"
"Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over
  Aligned Large Language Models","Alignment, endowing a pre-trained Large language model (LLM) with the ability
to follow instructions, is crucial for its real-world applications.
Conventional supervised fine-tuning (SFT) methods formalize it as causal
language modeling typically with a cross-entropy objective, requiring a large
amount of high-quality instruction-response pairs. However, the quality of
widely used SFT datasets can not be guaranteed due to the high cost and
intensive labor for the creation and maintenance in practice. To overcome the
limitations associated with the quality of SFT datasets, we introduce a novel
\textbf{p}reference-\textbf{o}riented supervised \textbf{f}ine-\textbf{t}uning
approach, namely PoFT. The intuition is to boost SFT by imposing a particular
preference: \textit{favoring the target model over aligned LLMs on the same SFT
data.} This preference encourages the target model to predict a higher
likelihood than that predicted by the aligned LLMs, incorporating assessment
information on data quality (i.e., predicted likelihood by the aligned LLMs)
into the training process. Extensive experiments are conducted, and the results
validate the effectiveness of the proposed method. PoFT achieves stable and
consistent improvements over the SFT baselines across different training
datasets and base models. Moreover, we prove that PoFT can be integrated with
existing SFT data filtering methods to achieve better performance, and further
improved by following preference optimization procedures, such as DPO.",2024-12-17,"Yuchen Fan, Yuzhong Hong, Qiushi Wang, Junwei Bao, Hongfei Jiang, Yang Song"
Dyn-HaMR: Recovering 4D Interacting Hand Motion from a Dynamic Camera,"We propose Dyn-HaMR, to the best of our knowledge, the first approach to
reconstruct 4D global hand motion from monocular videos recorded by dynamic
cameras in the wild. Reconstructing accurate 3D hand meshes from monocular
videos is a crucial task for understanding human behaviour, with significant
applications in augmented and virtual reality (AR/VR). However, existing
methods for monocular hand reconstruction typically rely on a weak perspective
camera model, which simulates hand motion within a limited camera frustum. As a
result, these approaches struggle to recover the full 3D global trajectory and
often produce noisy or incorrect depth estimations, particularly when the video
is captured by dynamic or moving cameras, which is common in egocentric
scenarios. Our Dyn-HaMR consists of a multi-stage, multi-objective optimization
pipeline, that factors in (i) simultaneous localization and mapping (SLAM) to
robustly estimate relative camera motion, (ii) an interacting-hand prior for
generative infilling and to refine the interaction dynamics, ensuring plausible
recovery under (self-)occlusions, and (iii) hierarchical initialization through
a combination of state-of-the-art hand tracking methods. Through extensive
evaluations on both in-the-wild and indoor datasets, we show that our approach
significantly outperforms state-of-the-art methods in terms of 4D global mesh
recovery. This establishes a new benchmark for hand motion reconstruction from
monocular video with moving cameras. Our project page is at
https://dyn-hamr.github.io/.",2024-12-17,"Zhengdi Yu, Stefanos Zafeiriou, Tolga Birdal"
"Efficient Speech Command Recognition Leveraging Spiking Neural Network
  and Curriculum Learning-based Knowledge Distillation","The intrinsic dynamics and event-driven nature of spiking neural networks
(SNNs) make them excel in processing temporal information by naturally
utilizing embedded time sequences as time steps. Recent studies adopting this
approach have demonstrated SNNs' effectiveness in speech command recognition,
achieving high performance by employing large time steps for long time
sequences. However, the large time steps lead to increased deployment burdens
for edge computing applications. Thus, it is important to balance high
performance and low energy consumption when detecting temporal patterns in edge
devices. Our solution comprises two key components. 1). We propose a
high-performance fully spike-driven framework termed SpikeSCR, characterized by
a global-local hybrid structure for efficient representation learning, which
exhibits long-term learning capabilities with extended time steps. 2). To
further fully embrace low energy consumption, we propose an effective knowledge
distillation method based on curriculum learning (KDCL), where valuable
representations learned from the easy curriculum are progressively transferred
to the hard curriculum with minor loss, striking a trade-off between power
efficiency and high performance. We evaluate our method on three benchmark
datasets: the Spiking Heidelberg Dataset (SHD), the Spiking Speech Commands
(SSC), and the Google Speech Commands (GSC) V2. Our experimental results
demonstrate that SpikeSCR outperforms current state-of-the-art (SOTA) methods
across these three datasets with the same time steps. Furthermore, by executing
KDCL, we reduce the number of time steps by 60% and decrease energy consumption
by 54.8% while maintaining comparable performance to recent SOTA results.
Therefore, this work offers valuable insights for tackling temporal processing
challenges with long time sequences in edge neuromorphic computing systems.",2024-12-17,"Jiaqi Wang, Liutao Yu, Liwei Huang, Chenlin Zhou, Han Zhang, Zhenxi Song, Min Zhang, Zhengyu Ma, Zhiguo Zhang"
Diffusion backbone of temporal higher-order networks,"Temporal higher-order networks, where each hyperlink involving a group of
nodes are activated or deactivated over time, are recently used to represent
complex systems such as social contacts, interactions or collaborations that
occur at specific times. Such networks are substrates for social contagion
processes like the diffusion of information and opinions. In this work, we
consider eight temporal higher-order networks derived from human face-to-face
interactions in various contexts and the Susceptible-Infected threshold process
on each of these networks: whenever a hyperlink is active and the number of
infected nodes in the hyperlink exceeds a threshold $\Theta$, each susceptible
node in the hyperlink is infected independently with probability $\beta$. The
objective is to understand (1) the contribution of each hyperlink to the
diffusion process, namely, the average number of nodes that are infected
directly via the activation of the hyperlink when the diffusion starts from an
arbitrary seed node, and (2) hyperlinks with what network properties tend to
contribute more. We first propose to construct the diffusion backbone. The
backbone is a weighted higher-order network, where the weight of each hyperlink
denotes the contribution of the hyperlink to a given diffusion process.
Secondly, we find that the backbone, or the contribution of hyperlinks, is
dependent on the parameters $\beta$ and $\Theta$ of the diffusion process,
which is also supported by our theoretical analysis of the backbone when
$\beta\rightarrow 0$. Thirdly, we systematically design centrality metrics for
hyperlinks in a temporal higher-order network, and each centrality metric is
used to estimate the ranking of hyperlinks by the weight in the backbone.
Finally, we find and explain why different centrality metrics can better
estimate the contributions of hyperlinks for different parameters of the
diffusion process.",2024-12-17,"Shilun Zhang, Alberto Ceria, Huijuan Wang"
"Benchmarking and Understanding Compositional Relational Reasoning of
  LLMs","Compositional relational reasoning (CRR) is a hallmark of human intelligence,
but we lack a clear understanding of whether and how existing transformer large
language models (LLMs) can solve CRR tasks. To enable systematic exploration of
the CRR capability of LLMs, we first propose a new synthetic benchmark called
Generalized Associative Recall (GAR) by integrating and generalizing the
essence of several tasks in mechanistic interpretability (MI) study in a
unified framework. Evaluation shows that GAR is challenging enough for existing
LLMs, revealing their fundamental deficiency in CRR. Meanwhile, it is easy
enough for systematic MI study. Then, to understand how LLMs solve GAR tasks,
we use attribution patching to discover the core circuits reused by Vicuna-33B
across different tasks and a set of vital attention heads. Intervention
experiments show that the correct functioning of these heads significantly
impacts task performance. Especially, we identify two classes of heads whose
activations represent the abstract notion of true and false in GAR tasks
respectively. They play a fundamental role in CRR across various models and
tasks. The dataset and code are available at https://github.com/Caiyun-AI/GAR.",2024-12-17,"Ruikang Ni, Da Xiao, Qingye Meng, Xiangyu Li, Shihui Zheng, Hongliang Liang"
"TSEML: A task-specific embedding-based method for few-shot
  classification of cancer molecular subtypes","Molecular subtyping of cancer is recognized as a critical and challenging
upstream task for personalized therapy. Existing deep learning methods have
achieved significant performance in this domain when abundant data samples are
available. However, the acquisition of densely labeled samples for cancer
molecular subtypes remains a significant challenge for conventional
data-intensive deep learning approaches. In this work, we focus on the few-shot
molecular subtype prediction problem in heterogeneous and small cancer
datasets, aiming to enhance precise diagnosis and personalized treatment. We
first construct a new few-shot dataset for cancer molecular subtype
classification and auxiliary cancer classification, named TCGA Few-Shot, from
existing publicly available datasets. To effectively leverage the relevant
knowledge from both tasks, we introduce a task-specific embedding-based
meta-learning framework (TSEML). TSEML leverages the synergistic strengths of a
model-agnostic meta-learning (MAML) approach and a prototypical network
(ProtoNet) to capture diverse and fine-grained features. Comparative
experiments conducted on the TCGA Few-Shot dataset demonstrate that our TSEML
framework achieves superior performance in addressing the problem of few-shot
molecular subtype classification.",2024-12-17,"Ran Sua, Rui Shi, Hui Cui, Ping Xuan, Chengyan Fang, Xikang Feng, Qiangguo Jin"
"Ask for More Than Bayes Optimal: A Theory of Indecisions for
  Classification","Selective classification frameworks are useful tools for automated decision
making in highly risky scenarios, since they allow for a classifier to only
make highly confident decisions, while abstaining from making a decision when
it is not confident enough to do so, which is otherwise known as an indecision.
For a given level of classification accuracy, we aim to make as many decisions
as possible. For many problems, this can be achieved without abstaining from
making decisions. But when the problem is hard enough, we show that we can
still control the misclassification rate of a classifier up to any user
specified level, while only abstaining from the minimum necessary amount of
decisions, even if this level of misclassification is smaller than the Bayes
optimal error rate. In many problem settings, the user could obtain a dramatic
decrease in misclassification while only paying a comparatively small price in
terms of indecisions.",2024-12-17,"Mohamed Ndaoud, Peter Radchenko, Bradley Rava"
"Cross-Dialect Information Retrieval: Information Access in Low-Resource
  and High-Variance Languages","A large amount of local and culture-specific knowledge (e.g., people,
traditions, food) can only be found in documents written in dialects. While
there has been extensive research conducted on cross-lingual information
retrieval (CLIR), the field of cross-dialect retrieval (CDIR) has received
limited attention. Dialect retrieval poses unique challenges due to the limited
availability of resources to train retrieval models and the high variability in
non-standardized languages. We study these challenges on the example of German
dialects and introduce the first German dialect retrieval dataset, dubbed
WikiDIR, which consists of seven German dialects extracted from Wikipedia.
Using WikiDIR, we demonstrate the weakness of lexical methods in dealing with
high lexical variation in dialects. We further show that commonly used
zero-shot cross-lingual transfer approach with multilingual encoders do not
transfer well to extremely low-resource setups, motivating the need for
resource-lean and dialect-specific retrieval models. We finally demonstrate
that (document) translation is an effective way to reduce the dialect gap in
CDIR.",2024-12-17,"Robert Litschko, Oliver Kraus, Verena Blaschke, Barbara Plank"
"Multi-View Incremental Learning with Structured Hebbian Plasticity for
  Enhanced Fusion Efficiency","The rapid evolution of multimedia technology has revolutionized human
perception, paving the way for multi-view learning. However, traditional
multi-view learning approaches are tailored for scenarios with fixed data
views, falling short of emulating the intricate cognitive procedures of the
human brain processing signals sequentially. Our cerebral architecture
seamlessly integrates sequential data through intricate feed-forward and
feedback mechanisms. In stark contrast, traditional methods struggle to
generalize effectively when confronted with data spanning diverse domains,
highlighting the need for innovative strategies that can mimic the brain's
adaptability and dynamic integration capabilities. In this paper, we propose a
bio-neurologically inspired multi-view incremental framework named MVIL aimed
at emulating the brain's fine-grained fusion of sequentially arriving views.
MVIL lies two fundamental modules: structured Hebbian plasticity and synaptic
partition learning. The structured Hebbian plasticity reshapes the structure of
weights to express the high correlation between view representations,
facilitating a fine-grained fusion of view representations. Moreover, synaptic
partition learning is efficient in alleviating drastic changes in weights and
also retaining old knowledge by inhibiting partial synapses. These modules
bionically play a central role in reinforcing crucial associations between
newly acquired information and existing knowledge repositories, thereby
enhancing the network's capacity for generalization. Experimental results on
six benchmark datasets show MVIL's effectiveness over state-of-the-art methods.",2024-12-17,"Yuhong Chen, Ailin Song, Huifeng Yin, Shuai Zhong, Fuhai Chen, Qi Xu, Shiping Wang, Mingkun Xu"
"Breaking the Programming Language Barrier: Multilingual Prompting to
  Empower Non-Native English Learners","Non-native English speakers (NNES) face multiple barriers to learning
programming. These barriers can be obvious, such as the fact that programming
language syntax and instruction are often in English, or more subtle, such as
being afraid to ask for help in a classroom full of native English speakers.
However, these barriers are frustrating because many NNES students know more
about programming than they can articulate in English. Advances in generative
AI (GenAI) have the potential to break down these barriers because state of the
art models can support interactions in multiple languages. Moreover, recent
work has shown that GenAI can be highly accurate at code generation and
explanation. In this paper, we provide the first exploration of NNES students
prompting in their native languages (Arabic, Chinese, and Portuguese) to
generate code to solve programming problems. Our results show that students are
able to successfully use their native language to solve programming problems,
but not without some difficulty specifying programming terminology and
concepts. We discuss the challenges they faced, the implications for practice
in the short term, and how this might transform computing education globally in
the long term.",2024-12-17,"James Prather, Brent N. Reeves, Paul Denny, Juho Leinonen, Stephen MacNeil, Andrew Luxton-Reilly, João Orvalho, Amin Alipour, Ali Alfageeh, Thezyrie Amarouche, Bailey Kimmel, Jared Wright, Musa Blake, Gweneth Barbre"
CRoF: CLIP-based Robust Few-shot Learning on Noisy Labels,"Noisy labels threaten the robustness of few-shot learning (FSL) due to the
inexact features in a new domain. CLIP, a large-scale vision-language model,
performs well in FSL on image-text embedding similarities, but it is
susceptible to misclassification caused by noisy labels. How to enhance domain
generalization of CLIP on noisy data within FSL tasks is a critical challenge.
In this paper, we provide a novel view to mitigate the influence of noisy
labels, CLIP-based Robust Few-shot learning (CRoF). CRoF is a general plug-in
module for CLIP-based models. To avoid misclassification and confused label
embedding, we design the few-shot task-oriented prompt generator to give more
discriminative descriptions of each category. The proposed prompt achieves
larger distances of inter-class textual embedding. Furthermore, rather than
fully trusting zero-shot classification by CLIP, we fine-tune CLIP on noisy
few-shot data in a new domain with a weighting strategy like label-smooth. The
weights for multiple potentially correct labels consider the relationship
between CLIP's prior knowledge and original label information to ensure
reliability. Our multiple label loss function further supports robust training
under this paradigm. Comprehensive experiments show that CRoF, as a plug-in,
outperforms fine-tuned and vanilla CLIP models on different noise types and
noise ratios.",2024-12-17,"Shizhuo Deng, Bowen Han, Jiaqi Chen, Hao Wang, Dongyue Chen, Tong Jia"
"Implicit Location-Caption Alignment via Complementary Masking for
  Weakly-Supervised Dense Video Captioning","Weakly-Supervised Dense Video Captioning (WSDVC) aims to localize and
describe all events of interest in a video without requiring annotations of
event boundaries. This setting poses a great challenge in accurately locating
the temporal location of event, as the relevant supervision is unavailable.
Existing methods rely on explicit alignment constraints between event locations
and captions, which involve complex event proposal procedures during both
training and inference. To tackle this problem, we propose a novel implicit
location-caption alignment paradigm by complementary masking, which simplifies
the complex event proposal and localization process while maintaining
effectiveness. Specifically, our model comprises two components: a dual-mode
video captioning module and a mask generation module. The dual-mode video
captioning module captures global event information and generates descriptive
captions, while the mask generation module generates differentiable positive
and negative masks for localizing the events. These masks enable the implicit
alignment of event locations and captions by ensuring that captions generated
from positively and negatively masked videos are complementary, thereby forming
a complete video description. In this way, even under weak supervision, the
event location and event caption can be aligned implicitly. Extensive
experiments on the public datasets demonstrate that our method outperforms
existing weakly-supervised methods and achieves competitive results compared to
fully-supervised methods.",2024-12-17,"Shiping Ge, Qiang Chen, Zhiwei Jiang, Yafeng Yin, Liu Qin, Ziyao Chen, Qing Gu"
Structural Cellular Hash Chemistry,"Hash Chemistry, a minimalistic artificial chemistry model of open-ended
evolution, has recently been extended to non-spatial and cellular versions. The
non-spatial version successfully demonstrated continuous adaptation and
unbounded growth of complexity of self-replicating entities, but it did not
simulate multiscale ecological interactions among the entities. On the
contrary, the cellular version explicitly represented multiscale spatial
ecological interactions among evolving patterns, yet it failed to show
meaningful adaptive evolution or complexity growth. It remains an open question
whether it is possible to create a similar minimalistic evolutionary system
that can exhibit all of those desired properties at once within a
computationally efficient framework. Here we propose an improved version called
Structural Cellular Hash Chemistry (SCHC). In SCHC, individual identities of
evolving patterns are explicitly represented and processed as the connected
components of the nearest neighbor graph of active cells. The neighborhood
connections are established by connecting active cells with other active cells
in their Moore neighborhoods in a 2D cellular grid. Evolutionary dynamics in
SCHC are simulated via pairwise competitions of two randomly selected patterns,
following the approach used in the non-spatial Hash Chemistry. SCHC's
computational cost was significantly less than the original and non-spatial
versions. Numerical simulations showed that these model modifications achieved
spontaneous movement, self-replication and unbounded growth of complexity of
spatial evolving patterns, which were clearly visible in space in a highly
intuitive manner. Detailed analysis of simulation results showed that there
were spatial ecological interactions among self-replicating patterns and their
diversity was also substantially promoted in SCHC, neither of which was present
in the non-spatial version.",2024-12-17,Hiroki Sayama
"RA-SGG: Retrieval-Augmented Scene Graph Generation Framework via
  Multi-Prototype Learning","Scene Graph Generation (SGG) research has suffered from two fundamental
challenges: the long-tailed predicate distribution and semantic ambiguity
between predicates. These challenges lead to a bias towards head predicates in
SGG models, favoring dominant general predicates while overlooking fine-grained
predicates. In this paper, we address the challenges of SGG by framing it as
multi-label classification problem with partial annotation, where relevant
labels of fine-grained predicates are missing. Under the new frame, we propose
Retrieval-Augmented Scene Graph Generation (RA-SGG), which identifies potential
instances to be multi-labeled and enriches the single-label with multi-labels
that are semantically similar to the original label by retrieving relevant
samples from our established memory bank. Based on augmented relations (i.e.,
discovered multi-labels), we apply multi-prototype learning to train our SGG
model. Several comprehensive experiments have demonstrated that RA-SGG
outperforms state-of-the-art baselines by up to 3.6% on VG and 5.9% on GQA,
particularly in terms of F@K, showing that RA-SGG effectively alleviates the
issue of biased prediction caused by the long-tailed distribution and semantic
ambiguity of predicates.",2024-12-17,"Kanghoon Yoon, Kibum Kim, Jaehyung Jeon, Yeonjun In, Donghyun Kim, Chanyoung Park"
Forbidden Patterns in Mixed Linear Layouts,"An ordered graph is a graph with a total order over its vertices. A linear
layout of an ordered graph is a partition of the edges into sets of either
non-crossing edges, called stacks, or non-nesting edges, called queues. The
stack (queue) number of an ordered graph is the minimum number of required
stacks (queues). Mixed linear layouts combine these layouts by allowing each
set of edges to form either a stack or a queue. The minimum number of stacks
plus queues is called the mixed page number. It is well known that ordered
graphs with small stack number are characterized, up to a function, by the
absence of large twists (that is, pairwise crossing edges). Similarly, ordered
graphs with small queue number are characterized by the absence of large
rainbows (that is, pairwise nesting edges). However, no such characterization
via forbidden patterns is known for mixed linear layouts.
  We address this gap by introducing patterns similar to twists and rainbows,
which we call thick patterns; such patterns allow a characterization, again up
to a function, of mixed linear layouts of bounded-degree graphs. That is, we
show that a family of ordered graphs with bounded maximum degree has bounded
mixed page number if and only if the size of the largest thick pattern is
bounded. In addition, we investigate an exact characterization of ordered
graphs whose mixed page number equals a fixed integer $ k $ via a finite set of
forbidden patterns. We show that for every $ k \ge 2 $, there is no such
characterization, which supports the nature of our first result.",2024-12-17,"Deborah Haun, Laura Merker, Sergey Pupyrev"
Noise-based Local Learning using Stochastic Magnetic Tunnel Junctions,"Brain-inspired learning in physical hardware has enormous potential to learn
fast at minimal energy expenditure. One of the characteristics of biological
learning systems is their ability to learn in the presence of various noise
sources. Inspired by this observation, we introduce a novel noise-based
learning approach for physical systems implementing multi-layer neural
networks. Simulation results show that our approach allows for effective
learning whose performance approaches that of the conventional effective yet
energy-costly backpropagation algorithm. Using a spintronics hardware
implementation, we demonstrate experimentally that learning can be achieved in
a small network composed of physical stochastic magnetic tunnel junctions.
These results provide a path towards efficient learning in general physical
systems which embraces rather than mitigates the noise inherent in physical
devices.",2024-12-17,"Kees Koenders, Leo Schnitzpan, Fabian Kammerbauer, Sinan Shu, Gerhard Jakob, Mathis Kläui, Johan Mentink, Nasir Ahmad, Marcel van Gerven"
"Rethinking Diffusion-Based Image Generators for Fundus Fluorescein
  Angiography Synthesis on Limited Data","Fundus imaging is a critical tool in ophthalmology, with different imaging
modalities offering unique advantages. For instance, fundus fluorescein
angiography (FFA) can accurately identify eye diseases. However, traditional
invasive FFA involves the injection of sodium fluorescein, which can cause
discomfort and risks. Generating corresponding FFA images from non-invasive
fundus images holds significant practical value but also presents challenges.
First, limited datasets constrain the performance and effectiveness of models.
Second, previous studies have primarily focused on generating FFA for single
diseases or single modalities, often resulting in poor performance for patients
with various ophthalmic conditions. To address these issues, we propose a novel
latent diffusion model-based framework, Diffusion, which introduces a
fine-tuning protocol to overcome the challenge of limited medical data and
unleash the generative capabilities of diffusion models. Furthermore, we
designed a new approach to tackle the challenges of generating across different
modalities and disease types. On limited datasets, our framework achieves
state-of-the-art results compared to existing methods, offering significant
potential to enhance ophthalmic diagnostics and patient care. Our code will be
released soon to support further research in this field.",2024-12-17,"Chengzhou Yu, Huihui Fang, Hongqiu Wang, Ting Deng, Qing Du, Yanwu Xu, Weihua Yang"
RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service,"Retrieval-augmented generation (RAG) improves the service quality of large
language models by retrieving relevant documents from credible literature and
integrating them into the context of the user query. Recently, the rise of the
cloud RAG service has made it possible for users to query relevant documents
conveniently. However, directly sending queries to the cloud brings potential
privacy leakage. In this paper, we are the first to formally define the
privacy-preserving cloud RAG service to protect the user query and propose
RemoteRAG as a solution regarding privacy, efficiency, and accuracy. For
privacy, we introduce $(n,\epsilon)$-DistanceDP to characterize privacy leakage
of the user query and the leakage inferred from relevant documents. For
efficiency, we limit the search range from the total documents to a small
number of selected documents related to a perturbed embedding generated from
$(n,\epsilon)$-DistanceDP, so that computation and communication costs required
for privacy protection significantly decrease. For accuracy, we ensure that the
small range includes target documents related to the user query with detailed
theoretical analysis. Experimental results also demonstrate that RemoteRAG can
resist existing embedding inversion attack methods while achieving no loss in
retrieval under various settings. Moreover, RemoteRAG is efficient, incurring
only $0.67$ seconds and $46.66$KB of data transmission ($2.72$ hours and $1.43$
GB with the non-optimized privacy-preserving scheme) when retrieving from a
total of $10^6$ documents.",2024-12-17,"Yihang Cheng, Lan Zhang, Junyang Wang, Mu Yuan, Yunhao Yao"
A Survey on Sequential Recommendation,"Different from most conventional recommendation problems, sequential
recommendation focuses on learning users' preferences by exploiting the
internal order and dependency among the interacted items, which has received
significant attention from both researchers and practitioners. In recent years,
we have witnessed great progress and achievements in this field, necessitating
a new survey. In this survey, we study the SR problem from a new perspective
(i.e., the construction of an item's properties), and summarize the most recent
techniques used in sequential recommendation such as pure ID-based SR, SR with
side information, multi-modal SR, generative SR, LLM-powered SR, ultra-long SR
and data-augmented SR. Moreover, we introduce some frontier research topics in
sequential recommendation, e.g., open-domain SR, data-centric SR, could-edge
collaborative SR, continuous SR, SR for good, and explainable SR. We believe
that our survey could be served as a valuable roadmap for readers in this
field.",2024-12-17,"Liwei Pan, Weike Pan, Meiyan Wei, Hongzhi Yin, Zhong Ming"
Towards a Training Free Approach for 3D Scene Editing,"Text driven diffusion models have shown remarkable capabilities in editing
images. However, when editing 3D scenes, existing works mostly rely on training
a NeRF for 3D editing. Recent NeRF editing methods leverages edit operations by
deploying 2D diffusion models and project these edits into 3D space. They
require strong positional priors alongside text prompt to identify the edit
location. These methods are operational on small 3D scenes and are more
generalized to particular scene. They require training for each specific edit
and cannot be exploited in real-time edits. To address these limitations, we
propose a novel method, FreeEdit, to make edits in training free manner using
mesh representations as a substitute for NeRF. Training-free methods are now a
possibility because of the advances in foundation model's space. We leverage
these models to bring a training-free alternative and introduce solutions for
insertion, replacement and deletion. We consider insertion, replacement and
deletion as basic blocks for performing intricate edits with certain
combinations of these operations. Given a text prompt and a 3D scene, our model
is capable of identifying what object should be inserted/replaced or deleted
and location where edit should be performed. We also introduce a novel
algorithm as part of FreeEdit to find the optimal location on grounding object
for placement. We evaluate our model by comparing it with baseline models on a
wide range of scenes using quantitative and qualitative metrics and showcase
the merits of our method with respect to others.",2024-12-17,"Vivek Madhavaram, Shivangana Rawat, Chaitanya Devaguptapu, Charu Sharma, Manohar Kaul"
Progressive Monitoring of Generative Model Training Evolution,"While deep generative models (DGMs) have gained popularity, their
susceptibility to biases and other inefficiencies that lead to undesirable
outcomes remains an issue. With their growing complexity, there is a critical
need for early detection of issues to achieve desired results and optimize
resources. Hence, we introduce a progressive analysis framework to monitor the
training process of DGMs. Our method utilizes dimensionality reduction
techniques to facilitate the inspection of latent representations, the
generated and real distributions, and their evolution across training
iterations. This monitoring allows us to pause and fix the training method if
the representations or distributions progress undesirably. This approach allows
for the analysis of a models' training dynamics and the timely identification
of biases and failures, minimizing computational loads. We demonstrate how our
method supports identifying and mitigating biases early in training a
Generative Adversarial Network (GAN) and improving the quality of the generated
data distribution.",2024-12-17,"Vidya Prasad, Anna Vilanova, Nicola Pezzotti"
EmbedFuzz: High Speed Fuzzing Through Transplantation,"Dynamic analysis and especially fuzzing are challenging tasks for embedded
firmware running on modern low-end Microcontroller Units (MCUs) due to
performance overheads from instruction emulation, the difficulty of emulating
the vast space of available peripherals, and low availability of open-source
embedded firmware. Consequently, efficient security testing of MCU firmware has
proved to be a resource- and engineering-heavy endeavor.
  EmbedFuzz introduces an efficient end-to-end fuzzing framework for MCU
firmware. Our novel firmware transplantation technique converts binary MCU
firmware to a functionally equivalent and fuzzing-enhanced version of the
firmware which executes on a compatible high-end device at native performance.
Besides the performance gains, our system enables advanced introspection
capabilities based on tooling for typical Linux user space processes, thus
simplifying analysis of crashes and bug triaging. In our evaluation against
state-of-the-art MCU fuzzers, EmbedFuzz exhibits up to eight-fold fuzzing
throughput while consuming at most a fourth of the energy thanks to its native
execution.",2024-12-17,"Florian Hofhammer, Qinying Wang, Atri Bhattacharyya, Majid Salehi, Bruno Crispo, Manuel Egele, Mathias Payer, Marcel Busch"
Open-World Panoptic Segmentation,"Perception is a key building block of autonomously acting vision systems such
as autonomous vehicles. It is crucial that these systems are able to understand
their surroundings in order to operate safely and robustly. Additionally,
autonomous systems deployed in unconstrained real-world scenarios must be able
of dealing with novel situations and object that have never been seen before.
In this article, we tackle the problem of open-world panoptic segmentation,
i.e., the task of discovering new semantic categories and new object instances
at test time, while enforcing consistency among the categories that we
incrementally discover. We propose Con2MAV, an approach for open-world panoptic
segmentation that extends our previous work, ContMAV, which was developed for
open-world semantic segmentation. Through extensive experiments across multiple
datasets, we show that our model achieves state-of-the-art results on
open-world segmentation tasks, while still performing competitively on the
known categories. We will open-source our implementation upon acceptance.
Additionally, we propose PANIC (Panoptic ANomalies In Context), a benchmark for
evaluating open-world panoptic segmentation in autonomous driving scenarios.
This dataset, recorded with a multi-modal sensor suite mounted on a car,
provides high-quality, pixel-wise annotations of anomalous objects at both
semantic and instance level. Our dataset contains 800 images, with more than 50
unknown classes, i.e., classes that do not appear in the training set, and 4000
object instances, making it an extremely challenging dataset for open-world
segmentation tasks in the autonomous driving scenario. We provide competitions
for multiple open-world tasks on a hidden test set. Our dataset and
competitions are available at https://www.ipb.uni-bonn.de/data/panic.",2024-12-17,"Matteo Sodano, Federico Magistri, Jens Behley, Cyrill Stachniss"
Gaussian Billboards: Expressive 2D Gaussian Splatting with Textures,"Gaussian Splatting has recently emerged as the go-to representation for
reconstructing and rendering 3D scenes. The transition from 3D to 2D Gaussian
primitives has further improved multi-view consistency and surface
reconstruction accuracy. In this work we highlight the similarity between 2D
Gaussian Splatting (2DGS) and billboards from traditional computer graphics.
Both use flat semi-transparent 2D geometry that is positioned, oriented and
scaled in 3D space. However 2DGS uses a solid color per splat and an opacity
modulated by a Gaussian distribution, where billboards are more expressive,
modulating the color with a uv-parameterized texture. We propose to unify these
concepts by presenting Gaussian Billboards, a modification of 2DGS to add
spatially-varying color achieved using per-splat texture interpolation. The
result is a mixture of the two representations, which benefits from both the
robust scene optimization power of 2DGS and the expressiveness of texture
mapping. We show that our method can improve the sharpness and quality of the
scene representation in a wide range of qualitative and quantitative
evaluations compared to the original 2DGS implementation.",2024-12-17,"Sebastian Weiss, Derek Bradley"
"AsyncSC: An Asynchronous Sidechain for Multi-Domain Data Exchange in
  Internet of Things","Sidechain techniques improve blockchain scalability and interoperability,
providing decentralized exchange and cross-chain collaboration solutions for
Internet of Things (IoT) data across various domains. However, current
state-of-the-art (SOTA) schemes for IoT multi-domain data exchange are
constrained by the need for synchronous networks, hindering efficient
cross-chain interactions in discontinuous networks and leading to suboptimal
data exchange. In this paper, we propose AsyncSC, a novel asynchronous
sidechain construction. It employs a committee to provide Cross-Blockchain as a
Service (C-BaaS) for data exchange in multi-domain IoT. To fulfill the need for
asynchronous and efficient data exchange, we combine the ideas of aggregate
signatures and verifiable delay functions to devise a novel cryptographic
primitive called delayed aggregate signature (DAS), which constructs
asynchronous cross-chain proofs (ACPs) that ensure the security of cross-chain
interactions. To ensure the consistency of asynchronous transactions, we
propose a multilevel buffered transaction pool that guarantees the transaction
sequencing. We analyze and prove the security of AsyncSC, simulate an
asynchronous communication environment, and conduct a comprehensive evaluation.
The results show that AsyncSC outperforms SOTA schemes, improving throughput by
an average of 1.21 to 3.96 times, reducing transaction latency by 59.76% to
83.61%, and maintaining comparable resource overhead.",2024-12-17,"Lingxiao Yang, Xuewen Dong, Zhiguo Wan, Sheng Gao, Wei Tong, Di Lu, Yulong Shen, Xiaojiang Du"
"Accelerating lensed quasars discovery and modeling with physics-informed
  variational autoencoders","Strongly lensed quasars provide valuable insights into the rate of cosmic
expansion, the distribution of dark matter in foreground deflectors, and the
characteristics of quasar hosts. However, detecting them in astronomical images
is difficult due to the prevalence of non-lensing objects. To address this
challenge, we developed a generative deep learning model called VariLens, built
upon a physics-informed variational autoencoder. This model seamlessly
integrates three essential modules: image reconstruction, object
classification, and lens modeling, offering a fast and comprehensive approach
to strong lens analysis. VariLens is capable of rapidly determining both (1)
the probability that an object is a lens system and (2) key parameters of a
singular isothermal ellipsoid (SIE) mass model -- including the Einstein radius
($\theta_\mathrm{E}$), lens center, and ellipticity -- in just milliseconds
using a single CPU. A direct comparison of VariLens estimates with traditional
lens modeling for 20 known lensed quasars within the Subaru Hyper Suprime-Cam
(HSC) footprint shows good agreement, with both results consistent within
$2\sigma$ for systems with $\theta_\mathrm{E}<3$ arcsecs. To identify new
lensed quasar candidates, we begin with an initial sample of approximately 80
million sources, combining HSC data with multiwavelength information from
various surveys. After applying a photometric preselection aimed at locating
$z>1.5$ sources, the number of candidates is reduced to 710,966. Subsequently,
VariLens highlights 13,831 sources, each showing a high likelihood of being a
lens. A visual assessment of these objects results in 42 promising candidates
that await spectroscopic confirmation. These results underscore the potential
of automated deep learning pipelines to efficiently detect and model strong
lenses in large datasets.",2024-12-17,"Irham T. Andika, Stefan Schuldt, Sherry H. Suyu, Satadru Bag, Raoul Cañameras, Alejandra Melo, Claudio Grillo, James H. H. Chan"
"ParMod: A Parallel and Modular Framework for Learning Non-Markovian
  Tasks","The commonly used Reinforcement Learning (RL) model, MDPs (Markov Decision
Processes), has a basic premise that rewards depend on the current state and
action only. However, many real-world tasks are non-Markovian, which has
long-term memory and dependency. The reward sparseness problem is further
amplified in non-Markovian scenarios. Hence learning a non-Markovian task (NMT)
is inherently more difficult than learning a Markovian one. In this paper, we
propose a novel \textbf{Par}allel and \textbf{Mod}ular RL framework, ParMod,
specifically for learning NMTs specified by temporal logic. With the aid of
formal techniques, the NMT is modulaized into a series of sub-tasks based on
the automaton structure (equivalent to its temporal logic counterpart). On this
basis, sub-tasks will be trained by a group of agents in a parallel fashion,
with one agent handling one sub-task. Besides parallel training, the core of
ParMod lies in: a flexible classification method for modularizing the NMT, and
an effective reward shaping method for improving the sample efficiency. A
comprehensive evaluation is conducted on several challenging benchmark problems
with respect to various metrics. The experimental results show that ParMod
achieves superior performance over other relevant studies. Our work thus
provides a good synergy among RL, NMT and temporal logic.",2024-12-17,"Ruixuan Miao, Xu Lu, Cong Tian, Bin Yu, Zhenhua Duan"
"Uncertainty-Aware Hybrid Inference with On-Device Small and Remote Large
  Language Models","This paper studies a hybrid language model (HLM) architecture that integrates
a small language model (SLM) operating on a mobile device with a large language
model (LLM) hosted at the base station (BS) of a wireless network. The HLM
token generation process follows the speculative inference principle: the SLM's
vocabulary distribution is uploaded to the LLM, which either accepts or rejects
it, with rejected tokens being resampled by the LLM. While this approach
ensures alignment between the vocabulary distributions of the SLM and LLM, it
suffers from low token throughput due to uplink transmission and the
computation costs of running both language models. To address this, we propose
a novel HLM structure coined Uncertainty-aware opportunistic HLM (U-HLM),
wherein the SLM locally measures its output uncertainty and skips both uplink
transmissions and LLM operations for tokens that are likely to be accepted.
This opportunistic skipping is enabled by our empirical finding of a linear
correlation between the SLM's uncertainty and the LLM's rejection probability.
We analytically derive the uncertainty threshold and evaluate its expected risk
of rejection. Simulations show that U-HLM reduces uplink transmissions and LLM
computations by 45.93%, while achieving up to 97.54% of the LLM's inference
accuracy and 2.54$\times$ faster token throughput than HLM without skipping.",2024-12-17,"Seungeun Oh, Jinhyuk Kim, Jihong Park, Seung-Woo Ko, Tony Q. S. Quek, Seong-Lyun Kim"
"Train More Parameters But Mind Their Placement: Insights into Language
  Adaptation with PEFT","Smaller LLMs still face significant challenges even in medium-resourced
languages, particularly when it comes to language-specific knowledge -- a
problem not easily resolved with machine-translated data. In this case study on
Icelandic, we aim to enhance the generation performance of an LLM by
specialising it using unstructured text corpora. A key focus is on preventing
interference with the models' capabilities of handling longer context during
this adaptation. Through ablation studies using various parameter-efficient
fine-tuning (PEFT) methods and setups, we find that increasing the number of
trainable parameters leads to better and more robust language adaptation. LoRAs
placed in the feed-forward layers and bottleneck adapters show promising
results with sufficient parameters, while prefix tuning and (IA)3 are not
suitable. Although improvements are consistent in 0-shot summarisation, some
adapted models struggle with longer context lengths, an issue that can be
mitigated by adapting only the final layers.",2024-12-17,Jenny Kunz
"Structural Pruning via Spatial-aware Information Redundancy for Semantic
  Segmentation","In recent years, semantic segmentation has flourished in various
applications. However, the high computational cost remains a significant
challenge that hinders its further adoption. The filter pruning method for
structured network slimming offers a direct and effective solution for the
reduction of segmentation networks. Nevertheless, we argue that most existing
pruning methods, originally designed for image classification, overlook the
fact that segmentation is a location-sensitive task, which consequently leads
to their suboptimal performance when applied to segmentation networks. To
address this issue, this paper proposes a novel approach, denoted as
Spatial-aware Information Redundancy Filter Pruning~(SIRFP), which aims to
reduce feature redundancy between channels. First, we formulate the pruning
process as a maximum edge weight clique problem~(MEWCP) in graph theory,
thereby minimizing the redundancy among the remaining features after pruning.
Within this framework, we introduce a spatial-aware redundancy metric based on
feature maps, thus endowing the pruning process with location sensitivity to
better adapt to pruning segmentation networks. Additionally, based on the
MEWCP, we propose a low computational complexity greedy strategy to solve this
NP-hard problem, making it feasible and efficient for structured pruning. To
validate the effectiveness of our method, we conducted extensive comparative
experiments on various challenging datasets. The results demonstrate the
superior performance of SIRFP for semantic segmentation tasks.",2024-12-17,"Dongyue Wu, Zilin Guo, Li Yu, Nong Sang, Changxin Gao"
"MedMax: Mixed-Modal Instruction Tuning for Training Biomedical
  Assistants","Recent advancements in mixed-modal generative models have enabled flexible
integration of information across image-text content. These models have opened
new avenues for developing unified biomedical assistants capable of analyzing
biomedical images, answering complex questions about them, and predicting the
impact of medical procedures on a patient's health. However, existing resources
face challenges such as limited data availability, narrow domain coverage, and
restricted sources (e.g., medical papers). To address these gaps, we present
MedMax, the first large-scale multimodal biomedical instruction-tuning dataset
for mixed-modal foundation models. With 1.47 million instances, MedMax
encompasses a diverse range of tasks, including multimodal content generation
(interleaved image-text data), biomedical image captioning and generation,
visual chatting, and report understanding. These tasks span diverse medical
domains such as radiology and histopathology. Subsequently, we fine-tune a
mixed-modal foundation model on the MedMax dataset, achieving significant
performance improvements: a 26% gain over the Chameleon model and an 18.3%
improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Additionally, we introduce a unified evaluation suite
for biomedical tasks, providing a robust framework to guide the development of
next-generation mixed-modal biomedical AI assistants.",2024-12-17,"Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover"
"Predicting User Behavior in Smart Spaces with LLM-Enhanced Logs and
  Personalized Prompts (Data Description)","Enhancing the intelligence of smart systems, such as smart home, and smart
vehicle, and smart grids, critically depends on developing sophisticated
planning capabilities that can anticipate the next desired function based on
historical interactions. While existing methods view user behaviors as
sequential data and apply models like RNNs and Transformers to predict future
actions, they often fail to incorporate domain knowledge and capture
personalized user preferences. In this paper, we propose a novel approach that
incorporates LLM-enhanced logs and personalized prompts. Our approach first
constructs a graph that captures individual behavior preferences derived from
their interaction histories. This graph effectively transforms into a soft
continuous prompt that precedes the sequence of user behaviors. Then our
approach leverages the vast general knowledge and robust reasoning capabilities
of a pretrained LLM to enrich the oversimplified and incomplete log records. By
enhancing these logs semantically, our approach better understands the user's
actions and intentions, especially for those rare events in the dataset. We
evaluate the method across four real-world datasets from both smart vehicle and
smart home settings. The findings validate the effectiveness of our
LLM-enhanced description and personalized prompt, shedding light on potential
ways to advance the intelligence of smart space. Note: While this manuscript
provides description of the data, we are \textbf{not} permitted to make these
datasets publicly available due to restrictions imposed by the data provider.",2024-12-17,Yunpeng Song
"Neural-Network-Driven Reward Prediction as a Heuristic: Advancing
  Q-Learning for Mobile Robot Path Planning","Q-learning is a widely used reinforcement learning technique for solving path
planning problems. It primarily involves the interaction between an agent and
its environment, enabling the agent to learn an optimal strategy that maximizes
cumulative rewards. Although many studies have reported the effectiveness of
Q-learning, it still faces slow convergence issues in practical applications.
To address this issue, we propose the NDR-QL method, which utilizes neural
network outputs as heuristic information to accelerate the convergence process
of Q-learning. Specifically, we improved the dual-output neural network model
by introducing a start-end channel separation mechanism and enhancing the
feature fusion process. After training, the proposed NDR model can output a
narrowly focused optimal probability distribution, referred to as the
guideline, and a broadly distributed suboptimal distribution, referred to as
the region. Subsequently, based on the guideline prediction, we calculate the
continuous reward function for the Q-learning method, and based on the region
prediction, we initialize the Q-table with a bias. We conducted training,
validation, and path planning simulation experiments on public datasets. The
results indicate that the NDR model outperforms previous methods by up to 5\%
in prediction accuracy. Furthermore, the proposed NDR-QL method improves the
convergence speed of the baseline Q-learning method by 90\% and also surpasses
the previously improved Q-learning methods in path quality metrics.",2024-12-17,"Yiming Ji, Kaijie Yun, Yang Liu, Zongwu Xie, Hong Liu"
"Streaming Keyword Spotting Boosted by Cross-layer Discrimination
  Consistency","Connectionist Temporal Classification (CTC), a non-autoregressive training
criterion, is widely used in online keyword spotting (KWS). However, existing
CTC-based KWS decoding strategies either rely on Automatic Speech Recognition
(ASR), which performs suboptimally due to its broad search over the acoustic
space without keyword-specific optimization, or on KWS-specific decoding
graphs, which are complex to implement and maintain. In this work, we propose a
streaming decoding algorithm enhanced by Cross-layer Discrimination Consistency
(CDC), tailored for CTC-based KWS. Specifically, we introduce a streamlined yet
effective decoding algorithm capable of detecting the start of the keyword at
any arbitrary position. Furthermore, we leverage discrimination consistency
information across layers to better differentiate between positive and false
alarm samples. Our experiments on both clean and noisy Hey Snips datasets show
that the proposed streaming decoding strategy outperforms ASR-based and
graph-based KWS baselines. The CDC-boosted decoding further improves
performance, yielding an average absolute recall improvement of 6.8% and a
46.3% relative reduction in the miss rate compared to the graph-based KWS
baseline, with a very low false alarm rate of 0.05 per hour.",2024-12-17,"Yu Xi, Haoyu Li, Xiaoyu Gu, Hao Li, Yidi Jiang, Kai Yu"
"Replications, Revisions, and Reanalyses: Managing Variance Theories in
  Software Engineering","Variance theories quantify the variance that one or more independent
variables cause in a dependent variable. In software engineering (SE), variance
theories are used to quantify -- among others -- the impact of tools,
techniques, and other treatments on software development outcomes. To acquire
variance theories, evidence from individual empirical studies needs to be
synthesized to more generally valid conclusions. However, research synthesis in
SE is mostly limited to meta-analysis, which requires homogeneity of the
synthesized studies to infer generalizable variance. In this paper, we aim to
extend the practice of research synthesis beyond meta-analysis. To this end, we
derive a conceptual framework for the evolution of variance theories and
demonstrate its use by applying it to an active research field in SE. The
resulting framework allows researchers to put new evidence in a clear relation
to an existing body of knowledge and systematically expand the scientific
frontier of a studied phenomenon.",2024-12-17,"Julian Frattini, Jannik Fischbach, Davide Fucci, Michael Unterkalmsteiner, Daniel Mendez"
"Improving the Transferability of 3D Point Cloud Attack via
  Spectral-aware Admix and Optimization Designs","Deep learning models for point clouds have shown to be vulnerable to
adversarial attacks, which have received increasing attention in various
safety-critical applications such as autonomous driving, robotics, and
surveillance. Existing 3D attackers generally design various attack strategies
in the white-box setting, requiring the prior knowledge of 3D model details.
However, real-world 3D applications are in the black-box setting, where we can
only acquire the outputs of the target classifier. Although few recent works
try to explore the black-box attack, they still achieve limited attack success
rates (ASR). To alleviate this issue, this paper focuses on attacking the 3D
models in a transfer-based black-box setting, where we first carefully design
adversarial examples in a white-box surrogate model and then transfer them to
attack other black-box victim models. Specifically, we propose a novel
Spectral-aware Admix with Augmented Optimization method (SAAO) to improve the
adversarial transferability. In particular, since traditional Admix strategy
are deployed in the 2D domain that adds pixel-wise images for perturbing, we
can not directly follow it to merge point clouds in coordinate domain as it
will destroy the geometric shapes. Therefore, we design spectral-aware fusion
that performs Graph Fourier Transform (GFT) to get spectral features of the
point clouds and add them in the spectral domain. Afterward, we run a few steps
with spectral-aware weighted Admix to select better optimization paths as well
as to adjust corresponding learning weights. At last, we run more steps to
generate adversarial spectral feature along the optimization path and perform
Inverse-GFT on the adversarial spectral feature to obtain the adversarial
example in the data domain. Experiments show that our SAAO achieves better
transferability compared to existing 3D attack methods.",2024-12-17,"Shiyu Hu, Daizong Liu, Wei Hu"
Jailbreaking? One Step Is Enough!,"Large language models (LLMs) excel in various tasks but remain vulnerable to
jailbreak attacks, where adversaries manipulate prompts to generate harmful
outputs. Examining jailbreak prompts helps uncover the shortcomings of LLMs.
However, current jailbreak methods and the target model's defenses are engaged
in an independent and adversarial process, resulting in the need for frequent
attack iterations and redesigning attacks for different models. To address
these gaps, we propose a Reverse Embedded Defense Attack (REDA) mechanism that
disguises the attack intention as the ""defense"". intention against harmful
content. Specifically, REDA starts from the target response, guiding the model
to embed harmful content within its defensive measures, thereby relegating
harmful content to a secondary role and making the model believe it is
performing a defensive task. The attacking model considers that it is guiding
the target model to deal with harmful content, while the target model thinks it
is performing a defensive task, creating an illusion of cooperation between the
two. Additionally, to enhance the model's confidence and guidance in
""defensive"" intentions, we adopt in-context learning (ICL) with a small number
of attack examples and construct a corresponding dataset of attack examples.
Extensive evaluations demonstrate that the REDA method enables cross-model
attacks without the need to redesign attack strategies for different models,
enables successful jailbreak in one iteration, and outperforms existing methods
on both open-source and closed-source models.",2024-12-17,"Weixiong Zheng, Peijian Zeng, Yiwei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou"
Gender Bias and Property Taxes,"Gender bias distorts the economic behavior and outcomes of women and
households. We investigate gender biases in property taxes. We analyze records
of more than 100,000 property tax appeal hearings and more than 2.7 years of
associated audio recordings, considering how panelist and appellant genders
associate with hearing outcomes. We first observe that female appellants fare
systematically worse than male appellants in their hearings. Second, we show
that, whereas male appellants' hearing outcomes do not vary meaningfully with
the gender composition of the panel they face, those of female appellants' do,
such that female appellants obtain systematically lesser (greater) reductions
to their home values when facing female (male) panelists. Employing a
multi-modal large language model (M-LLM), we next construct measures of
participant behavior and tone from hearing audio recordings. We observe
markedly different behaviors between male and female appellants and, in the
case of male appellants, we find that these differences also depend on the
gender of the panelists they face (e.g., male appellants appear to behave
systematically more aggressively towards female panelists). In contrast, the
behavior of female appellants remains relatively constant, regardless of their
panel's gender. Finally, we show that female appellants continue to fare worse
in front of female panels, even when we condition upon the appelant's
in-hearing behavior and tone. Our results are thus consistent with the idea
that gender biases are driven, at least in part, by unvoiced beliefs and
perceptions on the part of ARB panelists. Our study documents the presence of
gender biases in property appraisal appeal hearings and highlights the
potential value of generative AI for analyzing large-scale, unstructured
administrative data.",2024-12-17,"Gordon Burtch, Alejandro Zentner"
"Don't Yell at Your Robot: Physical Correction as the Collaborative
  Interface for Language Model Powered Robots","We present a novel approach for enhancing human-robot collaboration using
physical interactions for real-time error correction of large language model
(LLM) powered robots. Unlike other methods that rely on verbal or text
commands, the robot leverages an LLM to proactively executes 6 DoF linear
Dynamical System (DS) commands using a description of the scene in natural
language. During motion, a human can provide physical corrections, used to
re-estimate the desired intention, also parameterized by linear DS. This
corrected DS can be converted to natural language and used as part of the
prompt to improve future LLM interactions. We provide proof-of-concept result
in a hybrid real+sim experiment, showcasing physical interaction as a new
possibility for LLM powered human-robot interface.",2024-12-17,"Chuye Zhang, Yifei Simon Shao, Harshil Parekh, Junyao Shi, Pratik Chaudhari, Vijay Kumar, Nadia Figueroa"
Convergence of the QuickVal Residual,"QuickSelect (aka Find), introduced by Hoare (1961), is a randomized algorithm
for selecting a specified order statistic from an input sequence of $n$
objects, or rather their identifying labels usually known as keys. The keys can
be numeric or symbol strings, or indeed any labels drawn from a given linearly
ordered set. We discuss various ways in which the cost of comparing two keys
can be measured, and we can measure the efficiency of the algorithm by the
total cost of such comparisons.
  We define and discuss a closely related algorithm known as QuickVal and a
natural probabilistic model for the input to this algorithm; QuickVal searches
(almost surely unsuccessfully) for a specified population quantile $\alpha \in
[0, 1]$ in an input sample of size $n$. Call the total cost of comparisons for
this algorithm $S_n$. We discuss a natural way to define the random variables
$S_1, S_2, \ldots$ on a common probability space. For a general class of cost
functions, Fill and Nakama (2013) proved under mild assumptions that the scaled
cost $S_n / n$ of QuickVal converges in $L^p$ and almost surely to a limit
random variable $S$. For a general cost function, we consider what we term the
QuickVal residual: \[
  R_n := \frac{S_n}n - S. \] The residual is of natural interest, especially in
light of the previous analogous work on the sorting algorithm QuickSort. In the
case $\alpha = 0$ of QuickMin with unit cost per key-comparison, we are able to
calculate -- \`a la Bindjeme and Fill (2012) for QuickSort -- the exact (and
asymptotic) $L^2$-norm of the residual. We take the result as motivation for
the scaling factor $\sqrt{n}$ for the QuickVal residual for general population
quantiles and for general cost. We then prove in general (under mild conditions
on the cost function) that $\sqrt{n}\,R_n$ converges in law to a scale-mixture
of centered Gaussians, and we also prove convergence of moments.",2024-12-17,"James Allen Fill, Jason Matterer"
"Distribution-Free Uncertainty Quantification in Mechanical Ventilation
  Treatment: A Conformal Deep Q-Learning Framework","Mechanical Ventilation (MV) is a critical life-support intervention in
intensive care units (ICUs). However, optimal ventilator settings are
challenging to determine because of the complexity of balancing
patient-specific physiological needs with the risks of adverse outcomes that
impact morbidity, mortality, and healthcare costs. This study introduces
ConformalDQN, a novel distribution-free conformal deep Q-learning approach for
optimizing mechanical ventilation in intensive care units. By integrating
conformal prediction with deep reinforcement learning, our method provides
reliable uncertainty quantification, addressing the challenges of Q-value
overestimation and out-of-distribution actions in offline settings. We trained
and evaluated our model using ICU patient records from the MIMIC-IV database.
ConformalDQN extends the Double DQN architecture with a conformal predictor and
employs a composite loss function that balances Q-learning with well-calibrated
probability estimation. This enables uncertainty-aware action selection,
allowing the model to avoid potentially harmful actions in unfamiliar states
and handle distribution shifts by being more conservative in
out-of-distribution scenarios. Evaluation against baseline models, including
physician policies, policy constraint methods, and behavior cloning,
demonstrates that ConformalDQN consistently makes recommendations within
clinically safe and relevant ranges, outperforming other methods by increasing
the 90-day survival rate. Notably, our approach provides an interpretable
measure of confidence in its decisions, which is crucial for clinical adoption
and potential human-in-the-loop implementations.",2024-12-17,"Niloufar Eghbali, Tuka Alhanai, Mohammad M. Ghassemi"
Round and Communication Efficient Graph Coloring,"In the context of communication complexity, we explore randomized protocols
for graph coloring, focusing specifically on the vertex and edge coloring
problems in $n$-vertex graphs $G$ with a maximum degree $\Delta$. We consider a
scenario where the edges of $G$ are partitioned between two players. Our first
contribution is a randomized protocol that efficiently finds a $(\Delta +
1)$-vertex coloring of $G$, utilizing $O(n)$ bits of communication in
expectation and completing in $O(\log \log n \cdot \log \Delta)$ rounds in the
worst case. This advancement represents a significant improvement over the work
of Flin and Mittal [PODC 2024], who achieved the same communication cost but
required $O(n)$ rounds in expectation, thereby making a significant reduction
in the round complexity. We also present a randomized protocol for a $(2\Delta
- 1)$-edge coloring of $G$, which maintains the same $O(n)$ bits of
communication in expectation over $O(\log^\ast \Delta)$ rounds in the worst
case. We complement the result with a tight $\Omega(n)$-bit lower bound on the
communication complexity of the $(2\Delta-1)$-edge coloring, while a similar
$\Omega(n)$ lower bound for the $(\Delta+1)$-vertex coloring has been
established by Flin and Mittal [PODC 2024].",2024-12-17,"Yi-Jun Chang, Gopinath Mishra, Hung Thuan Nguyen, Farrel D Salim"
"SIDE: Socially Informed Drought Estimation Toward Understanding Societal
  Impact Dynamics of Environmental Crisis","Drought has become a critical global threat with significant societal impact.
Existing drought monitoring solutions primarily focus on assessing drought
severity using quantitative measurements, overlooking the diverse societal
impact of drought from human-centric perspectives. Motivated by the collective
intelligence on social media and the computational power of AI, this paper
studies a novel problem of socially informed AI-driven drought estimation that
aims to leverage social and news media information to jointly estimate drought
severity and its societal impact. Two technical challenges exist: 1) How to
model the implicit temporal dynamics of drought societal impact. 2) How to
capture the social-physical interdependence between the physical drought
condition and its societal impact. To address these challenges, we develop
SIDE, a socially informed AI-driven drought estimation framework that
explicitly quantifies the societal impact of drought and effectively models the
social-physical interdependency for joint severity-impact estimation.
Experiments on real-world datasets from California and Texas demonstrate SIDE's
superior performance compared to state-of-the-art baselines in accurately
estimating drought severity and its societal impact. SIDE offers valuable
insights for developing human-centric drought mitigation strategies to foster
sustainable and resilient communities.",2024-12-17,"Lanyu Shang, Bozhang Chen, Shiwei Liu, Yang Zhang, Ruohan Zong, Anav Vora, Ximing Cai, Na Wei, Dong Wang"
"Task-Agnostic Language Model Watermarking via High Entropy Passthrough
  Layers","In the era of costly pre-training of large language models, ensuring the
intellectual property rights of model owners, and insuring that said models are
responsibly deployed, is becoming increasingly important. To this end, we
propose model watermarking via passthrough layers, which are added to existing
pre-trained networks and trained using a self-supervised loss such that the
model produces high-entropy output when prompted with a unique private key, and
acts normally otherwise. Unlike existing model watermarking methods, our method
is fully task-agnostic, and can be applied to both classification and
sequence-to-sequence tasks without requiring advanced access to downstream
fine-tuning datasets. We evaluate the proposed passthrough layers on a wide
range of downstream tasks, and show experimentally our watermarking method
achieves a near-perfect watermark extraction accuracy and false-positive rate
in most cases without damaging original model performance. Additionally, we
show our method is robust to both downstream fine-tuning, fine-pruning, and
layer removal attacks, and can be trained in a fraction of the time required to
train the original model. Code is available in the paper.",2024-12-17,"Vaden Masrani, Mohammad Akbari, David Ming Xuan Yue, Ahmad Rezaei, Yong Zhang"
"Efficient Oriented Object Detection with Enhanced Small Object
  Recognition in Aerial Images","Achieving a balance between computational efficiency and detection accuracy
in the realm of rotated bounding box object detection within aerial imagery is
a significant challenge. While prior research has aimed at creating lightweight
models that enhance computational performance and feature extraction, there
remains a gap in the performance of these networks when it comes to the
detection of small and multi-scale objects in remote sensing (RS) imagery. To
address these challenges, we present a novel enhancement to the YOLOv8 model,
tailored for oriented object detection tasks and optimized for environments
with limited computational resources. Our model features a wavelet
transform-based C2f module for capturing associative features and an Adaptive
Scale Feature Pyramid (ASFP) module that leverages P2 layer details.
Additionally, the incorporation of GhostDynamicConv significantly contributes
to the model's lightweight nature, ensuring high efficiency in aerial imagery
analysis. Featuring a parameter count of 21.6M, our approach provides a more
efficient architectural design than DecoupleNet, which has 23.3M parameters,
all while maintaining detection accuracy. On the DOTAv1.0 dataset, our model
demonstrates a mean Average Precision (mAP) that is competitive with leading
methods such as DecoupleNet. The model's efficiency, combined with its reduced
parameter count, makes it a strong candidate for aerial object detection,
particularly in resource-constrained environments.",2024-12-17,"Zhifei Shi, Zongyao Yin, Sheng Chang, Xiao Yi, Xianchuan Yu"
"The Jacobi Factoring Circuit: Quantum Factoring with Near-Linear Gates
  and Sublinear Space and Depth","We present a compact quantum circuit for factoring a large class of integers,
including some whose classical hardness is expected to be equivalent to RSA
(but not including RSA integers themselves). To our knowledge, it is the first
polynomial-time circuit to achieve sublinear qubit count for a classically-hard
factoring problem; the circuit also achieves sublinear depth and nearly linear
gate count. We build on the quantum algorithm for squarefree decomposition
discovered by Li, Peng, Du and Suter (Nature Scientific Reports 2012), which
relies on computing the Jacobi symbol in quantum superposition. Our circuit
completely factors any number $N$, whose prime decomposition has distinct
exponents, and finds at least one non-trivial factor if not all exponents are
the same. In particular, to factor an $n$-bit integer $N=P^2 Q$ (with $P$ and
$Q$ prime, and $Q<2^m$ for some $m$), our circuit uses $\tilde{O}(m)$ qubits
and has depth at most $\tilde{O}(m + n/m)$, with $\tilde{O}(n)$ quantum gates.
When $m=\Theta(n^a)$ with $2/3 < a < 1$, the space and depth are sublinear in
$n$, yet no known classical algorithms exploit the relatively small size of $Q$
to run faster than general-purpose factoring algorithms. We thus believe that
factoring such numbers has potential to be the most concretely efficient
classically-verifiable proof of quantumness currently known.
  The technical core of our contribution is a new space-efficient and
parallelizable quantum algorithm to compute the Jacobi symbol of $A$ mod $B$,
in the regime where $B$ is classical and much larger than $A$. In the context
of the larger Jacobi algorithm for factoring $N = P^2Q$, this reduces the
overall qubit count to be roughly proportional to the length of $Q$, rather
than the length of $N$. Finally, we note that our circuit for computing the
Jacobi symbol generalizes to related problems, such as computing the GCD.",2024-12-17,"Gregory D. Kahanamoku-Meyer, Seyoon Ragavan, Vinod Vaikuntanathan, Katherine Van Kirk"
"Personalized Federated Deep Reinforcement Learning for Heterogeneous
  Edge Content Caching Networks","Proactive caching is essential for minimizing latency and improving Quality
of Experience (QoE) in multi-server edge networks. Federated Deep Reinforcement
Learning (FDRL) is a promising approach for developing cache policies tailored
to dynamic content requests. However, FDRL faces challenges such as an
expanding caching action space due to increased content numbers and difficulty
in adapting global information to heterogeneous edge environments. In this
paper, we propose a Personalized Federated Deep Reinforcement Learning
framework for Caching, called PF-DRL-Ca, with the aim to maximize system
utility while satisfying caching capability constraints. To manage the
expanding action space, we employ a new DRL algorithm, Multi-head Deep
Q-Network (MH-DQN), which reshapes the action output layers of DQN into a
multi-head structure where each head generates a sub-dimensional action. We
next integrate the proposed MH-DQN into a personalized federated training
framework, employing a layer-wise approach for training to derive a
personalized model that can adapt to heterogeneous environments while
exploiting the global information to accelerate learning convergence. Our
extensive experimental results demonstrate the superiority of MH-DQN over
traditional DRL algorithms on a single server, as well as the advantages of the
personal federated training architecture compared to other frameworks.",2024-12-17,"Zhen Li, Tan Li, Hai Liu, Tse-Tin Chan"
Stiefel Flow Matching for Moment-Constrained Structure Elucidation,"Molecular structure elucidation is a fundamental step in understanding
chemical phenomena, with applications in identifying molecules in natural
products, lab syntheses, forensic samples, and the interstellar medium. We
consider the task of predicting a molecule's all-atom 3D structure given only
its molecular formula and moments of inertia, motivated by the ability of
rotational spectroscopy to measure these moments. While existing generative
models can conditionally sample 3D structures with approximately correct
moments, this soft conditioning fails to leverage the many digits of precision
afforded by experimental rotational spectroscopy. To address this, we first
show that the space of $n$-atom point clouds with a fixed set of moments of
inertia is embedded in the Stiefel manifold $\mathrm{St}(n, 4)$. We then
propose Stiefel Flow Matching as a generative model for elucidating 3D
structure under exact moment constraints. Additionally, we learn simpler and
shorter flows by finding approximate solutions for equivariant optimal
transport on the Stiefel manifold. Empirically, enforcing exact moment
constraints allows Stiefel Flow Matching to achieve higher success rates and
faster sampling than Euclidean diffusion models, even on high-dimensional
manifolds corresponding to large molecules in the GEOM dataset.",2024-12-17,"Austin Cheng, Alston Lo, Kin Long Kelvin Lee, Santiago Miret, Alán Aspuru-Guzik"
"A Scalable Approach to Benchmarking the In-Conversation Differential
  Diagnostic Accuracy of a Health AI","Diagnostic errors in healthcare persist as a critical challenge, with
increasing numbers of patients turning to online resources for health
information. While AI-powered healthcare chatbots show promise, there exists no
standardized and scalable framework for evaluating their diagnostic
capabilities. This study introduces a scalable benchmarking methodology for
assessing health AI systems and demonstrates its application through August, an
AI-driven conversational chatbot. Our methodology employs 400 validated
clinical vignettes across 14 medical specialties, using AI-powered patient
actors to simulate realistic clinical interactions. In systematic testing,
August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a
top-two accuracy of 85.0% (340/400 cases), significantly outperforming
traditional symptom checkers. The system demonstrated 95.8% accuracy in
specialist referrals and required 47% fewer questions compared to conventional
symptom checkers (mean 16 vs 29 questions), while maintaining empathetic
dialogue throughout consultations. These findings demonstrate the potential of
AI chatbots to enhance healthcare delivery, though implementation challenges
remain regarding real-world validation and integration of objective clinical
data. This research provides a reproducible framework for evaluating healthcare
AI systems, contributing to the responsible development and deployment of AI in
clinical settings.",2024-12-17,"Deep Bhatt, Surya Ayyagari, Anuruddh Mishra"
"Addressing Small and Imbalanced Medical Image Datasets Using Generative
  Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K
  Sampling","The development of accurate medical image classification models is often
constrained by privacy concerns and data scarcity for certain conditions,
leading to small and imbalanced datasets. To address these limitations, this
study explores the use of generative models, such as Denoising Diffusion
Probabilistic Models (DDPM) and Progressive Growing Generative Adversarial
Networks (PGGANs), for dataset augmentation. The research introduces a
framework to assess the impact of synthetic images generated by DDPM and PGGANs
on the performance of four models: a custom CNN, Untrained VGG16, Pretrained
VGG16, and Pretrained ResNet50. Experiments were conducted using Random
Sampling and Greedy K Sampling to create small, imbalanced datasets. The
synthetic images were evaluated using Frechet Inception Distance (FID) and
compared to original datasets through classification metrics. The results show
that DDPM consistently generated more realistic images with lower FID scores
and significantly outperformed PGGANs in improving classification metrics
across all models and datasets. Incorporating DDPM-generated images into the
original datasets increased accuracy by up to 6%, enhancing model robustness
and stability, particularly in imbalanced scenarios. Random Sampling
demonstrated superior stability, while Greedy K Sampling offered diversity at
the cost of higher FID scores. This study highlights the efficacy of DDPM in
augmenting small, imbalanced medical image datasets, improving model
performance by balancing the dataset and expanding its size.",2024-12-17,"Iman Khazrak, Shakhnoza Takhirova, Mostafa M. Rezaee, Mehrdad Yadollahi, Robert C. Green II, Shuteng Niu"
"Movable Antenna Aided NOMA: Joint Antenna Positioning, Precoding, and
  Decoding Design","This paper investigates movable antenna (MA) aided non-orthogonal multiple
access (NOMA) for multi-user downlink communication, where the base station
(BS) is equipped with a fixed-position antenna (FPA) array to serve multiple
MA-enabled users. An optimization problem is formulated to maximize the minimum
achievable rate among all the users by jointly optimizing the MA positioning of
each user, the precoding matrix at the BS, and the successive interference
cancellation (SIC) decoding indicator matrix at the users, subject to a set of
constraints including the limited movement area of the MAs, the maximum
transmit power of the BS, and the SIC decoding condition. To solve this
non-convex problem, we propose a two-loop iterative optimization algorithm that
combines the hippopotamus optimization (HO) method with the alternating
optimization (AO) method to obtain a suboptimal solution efficiently.
Specifically, in the inner loop, the complex-valued precoding matrix and the
binary decoding indicator matrix are optimized alternatively by the successive
convex approximation (SCA) technique with customized greedy search to maximize
the minimum achievable rate for the given positions of the MAs. In the outer
loop, each user's antenna position is updated using the HO algorithm, following
a novel nature-inspired intelligent optimization framework. Simulation results
show that the proposed algorithms can effectively avoid local optimum for
highly coupled variables and significantly improve the rate performance of the
NOMA system compared to the conventional FPA system as well as other benchmark
schemes.",2024-12-17,"Zhenyu Xiao, Zhe Li, Lipeng Zhu, Boyu Ning, Daniel Benevides da Costa, Xiang-Gen Xia, Rui Zhang"
"When to Speak, When to Abstain: Contrastive Decoding with Abstention","Large Language Models (LLMs) demonstrate exceptional performance across
diverse tasks by leveraging both pre-trained knowledge (i.e., parametric
knowledge) and external knowledge (i.e., contextual knowledge). While
substantial efforts have been made to leverage both forms of knowledge,
scenarios in which the model lacks any relevant knowledge remain underexplored.
Such limitations can result in issues like hallucination, causing reduced
reliability and potential risks in high-stakes applications. To address such
limitations, this paper extends the task scope to encompass cases where the
user's request cannot be fulfilled due to the lack of relevant knowledge. To
this end, we introduce Contrastive Decoding with Abstention (CDA), a
training-free decoding method that empowers LLMs to generate responses when
relevant knowledge is available and to abstain otherwise. CDA evaluates the
relevance of each knowledge for a given query, adaptively determining which
knowledge to prioritize or which to completely ignore. Extensive experiments
with four LLMs on three question-answering datasets demonstrate that CDA can
effectively perform accurate generation and abstention simultaneously. These
findings highlight CDA's potential to broaden the applicability of LLMs,
enhancing reliability and preserving user trust.",2024-12-17,"Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim"
"Equilibrium Computation in the Hotelling-Downs Model of Spatial
  Competition","The Hotelling-Downs model is a natural and appealing model for understanding
strategic positioning by candidates in elections. In this model, voters are
distributed on a line, representing their ideological position on an issue.
Each candidate then chooses as a strategy a position on the line to maximize
her vote share. Each voter votes for the nearest candidate, closest to their
ideological position. This sets up a game between the candidates, and we study
pure Nash equilibria in this game. The model and its variants are an important
tool in political economics, and are studied widely in computational social
choice as well.
  Despite the interest and practical relevance, most prior work focuses on the
existence and properties of pure Nash equilibria in this model, ignoring
computational issues. Our work gives algorithms for computing pure Nash
equilibria in the basic model. We give three algorithms, depending on whether
the distribution of voters is continuous or discrete, and similarly, whether
the possible candidate positions are continuous or discrete. In each case, our
algorithms return either an exact equilibrium or one arbitrarily close to
exact, assuming existence. We believe our work will be useful, and may prompt
interest, in computing equilibria in the wide variety of extensions of the
basic model as well.",2024-12-17,"Umang Bhaskar, Soumyajit Pyne"
"Boosting LLM-based Relevance Modeling with Distribution-Aware Robust
  Learning","With the rapid advancement of pre-trained large language models (LLMs),
recent endeavors have leveraged the capabilities of LLMs in relevance modeling,
resulting in enhanced performance. This is usually done through the process of
fine-tuning LLMs on specifically annotated datasets to determine the relevance
between queries and items. However, there are two limitations when LLMs are
naively employed for relevance modeling through fine-tuning and inference.
First, it is not inherently efficient for performing nuanced tasks beyond
simple yes or no answers, such as assessing search relevance. It may therefore
tend to be overconfident and struggle to distinguish fine-grained degrees of
relevance (e.g., strong relevance, weak relevance, irrelevance) used in search
engines. Second, it exhibits significant performance degradation when
confronted with data distribution shift in real-world scenarios. In this paper,
we propose a novel Distribution-Aware Robust Learning framework (DaRL) for
relevance modeling in Alipay Search. Specifically, we design an effective loss
function to enhance the discriminability of LLM-based relevance modeling across
various fine-grained degrees of query-item relevance. To improve the
generalizability of LLM-based relevance modeling, we first propose the
Distribution-Aware Sample Augmentation (DASA) module. This module utilizes
out-of-distribution (OOD) detection techniques to actively select appropriate
samples that are not well covered by the original training set for model
fine-tuning. Furthermore, we adopt a multi-stage fine-tuning strategy to
simultaneously improve in-distribution (ID) and OOD performance, bridging the
performance gap between them. DaRL has been deployed online to serve the
Alipay's insurance product search...",2024-12-17,"Hong Liu, Saisai Gong, Yixin Ji, Kaixin Wu, Jia Xu, Jinjie Gu"
"Unleashing the Potential of Model Bias for Generalized Category
  Discovery","Generalized Category Discovery is a significant and complex task that aims to
identify both known and undefined novel categories from a set of unlabeled
data, leveraging another labeled dataset containing only known categories. The
primary challenges stem from model bias induced by pre-training on only known
categories and the lack of precise supervision for novel ones, leading to
category bias towards known categories and category confusion among different
novel categories, which hinders models' ability to identify novel categories
effectively. To address these challenges, we propose a novel framework named
Self-Debiasing Calibration (SDC). Unlike prior methods that regard model bias
towards known categories as an obstacle to novel category identification, SDC
provides a novel insight into unleashing the potential of the bias to
facilitate novel category learning. Specifically, the output of the biased
model serves two key purposes. First, it provides an accurate modeling of
category bias, which can be utilized to measure the degree of bias and debias
the output of the current training model. Second, it offers valuable insights
for distinguishing different novel categories by transferring knowledge between
similar categories. Based on these insights, SDC dynamically adjusts the output
logits of the current training model using the output of the biased model. This
approach produces less biased logits to effectively address the issue of
category bias towards known categories, and generates more accurate pseudo
labels for unlabeled data, thereby mitigating category confusion for novel
categories. Experiments on three benchmark datasets show that SDC outperforms
SOTA methods, especially in the identification of novel categories. Our code
and data are available at \url{https://github.com/Lackel/SDC}.",2024-12-17,"Wenbin An, Haonan Lin, Jiahao Nie, Feng Tian, Wenkai Shi, Yaqiang Wu, Qianying Wang, Ping Chen"
Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training,"Vision Mamba (e.g., Vim) has successfully been integrated into computer
vision, and token reduction has yielded promising outcomes in Vision
Transformers (ViTs). However, token reduction performs less effectively on
Vision Mamba compared to ViTs. Pruning informative tokens in Mamba leads to a
high loss of key knowledge and bad performance. This makes it not a good
solution for enhancing efficiency in Mamba. Token merging, which preserves more
token information than pruning, has demonstrated commendable performance in
ViTs. Nevertheless, vanilla merging performance decreases as the reduction
ratio increases either, failing to maintain the key knowledge in Mamba.
Re-training the token-reduced model enhances the performance of Mamba, by
effectively rebuilding the key knowledge. Empirically, pruned Vims only drop up
to 0.9% accuracy on ImageNet-1K, recovered by our proposed framework R-MeeTo in
our main evaluation. We show how simple and effective the fast recovery can be
achieved at minute-level, in particular, a 35.9% accuracy spike over 3 epochs
of training on Vim-Ti. Moreover, Vim-Ti/S/B are re-trained within 5/7/17
minutes, and Vim-S only drop 1.3% with 1.2x (up to 1.5x) speed up in inference.",2024-12-17,"Mingjia Shi, Yuhao Zhou, Ruiji Yu, Zekai Li, Zhiyuan Liang, Xuanlei Zhao, Xiaojiang Peng, Tanmay Rajpurohit, Shanmukha Ramakrishna Vedantam, Wangbo Zhao, Kai Wang, Yang You"
"Multi-UAV Collaborative Trajectory Planning for Seamless Data Collection
  and Transmission","Unmanned aerial vehicles (UAVs) have attracted plenty of attention due to
their high flexibility and enhanced communication ability. However, the limited
coverage and energy of UAVs make it difficult to provide timely wireless
service for large-scale sensor networks, which also exist in multiple UAVs. To
this end, the advanced collaboration mechanism of UAVs urgently needs to be
designed. In this paper, we propose a multi-UAV collaborative scheme for
seamless data collection and transmission, where UAVs are dispatched to
collection points (CPs) to collect and transmit the time-critical data to the
ground base station (BS) simultaneously through the cooperative backhaul link.
Specifically, the mission completion time is minimized by optimizing the
trajectories, task allocation, collection time scheduling, and transmission
topology of UAVs while ensuring backhaul link to the BS. However, the
formulated problem is non-convex and challenging to solve directly. To tackle
this problem, the CP locations and transmission topology of UAVs are obtained
by sensor node (SN) clustering and region division. Next, the transmission
connectivity condition between UAVs is derived to facilitate the trajectory
discretization and thus reduce the dimensions of variables. This simplifies the
problem to optimizing the UAV hovering locations, hovering time, and CP serving
sequence. Then, we propose a point-matching-based trajectory planning algorithm
to solve the problem efficiently. The simulation results show that the proposed
scheme achieves significant performance gains over the two benchmarks.",2024-12-17,"Rui Wang, Kaitao Meng, Deshi Li"
"DuSSS: Dual Semantic Similarity-Supervised Vision-Language Model for
  Semi-Supervised Medical Image Segmentation","Semi-supervised medical image segmentation (SSMIS) uses consistency learning
to regularize model training, which alleviates the burden of pixel-wise manual
annotations. However, it often suffers from error supervision from low-quality
pseudo labels. Vision-Language Model (VLM) has great potential to enhance
pseudo labels by introducing text prompt guided multimodal supervision
information. It nevertheless faces the cross-modal problem: the obtained
messages tend to correspond to multiple targets. To address aforementioned
problems, we propose a Dual Semantic Similarity-Supervised VLM (DuSSS) for
SSMIS. Specifically, 1) a Dual Contrastive Learning (DCL) is designed to
improve cross-modal semantic consistency by capturing intrinsic representations
within each modality and semantic correlations across modalities. 2) To
encourage the learning of multiple semantic correspondences, a Semantic
Similarity-Supervision strategy (SSS) is proposed and injected into each
contrastive learning process in DCL, supervising semantic similarity via the
distribution-based uncertainty levels. Furthermore, a novel VLM-based SSMIS
network is designed to compensate for the quality deficiencies of
pseudo-labels. It utilizes the pretrained VLM to generate text prompt guided
supervision information, refining the pseudo label for better consistency
regularization. Experimental results demonstrate that our DuSSS achieves
outstanding performance with Dice of 82.52%, 74.61% and 78.03% on three public
datasets (QaTa-COV19, BM-Seg and MoNuSeg).",2024-12-17,"Qingtao Pan, Wenhao Qiao, Jingjiao Lou, Bing Ji, Shuo Li"
A System for Microserving of LLMs,"The recent advances in LLMs bring a strong demand for efficient system
support to improve overall serving efficiency. As LLM inference scales towards
multiple GPUs and even multiple compute nodes, various coordination patterns,
such as prefill-decode disaggregation and context migration, arise in serving
systems. Most inference services today expose a coarse-grained request-level
API with a pre-configured coordination strategy, limiting the ability to
customize and dynamically reconfigure the coordination. In this paper, we
propose LLM microserving, a multi-level architecture for structuring and
programming LLM inference services. We introduces simple yet effective
microserving APIs to support fine-grained sub-request level actions. A
programmable router transforms user requests into sub-request calls, enabling
the dynamic reconfiguration of serving patterns. To support diverse execution
patterns, we develop a unified KV cache interface that handles various KV
compute, transfer, and reuse scenarios. Our evaluation shows that LLM
microserving can be reconfigured to support multiple disaggregation
orchestration strategies in a few lines of Python code while maintaining
state-of-the-art performance for LLM inference tasks. Additionally, it allows
us to explore new strategy variants that reduce up to 47% of job completion
time compared to the existing strategies.",2024-12-17,"Hongyi Jin, Ruihang Lai, Charlie F. Ruan, Yingcheng Wang, Todd C. Mowry, Xupeng Miao, Zhihao Jia, Tianqi Chen"
Boosting Long-Context Management via Query-Guided Activation Refilling,"Processing long contexts poses a significant challenge for large language
models (LLMs) due to their inherent context-window limitations and the
computational burden of extensive key-value (KV) activations, which severely
impact efficiency. For information-seeking tasks, full context perception is
often unnecessary, as a query's information needs can dynamically range from
localized details to a global perspective, depending on its complexity.
However, existing methods struggle to adapt effectively to these dynamic
information needs.
  In the paper, we propose a method for processing long-context
information-seeking tasks via query-guided Activation Refilling (ACRE). ACRE
constructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache
compactly captures global information, and the layer-2 (L2) cache provides
detailed and localized information. ACRE establishes a proxying relationship
between the two caches, allowing the input query to attend to the L1 cache and
dynamically refill it with relevant entries from the L2 cache. This mechanism
integrates global understanding with query-specific local details, thus
improving answer decoding. Experiments on a variety of long-context
information-seeking datasets demonstrate ACRE's effectiveness, achieving
improvements in both performance and efficiency.",2024-12-17,"Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian"
"AutoSGNN: Automatic Propagation Mechanism Discovery for Spectral Graph
  Neural Networks","In real-world applications, spectral Graph Neural Networks (GNNs) are
powerful tools for processing diverse types of graphs. However, a single GNN
often struggles to handle different graph types-such as homogeneous and
heterogeneous graphs-simultaneously. This challenge has led to the manual
design of GNNs tailored to specific graph types, but these approaches are
limited by the high cost of labor and the constraints of expert knowledge,
which cannot keep up with the rapid growth of graph data. To overcome these
challenges, we propose AutoSGNN, an automated framework for discovering
propagation mechanisms in spectral GNNs. AutoSGNN unifies the search space for
spectral GNNs by integrating large language models with evolutionary strategies
to automatically generate architectures that adapt to various graph types.
Extensive experiments on nine widely-used datasets, encompassing both
homophilic and heterophilic graphs, demonstrate that AutoSGNN outperforms
state-of-the-art spectral GNNs and graph neural architecture search methods in
both performance and efficiency.",2024-12-17,"Shibing Mo, Kai Wu, Qixuan Gao, Xiangyi Teng, Jing Liu"
if-ZKP: Intel FPGA-Based Acceleration of Zero Knowledge Proofs,"Zero-Knowledge Proofs (ZKPs) have emerged as an important cryptographic
technique allowing one party (prover) to prove the correctness of a statement
to some other party (verifier) and nothing else. ZKPs give rise to user's
privacy in many applications such as blockchains, digital voting, and machine
learning. Traditionally, ZKPs suffered from poor scalability but recently, a
sub-class of ZKPs known as Zero-knowledge Succinct Non-interactive ARgument of
Knowledges (zk-SNARKs) have addressed this challenge. They are getting
significant attention and are being implemented by many public libraries. In
this paper, we present a novel scalable architecture that is suitable for
accelerating the zk-SNARK prover compute on FPGAs. We focus on the multi-scalar
multiplication (MSM) that accounts for the majority of computation time spent
in zk-SNARK systems. The MSM calculations extensive rely on modular arithmetic
so highly optimized Intel IP Libraries for modular arithmetic are used. The
proposed architecture exploits the parallelism inherent to MSM and is
implemented using the Intel OneAPI framework for FPGAs. Our implementation runs
110x-150x faster compared to reference software library, uses a generic curve
form in Jacobian coordinates and is the first to report FPGA hardware
acceleration results for BLS12-381 and BN128 family of elliptic curves.",2024-12-17,"Shahzad Ahmad Butt, Benjamin Reynolds, Veeraraghavan Ramamurthy, Xiao Xiao, Pohrong Chu, Setareh Sharifian, Sergey Gribok, Bogdan Pasca"
"Subversion Strategy Eval: Evaluating AI's stateless strategic
  capabilities against control protocols","AI control protocols are plans for usefully deploying AI systems in a way
that is safe, even if the AI intends to subvert the protocol. Previous work
evaluated protocols by subverting them with a human-AI red team, where an AI
follows the human-written strategy. This paper investigates how well AI systems
can generate and act on strategies for subverting control protocols whilst
operating without private memory. Usually, decision-makers only need the
ability to generate optimal plans. However, to subvert a protocol, an AI system
must be able to reliably generate optimal plans in each context; coordinate
plans with other instances of itself without communicating; and take actions
with well-calibrated probabilities. We develop evaluations for a model's
ability to generate subversion strategies and develop affordance experiments
that help isolate component capabilities. Our initial evaluations with
Claude-3.5-sonnet highlight reasons why statelessly strategizing to subvert
control protocols might be hard. We hope that our work can serve as a starting
point for evaluations aimed at assessing whether a model is capable of
strategizing to subvert control protocols.",2024-12-17,"Alex Mallen, Charlie Griffin, Alessandro Abate, Buck Shlegeris"
"Human-in-the-Loop Generation of Adversarial Texts: A Case Study on
  Tibetan Script","DNN-based language models perform excellently on various tasks, but even SOTA
LLMs are susceptible to textual adversarial attacks. Adversarial texts play
crucial roles in multiple subfields of NLP. However, current research has the
following issues. (1) Most textual adversarial attack methods target
rich-resourced languages. How do we generate adversarial texts for less-studied
languages? (2) Most textual adversarial attack methods are prone to generating
invalid or ambiguous adversarial texts. How do we construct high-quality
adversarial robustness benchmarks? (3) New language models may be immune to
part of previously generated adversarial texts. How do we update adversarial
robustness benchmarks? To address the above issues, we introduce HITL-GAT, a
system based on a general approach to human-in-the-loop generation of
adversarial texts. HITL-GAT contains four stages in one pipeline: victim model
construction, adversarial example generation, high-quality benchmark
construction, and adversarial robustness evaluation. Additionally, we utilize
HITL-GAT to make a case study on Tibetan script which can be a reference for
the adversarial research of other less-studied languages.",2024-12-17,"Xi Cao, Yuan Sun, Jiajun Li, Quzong Gesang, Nuo Qun, Tashi Nyima"
"Pattern Analogies: Learning to Perform Programmatic Image Edits by
  Analogy","Pattern images are everywhere in the digital and physical worlds, and tools
to edit them are valuable. But editing pattern images is tricky: desired edits
are often programmatic: structure-aware edits that alter the underlying program
which generates the pattern. One could attempt to infer this underlying
program, but current methods for doing so struggle with complex images and
produce unorganized programs that make editing tedious. In this work, we
introduce a novel approach to perform programmatic edits on pattern images. By
using a pattern analogy -- a pair of simple patterns to demonstrate the
intended edit -- and a learning-based generative model to execute these edits,
our method allows users to intuitively edit patterns. To enable this paradigm,
we introduce SplitWeave, a domain-specific language that, combined with a
framework for sampling synthetic pattern analogies, enables the creation of a
large, high-quality synthetic training dataset. We also present TriFuser, a
Latent Diffusion Model (LDM) designed to overcome critical issues that arise
when naively deploying LDMs to this task. Extensive experiments on real-world,
artist-sourced patterns reveals that our method faithfully performs the
demonstrated edit while also generalizing to related pattern styles beyond its
training distribution.",2024-12-17,"Aditya Ganeshan, Thibault Groueix, Paul Guerrero, Radomír Měch, Matthew Fisher, Daniel Ritchie"
"PromptDet: A Lightweight 3D Object Detection Framework with LiDAR
  Prompts","Multi-camera 3D object detection aims to detect and localize objects in 3D
space using multiple cameras, which has attracted more attention due to its
cost-effectiveness trade-off. However, these methods often struggle with the
lack of accurate depth estimation caused by the natural weakness of the camera
in ranging. Recently, multi-modal fusion and knowledge distillation methods for
3D object detection have been proposed to solve this problem, which are
time-consuming during the training phase and not friendly to memory cost. In
light of this, we propose PromptDet, a lightweight yet effective 3D object
detection framework motivated by the success of prompt learning in 2D
foundation model. Our proposed framework, PromptDet, comprises two integral
components: a general camera-based detection module, exemplified by models like
BEVDet and BEVDepth, and a LiDAR-assisted prompter. The LiDAR-assisted prompter
leverages the LiDAR points as a complementary signal, enriched with a minimal
set of additional trainable parameters. Notably, our framework is flexible due
to our prompt-like design, which can not only be used as a lightweight
multi-modal fusion method but also as a camera-only method for 3D object
detection during the inference phase. Extensive experiments on nuScenes
validate the effectiveness of the proposed PromptDet. As a multi-modal
detector, PromptDet improves the mAP and NDS by at most 22.8\% and 21.1\% with
fewer than 2\% extra parameters compared with the camera-only baseline. Without
LiDAR points, PromptDet still achieves an improvement of at most 2.4\% mAP and
4.0\% NDS with almost no impact on camera detection inference time.",2024-12-17,"Kun Guo, Qiang Ling"
"Graph Learning in the Era of LLMs: A Survey from the Perspective of
  Data, Models, and Tasks","With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)
Data (e.g., citation networks, recommendation systems, social networks, and
ai4science), the integration of Graph Neural Networks (GNNs) and Large Language
Models (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as
collaborators, LLM as predictor) has emerged as a promising technological
paradigm. The core of this new graph learning paradigm lies in the synergistic
combination of GNNs' ability to capture complex structural relationships and
LLMs' proficiency in understanding informative contexts from the rich textual
descriptions of graphs. Therefore, we can leverage graph description texts with
rich semantic context to fundamentally enhance Data quality, thereby improving
the representational capacity of model-centric approaches in line with
data-centric machine learning principles. By leveraging the strengths of these
distinct neural network architectures, this integrated approach addresses a
wide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph
question answering), particularly in complex industrial scenarios (e.g.,
supervised, few-shot, and zero-shot settings). In other words, we can treat
text as a medium to enable cross-domain generalization of graph learning Model,
allowing a single graph model to effectively handle the diversity of downstream
graph-based Task across different data domains. This work serves as a
foundational reference for researchers and practitioners looking to advance
graph learning methodologies in the rapidly evolving landscape of LLM. We
consistently maintain the related open-source materials at
\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.",2024-12-17,"Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang"
Cluster Editing on Cographs and Related Classes,"In the Cluster Editing problem, sometimes known as (unweighted) Correlation
Clustering, we must insert and delete a minimum number of edges to achieve a
graph in which every connected component is a clique. Owing to its applications
in computational biology, social network analysis, machine learning, and
others, this problem has been widely studied for decades and is still
undergoing active research. There exist several parameterized algorithms for
general graphs, but little is known about the complexity of the problem on
specific classes of graphs.
  Among the few important results in this direction, if only deletions are
allowed, the problem can be solved in polynomial time on cographs, which are
the $P_4$-free graphs. However, the complexity of the broader editing problem
on cographs is still open. We show that even on a very restricted subclass of
cographs, the problem is NP-hard, W[1]-hard when parameterized by the number
$p$ of desired clusters, and that time $n^{o(p/\log p)}$ is forbidden under the
ETH. This shows that the editing variant is substantially harder than the
deletion-only case, and that hardness holds for the many superclasses of
cographs (including graphs of clique-width at most $2$, perfect graphs, circle
graphs, permutation graphs). On the other hand, we provide an almost tight
upper bound of time $n^{O(p)}$, which is a consequence of a more general
$n^{O(cw \cdot p)}$ time algorithm, where $cw$ is the clique-width. Given that
forbidding $P_4$s maintains NP-hardness, we look at $\{P_4, C_4\}$-free graphs,
also known as trivially perfect graphs, and provide a cubic-time algorithm for
this class.",2024-12-17,"Manuel Lafond, Alitzel López Sánchez, Weidong Luo"
"Persona-SQ: A Personalized Suggested Question Generation Framework For
  Real-world Documents","Suggested questions (SQs) provide an effective initial interface for users to
engage with their documents in AI-powered reading applications. In practical
reading sessions, users have diverse backgrounds and reading goals, yet current
SQ features typically ignore such user information, resulting in homogeneous or
ineffective questions. We introduce a pipeline that generates personalized SQs
by incorporating reader profiles (professions and reading goals) and
demonstrate its utility in two ways: 1) as an improved SQ generation pipeline
that produces higher quality and more diverse questions compared to current
baselines, and 2) as a data generator to fine-tune extremely small models that
perform competitively with much larger models on SQ generation. Our approach
can not only serve as a drop-in replacement in current SQ systems to
immediately improve their performance but also help develop on-device SQ models
that can run locally to deliver fast and private SQ experience.",2024-12-17,"Zihao Lin, Zichao Wang, Yuanting Pan, Varun Manjunatha, Ryan Rossi, Angela Lau, Lifu Huang, Tong Sun"
"Predicting Workload in Virtual Flight Simulations using EEG Features
  (Including Post-hoc Analysis in Appendix)","Effective cognitive workload management has a major impact on the safety and
performance of pilots. Integrating brain-computer interfaces (BCIs) presents an
opportunity for real-time workload assessment. Leveraging cognitive workload
data from immersive, high-fidelity virtual reality (VR) flight simulations
enhances ecological validity and allows for dynamic adjustments to training
scenarios based on individual cognitive states. While prior studies have
predominantly concentrated on EEG spectral power for workload prediction,
delving into inter-brain connectivity may yield deeper insights. This study
assessed the predictive value of EEG spectral and connectivity features in
distinguishing high vs. low workload periods during simulated flight in VR and
Desktop conditions. EEG data were collected from 52 non-pilot participants
conducting flight tasks in an aircraft simulation, after which they reported
cognitive workload using the NASA Task Load Index. Using an ensemble approach,
a stacked classifier was trained to predict workload using two feature sets
extracted from the EEG data: 1) spectral features (Baseline model), and 2) a
combination of spectral and connectivity features (Connectivity model), both
within the alpha, beta, and theta band ranges. Results showed that the
performance of the Connectivity model surpassed the Baseline model.
Additionally, Recursive Feature Elimination (RFE) provided insights into the
most influential workload-predicting features, highlighting the potential
dominance of parietal-directed connectivity in managing cognitive workload
during simulated flight. Further research on other connectivity metrics and
alternative models (such as deep learning) in a large sample of pilots is
essential to validate the possibility of a real-time BCI for the prediction of
workload under safety-critical operational conditions.",2024-12-17,"Bas Verkennis, Evy van Weelden, Francesca L. Marogna, Maryam Alimardani, Travis J. Wiltshire, Max M. Louwerse"
DeepSN: A Sheaf Neural Framework for Influence Maximization,"Influence maximization is key topic in data mining, with broad applications
in social network analysis and viral marketing. In recent years, researchers
have increasingly turned to machine learning techniques to address this
problem. They have developed methods to learn the underlying diffusion
processes in a data-driven manner, which enhances the generalizability of the
solution, and have designed optimization objectives to identify the optimal
seed set. Nonetheless, two fundamental gaps remain unsolved: (1) Graph Neural
Networks (GNNs) are increasingly used to learn diffusion models, but in their
traditional form, they often fail to capture the complex dynamics of influence
diffusion, (2) Designing optimization objectives is challenging due to
combinatorial explosion when solving this problem. To address these challenges,
we propose a novel framework, DeepSN. Our framework employs sheaf neural
diffusion to learn diverse influence patterns in a data-driven, end-to-end
manner, providing enhanced separability in capturing diffusion characteristics.
We also propose an optimization technique that accounts for overlapping
influence between vertices, which helps to reduce the search space and identify
the optimal seed set effectively and efficiently. Finally, we conduct extensive
experiments on both synthetic and real-world datasets to demonstrate the
effectiveness of our framework.",2024-12-16,"Asela Hevapathige, Qing Wang, Ahad N. Zehmakan"
Characterizing the Networks Sending Enterprise Phishing Emails,"Phishing attacks on enterprise employees present one of the most costly and
potent threats to organizations. We explore an understudied facet of enterprise
phishing attacks: the email relay infrastructure behind successfully delivered
phishing emails. We draw on a dataset spanning one year across thousands of
enterprises, billions of emails, and over 800,000 delivered phishing attacks.
Our work sheds light on the network origins of phishing emails received by
real-world enterprises, differences in email traffic we observe from networks
sending phishing emails, and how these characteristics change over time.
  Surprisingly, we find that over one-third of the phishing email in our
dataset originates from highly reputable networks, including Amazon and
Microsoft. Their total volume of phishing email is consistently high across
multiple months in our dataset, even though the overwhelming majority of email
sent by these networks is benign. In contrast, we observe that a large portion
of phishing emails originate from networks where the vast majority of emails
they send are phishing, but their email traffic is not consistent over time.
Taken together, our results explain why no singular defense strategy, such as
static blocklists (which are commonly used in email security filters deployed
by organizations in our dataset), is effective at blocking enterprise phishing.
Based on our offline analysis, we partnered with a large email security company
to deploy a classifier that uses dynamically updated network-based features. In
a production environment over a period of 4.5 months, our new detector was able
to identify 3-5% more enterprise email attacks that were previously undetected
by the company's existing classifiers.",2024-12-16,"Elisa Luo, Liane Young, Grant Ho, M. H. Afifi, Marco Schweighauser, Ethan Katz-Bassett, Asaf Cidon"
Parallel Motif-Based Community Detection,"Community detection is a central task in graph analytics. Given the
substantial growth in graph size, scalability in community detection continues
to be an unresolved challenge. Recently, alongside established methods like
Louvain and Infomap, motif-based community detection has emerged. Techniques
like Tectonic are notable for their advanced ability to identify communities by
pruning edges based on motif similarity scores and analyzing the resulting
connected components.
  In this study, we perform a comprehensive evaluation of community detection
methods, focusing on both the quality of their output and their scalability.
Specifically, we contribute an open-source parallel framework for motif-based
community detection based on a shared memory architecture. We conduct a
thorough comparative analysis of community detection techniques from various
families among state-of-the-art methods, including Tectonic, label propagation,
spectral clustering, Louvain, LambdaCC, and Infomap on graphs with up to
billions of edges. A key finding of our analysis is that motif-based graph
clustering provides a good balance between performance and efficiency. Our work
provides several novel insights. Interestingly, we pinpoint biases in prior
works in evaluating community detection methods using the top 5K groundtruth
communities from SNAP only, as these are frequently near-cliques. Our empirical
studies lead to rules of thumb threshold picking strategies that can be
critical for real applications. Finally, we show that Tectonic can fail to
recover two well-separated clusters. To address this, we suggest a new
similarity measure based on counts of triangles and wedges (TW) that prevents
the over-segmentation of communities by Tectonic.",2024-12-16,"Tianyi Chen, Charalampos E. Tsourakakis"
Priority-Aware Model-Distributed Inference at Edge Networks,"Distributed inference techniques can be broadly classified into
data-distributed and model-distributed schemes. In data-distributed inference
(DDI), each worker carries the entire Machine Learning (ML) model but processes
only a subset of the data. However, feeding the data to workers results in high
communication costs, especially when the data is large. An emerging paradigm is
model-distributed inference (MDI), where each worker carries only a subset of
ML layers. In MDI, a source device that has data processes a few layers of ML
model and sends the output to a neighboring device, i.e., offloads the rest of
the layers. This process ends when all layers are processed in a distributed
manner. In this paper, we investigate the design and development of MDI when
multiple data sources co-exist. We consider that each data source has a
different importance and, hence, a priority. We formulate and solve a
priority-aware model allocation optimization problem. Based on the structure of
the optimal solution, we design a practical Priority-Aware Model- Distributed
Inference (PA-MDI) algorithm that determines model allocation and distribution
over devices by taking into account the priorities of different sources.
Experiments were conducted on a real-life testbed of NVIDIA Jetson Xavier and
Nano edge devices as well as in the Colosseum testbed with ResNet-50, ResNet-
56, and GPT-2 models. The experimental results show that PA-MDI performs
priority-aware model allocation successfully while reducing the inference time
as compared to baselines.",2024-12-16,"Teng Li, Hulya Seferoglu"
"The Ramanujan Library -- Automated Discovery on the Hypergraph of
  Integer Relations","Fundamental mathematical constants appear in nearly every field of science,
from physics to biology. Formulas that connect different constants often bring
great insight by hinting at connections between previously disparate fields.
Discoveries of such relations, however, have remained scarce events, relying on
sporadic strokes of creativity by human mathematicians. Recent developments of
algorithms for automated conjecture generation have accelerated the discovery
of formulas for specific constants. Yet, the discovery of connections between
constants has not been addressed. In this paper, we present the first library
dedicated to mathematical constants and their interrelations. This library can
serve as a central repository of knowledge for scientists from different areas,
and as a collaborative platform for development of new algorithms. The library
is based on a new representation that we propose for organizing the formulas of
mathematical constants: a hypergraph, with each node representing a constant
and each edge representing a formula. Using this representation, we propose and
demonstrate a systematic approach for automatically enriching this library
using PSLQ, an integer relation algorithm based on QR decomposition and lattice
construction. During its development and testing, our strategy led to the
discovery of 75 previously unknown connections between constants, including a
new formula for the `first continued fraction' constant $C_1$, novel formulas
for natural logarithms, and new formulas connecting $\pi$ and $e$. The latter
formulas generalize a century-old relation between $\pi$ and $e$ by Ramanujan,
which until now was considered a singular formula and is now found to be part
of a broader mathematical structure. The code supporting this library is a
public, open-source API that can serve researchers in experimental mathematics
and other fields of science.",2024-12-16,"Itay Beit-Halachmi, Ido Kaminer"
"Visual Instruction Tuning with 500x Fewer Parameters through Modality
  Linear Representation-Steering","Multimodal Large Language Models (MLLMs) have significantly advanced visual
tasks by integrating visual representations into large language models (LLMs).
The textual modality, inherited from LLMs, equips MLLMs with abilities like
instruction following and in-context learning. In contrast, the visual modality
enhances performance in downstream tasks by leveraging rich semantic content,
spatial information, and grounding capabilities. These intrinsic modalities
work synergistically across various visual tasks. Our research initially
reveals a persistent imbalance between these modalities, with text often
dominating output generation during visual instruction tuning. This imbalance
occurs when using both full fine-tuning and parameter-efficient fine-tuning
(PEFT) methods. We then found that re-balancing these modalities can
significantly reduce the number of trainable parameters required, inspiring a
direction for further optimizing visual instruction tuning. We introduce
Modality Linear Representation-Steering (MoReS) to achieve the goal. MoReS
effectively re-balances the intrinsic modalities throughout the model, where
the key idea is to steer visual representations through linear transformations
in the visual subspace across each model layer. To validate our solution, we
composed LLaVA Steering, a suite of models integrated with the proposed MoReS
method. Evaluation results show that the composed LLaVA Steering models
require, on average, 500 times fewer trainable parameters than LoRA needs while
still achieving comparable performance across three visual benchmarks and eight
visual question-answering tasks. Last, we present the LLaVA Steering Factory,
an in-house developed platform that enables researchers to quickly customize
various MLLMs with component-based architecture for seamlessly integrating
state-of-the-art models, and evaluate their intrinsic modality imbalance.",2024-12-16,"Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma"
"AutoSciLab: A Self-Driving Laboratory For Interpretable Scientific
  Discovery","Advances in robotic control and sensing have propelled the rise of automated
scientific laboratories capable of high-throughput experiments. However,
automated scientific laboratories are currently limited by human intuition in
their ability to efficiently design and interpret experiments in
high-dimensional spaces, throttling scientific discovery. We present
AutoSciLab, a machine learning framework for driving autonomous scientific
experiments, forming a surrogate researcher purposed for scientific discovery
in high-dimensional spaces. AutoSciLab autonomously follows the scientific
method in four steps: (i) generating high-dimensional experiments (x \in R^D)
using a variational autoencoder (ii) selecting optimal experiments by forming
hypotheses using active learning (iii) distilling the experimental results to
discover relevant low-dimensional latent variables (z \in R^d, with d << D)
with a 'directional autoencoder' and (iv) learning a human interpretable
equation connecting the discovered latent variables with a quantity of interest
(y = f(z)), using a neural network equation learner. We validate the
generalizability of AutoSciLab by rediscovering a) the principles of projectile
motion and b) the phase transitions within the spin-states of the Ising model
(NP-hard problem). Applying our framework to an open-ended nanophotonics
challenge, AutoSciLab uncovers a fundamentally novel method for directing
incoherent light emission that surpasses the current state-of-the-art (Iyer et
al. 2023b, 2020).",2024-12-16,"Saaketh Desai, Sadhvikas Addamane, Jeffrey Y. Tsao, Igal Brener, Laura P. Swiler, Remi Dingreville, Prasad P. Iyer"
A Large Language Model Approach to Identify Flakiness in C++ Projects,"The role of regression testing in software testing is crucial as it ensures
that any new modifications do not disrupt the existing functionality and
behaviour of the software system. The desired outcome is for regression tests
to yield identical results without any modifications made to the system being
tested. In practice, however, the presence of Flaky Tests introduces
non-deterministic behaviour and undermines the reliability of regression
testing results.
  In this paper, we propose an LLM-based approach for identifying the root
cause of flaky tests in C++ projects at the code level, with the intention of
assisting developers in debugging and resolving them more efficiently. We
compile a comprehensive collection of C++ project flaky tests sourced from
GitHub repositories. We fine-tune Mistral-7b, Llama2-7b and CodeLlama-7b models
on the C++ dataset and an existing Java dataset and evaluate the performance in
terms of precision, recall, accuracy, and F1 score. We assess the performance
of the models across various datasets and offer recommendations for both
research and industry applications.
  The results indicate that our models exhibit varying performance on the C++
dataset, while their performance is comparable to that of the Java dataset. The
Mistral-7b surpasses the other two models regarding all metrics, achieving a
score of 1. Our results demonstrate the exceptional capability of LLMs to
accurately classify flakiness in C++ and Java projects, providing a promising
approach to enhance the efficiency of debugging flaky tests in practice.",2024-12-16,"Xin Sun, Daniel Ståhl, Kristian Sandahl"
"F-RBA: A Federated Learning-based Framework for Risk-based
  Authentication","The proliferation of Internet services has led to an increasing need to
protect private data. User authentication serves as a crucial mechanism to
ensure data security. Although robust authentication forms the cornerstone of
remote service security, it can still leave users vulnerable to credential
disclosure, device-theft attacks, session hijacking, and inadequate adaptive
security measures. Risk-based Authentication (RBA) emerges as a potential
solution, offering a multi-level authentication approach that enhances user
experience without compromising security. In this paper, we propose a Federated
Risk-based Authentication (F-RBA) framework that leverages Federated Learning
to ensure privacy-centric training, keeping user data local while distributing
learning across devices. Whereas traditional approaches rely on centralized
storage, F-RBA introduces a distributed architecture where risk assessment
occurs locally on users' devices. The framework's core innovation lies in its
similarity-based feature engineering approach, which addresses the
heterogeneous data challenges inherent in federated settings, a significant
advancement for distributed authentication. By facilitating real-time risk
evaluation across devices while maintaining unified user profiles, F-RBA
achieves a balance between data protection, security, and scalability. Through
its federated approach, F-RBA addresses the cold-start challenge in risk model
creation, enabling swift adaptation to new users without compromising security.
Empirical evaluation using a real-world multi-user dataset demonstrates the
framework's effectiveness, achieving a superior true positive rate for
detecting suspicious logins compared to conventional unsupervised anomaly
detection models. This research introduces a new paradigm for privacy-focused
RBA in distributed digital environments, facilitating advancements in federated
security systems.",2024-12-16,"Hamidreza Fereidouni, Abdelhakim Senhaji Hafid, Dimitrios Makrakis, Yaser Baseri"
ChronoFlow: A Data-Driven Model for Gyrochronology,"Gyrochronology is a technique for constraining stellar ages using rotation
periods, which change over a star's main sequence lifetime due to magnetic
braking. This technique shows promise for main sequence FGKM stars, where other
methods are imprecise. However, models have historically struggled to capture
the observed rotational dispersion in stellar populations. To properly
understand this complexity, we have assembled the largest standardized data
catalog of rotators in open clusters to date, consisting of ~7,400 stars across
30 open clusters/associations spanning ages of 1.5 Myr to 4 Gyr. We have also
developed ChronoFlow: a flexible data-driven model which accurately captures
observed rotational dispersion. We show that ChronoFlow can be used to
accurately forward model rotational evolution, and to infer both cluster and
individual stellar ages. We recover cluster ages with a statistical uncertainty
of 0.06 dex ($\approx$ 15%), and individual stellar ages with a statistical
uncertainty of 0.7 dex. Additionally, we conducted robust systematic tests to
analyze the impact of extinction models, cluster membership, and calibration
ages on our model's performance. These contribute an additional $\approx$ 0.06
dex of uncertainty in cluster age estimates, resulting in a total error budget
of 0.08 dex. We estimate ages for the NGC 6709 open cluster and the Theia 456
stellar stream, and calculate revised rotational ages for M34, NGC 2516, NGC
1750, and NGC 1647. Our results show that ChronoFlow can precisely estimate the
ages of coeval stellar populations, and constrain ages for individual stars.
Furthermore, its predictions may be used to inform physical spin down models.
ChronoFlow will be publicly available at
https://github.com/philvanlane/chronoflow.",2024-12-16,"Phil R. Van-Lane, Joshua S. Speagle, Gwendolyn M. Eadie, Stephanie T. Douglas, Phillip A. Cargile, Catherine Zucker, Yuxi, Lu, Ruth Angus"
OmniPrism: Learning Disentangled Visual Concept for Image Generation,"Creative visual concept generation often draws inspiration from specific
concepts in a reference image to produce relevant outcomes. However, existing
methods are typically constrained to single-aspect concept generation or are
easily disrupted by irrelevant concepts in multi-aspect concept scenarios,
leading to concept confusion and hindering creative generation. To address
this, we propose OmniPrism, a visual concept disentangling approach for
creative image generation. Our method learns disentangled concept
representations guided by natural language and trains a diffusion model to
incorporate these concepts. We utilize the rich semantic space of a multimodal
extractor to achieve concept disentanglement from given images and concept
guidance. To disentangle concepts with different semantics, we construct a
paired concept disentangled dataset (PCD-200K), where each pair shares the same
concept such as content, style, and composition. We learn disentangled concept
representations through our contrastive orthogonal disentangled (COD) training
pipeline, which are then injected into additional diffusion cross-attention
layers for generation. A set of block embeddings is designed to adapt each
block's concept domain in the diffusion models. Extensive experiments
demonstrate that our method can generate high-quality, concept-disentangled
results with high fidelity to text prompts and desired concepts.",2024-12-16,"Yangyang Li, Daqing Liu, Wu Liu, Allen He, Xinchen Liu, Yongdong Zhang, Guoqing Jin"
Wonderland: Navigating 3D Scenes from a Single Image,"This paper addresses a challenging question: How can we efficiently create
high-quality, wide-scope 3D scenes from a single arbitrary image? Existing
methods face several constraints, such as requiring multi-view data,
time-consuming per-scene optimization, low visual quality in backgrounds, and
distorted reconstructions in unseen areas. We propose a novel pipeline to
overcome these limitations. Specifically, we introduce a large-scale
reconstruction model that uses latents from a video diffusion model to predict
3D Gaussian Splattings for the scenes in a feed-forward manner. The video
diffusion model is designed to create videos precisely following specified
camera trajectories, allowing it to generate compressed video latents that
contain multi-view information while maintaining 3D consistency. We train the
3D reconstruction model to operate on the video latent space with a progressive
training strategy, enabling the efficient generation of high-quality,
wide-scope, and generic 3D scenes. Extensive evaluations across various
datasets demonstrate that our model significantly outperforms existing methods
for single-view 3D scene generation, particularly with out-of-domain images.
For the first time, we demonstrate that a 3D reconstruction model can be
effectively built upon the latent space of a diffusion model to realize
efficient 3D scene generation.",2024-12-16,"Hanwen Liang, Junli Cao, Vidit Goel, Guocheng Qian, Sergei Korolev, Demetri Terzopoulos, Konstantinos N. Plataniotis, Sergey Tulyakov, Jian Ren"
"CG-Bench: Clue-grounded Question Answering Benchmark for Long Video
  Understanding","Most existing video understanding benchmarks for multimodal large language
models (MLLMs) focus only on short videos. The limited number of benchmarks for
long video understanding often rely solely on multiple-choice questions (MCQs).
However, because of the inherent limitation of MCQ-based evaluation and the
increasing reasoning ability of MLLMs, models can give the current answer
purely by combining short video understanding with elimination, without
genuinely understanding the video content. To address this gap, we introduce
CG-Bench, a novel benchmark designed for clue-grounded question answering in
long videos. CG-Bench emphasizes the model's ability to retrieve relevant clues
for questions, enhancing evaluation credibility. It features 1,219 manually
curated videos categorized by a granular system with 14 primary categories, 171
secondary categories, and 638 tertiary categories, making it the largest
benchmark for long video analysis. The benchmark includes 12,129 QA pairs in
three major question types: perception, reasoning, and hallucination.
Compensating the drawbacks of pure MCQ-based evaluation, we design two novel
clue-based evaluation methods: clue-grounded white box and black box
evaluations, to assess whether the model generates answers based on the correct
understanding of the video. We evaluate multiple closed-source and open-source
MLLMs on CG-Bench. Results indicate that current models significantly
underperform in understanding long videos compared to short ones, and a
significant gap exists between open-source and commercial models. We hope
CG-Bench can advance the development of more trustworthy and capable MLLMs for
long video understanding. All annotations and video data are released at
https://cg-bench.github.io/leaderboard/.",2024-12-16,"Guo Chen, Yicheng Liu, Yifei Huang, Yuping He, Baoqi Pei, Jilan Xu, Yali Wang, Tong Lu, Limin Wang"
"Development of a Compact High-Voltage Functional Electrical Stimulation
  Device","This report details the design and development of a compact high-voltage
functional electrical stimulation (FES) device. Unlike conventional FES
systems, the proposed design prioritizes user comfort by leveraging rapid
switching times to effectively activate muscles while minimizing stimulation of
pain receptors. The device is equipped with a high compliance voltage of up to
135 V, enabling its use across various muscle groups and accommodating users
with differing skin conductance levels. At the core of the system is a switched
capacitor (SC) stimulator, which facilitates fast switching, and a flyback
converter that steps up the battery voltage. The design exclusively utilizes
off-the-shelf components, significantly reducing prototyping costs. Initially,
a large testing board was developed to evaluate the performance of the SC
stimulator in comparison with conventional H-bridge-based current-regulated
stimulators. Subsequently, a compact, three-board PCB design was created to
enable battery-powered operation, making it suitable for wearable applications.
The proposed design methodology is broadly applicable to a wide range of neural
rehabilitation applications.",2024-12-16,"Haiduo Wang, Ruizhe Tang, Xilin Liu"
"Virtual Agent-Based Communication Skills Training to Facilitate Health
  Persuasion Among Peers","Many laypeople are motivated to improve the health behavior of their family
or friends but do not know where to start, especially if the health behavior is
potentially stigmatizing or controversial. We present an approach that uses
virtual agents to coach community-based volunteers in health counseling
techniques, such as motivational interviewing, and allows them to practice
these skills in role-playing scenarios. We use this approach in a virtual
agent-based system to increase COVID-19 vaccination by empowering users to
influence their social network. In a between-subjects comparative design study,
we test the effects of agent system interactivity and role-playing
functionality on counseling outcomes, with participants evaluated by
standardized patients and objective judges. We find that all versions are
effective at producing peer counselors who score adequately on a standardized
measure of counseling competence, and that participants were significantly more
satisfied with interactive virtual agents compared to passive viewing of the
training material. We discuss design implications for interpersonal skills
training systems based on our findings.",2024-12-16,"Farnaz Nouraei, Keith Rebello, Mina Fallah, Prasanth Murali, Haley Matuszak, Valerie Jap, Andrea Parker, Michael Paasche-Orlow, Timothy Bickmore"
"Exploring Semantic Consistency and Style Diversity for Domain
  Generalized Semantic Segmentation","Domain Generalized Semantic Segmentation (DGSS) seeks to utilize source
domain data exclusively to enhance the generalization of semantic segmentation
across unknown target domains. Prevailing studies predominantly concentrate on
feature normalization and domain randomization, these approaches exhibit
significant limitations. Feature normalization-based methods tend to confuse
semantic features in the process of constraining the feature space
distribution, resulting in classification misjudgment. Domain
randomization-based methods frequently incorporate domain-irrelevant noise due
to the uncontrollability of style transformations, resulting in segmentation
ambiguity. To address these challenges, we introduce a novel framework, named
SCSD for Semantic Consistency prediction and Style Diversity generalization. It
comprises three pivotal components: Firstly, a Semantic Query Booster is
designed to enhance the semantic awareness and discrimination capabilities of
object queries in the mask decoder, enabling cross-domain semantic consistency
prediction. Secondly, we develop a Text-Driven Style Transform module that
utilizes domain difference text embeddings to controllably guide the style
transformation of image features, thereby increasing inter-domain style
diversity. Lastly, to prevent the collapse of similar domain feature spaces, we
introduce a Style Synergy Optimization mechanism that fortifies the separation
of inter-domain features and the aggregation of intra-domain features by
synergistically weighting style contrastive loss and style aggregation loss.
Extensive experiments demonstrate that the proposed SCSD significantly
outperforms existing state-of-theart methods. Notably, SCSD trained on GTAV
achieved an average of 49.11 mIoU on the four unseen domain datasets,
surpassing the previous state-of-the-art method by +4.08 mIoU. Code is
available at https://github.com/nhw649/SCSD.",2024-12-16,"Hongwei Niu, Linhuang Xie, Jianghang Lin, Shengchuan Zhang"
"Backstepping Control of Tendon-Driven Continuum Robots in Large
  Deflections Using the Cosserat Rod Model","This paper presents a study on the backstepping control of tendon-driven
continuum robots for large deflections using the Cosserat rod model. Continuum
robots are known for their flexibility and adaptability, making them suitable
for various applications. However, modeling and controlling them pose
challenges due to their nonlinear dynamics. To model their dynamics, the
Cosserat rod method is employed to account for significant deflections, and a
numerical solution method is developed to solve the resulting partial
differential equations. Previous studies on controlling tendon-driven continuum
robots using Cosserat rod theory focused on sliding mode control and were not
tested for large deflections, lacking experimental validation. In this paper,
backstepping control is proposed as an alternative to sliding mode control for
achieving a significant bending. The numerical results are validated through
experiments in this study, demonstrating that the proposed backstepping control
approach is a promising solution for achieving large deflections with smoother
trajectories, reduced settling time, and lower overshoot. Furthermore, two
scenarios involving external forces and disturbances were introduced to further
highlight the robustness of the backstepping control approach.",2024-12-16,"Rana Danesh, Farrokh Janabi-Sharifi"
"Thermodynamics-informed graph neural networks for real-time simulation
  of digital human twins","The growing importance of real-time simulation in the medical field has
exposed the limitations and bottlenecks inherent in the digital representation
of complex biological systems. This paper presents a novel methodology aimed at
advancing current lines of research in soft tissue simulation. The proposed
approach introduces a hybrid model that integrates the geometric bias of graph
neural networks with the physical bias derived from the imposition of a
metriplectic structure as soft and hard constrains in the architecture, being
able to simulate hepatic tissue with dissipative properties. This approach
provides an efficient solution capable of generating predictions at high
feedback rate while maintaining a remarkable generalization ability for
previously unseen anatomies. This makes these features particularly relevant in
the context of precision medicine and haptic rendering.
  Based on the adopted methodologies, we propose a model that predicts human
liver responses to traction and compression loads in as little as 7.3
milliseconds for optimized configurations and as fast as 1.65 milliseconds in
the most efficient cases, all in the forward pass. The model achieves relative
position errors below 0.15\%, with stress tensor and velocity estimations
maintaining relative errors under 7\%. This demonstrates the robustness of the
approach developed, which is capable of handling diverse load states and
anatomies effectively. This work highlights the feasibility of integrating
real-time simulation with patient-specific geometries through deep learning,
paving the way for more robust digital human twins in medical applications.",2024-12-16,"Lucas Tesán, David González, Pedro Martins, Elías Cueto"
Memory-Reduced Meta-Learning with Guaranteed Convergence,"The optimization-based meta-learning approach is gaining increased traction
because of its unique ability to quickly adapt to a new task using only small
amounts of data. However, existing optimization-based meta-learning approaches,
such as MAML, ANIL and their variants, generally employ backpropagation for
upper-level gradient estimation, which requires using historical lower-level
parameters/gradients and thus increases computational and memory overhead in
each iteration. In this paper, we propose a meta-learning algorithm that can
avoid using historical parameters/gradients and significantly reduce memory
costs in each iteration compared to existing optimization-based meta-learning
approaches. In addition to memory reduction, we prove that our proposed
algorithm converges sublinearly with the iteration number of upper-level
optimization, and the convergence error decays sublinearly with the batch size
of sampled tasks. In the specific case in terms of deterministic meta-learning,
we also prove that our proposed algorithm converges to an exact solution.
Moreover, we quantify that the computational complexity of the algorithm is on
the order of $\mathcal{O}(\epsilon^{-1})$, which matches existing convergence
results on meta-learning even without using any historical
parameters/gradients. Experimental results on meta-learning benchmarks confirm
the efficacy of our proposed algorithm.",2024-12-16,"Honglin Yang, Ji Ma, Xiao Yu"
"Deep-learning-based identification of individual motion characteristics
  from upper-limb trajectories towards disorder stage evaluation","The identification of individual movement characteristics sets the foundation
for the assessment of personal rehabilitation progress and can provide
diagnostic information on levels and stages of movement disorders. This work
presents a preliminary study for differentiating individual motion patterns
using a dataset of 3D upper-limb transport trajectories measured in task-space.
Identifying individuals by deep time series learning can be a key step to
abstracting individual motion properties. In this study, a classification
accuracy of about 95% is reached for a subset of nine, and about 78% for the
full set of 31 individuals. This provides insights into the separability of
patient attributes by exerting a simple standardized task to be transferred to
portable systems.",2024-12-16,"Tim Sziburis, Susanne Blex, Tobias Glasmachers, Ioannis Iossifidis"
The Open Source Advantage in Large Language Models (LLMs),"Large language models (LLMs) mark a key shift in natural language processing
(NLP), having advanced text generation, translation, and domain-specific
reasoning. Closed-source models like GPT-4, powered by proprietary datasets and
extensive computational resources, lead with state-of-the-art performance
today. However, they face criticism for their ""black box"" nature and for
limiting accessibility in a manner that hinders reproducibility and equitable
AI development. By contrast, open-source initiatives like LLaMA and BLOOM
prioritize democratization through community-driven development and
computational efficiency. These models have significantly reduced performance
gaps, particularly in linguistic diversity and domain-specific applications,
while providing accessible tools for global researchers and developers.
Notably, both paradigms rely on foundational architectural innovations, such as
the Transformer framework by Vaswani et al. (2017). Closed-source models excel
by scaling effectively, while open-source models adapt to real-world
applications in underrepresented languages and domains. Techniques like
Low-Rank Adaptation (LoRA) and instruction-tuning datasets enable open-source
models to achieve competitive results despite limited resources. To be sure,
the tension between closed-source and open-source approaches underscores a
broader debate on transparency versus proprietary control in AI. Ethical
considerations further highlight this divide. Closed-source systems restrict
external scrutiny, while open-source models promote reproducibility and
collaboration but lack standardized auditing documentation frameworks to
mitigate biases. Hybrid approaches that leverage the strengths of both
paradigms are likely to shape the future of LLM innovation, ensuring
accessibility, competitive technical performance, and ethical deployment.",2024-12-16,"Jiya Manchanda, Laura Boettcher, Matheus Westphalen, Jasser Jasser"
"CP-Guard: Malicious Agent Detection and Defense in Collaborative Bird's
  Eye View Perception","Collaborative Perception (CP) has shown a promising technique for autonomous
driving, where multiple connected and autonomous vehicles (CAVs) share their
perception information to enhance the overall perception performance and expand
the perception range. However, in CP, ego CAV needs to receive messages from
its collaborators, which makes it easy to be attacked by malicious agents. For
example, a malicious agent can send harmful information to the ego CAV to
mislead it. To address this critical issue, we propose a novel method,
\textbf{CP-Guard}, a tailored defense mechanism for CP that can be deployed by
each agent to accurately detect and eliminate malicious agents in its
collaboration network. Our key idea is to enable CP to reach a consensus rather
than a conflict against the ego CAV's perception results. Based on this idea,
we first develop a probability-agnostic sample consensus (PASAC) method to
effectively sample a subset of the collaborators and verify the consensus
without prior probabilities of malicious agents. Furthermore, we define a
collaborative consistency loss (CCLoss) to capture the discrepancy between the
ego CAV and its collaborators, which is used as a verification criterion for
consensus. Finally, we conduct extensive experiments in collaborative bird's
eye view (BEV) tasks and our results demonstrate the effectiveness of our
CP-Guard.",2024-12-16,"Senkang Hu, Yihang Tao, Guowen Xu, Yiqin Deng, Xianhao Chen, Yuguang Fang, Sam Kwong"
Fairness Shields: Safeguarding against Biased Decision Makers,"As AI-based decision-makers increasingly influence human lives, it is a
growing concern that their decisions are often unfair or biased with respect to
people's sensitive attributes, such as gender and race. Most existing bias
prevention measures provide probabilistic fairness guarantees in the long run,
and it is possible that the decisions are biased on specific instances of short
decision sequences. We introduce fairness shielding, where a symbolic
decision-maker -- the fairness shield -- continuously monitors the sequence of
decisions of another deployed black-box decision-maker, and makes interventions
so that a given fairness criterion is met while the total intervention costs
are minimized. We present four different algorithms for computing fairness
shields, among which one guarantees fairness over fixed horizons, and three
guarantee fairness periodically after fixed intervals. Given a distribution
over future decisions and their intervention costs, our algorithms solve
different instances of bounded-horizon optimal control problems with different
levels of computational costs and optimality guarantees. Our empirical
evaluation demonstrates the effectiveness of these shields in ensuring fairness
while maintaining cost efficiency across various scenarios.",2024-12-16,"Filip Cano, Thomas A. Henzinger, Bettina Könighofer, Konstantin Kueffner, Kaushik Mallik"
Cost-Effective Label-free Node Classification with LLMs,"Graph neural networks (GNNs) have emerged as go-to models for node
classification in graph data due to their powerful abilities in fusing graph
structures and attributes. However, such models strongly rely on adequate
high-quality labeled data for training, which are expensive to acquire in
practice. With the advent of large language models (LLMs), a promising way is
to leverage their superb zero-shot capabilities and massive knowledge for node
labeling. Despite promising results reported, this methodology either demands
considerable queries to LLMs, or suffers from compromised performance caused by
noisy labels produced by LLMs.
  To remedy these issues, this work presents Cella, an active self-training
framework that integrates LLMs into GNNs in a cost-effective manner. The design
recipe of Cella is to iteratively identify small sets of ""critical"" samples
using GNNs and extract informative pseudo-labels for them with both LLMs and
GNNs as additional supervision signals to enhance model training. Particularly,
Cella includes three major components: (i) an effective active node selection
strategy for initial annotations; (ii) a judicious sample selection scheme to
sift out the ""critical"" nodes based on label disharmonicity and entropy; and
(iii) a label refinement module combining LLMs and GNNs with rewired topology.
Our extensive experiments over five benchmark text-attributed graph datasets
demonstrate that Cella significantly outperforms the state of the arts under
the same query budget to LLMs in terms of label-free node classification. In
particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an
8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost
of less than one cent.",2024-12-16,"Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui Lai"
"AlphaZero Neural Scaling and Zipf's Law: a Tale of Board Games and Power
  Laws","Neural scaling laws are observed in a range of domains, to date with no clear
understanding of why they occur. Recent theories suggest that loss power laws
arise from Zipf's law, a power law observed in domains like natural language.
One theory suggests that language scaling laws emerge when Zipf-distributed
task quanta are learned in descending order of frequency. In this paper we
examine power-law scaling in AlphaZero, a reinforcement learning algorithm,
using a theory of language-model scaling. We find that game states in training
and inference data scale with Zipf's law, which is known to arise from the tree
structure of the environment, and examine the correlation between scaling-law
and Zipf's-law exponents. In agreement with quanta scaling theory, we find that
agents optimize state loss in descending order of frequency, even though this
order scales inversely with modelling complexity. We also find that inverse
scaling, the failure of models to improve with size, is correlated with unusual
Zipf curves where end-game states are among the most frequent states. We show
evidence that larger models shift their focus to these less-important states,
sacrificing their understanding of important early-game states.",2024-12-16,"Oren Neumann, Claudius Gros"
DARWIN 1.5: Large Language Models as Materials Science Adapted Learners,"Materials discovery and design aim to find components and structures with
desirable properties over highly complex and diverse search spaces. Traditional
solutions, such as high-throughput simulations and machine learning (ML), often
rely on complex descriptors, which hinder generalizability and transferability
across tasks. Moreover, these descriptors may deviate from experimental data
due to inevitable defects and purity issues in the real world, which may reduce
their effectiveness in practical applications. To address these challenges, we
propose Darwin 1.5, an open-source large language model (LLM) tailored for
materials science. By leveraging natural language as input, Darwin eliminates
the need for task-specific descriptors and enables a flexible, unified approach
to material property prediction and discovery. We employ a two-stage training
strategy combining question-answering (QA) fine-tuning with multi-task learning
(MTL) to inject domain-specific knowledge in various modalities and facilitate
cross-task knowledge transfer. Through our strategic approach, we achieved a
significant enhancement in the prediction accuracy of LLMs, with a maximum
improvement of 60\% compared to LLaMA-7B base models. It further outperforms
traditional machine learning models on various tasks in material science,
showcasing the potential of LLMs to provide a more versatile and scalable
foundation model for materials discovery and design.",2024-12-16,"Tong Xie, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Wenjie Zhang, Chunyu Kit, Dongzhan Zhou, Bram Hoex"
"A Digital twin for Diesel Engines: Operator-infused PINNs with Transfer
  Learning for Engine Health Monitoring","Improving diesel engine efficiency and emission reduction have been critical
research topics. Recent government regulations have shifted this focus to
another important area related to engine health and performance monitoring.
Although the advancements in the use of deep learning methods for system
monitoring have shown promising results in this direction, designing efficient
methods suitable for field systems remains an open research challenge. The
objective of this study is to develop a computationally efficient neural
network-based approach for identifying unknown parameters of a mean value
diesel engine model to facilitate physics-based health monitoring and
maintenance forecasting. We propose a hybrid method combining physics informed
neural networks, PINNs, and a deep neural operator, DeepONet to predict unknown
parameters and gas flow dynamics in a diesel engine. The operator network
predicts independent actuator dynamics learnt through offline training, thereby
reducing the PINNs online computational cost. To address PINNs need for
retraining with changing input scenarios, we propose two transfer learning (TL)
strategies. The first strategy involves multi-stage transfer learning for
parameter identification. While this method is computationally efficient as
compared to online PINN training, improvements are required to meet field
requirements. The second TL strategy focuses solely on training the output
weights and biases of a subset of multi-head networks pretrained on a larger
dataset, substantially reducing computation time during online prediction. We
also evaluate our model for epistemic and aleatoric uncertainty by
incorporating dropout in pretrained networks and Gaussian noise in the training
dataset. This strategy offers a tailored, computationally inexpensive, and
physics-based approach for parameter identification in diesel engine sub
systems.",2024-12-16,"Kamaljyoti Nath, Varun Kumar, Daniel J. Smith, George Em Karniadakis"
Inferring Functionality of Attention Heads from their Parameters,"Attention heads are one of the building blocks of large language models
(LLMs). Prior work on investigating their operation mostly focused on analyzing
their behavior during inference for specific circuits or tasks. In this work,
we seek a comprehensive mapping of the operations they implement in a model. We
propose MAPS (Mapping Attention head ParameterS), an efficient framework that
infers the functionality of attention heads from their parameters, without any
model training or inference. We showcase the utility of MAPS for answering two
types of questions: (a) given a predefined operation, mapping how strongly
heads across the model implement it, and (b) given an attention head, inferring
its salient functionality. Evaluating MAPS on 20 operations across 6 popular
LLMs shows its estimations correlate with the head's outputs during inference
and are causally linked to the model's predictions. Moreover, its mappings
reveal attention heads of certain operations that were overlooked in previous
studies, and valuable insights on function universality and architecture biases
in LLMs. Next, we present an automatic pipeline and analysis that leverage MAPS
to characterize the salient operations of a given head. Our pipeline produces
plausible operation descriptions for most heads, as assessed by human judgment,
while revealing diverse operations.",2024-12-16,"Amit Elhelo, Mor Geva"
Approximating the Top Eigenvector in Random Order Streams,"When rows of an $n \times d$ matrix $A$ are given in a stream, we study
algorithms for approximating the top eigenvector of the matrix ${A}^TA$
(equivalently, the top right singular vector of $A$). We consider worst case
inputs $A$ but assume that the rows are presented to the streaming algorithm in
a uniformly random order. We show that when the gap parameter $R =
\sigma_1(A)^2/\sigma_2(A)^2 = \Omega(1)$, then there is a randomized algorithm
that uses $O(h \cdot d \cdot \operatorname{polylog}(d))$ bits of space and
outputs a unit vector $v$ that has a correlation $1 - O(1/\sqrt{R})$ with the
top eigenvector $v_1$. Here $h$ denotes the number of \emph{heavy rows} in the
matrix, defined as the rows with Euclidean norm at least $\|{A}\|_F/\sqrt{d
\cdot \operatorname{polylog}(d)}$. We also provide a lower bound showing that
any algorithm using $O(hd/R)$ bits of space can obtain at most $1 -
\Omega(1/R^2)$ correlation with the top eigenvector. Thus, parameterizing the
space complexity in terms of the number of heavy rows is necessary for high
accuracy solutions.
  Our results improve upon the $R = \Omega(\log n \cdot \log d)$ requirement in
a recent work of Price and Xun (FOCS 2024). We note that the algorithm of Price
and Xun works for arbitrary order streams whereas our algorithm requires a
stronger assumption that the rows are presented in a uniformly random order. We
additionally show that the gap requirements in their analysis can be brought
down to $R = \Omega(\log^2 d)$ for arbitrary order streams and $R = \Omega(\log
d)$ for random order streams. The requirement of $R = \Omega(\log d)$ for
random order streams is nearly tight for their analysis as we obtain a simple
instance with $R = \Omega(\log d/\log\log d)$ for which their algorithm, with
any fixed learning rate, cannot output a vector approximating the top
eigenvector $v_1$.",2024-12-16,"Praneeth Kacham, David P. Woodruff"
Gramian Multimodal Representation Learning and Alignment,"Human perception integrates multiple modalities, such as vision, hearing, and
language, into a unified understanding of the surrounding reality. While recent
multimodal models have achieved significant progress by aligning pairs of
modalities via contrastive learning, their solutions are unsuitable when
scaling to multiple modalities. These models typically align each modality to a
designated anchor without ensuring the alignment of all modalities with each
other, leading to suboptimal performance in tasks requiring a joint
understanding of multiple modalities. In this paper, we structurally rethink
the pairwise conventional approach to multimodal learning and we present the
novel Gramian Representation Alignment Measure (GRAM), which overcomes the
above-mentioned limitations. GRAM learns and then aligns $n$ modalities
directly in the higher-dimensional space in which modality embeddings lie by
minimizing the Gramian volume of the $k$-dimensional parallelotope spanned by
the modality vectors, ensuring the geometric alignment of all modalities
simultaneously. GRAM can replace cosine similarity in any downstream method,
holding for 2 to $n$ modality and providing more meaningful alignment with
respect to previous similarity measures. The novel GRAM-based contrastive loss
function enhances the alignment of multimodal models in the higher-dimensional
embedding space, leading to new state-of-the-art performance in downstream
tasks such as video-audio-text retrieval and audio-video classification. The
project page, the code, and the pretrained models are available at
https://ispamm.github.io/GRAM/.",2024-12-16,"Giordano Cicchetti, Eleonora Grassucci, Luigi Sigillo, Danilo Comminiello"
"Reliable Breast Cancer Molecular Subtype Prediction based on
  uncertainty-aware Bayesian Deep Learning by Mammography","Breast cancer is a heterogeneous disease with different molecular subtypes,
clinical behavior, treatment responses as well as survival outcomes. The
development of a reliable, accurate, available and inexpensive method to
predict the molecular subtypes using medical images plays an important role in
the diagnosis and prognosis of breast cancer. Recently, deep learning methods
have shown good performance in the breast cancer classification tasks using
various medical images. Despite all that success, classical deep learning
cannot deliver the predictive uncertainty. The uncertainty represents the
validity of the predictions.Therefore, the high predicted uncertainty might
cause a negative effect in the accurate diagnosis of breast cancer molecular
subtypes. To overcome this, uncertainty quantification methods are used to
determine the predictive uncertainty. Accordingly, in this study, we proposed
an uncertainty-aware Bayesian deep learning model using the full mammogram
images. In addition, to increase the performance of the multi-class molecular
subtype classification task, we proposed a novel hierarchical classification
strategy, named the two-stage classification strategy. The separate AUC of the
proposed model for each subtype was 0.71, 0.75 and 0.86 for HER2-enriched,
luminal and triple-negative classes, respectively. The proposed model not only
has a comparable performance to other studies in the field of breast cancer
molecular subtypes prediction, even using full mammography images, but it is
also more reliable, due to quantify the predictive uncertainty.",2024-12-16,"Mohaddeseh Chegini, Ali Mahloojifar"
"Coconut Palm Tree Counting on Drone Images with Deep Object Detection
  and Synthetic Training Data","Drones have revolutionized various domains, including agriculture. Recent
advances in deep learning have propelled among other things object detection in
computer vision. This study utilized YOLO, a real-time object detector, to
identify and count coconut palm trees in Ghanaian farm drone footage. The farm
presented has lost track of its trees due to different planting phases. While
manual counting would be very tedious and error-prone, accurately determining
the number of trees is crucial for efficient planning and management of
agricultural processes, especially for optimizing yields and predicting
production. We assessed YOLO for palm detection within a semi-automated
framework, evaluated accuracy augmentations, and pondered its potential for
farmers. Data was captured in September 2022 via drones. To optimize YOLO with
scarce data, synthetic images were created for model training and validation.
The YOLOv7 model, pretrained on the COCO dataset (excluding coconut palms), was
adapted using tailored data. Trees from footage were repositioned on synthetic
images, with testing on distinct authentic images. In our experiments, we
adjusted hyperparameters, improving YOLO's mean average precision (mAP). We
also tested various altitudes to determine the best drone height. From an
initial mAP@.5 of $0.65$, we achieved 0.88, highlighting the value of synthetic
images in agricultural scenarios.",2024-12-16,"Tobias Rohe, Barbara Böhm, Michael Kölle, Jonas Stein, Robert Müller, Claudia Linnhoff-Popien"
Precise Length Control in Large Language Models,"Large Language Models (LLMs) are increasingly used in production systems,
powering applications such as chatbots, summarization, and question answering.
Despite their success, controlling the length of their response remains a
significant challenge, particularly for tasks requiring structured outputs or
specific levels of detail. In this work, we propose a method to adapt
pre-trained decoder-only LLMs for precise control of response length. Our
approach incorporates a secondary length-difference positional encoding (LDPE)
into the input embeddings, which counts down to a user-set response termination
length. Fine-tuning with LDPE allows the model to learn to terminate responses
coherently at the desired length, achieving mean token errors of less than 3
tokens. We also introduce Max New Tokens++, an extension that enables flexible
upper-bound length control, rather than an exact target. Experimental results
on tasks such as question answering and document summarization demonstrate that
our method enables precise length control without compromising response
quality.",2024-12-16,"Bradley Butcher, Michael O'Keefe, James Titchener"
Stepwise Reasoning Error Disruption Attack of LLMs,"Large language models (LLMs) have made remarkable strides in complex
reasoning tasks, but their safety and robustness in reasoning processes remain
underexplored. Existing attacks on LLM reasoning are constrained by specific
settings or lack of imperceptibility, limiting their feasibility and
generalizability. To address these challenges, we propose the Stepwise
rEasoning Error Disruption (SEED) attack, which subtly injects errors into
prior reasoning steps to mislead the model into producing incorrect subsequent
reasoning and final answers. Unlike previous methods, SEED is compatible with
zero-shot and few-shot settings, maintains the natural reasoning flow, and
ensures covert execution without modifying the instruction. Extensive
experiments on four datasets across four different models demonstrate SEED's
effectiveness, revealing the vulnerabilities of LLMs to disruptions in
reasoning processes. These findings underscore the need for greater attention
to the robustness of LLM reasoning to ensure safety in practical applications.",2024-12-16,"Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu"
"RetroLLM: Empowering Large Language Models to Retrieve Fine-grained
  Evidence within Generation","Large language models (LLMs) exhibit remarkable generative capabilities but
often suffer from hallucinations. Retrieval-augmented generation (RAG) offers
an effective solution by incorporating external knowledge, but existing methods
still face several limitations: additional deployment costs of separate
retrievers, redundant input tokens from retrieved text chunks, and the lack of
joint optimization of retrieval and generation. To address these issues, we
propose \textbf{RetroLLM}, a unified framework that integrates retrieval and
generation into a single, cohesive process, enabling LLMs to directly generate
fine-grained evidence from the corpus with constrained decoding. Moreover, to
mitigate false pruning in the process of constrained evidence generation, we
introduce (1) hierarchical FM-Index constraints, which generate
corpus-constrained clues to identify a subset of relevant documents before
evidence generation, reducing irrelevant decoding space; and (2) a
forward-looking constrained decoding strategy, which considers the relevance of
future sequences to improve evidence accuracy. Extensive experiments on five
open-domain QA datasets demonstrate RetroLLM's superior performance across both
in-domain and out-of-domain tasks. The code is available at
\url{https://github.com/sunnynexus/RetroLLM}.",2024-12-16,"Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou"
PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension,"Multimodal punchlines, which involve humor or sarcasm conveyed in
image-caption pairs, are a popular way of communication on online multimedia
platforms. With the rapid development of multimodal large language models
(MLLMs), it is essential to assess their ability to effectively comprehend
these punchlines. However, existing benchmarks on punchline comprehension
suffer from three major limitations: 1) language shortcuts that allow models to
solely rely on text, 2) lack of question diversity, and 3) narrow focus on a
specific domain of multimodal content (e.g., cartoon). To address these
limitations, we introduce a multimodal \textbf{Punch}line comprehension
\textbf{Bench}mark, named \textbf{PunchBench}, which is tailored for accurate
and comprehensive evaluation of punchline comprehension. To enhance the
evaluation accuracy, we generate synonymous and antonymous captions by
modifying original captions, which mitigates the impact of shortcuts in the
captions. To provide a comprehensive evaluation, PunchBench incorporates
diverse question formats and image-captions from various domains. On this
basis, we conduct extensive evaluations and reveal a significant gap between
state-of-the-art MLLMs and humans in punchline comprehension. To improve
punchline comprehension, we propose Simple-to-Complex Chain-of-Question
(SC-CoQ) strategy, enabling the models to incrementally address complicated
questions by first mastering simple ones. SC-CoQ effectively enhances the
performance of various MLLMs on PunchBench, surpassing in-context learning and
chain-of-thought.",2024-12-16,"Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun"
"Probabilistic Behavioral Aggregation: A Case Study on the Nordic Power
  Grid","This study applies the Probabilistic Behavioral Tuning (ProBeTune) framework
to transient power grid simulations to address challenges posed by increasing
grid complexity. ProBeTune offers a probabilistic approach to model
aggregation, using a behavioral distance measure to quantify and minimize
discrepancies between a full-scale system and a simplified model. We
demonstrate the effectiveness of ProBeTune on the Nordic5 (N5) test case, a
model representing the Nordic power grid with complex nodal dynamics and a high
share of RESs. We substantially reduce the complexity of the dynamics by tuning
the system to align with a reduced swing-equation model. We confirm the
validity of the swing equation with tailored controllers and parameter
distributions for capturing the essential dynamics of the Nordic region. This
reduction could allow interconnected systems like the Central European power
grid to treat the Nordic grid as a single dynamic actor, facilitating more
manageable stability assessments. The findings lay the groundwork for future
research on applying ProBeTune to microgrids and other complex sub-systems,
aiming to enhance scalability and accuracy in power grid modeling amidst rising
complexity.",2024-12-16,"Anna Büttner, Frank Hellmann"
"SegMAN: Omni-scale Context Modeling with State Space Models and Local
  Attention for Semantic Segmentation","High-quality semantic segmentation relies on three key capabilities: global
context modeling, local detail encoding, and multi-scale feature extraction.
However, recent methods struggle to possess all these capabilities
simultaneously. Hence, we aim to empower segmentation networks to
simultaneously carry out efficient global context modeling, high-quality local
detail encoding, and rich multi-scale feature representation for varying input
resolutions. In this paper, we introduce SegMAN, a novel linear-time model
comprising a hybrid feature encoder dubbed SegMAN Encoder, and a decoder based
on state space models. Specifically, the SegMAN Encoder synergistically
integrates sliding local attention with dynamic state space models, enabling
highly efficient global context modeling while preserving fine-grained local
details. Meanwhile, the MMSCopE module in our decoder enhances multi-scale
context feature extraction and adaptively scales with the input resolution. We
comprehensively evaluate SegMAN on three challenging datasets: ADE20K,
Cityscapes, and COCO-Stuff. For instance, SegMAN-B achieves 52.6% mIoU on
ADE20K, outperforming SegNeXt-L by 1.6% mIoU while reducing computational
complexity by over 15% GFLOPs. On Cityscapes, SegMAN-B attains 83.8% mIoU,
surpassing SegFormer-B3 by 2.1% mIoU with approximately half the GFLOPs.
Similarly, SegMAN-B improves upon VWFormer-B3 by 1.6% mIoU with lower GFLOPs on
the COCO-Stuff dataset. Our code is available at
https://github.com/yunxiangfu2001/SegMAN.",2024-12-16,"Yunxiang Fu, Meng Lou, Yizhou Yu"
"Using Instruction-Tuned Large Language Models to Identify Indicators of
  Vulnerability in Police Incident Narratives","Objectives: Compare qualitative coding of instruction tuned large language
models (IT-LLMs) against human coders in classifying the presence or absence of
vulnerability in routinely collected unstructured text that describes
police-public interactions. Evaluate potential bias in IT-LLM codings. Methods:
Analyzing publicly available text narratives of police-public interactions
recorded by Boston Police Department, we provide humans and IT-LLMs with
qualitative labelling codebooks and compare labels generated by both, seeking
to identify situations associated with (i) mental ill health; (ii) substance
misuse; (iii) alcohol dependence; and (iv) homelessness. We explore multiple
prompting strategies and model sizes, and the variability of labels generated
by repeated prompts. Additionally, to explore model bias, we utilize
counterfactual methods to assess the impact of two protected characteristics -
race and gender - on IT-LLM classification. Results: Results demonstrate that
IT-LLMs can effectively support human qualitative coding of police incident
narratives. While there is some disagreement between LLM and human generated
labels, IT-LLMs are highly effective at screening narratives where no
vulnerabilities are present, potentially vastly reducing the requirement for
human coding. Counterfactual analyses demonstrate that manipulations to both
gender and race of individuals described in narratives have very limited
effects on IT-LLM classifications beyond those expected by chance. Conclusions:
IT-LLMs offer effective means to augment human qualitative coding in a way that
requires much lower levels of resource to analyze large unstructured datasets.
Moreover, they encourage specificity in qualitative coding, promote
transparency, and provide the opportunity for more standardized, replicable
approaches to analyzing large free-text police data sources.",2024-12-16,"Sam Relins, Daniel Birks, Charlie Lloyd"
"Automated Detection of Inter-Language Design Smells in Multi-Language
  Deep Learning Frameworks","Nowadays, most DL frameworks (DLFs) use multilingual programming of Python
and C/C++, facilitating the flexibility and performance of the DLF. However,
inappropriate interlanguage interaction may introduce design smells involving
multiple programming languages (PLs), i.e., Inter-Language Design Smells
(ILDS). Despite the negative impact of ILDS on multi-language DLFs, there is a
lack of an automated approach for detecting ILDS in multi-language DLFs and a
comprehensive understanding on ILDS in such DLFs. This work automatically
detects ILDS in multi-language DLFs written in the combination of Python and
C/C++, and to obtain a understanding on such ILDS in DLFs. We first developed
an approach to automatically detecting ILDS in the multi-language DLFs written
in the combination of Python and C/C++, including a number of ILDS and their
detection rules defined based on inter-language communication mechanisms and
code analysis. We then developed the CPSMELL tool that implements detection
rules for automatically detecting such ILDS, and manually validated the
accuracy of the tool. Finally, we performed a study to evaluate the ILDS in
multi-language DLFs. We proposed seven ILDS and achieved an accuracy of 98.17%
in the manual validation of CPSMELL in 5 popular multi-language DLFs. The study
results revealed that among the 5 DLFs, TensorFlow, PyTorch, and PaddlePaddle
exhibit relatively high prevalence of ILDS; each smelly file contains around 5
ILDS instances on average, with ILDS Long Lambda Function For Inter-language
Binding and Unused Native Entity being relatively prominent; throughout the
evolution process of the 5 DLFs, some ILDS were resolved to a certain extent,
but the overall count of ILDS instances shows an upward trend. The automated
detection of the proposed ILDS achieved a high accuracy, and the study provides
a comprehensive understanding on ILDS in the multi-language DLFs.",2024-12-16,"Zengyang Li, Xiaoyong Zhang, Wenshuo Wang, Peng Liang, Ran Mo, Jie Tan, Hui Liu"
Transformers Use Causal World Models in Maze-Solving Tasks,"Recent studies in interpretability have explored the inner workings of
transformer models trained on tasks across various domains, often discovering
that these networks naturally develop surprisingly structured representations.
When such representations comprehensively reflect the task domain's structure,
they are commonly referred to as ``World Models'' (WMs). In this work, we
discover such WMs in transformers trained on maze tasks. In particular, by
employing Sparse Autoencoders (SAEs) and analysing attention patterns, we
examine the construction of WMs and demonstrate consistency between the circuit
analysis and the SAE feature-based analysis. We intervene upon the isolated
features to confirm their causal role and, in doing so, find asymmetries
between certain types of interventions. Surprisingly, we find that models are
able to reason with respect to a greater number of active features than they
see during training, even if attempting to specify these in the input token
sequence would lead the model to fail. Futhermore, we observe that varying
positional encodings can alter how WMs are encoded in a model's residual
stream. By analyzing the causal role of these WMs in a toy domain we hope to
make progress toward an understanding of emergent structure in the
representations acquired by Transformers, leading to the development of more
interpretable and controllable AI systems.",2024-12-16,"Alex F. Spies, William Edwards, Michael I. Ivanitskiy, Adrians Skapars, Tilman Räuker, Katsumi Inoue, Alessandra Russo, Murray Shanahan"
"Towards Understanding Systems Trade-offs in Retrieval-Augmented
  Generation Model Inference","The rapid increase in the number of parameters in large language models
(LLMs) has significantly increased the cost involved in fine-tuning and
retraining LLMs, a necessity for keeping models up to date and improving
accuracy. Retrieval-Augmented Generation (RAG) offers a promising approach to
improving the capabilities and accuracy of LLMs without the necessity of
retraining. Although RAG eliminates the need for continuous retraining to
update model data, it incurs a trade-off in the form of slower model inference
times. Resultingly, the use of RAG in enhancing the accuracy and capabilities
of LLMs often involves diverse performance implications and trade-offs based on
its design. In an effort to begin tackling and mitigating the performance
penalties associated with RAG from a systems perspective, this paper introduces
a detailed taxonomy and characterization of the different elements within the
RAG ecosystem for LLMs that explore trade-offs within latency, throughput, and
memory. Our study reveals underlying inefficiencies in RAG for systems
deployment, that can result in TTFT latencies that are twice as long and
unoptimized datastores that consume terabytes of storage.",2024-12-16,"Michael Shen, Muhammad Umar, Kiwan Maeng, G. Edward Suh, Udit Gupta"
"UnMA-CapSumT: Unified and Multi-Head Attention-driven Caption
  Summarization Transformer","Image captioning is the generation of natural language descriptions of images
which have increased immense popularity in the recent past. With this different
deep-learning techniques are devised for the development of factual and
stylized image captioning models. Previous models focused more on the
generation of factual and stylized captions separately providing more than one
caption for a single image. The descriptions generated from these suffer from
out-of-vocabulary and repetition issues. To the best of our knowledge, no such
work exists that provided a description that integrates different captioning
methods to describe the contents of an image with factual and stylized
(romantic and humorous) elements. To overcome these limitations, this paper
presents a novel Unified Attention and Multi-Head Attention-driven Caption
Summarization Transformer (UnMA-CapSumT) based Captioning Framework. It
utilizes both factual captions and stylized captions generated by the Modified
Adaptive Attention-based factual image captioning model (MAA-FIC) and Style
Factored Bi-LSTM with attention (SF-Bi-ALSTM) driven stylized image captioning
model respectively. SF-Bi-ALSTM-based stylized IC model generates two prominent
styles of expression- {romance, and humor}. The proposed summarizer UnMHA-ST
combines both factual and stylized descriptions of an input image to generate
styled rich coherent summarized captions. The proposed UnMHA-ST transformer
learns and summarizes different linguistic styles efficiently by incorporating
proposed word embedding fastText with Attention Word Embedding (fTA-WE) and
pointer-generator network with coverage mechanism concept to solve the
out-of-vocabulary issues and repetition problem. Extensive experiments are
conducted on Flickr8K and a subset of FlickrStyle10K with supporting ablation
studies to prove the efficiency and efficacy of the proposed framework.",2024-12-16,"Dhruv Sharma, Chhavi Dhiman, Dinesh Kumar"
"Are You Doubtful? Oh, It Might Be Difficult Then! Exploring the Use of
  Model Uncertainty for Question Difficulty Estimation","In an educational setting, an estimate of the difficulty of multiple-choice
questions (MCQs), a commonly used strategy to assess learning progress,
constitutes very useful information for both teachers and students. Since human
assessment is costly from multiple points of view, automatic approaches to MCQ
item difficulty estimation are investigated, yielding however mixed success
until now. Our approach to this problem takes a different angle from previous
work: asking various Large Language Models to tackle the questions included in
two different MCQ datasets, we leverage model uncertainty to estimate item
difficulty. By using both model uncertainty features as well as textual
features in a Random Forest regressor, we show that uncertainty features
contribute substantially to difficulty prediction, where difficulty is
inversely proportional to the number of students who can correctly answer a
question. In addition to showing the value of our approach, we also observe
that our model achieves state-of-the-art results on the BEA publicly available
dataset.",2024-12-16,"Leonidas Zotos, Hedderik van Rijn, Malvina Nissim"
Robust Contact-rich Manipulation through Implicit Motor Adaptation,"Contact-rich manipulation plays a vital role in daily human activities, yet
uncertain physical parameters pose significant challenges for both model-based
and model-free planning and control. A promising approach to address this
challenge is to develop policies robust to a wide range of parameters. Domain
adaptation and domain randomization are commonly used to achieve such policies
but often compromise generalization to new instances or perform conservatively
due to neglecting instance-specific information. \textit{Explicit motor
adaptation} addresses these issues by estimating system parameters online and
then retrieving the parameter-conditioned policy from a parameter-augmented
base policy. However, it typically relies on precise system identification or
additional high-quality policy retraining, presenting substantial challenges
for contact-rich tasks with diverse physical parameters. In this work, we
propose \textit{implicit motor adaptation}, which leverages tensor
factorization as an implicit representation of the base policy. Given a roughly
estimated parameter distribution, the parameter-conditioned policy can be
efficiently derived by exploiting the separable structure of tensor cores from
the base policy. This framework eliminates the need for precise system
estimation and policy retraining while preserving optimal behavior and strong
generalization. We provide a theoretical analysis validating this method,
supported by numerical evaluations on three contact-rich manipulation
primitives. Both simulation and real-world experiments demonstrate its ability
to generate robust policies for diverse instances.",2024-12-16,"Teng Xue, Amirreza Razmjoo, Suhan Shetty, Sylvain Calinon"
"Uncovering Student Engagement Patterns in Moodle with Interpretable
  Machine Learning","Understanding and enhancing student engagement through digital platforms is
critical in higher education. This study introduces a methodology for
quantifying engagement across an entire module using virtual learning
environment (VLE) activity log data. Using study session frequency, immediacy,
and diversity, we create a cumulative engagement metric and model it against
weekly VLE interactions with resources to identify critical periods and
resources predictive of student engagement.
  In a case study of a computing module at University College London's
Department of Statistical Science, we further examine how delivery methods
(online, hybrid, in-person) impact student behaviour. Across nine regression
models, we validate the consistency of the random forest model and highlight
the interpretive strengths of generalised additive models for analysing
engagement patterns.
  Results show weekly VLE clicks as reliable engagement predictors, with early
weeks and the first assessment period being key. However, the impact of
delivery methods on engagement is inconclusive due to inconsistencies across
models. These findings support early intervention strategies to assist students
at risk of disengagement. This work contributes to learning analytics research
by proposing a refined VLE-based engagement metric and advancing data-driven
teaching strategies in higher education.",2024-12-16,"Laura J. Johnston, Jim E. Griffin, Ioanna Manolopoulou, Takoua Jendoubi"
You Only Submit One Image to Find the Most Suitable Generative Model,"Deep generative models have achieved promising results in image generation,
and various generative model hubs, e.g., Hugging Face and Civitai, have been
developed that enable model developers to upload models and users to download
models. However, these model hubs lack advanced model management and
identification mechanisms, resulting in users only searching for models through
text matching, download sorting, etc., making it difficult to efficiently find
the model that best meets user requirements. In this paper, we propose a novel
setting called Generative Model Identification (GMI), which aims to enable the
user to identify the most appropriate generative model(s) for the user's
requirements from a large number of candidate models efficiently. To our best
knowledge, it has not been studied yet. In this paper, we introduce a
comprehensive solution consisting of three pivotal modules: a weighted Reduced
Kernel Mean Embedding (RKME) framework for capturing the generated image
distribution and the relationship between images and prompts, a pre-trained
vision-language model aimed at addressing dimensionality challenges, and an
image interrogator designed to tackle cross-modality issues. Extensive
empirical results demonstrate the proposal is both efficient and effective. For
example, users only need to submit a single example image to describe their
requirements, and the model platform can achieve an average top-4
identification accuracy of more than 80%.",2024-12-16,"Zhi Zhou, Lan-Zhe Guo, Peng-Xiao Song, Yu-Feng Li"
"HiGDA: Hierarchical Graph of Nodes to Learn Local-to-Global Topology for
  Semi-Supervised Domain Adaptation","The enhanced representational power and broad applicability of deep learning
models have attracted significant interest from the research community in
recent years. However, these models often struggle to perform effectively under
domain shift conditions, where the training data (the source domain) is related
to but exhibits different distributions from the testing data (the target
domain). To address this challenge, previous studies have attempted to reduce
the domain gap between source and target data by incorporating a few labeled
target samples during training - a technique known as semi-supervised domain
adaptation (SSDA). While this strategy has demonstrated notable improvements in
classification performance, the network architectures used in these approaches
primarily focus on exploiting the features of individual images, leaving room
for improvement in capturing rich representations. In this study, we introduce
a Hierarchical Graph of Nodes designed to simultaneously present
representations at both feature and category levels. At the feature level, we
introduce a local graph to identify the most relevant patches within an image,
facilitating adaptability to defined main object representations. At the
category level, we employ a global graph to aggregate the features from samples
within the same category, thereby enriching overall representations. Extensive
experiments on widely used SSDA benchmark datasets, including Office-Home,
DomainNet, and VisDA2017, demonstrate that both quantitative and qualitative
results substantiate the effectiveness of HiGDA, establishing it as a new
state-of-the-art method.",2024-12-16,"Ba Hung Ngo, Doanh C. Bui, Nhat-Tuong Do-Tran, Tae Jong Choi"
ColorFlow: Retrieval-Augmented Image Sequence Colorization,"Automatic black-and-white image sequence colorization while preserving
character and object identity (ID) is a complex task with significant market
demand, such as in cartoon or comic series colorization. Despite advancements
in visual colorization using large-scale generative models like diffusion
models, challenges with controllability and identity consistency persist,
making current solutions unsuitable for industrial application.To address this,
we propose ColorFlow, a three-stage diffusion-based framework tailored for
image sequence colorization in industrial applications. Unlike existing methods
that require per-ID finetuning or explicit ID embedding extraction, we propose
a novel robust and generalizable Retrieval Augmented Colorization pipeline for
colorizing images with relevant color references. Our pipeline also features a
dual-branch design: one branch for color identity extraction and the other for
colorization, leveraging the strengths of diffusion models. We utilize the
self-attention mechanism in diffusion models for strong in-context learning and
color identity matching. To evaluate our model, we introduce ColorFlow-Bench, a
comprehensive benchmark for reference-based colorization. Results show that
ColorFlow outperforms existing models across multiple metrics, setting a new
standard in sequential image colorization and potentially benefiting the art
industry. We release our codes and models on our project page:
https://zhuang2002.github.io/ColorFlow/.",2024-12-16,"Junhao Zhuang, Xuan Ju, Zhaoyang Zhang, Yong Liu, Shiyi Zhang, Chun Yuan, Ying Shan"
"EventSum: A Large-Scale Event-Centric Summarization Dataset for Chinese
  Multi-News Documents","In real life, many dynamic events, such as major disasters and large-scale
sports events, evolve continuously over time. Obtaining an overview of these
events can help people quickly understand the situation and respond more
effectively. This is challenging because the key information of the event is
often scattered across multiple documents, involving complex event knowledge
understanding and reasoning, which is under-explored in previous work.
Therefore, we proposed the Event-Centric Multi-Document Summarization (ECS)
task, which aims to generate concise and comprehensive summaries of a given
event based on multiple related news documents. Based on this, we constructed
the EventSum dataset, which was constructed using Baidu Baike entries and
underwent extensive human annotation, to facilitate relevant research. It is
the first large scale Chinese multi-document summarization dataset, containing
5,100 events and a total of 57,984 news documents, with an average of 11.4
input news documents and 13,471 characters per event. To ensure data quality
and mitigate potential data leakage, we adopted a multi-stage annotation
approach for manually labeling the test set. Given the complexity of
event-related information, existing metrics struggle to comprehensively assess
the quality of generated summaries. We designed specific metrics including
Event Recall, Argument Recall, Causal Recall, and Temporal Recall along with
corresponding calculation methods for evaluation. We conducted comprehensive
experiments on EventSum to evaluate the performance of advanced long-context
Large Language Models (LLMs) on this task. Our experimental results indicate
that: 1) The event-centric multi-document summarization task remains
challenging for existing long-context LLMs; 2) The recall metrics we designed
are crucial for evaluating the comprehensiveness of the summary information.",2024-12-16,"Mengna Zhu, Kaisheng Zeng, Mao Wang, Kaiming Xiao, Lei Hou, Hongbin Huang, Juanzi Li"
"Designing Semi-Structured Pruning of Graph Convolutional Networks for
  Skeleton-based Recognition","Deep neural networks (DNNs) are nowadays witnessing a major success in
solving many pattern recognition tasks including skeleton-based classification.
The deployment of DNNs on edge-devices, endowed with limited time and memory
resources, requires designing lightweight and efficient variants of these
networks. Pruning is one of the lightweight network design techniques that
operate by removing unnecessary network parts, in a structured or an
unstructured manner, including individual weights, neurons or even entire
channels. Nonetheless, structured and unstructured pruning methods, when
applied separately, may either be inefficient or ineffective. In this paper, we
devise a novel semi-structured method that discards the downsides of structured
and unstructured pruning while gathering their upsides to some extent. The
proposed solution is based on a differentiable cascaded parametrization which
combines (i) a band-stop mechanism that prunes weights depending on their
magnitudes, (ii) a weight-sharing parametrization that prunes connections
either individually or group-wise, and (iii) a gating mechanism which
arbitrates between different group-wise and entry-wise pruning. All these
cascaded parametrizations are built upon a common latent tensor which is
trained end-to-end by minimizing a classification loss and a surrogate tensor
rank regularizer. Extensive experiments, conducted on the challenging tasks of
action and hand-gesture recognition, show the clear advantage of our proposed
semi-structured pruning approach against both structured and unstructured
pruning, when taken separately, as well as the related work.",2024-12-16,Hichem Sahbi
SAT-Based Search for Minwise Independent Families,"Proposed for rapid document similarity estimation in web search engines, the
celebrated property of minwise independence imposes highly symmetric
constraints on a family $\mathcal{F}$ of permutations of $\{1,\ldots, n\}$: The
property is fulfilled by $\mathcal{F}$ if for each $j\in \{1,\ldots,n\}$, any
cardinality-$j$ subset $X\subseteq \{1,\ldots,n\}$, and any fixed element
$x^\ast\in X$, it occurs with probability $1/j$ that a randomly drawn
permutation $\pi$ from $\mathcal{F}$ satisfies $\pi(x^\ast)=\min \{\pi(x) :
x\in X\}$. The central interest is to find a family with fewest possible
members meeting the stated constraints. We provide a framework that, firstly,
is realized as a pure SAT model and, secondly, generalizes a heuristic of
Mathon and van Trung to the search of these families. Originally, the latter
enforces an underlying group-theoretic decomposition to achieve a significant
speed-up for the computer-aided search of structures which can be identified
with so-called rankwise independent families. We observe that this approach is
suitable to find provenly optimal new representatives of minwise independent
families while yielding a decisive speed-up, too. As the problem has a naive
search space of size at least $(n!)^n$, we also carefully address symmetry
breaking. Finally, we add a bijective proof for a problem encountered by
Bargachev when deriving a lower bound on the number of members in a minimal
rankwise independent family.",2024-12-16,"Enrico Iurlano, Günther R. Raidl"
"A priori and a posteriori analysis of the discontinuous Galerkin
  approximation of the time-harmonic Maxwell's equations under minimal
  regularity assumptions","We derive a priori and a posteriori error estimates for the discontinuous
Galerkin (dG) approximation of the time-harmonic Maxwell's equations.
Specifically, we consider an interior penalty dG method, and establish error
estimates that are valid under minimal regularity assumptions and involving
constants that do not depend on the frequency for sufficiently fine meshes. The
key result of our a priori error analysis is that the dG solution is
asymptotically optimal in an augmented energy norm that contains the dG
stabilization. Specifically, up to a constant that tends to one as the mesh is
refined, the dG solution is as accurate as the best approximation in the same
norm. The main insight is that the quantities controlling the smallness of the
mesh size are essentially those already appearing in the conforming setting. We
also show that for fine meshes, the inf-sup stability constant is as good as
the continuous one up to a factor two. Concerning the a posteriori analysis, we
consider a residual-based error estimator under the assumption of piecewise
constant material properties. We derive a global upper bound and local lower
bounds on the error with constants that (i) only depend on the shape-regularity
of the mesh if it is sufficiently refined and (ii) are independent of the
stabilization bilinear form.",2024-12-16,"T. Chaumont-Frelet, A. Ern"
"ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible
  Speech Synthesis","Prosody contains rich information beyond the literal meaning of words, which
is crucial for the intelligibility of speech. Current models still fall short
in phrasing and intonation; they not only miss or misplace breaks when
synthesizing long sentences with complex structures but also produce unnatural
intonation. We propose ProsodyFM, a prosody-aware text-to-speech synthesis
(TTS) model with a flow-matching (FM) backbone that aims to enhance the
phrasing and intonation aspects of prosody. ProsodyFM introduces two key
components: a Phrase Break Encoder to capture initial phrase break locations,
followed by a Duration Predictor for the flexible adjustment of break
durations; and a Terminal Intonation Encoder which integrates a set of
intonation shape tokens combined with a novel Pitch Processor for more robust
modeling of human-perceived intonation change. ProsodyFM is trained with no
explicit prosodic labels and yet can uncover a broad spectrum of break
durations and intonation patterns. Experimental results demonstrate that
ProsodyFM can effectively improve the phrasing and intonation aspects of
prosody, thereby enhancing the overall intelligibility compared to four
state-of-the-art (SOTA) models. Out-of-distribution experiments show that this
prosody improvement can further bring ProsodyFM superior generalizability for
unseen complex sentences and speakers. Our case study intuitively illustrates
the powerful and fine-grained controllability of ProsodyFM over phrasing and
intonation.",2024-12-16,"Xiangheng He, Junjie Chen, Zixing Zhang, Björn W. Schuller"
The Black Ninjas and the Sniper: On Robustness of Population Protocols,"Population protocols are a model of distributed computation in which an
arbitrary number of indistinguishable finite-state agents interact in pairs to
decide some property of their initial configuration. We investigate the
behaviour of population protocols under adversarial faults that cause agents to
silently crash and no longer interact with other agents. As a starting point,
we consider the property ``the number of agents exceeds a given threshold
$t$'', represented by the predicate $x \geq t$, and show that the standard
protocol for $x \geq t$ is very fragile: one single crash in a computation with
$x:=2t-1$ agents can already cause the protocol to answer incorrectly that $x
\geq t$ does not hold. However, a slightly less known protocol is robust: for
any number $t' \geq t$ of agents, at least $t' - t+1$ crashes must occur for
the protocol to answer that the property does not hold.
  We formally define robustness for arbitrary population protocols, and
investigate the question whether every predicate computable by population
protocols has a robust protocol. Angluin et al. proved in 2007 that population
protocols decide exactly the Presburger predicates, which can be represented as
Boolean combinations of threshold predicates of the form $\sum_{i=1}^n a_i
\cdot x_i \geq t$ for $a_1,...,a_n, t \in \mathbb{Z}$ and modulo prdicates of
the form $\sum_{i=1}^n a_i \cdot x_i \bmod m \geq t $ for $a_1, \ldots, a_n, m,
t \in \mathbb{N}$. We design robust protocols for all threshold and modulo
predicates. We also show that, unfortunately, the techniques in the literature
that construct a protocol for a Boolean combination of predicates given
protocols for the conjuncts do not preserve robustness. So the question remains
open.",2024-12-16,"Benno Lossin, Philipp Czerner, Javier Esparza, Roland Guttenberg, Tobias Prehn"
"Fast and Slow Gradient Approximation for Binary Neural Network
  Optimization","Binary Neural Networks (BNNs) have garnered significant attention due to
their immense potential for deployment on edge devices. However, the
non-differentiability of the quantization function poses a challenge for the
optimization of BNNs, as its derivative cannot be backpropagated. To address
this issue, hypernetwork based methods, which utilize neural networks to learn
the gradients of non-differentiable quantization functions, have emerged as a
promising approach due to their adaptive learning capabilities to reduce
estimation errors. However, existing hypernetwork based methods typically rely
solely on current gradient information, neglecting the influence of historical
gradients. This oversight can lead to accumulated gradient errors when
calculating gradient momentum during optimization. To incorporate historical
gradient information, we design a Historical Gradient Storage (HGS) module,
which models the historical gradient sequence to generate the first-order
momentum required for optimization. To further enhance gradient generation in
hypernetworks, we propose a Fast and Slow Gradient Generation (FSG) method.
Additionally, to produce more precise gradients, we introduce Layer Recognition
Embeddings (LRE) into the hypernetwork, facilitating the generation of
layer-specific fine gradients. Extensive comparative experiments on the
CIFAR-10 and CIFAR-100 datasets demonstrate that our method achieves faster
convergence and lower loss values, outperforming existing baselines.Code is
available at http://github.com/two-tiger/FSG .",2024-12-16,"Xinquan Chen, Junqi Gao, Biqing Qi, Dong Li, Yiang Luo, Fangyuan Li, Pengfei Li"
"Does it Chug? Towards a Data-Driven Understanding of Guitar Tone
  Description","Natural language is commonly used to describe instrument timbre, such as a
""warm"" or ""heavy"" sound. As these descriptors are based on human perception,
there can be disagreement over which acoustic features correspond to a given
adjective. In this work, we pursue a data-driven approach to further our
understanding of such adjectives in the context of guitar tone. Our main
contribution is a dataset of timbre adjectives, constructed by processing
single clips of instrument audio to produce varied timbres through adjustments
in EQ and effects such as distortion. Adjective annotations are obtained for
each clip by crowdsourcing experts to complete a pairwise comparison and a
labeling task. We examine the dataset and reveal correlations between adjective
ratings and highlight instances where the data contradicts prevailing theories
on spectral features and timbral adjectives, suggesting a need for a more
nuanced, data-driven understanding of timbre.",2024-12-16,"Pratik Sutar, Jason Naradowsky, Yusuke Miyao"
"What Matters in Learning A Zero-Shot Sim-to-Real RL Policy for Quadrotor
  Control? A Comprehensive Study","Executing precise and agile flight maneuvers is critical for quadrotors in
various applications. Traditional quadrotor control approaches are limited by
their reliance on flat trajectories or time-consuming optimization, which
restricts their flexibility. Recently, RL-based policy has emerged as a
promising alternative due to its ability to directly map observations to
actions, reducing the need for detailed system knowledge and actuation
constraints. However, a significant challenge remains in bridging the
sim-to-real gap, where RL-based policies often experience instability when
deployed in real world. In this paper, we investigate key factors for learning
robust RL-based control policies that are capable of zero-shot deployment in
real-world quadrotors. We identify five critical factors and we develop a
PPO-based training framework named SimpleFlight, which integrates these five
techniques. We validate the efficacy of SimpleFlight on Crazyflie quadrotor,
demonstrating that it achieves more than a 50% reduction in trajectory tracking
error compared to state-of-the-art RL baselines, and achieves 70% improvement
over the traditional MPC. The policy derived by SimpleFlight consistently
excels across both smooth polynominal trajectories and challenging infeasible
zigzag trajectories on small thrust-to-weight quadrotors. In contrast, baseline
methods struggle with high-speed or infeasible trajectories. To support further
research and reproducibility, we integrate SimpleFlight into a GPU-based
simulator Omnidrones and provide open-source access to the code and model
checkpoints. We hope SimpleFlight will offer valuable insights for advancing
RL-based quadrotor control. For more details, visit our project website at
https://sites.google.com/view/simpleflight/.",2024-12-16,"Jiayu Chen, Chao Yu, Yuqing Xie, Feng Gao, Yinuo Chen, Shu'ang Yu, Wenhao Tang, Shilong Ji, Mo Mu, Yi Wu, Huazhong Yang, Yu Wang"
"Establishing a Foundation for Tetun Text Ad-Hoc Retrieval: Indexing,
  Stemming, Retrieval, and Ranking","Searching for information on the internet and digital platforms to satisfy an
information need requires effective retrieval solutions. However, such
solutions are not yet available for Tetun, making it challenging to find
relevant documents for text-based search queries in this language. To address
these challenges, this study investigates Tetun text retrieval with a focus on
the ad-hoc retrieval task. It begins by developing essential language resources
-- including a list of stopwords, a stemmer, and a test collection -- which
serve as foundational components for solutions tailored to Tetun text
retrieval. Various strategies are then explored using both document titles and
content to evaluate retrieval effectiveness. The results show that retrieving
document titles, after removing hyphens and apostrophes without applying
stemming, significantly improves retrieval performance compared to the
baseline. Efficiency increases by 31.37%, while effectiveness achieves an
average gain of 9.40% in MAP@10 and 30.35% in nDCG@10 with DFR BM25. Beyond the
top-10 cutoff point, Hiemstra LM demonstrates strong performance across various
retrieval strategies and evaluation metrics. Contributions of this work include
the development of Labadain-Stopwords (a list of 160 Tetun stopwords),
Labadain-Stemmer (a Tetun stemmer with three variants), and
Labadain-Avaliad\'or (a Tetun test collection containing 59 topics, 33,550
documents, and 5,900 qrels).",2024-12-16,"Gabriel de Jesus, Sérgio Nunes"
"DriveGazen: Event-Based Driving Status Recognition using Conventional
  Camera","We introduce a wearable driving status recognition device and our open-source
dataset, along with a new real-time method robust to changes in lighting
conditions for identifying driving status from eye observations of drivers. The
core of our method is generating event frames from conventional intensity
frames, and the other is a newly designed Attention Driving State Network
(ADSN). Compared to event cameras, conventional cameras offer complete
information and lower hardware costs, enabling captured frames to encode rich
spatial information. However, these textures lack temporal information, posing
challenges in effectively identifying driving status. DriveGazen addresses this
issue from three perspectives. First, we utilize video frames to generate
realistic synthetic dynamic vision sensor (DVS) events. Second, we adopt a
spiking neural network to decode pertinent temporal information. Lastly, ADSN
extracts crucial spatial cues from corresponding intensity frames and conveys
spatial attention to convolutional spiking layers during both training and
inference through a novel guide attention module to guide the feature learning
and feature enhancement of the event frame. We specifically collected the
Driving Status (DriveGaze) dataset to demonstrate the effectiveness of our
approach. Additionally, we validate the superiority of the DriveGazen on the
Single-eye Event-based Emotion (SEE) dataset. To the best of our knowledge, our
method is the first to utilize guide attention spiking neural networks and
eye-based event frames generated from conventional cameras for driving status
recognition. Please refer to our project page for more details:
https://github.com/TooyoungALEX/AAAI25-DriveGazen.",2024-12-16,Xiaoyin Yang
"Common Ground, Diverse Roots: The Difficulty of Classifying Common
  Examples in Spanish Varieties","Variations in languages across geographic regions or cultures are crucial to
address to avoid biases in NLP systems designed for culturally sensitive tasks,
such as hate speech detection or dialog with conversational agents. In
languages such as Spanish, where varieties can significantly overlap, many
examples can be valid across them, which we refer to as common examples.
Ignoring these examples may cause misclassifications, reducing model accuracy
and fairness. Therefore, accounting for these common examples is essential to
improve the robustness and representativeness of NLP systems trained on such
data. In this work, we address this problem in the context of Spanish
varieties. We use training dynamics to automatically detect common examples or
errors in existing Spanish datasets. We demonstrate the efficacy of using
predicted label confidence for our Datamaps
\cite{swayamdipta-etal-2020-dataset} implementation for the identification of
hard-to-classify examples, especially common examples, enhancing model
performance in variety identification tasks. Additionally, we introduce a Cuban
Spanish Variety Identification dataset with common examples annotations
developed to facilitate more accurate detection of Cuban and Caribbean Spanish
varieties. To our knowledge, this is the first dataset focused on identifying
the Cuban, or any other Caribbean, Spanish variety.",2024-12-16,"Javier A. Lopetegui, Arij Riabi, Djamé Seddah"
Generalized Bayesian deep reinforcement learning,"Bayesian reinforcement learning (BRL) is a method that merges principles from
Bayesian statistics and reinforcement learning to make optimal decisions in
uncertain environments. Similar to other model-based RL approaches, it involves
two key components: (1) Inferring the posterior distribution of the data
generating process (DGP) modeling the true environment and (2) policy learning
using the learned posterior. We propose to model the dynamics of the unknown
environment through deep generative models assuming Markov dependence. In
absence of likelihood functions for these models we train them by learning a
generalized predictive-sequential (or prequential) scoring rule (SR) posterior.
We use sequential Monte Carlo (SMC) samplers to draw samples from this
generalized Bayesian posterior distribution. In conjunction, to achieve
scalability in the high dimensional parameter space of the neural networks, we
use the gradient based Markov chain Monte Carlo (MCMC) kernels within SMC. To
justify the use of the prequential scoring rule posterior we prove a
Bernstein-von Misses type theorem. For policy learning, we propose expected
Thompson sampling (ETS) to learn the optimal policy by maximizing the expected
value function with respect to the posterior distribution. This improves upon
traditional Thompson sampling (TS) and its extensions which utilize only one
sample drawn from the posterior distribution. This improvement is studied both
theoretically and using simulation studies assuming discrete action and
state-space. Finally we successfully extend our setup for a challenging problem
with continuous action space without theoretical guarantees.",2024-12-16,"Shreya Sinha Roy, Richard G. Everitt, Christian P. Robert, Ritabrata Dutta"
CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation,"The emergence of long-context text applications utilizing large language
models (LLMs) has presented significant scalability challenges, particularly in
memory footprint. The linear growth of the Key-Value (KV) cache responsible for
storing attention keys and values to minimize redundant computations can lead
to substantial increases in memory consumption, potentially causing models to
fail to serve with limited memory resources. To address this issue, we propose
a novel approach called Cache Sparse Representation (CSR), which converts the
KV cache by transforming the dense Key-Value cache tensor into sparse indexes
and weights, offering a more memory-efficient representation during LLM
inference. Furthermore, we introduce NeuralDict, a novel neural network-based
method for automatically generating the dictionary used in our sparse
representation. Our extensive experiments demonstrate that CSR achieves
performance comparable to state-of-the-art KV cache quantization algorithms
while maintaining robust functionality in memory-constrained environments.",2024-12-16,"Hongxuan Zhang, Yao Zhao, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, Guihai Chen"
"Efficiently Achieving Secure Model Training and Secure Aggregation to
  Ensure Bidirectional Privacy-Preservation in Federated Learning","Bidirectional privacy-preservation federated learning is crucial as both
local gradients and the global model may leak privacy. However, only a few
works attempt to achieve it, and they often face challenges such as excessive
communication and computational overheads, or significant degradation of model
accuracy, which hinders their practical applications. In this paper, we design
an efficient and high-accuracy bidirectional privacy-preserving scheme for
federated learning to complete secure model training and secure aggregation. To
efficiently achieve bidirectional privacy, we design an efficient and
accuracy-lossless model perturbation method on the server side (called
$\mathbf{MP\_Server}$) that can be combined with local differential privacy
(LDP) to prevent clients from accessing the model, while ensuring that the
local gradients obtained on the server side satisfy LDP. Furthermore, to ensure
model accuracy, we customize a distributed differential privacy mechanism on
the client side (called $\mathbf{DDP\_Client}$). When combined with
$\mathbf{MP\_Server}$, it ensures LDP of the local gradients, while ensuring
that the aggregated result matches the accuracy of central differential privacy
(CDP). Extensive experiments demonstrate that our scheme significantly
outperforms state-of-the-art bidirectional privacy-preservation baselines
(SOTAs) in terms of computational cost, model accuracy, and defense ability
against privacy attacks. Particularly, given target accuracy, the training time
of SOTAs is approximately $200$ times, or even over $1000$ times, longer than
that of our scheme. When the privacy budget is set relatively small, our scheme
incurs less than $6\%$ accuracy loss compared to the privacy-ignoring method,
while SOTAs suffer up to $20\%$ accuracy loss. Experimental results also show
that the defense capability of our scheme outperforms than SOTAs.",2024-12-16,"Xue Yang, Depan Peng, Yan Feng, Xiaohu Tang, Weijun Fang, Jun Shao"
"Personalized LLM for Generating Customized Responses to the Same Query
  from Different Users","Existing work on large language model (LLM) personalization assigned
different responding roles to LLM, but overlooked the diversity of questioners.
In this work, we propose a new form of questioner-aware LLM personalization,
generating different responses even for the same query from different
questioners. We design a dual-tower model architecture with a cross-questioner
general encoder and a questioner-specific encoder. We further apply contrastive
learning with multi-view augmentation, pulling close the dialogue
representations of the same questioner, while pulling apart those of different
questioners. To mitigate the impact of question diversity on
questioner-contrastive learning, we cluster the dialogues based on question
similarity and restrict the scope of contrastive learning within each cluster.
We also build a multi-questioner dataset from English and Chinese scripts and
WeChat records, called MQDialog, containing 173 questioners and 12 responders.
Extensive evaluation with different metrics shows a significant improvement in
the quality of personalized response generation.",2024-12-16,"Hang Zeng, Chaoyue Niu, Fan Wu, Chengfei Lv, Guihai Chen"
"SECRET: Towards Scalable and Efficient Code Retrieval via Segmented Deep
  Hashing","Code retrieval, which retrieves code snippets based on users' natural
language descriptions, is widely used by developers and plays a pivotal role in
real-world software development. The advent of deep learning has shifted the
retrieval paradigm from lexical-based matching towards leveraging deep learning
models to encode source code and queries into vector representations,
facilitating code retrieval according to vector similarity. Despite the
effectiveness of these models, managing large-scale code database presents
significant challenges. Previous research proposes deep hashing-based methods,
which generate hash codes for queries and code snippets and use Hamming
distance for rapid recall of code candidates. However, this approach's reliance
on linear scanning of the entire code base limits its scalability. To further
improve the efficiency of large-scale code retrieval, we propose a novel
approach SECRET (Scalable and Efficient Code Retrieval via SegmEnTed deep
hashing). SECRET converts long hash codes calculated by existing deep hashing
approaches into several short hash code segments through an iterative training
strategy. After training, SECRET recalls code candidates by looking up the hash
tables for each segment, the time complexity of recall can thus be greatly
reduced. Extensive experimental results demonstrate that SECRET can drastically
reduce the retrieval time by at least 95% while achieving comparable or even
higher performance of existing deep hashing approaches. Besides, SECRET also
exhibits superior performance and efficiency compared to the classical hash
table-based approach known as LSH under the same number of hash tables.",2024-12-16,"Wenchao Gu, Ensheng Shi, Yanlin Wang, Lun Du, Shi Han, Hongyu Zhang, Dongmei Zhang, Michael R. Lyu"
"Learning UAV-based path planning for efficient localization of objects
  using prior knowledge","UAV's are becoming popular for various object search applications in
agriculture, however they usually use time-consuming row-by-row flight paths.
This paper presents a deep-reinforcement-learning method for path planning to
efficiently localize objects of interest using UAVs with a minimal flight-path
length. The method uses some global prior knowledge with uncertain object
locations and limited resolution in combination with a local object map created
using the output of an object detection network. The search policy could be
learned using deep Q-learning. We trained the agent in simulation, allowing
thorough evaluation of the object distribution, typical errors in the
perception system and prior knowledge, and different stopping criteria. When
objects were non-uniformly distributed over the field, the agent found the
objects quicker than a row-by-row flight path, showing that it learns to
exploit the distribution of objects. Detection errors and quality of prior
knowledge had only minor effect on the performance, indicating that the learned
search policy was robust to errors in the perception system and did not need
detailed prior knowledge. Without prior knowledge, the learned policy was still
comparable in performance to a row-by-row flight path. Finally, we demonstrated
that it is possible to learn the appropriate moment to end the search task. The
applicability of the approach for object search on a real drone was
comprehensively discussed and evaluated. Overall, we conclude that the learned
search policy increased the efficiency of finding objects using a UAV, and can
be applied in real-world conditions when the specified assumptions are met.",2024-12-16,"Rick van Essen, Eldert van Henten, Gert Kootstra"
"Discrepancy-Aware Attention Network for Enhanced Audio-Visual Zero-Shot
  Learning","Audio-visual Zero-Shot Learning (ZSL) has attracted significant attention for
its ability to identify unseen classes and perform well in video classification
tasks. However, modal imbalance in (G)ZSL leads to over-reliance on the optimal
modality, reducing discriminative capabilities for unseen classes. Some studies
have attempted to address this issue by modifying parameter gradients, but two
challenges still remain: (a) Quality discrepancies, where modalities offer
differing quantities and qualities of information for the same concept. (b)
Content discrepancies, where sample contributions within a modality vary
significantly. To address these challenges, we propose a Discrepancy-Aware
Attention Network (DAAN) for Enhanced Audio-Visual ZSL. Our approach introduces
a Quality-Discrepancy Mitigation Attention (QDMA) unit to minimize redundant
information in the high-quality modality and a Contrastive Sample-level
Gradient Modulation (CSGM) block to adjust gradient magnitudes and balance
content discrepancies. We quantify modality contributions by integrating
optimization and convergence rate for more precise gradient modulation in CSGM.
Experiments demonstrates DAAN achieves state-of-the-art performance on
benchmark datasets, with ablation studies validating the effectiveness of
individual modules.",2024-12-16,"RunLin Yu, Yipu Gong, Wenrui Li, Aiwen Sun, Mengren Zheng"
"Seeker: Towards Exception Safety Code Generation with Intermediate
  Language Agents Framework","In real world software development, improper or missing exception handling
can severely impact the robustness and reliability of code. Exception handling
mechanisms require developers to detect, capture, and manage exceptions
according to high standards, but many developers struggle with these tasks,
leading to fragile code. This problem is particularly evident in open-source
projects and impacts the overall quality of the software ecosystem. To address
this challenge, we explore the use of large language models (LLMs) to improve
exception handling in code. Through extensive analysis, we identify three key
issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception
Block, and Distorted Handling Solution. These problems are widespread across
real world repositories, suggesting that robust exception handling practices
are often overlooked or mishandled. In response, we propose Seeker, a
multi-agent framework inspired by expert developer strategies for exception
handling. Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler
to assist LLMs in detecting, capturing, and resolving exceptions more
effectively. Our work is the first systematic study on leveraging LLMs to
enhance exception handling practices in real development scenarios, providing
valuable insights for future improvements in code reliability.",2024-12-16,"Xuanming Zhang, Yuxuan Chen, Yiming Zheng, Zhexin Zhang, Yuan Yuan, Minlie Huang"
Re-Attentional Controllable Video Diffusion Editing,"Editing videos with textual guidance has garnered popularity due to its
streamlined process which mandates users to solely edit the text prompt
corresponding to the source video. Recent studies have explored and exploited
large-scale text-to-image diffusion models for text-guided video editing,
resulting in remarkable video editing capabilities. However, they may still
suffer from some limitations such as mislocated objects, incorrect number of
objects. Therefore, the controllability of video editing remains a formidable
challenge. In this paper, we aim to challenge the above limitations by
proposing a Re-Attentional Controllable Video Diffusion Editing (ReAtCo)
method. Specially, to align the spatial placement of the target objects with
the edited text prompt in a training-free manner, we propose a Re-Attentional
Diffusion (RAD) to refocus the cross-attention activation responses between the
edited text prompt and the target video during the denoising stage, resulting
in a spatially location-aligned and semantically high-fidelity manipulated
video. In particular, to faithfully preserve the invariant region content with
less border artifacts, we propose an Invariant Region-guided Joint Sampling
(IRJS) strategy to mitigate the intrinsic sampling errors w.r.t the invariant
regions at each denoising timestep and constrain the generated content to be
harmonized with the invariant region content. Experimental results verify that
ReAtCo consistently improves the controllability of video diffusion editing and
achieves superior video editing performance.",2024-12-16,"Yuanzhi Wang, Yong Li, Mengyi Liu, Xiaoya Zhang, Xin Liu, Zhen Cui, Antoni B. Chan"
Vocabulary Expansion of Chat Models with Unlabeled Target Language Data,"Chat models (i.e. language models trained to follow instructions through
conversation with humans) outperform base models (i.e. trained solely on
unlabeled data) in both conversation and general task-solving abilities. These
models are generally English-centric and require further adaptation for
languages that are underrepresented in or absent from their training data. A
common technique for adapting base models is to extend the model's vocabulary
with target language tokens, i.e. vocabulary expansion (VE), and then
continually pre-train it on language-specific data. Using chat data is ideal
for chat model adaptation, but often, either this does not exist or is costly
to construct. Alternatively, adapting chat models with unlabeled data is a
possible solution, but it could result in catastrophic forgetting. In this
paper, we investigate the impact of using unlabeled target language data for VE
on chat models for the first time. We first show that off-the-shelf VE
generally performs well across target language tasks and models in 71% of
cases, though it underperforms in scenarios where source chat models are
already strong. To further improve adapted models, we propose post-hoc
techniques that inject information from the source model without requiring any
further training. Experiments reveal the effectiveness of our methods, helping
the adapted models to achieve performance improvements in 87% of cases.",2024-12-16,"Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras"
"On Large Language Models in Mission-Critical IT Governance: Are We Ready
  Yet?","Context. The security of critical infrastructure has been a fundamental
concern since the advent of computers, and this concern has only intensified in
today's cyber warfare landscape. Protecting mission-critical systems (MCSs),
including essential assets like healthcare, telecommunications, and military
coordination, is vital for national security. These systems require prompt and
comprehensive governance to ensure their resilience, yet recent events have
shown that meeting these demands is increasingly challenging. Aim. Building on
prior research that demonstrated the potential of GAI, particularly Large
Language Models (LLMs), in improving risk analysis tasks, we aim to explore
practitioners' perspectives, specifically developers and security personnel, on
using generative AI (GAI) in the governance of IT MCSs seeking to provide
insights and recommendations for various stakeholders, including researchers,
practitioners, and policymakers. Method. We designed a survey to collect
practical experiences, concerns, and expectations of practitioners who develop
and implement security solutions in the context of MCSs. Analyzing this data
will help identify key trends, challenges, and opportunities for introducing
GAIs in this niche domain. Conclusions and Future Works. Our findings highlight
that the safe use of LLMs in MCS governance requires interdisciplinary
collaboration. Researchers should focus on designing regulation-oriented models
and focus on accountability; practitioners emphasize data protection and
transparency, while policymakers must establish a unified AI framework with
global benchmarks to ensure ethical and secure LLMs-based MCS governance.",2024-12-16,"Matteo Esposito, Francesco Palagiano, Valentina Lenarduzzi, Davide Taibi"
"Ultra-High-Definition Dynamic Multi-Exposure Image Fusion via Infinite
  Pixel Learning","With the continuous improvement of device imaging resolution, the popularity
of Ultra-High-Definition (UHD) images is increasing. Unfortunately, existing
methods for fusing multi-exposure images in dynamic scenes are designed for
low-resolution images, which makes them inefficient for generating high-quality
UHD images on a resource-constrained device. To alleviate the limitations of
extremely long-sequence inputs, inspired by the Large Language Model (LLM) for
processing infinitely long texts, we propose a novel learning paradigm to
achieve UHD multi-exposure dynamic scene image fusion on a single
consumer-grade GPU, named Infinite Pixel Learning (IPL). The design of our
approach comes from three key components: The first step is to slice the input
sequences to relieve the pressure generated by the model processing the data
stream; Second, we develop an attention cache technique, which is similar to KV
cache for infinite data stream processing; Finally, we design a method for
attention cache compression to alleviate the storage burden of the cache on the
device. In addition, we provide a new UHD benchmark to evaluate the
effectiveness of our method. Extensive experimental results show that our
method maintains high-quality visual performance while fusing UHD dynamic
multi-exposure images in real-time (>40fps) on a single consumer-grade GPU.",2024-12-16,"Xingchi Chen, Zhuoran Zheng, Xuerui Li, Yuying Chen, Shu Wang, Wenqi Ren"
"Runtime Analysis for Multi-Objective Evolutionary Algorithms in
  Unbounded Integer Spaces","Randomized search heuristics have been applied successfully to a plethora of
problems. This success is complemented by a large body of theoretical results.
Unfortunately, the vast majority of these results regard problems with binary
or continuous decision variables -- the theoretical analysis of randomized
search heuristics for unbounded integer domains is almost nonexistent. To
resolve this shortcoming, we start the runtime analysis of multi-objective
evolutionary algorithms, which are among the most successful randomized search
heuristics, for unbounded integer search spaces. We analyze single- and
full-dimensional mutation operators with three different mutation strengths,
namely changes by plus/minus one (unit strength), random changes following a
law with exponential tails, and random changes following a power-law. The
performance guarantees we prove on a recently proposed natural benchmark
problem suggest that unit mutation strengths can be slow when the initial
solutions are far from the Pareto front. When setting the expected change right
(depending on the benchmark parameter and the distance of the initial
solutions), the mutation strength with exponential tails yields the best
runtime guarantees in our results -- however, with a wrong choice of this
expectation, the performance guarantees quickly become highly uninteresting.
With power-law mutation, which is an essentially parameter-less mutation
operator, we obtain good results uniformly over all problem parameters and
starting points. We complement our mathematical findings with experimental
results that suggest that our bounds are not always tight. Most prominently,
our experiments indicate that power-law mutation outperforms the one with
exponential tails even when the latter uses a near-optimal parametrization.
Hence, we suggest to favor power-law mutation for unknown problems in integer
spaces.",2024-12-16,"Benjamin Doerr, Martin S. Krejca, Günter Rudolph"
Multimodal LLM for Intelligent Transportation Systems,"In the evolving landscape of transportation systems, integrating Large
Language Models (LLMs) offers a promising frontier for advancing intelligent
decision-making across various applications. This paper introduces a novel
3-dimensional framework that encapsulates the intersection of applications,
machine learning methodologies, and hardware devices, particularly emphasizing
the role of LLMs. Instead of using multiple machine learning algorithms, our
framework uses a single, data-centric LLM architecture that can analyze time
series, images, and videos. We explore how LLMs can enhance data interpretation
and decision-making in transportation. We apply this LLM framework to different
sensor datasets, including time-series data and visual data from sources like
Oxford Radar RobotCar, D-Behavior (D-Set), nuScenes by Motional, and Comma2k19.
The goal is to streamline data processing workflows, reduce the complexity of
deploying multiple models, and make intelligent transportation systems more
efficient and accurate. The study was conducted using state-of-the-art
hardware, leveraging the computational power of AMD RTX 3060 GPUs and Intel
i9-12900 processors. The experimental results demonstrate that our framework
achieves an average accuracy of 91.33\% across these datasets, with the highest
accuracy observed in time-series data (92.7\%), showcasing the model's
proficiency in handling sequential information essential for tasks such as
motion planning and predictive maintenance. Through our exploration, we
demonstrate the versatility and efficacy of LLMs in handling multimodal data
within the transportation sector, ultimately providing insights into their
application in real-world scenarios. Our findings align with the broader
conference themes, highlighting the transformative potential of LLMs in
advancing transportation technologies.",2024-12-16,"Dexter Le, Aybars Yunusoglu, Karn Tiwari, Murat Isik, I. Can Dikmen"
"Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer
  detection","Pulmonary pathologies are a significant global health concern, often leading
to fatal outcomes if not diagnosed and treated promptly. Chest radiography
serves as a primary diagnostic tool, but the availability of experienced
radiologists remains limited. Advances in Artificial Intelligence (AI) and
machine learning, particularly in computer vision, offer promising solutions to
address this challenge.
  This research evaluates a deep learning model designed to detect lung cancer,
specifically pulmonary nodules, along with eight other lung pathologies, using
chest radiographs. The study leverages diverse datasets comprising over 135,120
frontal chest radiographs to train a Convolutional Neural Network (CNN). A
two-stage classification system, utilizing ensemble methods and transfer
learning, is employed to first triage images into Normal or Abnormal categories
and then identify specific pathologies, including lung nodules.
  The deep learning model achieves notable results in nodule classification,
with a top-performing accuracy of 77%, a sensitivity of 0.713, a specificity of
0.776 during external validation, and an AUC score of 0.888. Despite these
successes, some misclassifications were observed, primarily false negatives.
  In conclusion, the model demonstrates robust potential for generalization
across diverse patient populations, attributed to the geographic diversity of
the training dataset. Future work could focus on integrating ETL data
distribution strategies and expanding the dataset with additional nodule-type
samples to further enhance diagnostic accuracy.",2024-12-16,"Abdelbaki Souid, Mohamed Hamroun, Soufiene Ben Othman, Hedi Sakli, Naceur Abdelkarim"
"LLM-DaaS: LLM-driven Drone-as-a-Service Operations from Text User
  Requests","We propose LLM-DaaS, a novel Drone-as-a-Service (DaaS) framework that
leverages Large Language Models (LLMs) to transform free-text user requests
into structured, actionable DaaS operation tasks. Our approach addresses the
key challenge of interpreting and structuring natural language input to
automate drone service operations under uncertain conditions. The system is
composed of three main components: free-text request processing, structured
request generation, and dynamic DaaS selection and composition. First, we
fine-tune different LLM models such as Phi-3.5, LLaMA-3.2 7b and Gemma 2b on a
dataset of text user requests mapped to structured DaaS requests. Users
interact with our model in a free conversational style, discussing package
delivery requests, while the fine-tuned LLM extracts DaaS metadata such as
delivery time, source and destination locations, and package weight. The DaaS
service selection model is designed to select the best available drone capable
of delivering the requested package from the delivery point to the nearest
optimal destination. Additionally, the DaaS composition model composes a
service from a set of the best available drones to deliver the package from the
source to the final destination. Second, the system integrates real-time
weather data to optimize drone route planning and scheduling, ensuring safe and
efficient operations. Simulations demonstrate the system's ability to
significantly improve task accuracy, operational efficiency, and establish
LLM-DaaS as a robust solution for DaaS operations in uncertain environments.",2024-12-16,"Lillian Wassim, Kamal Mohamed, Ali Hamdi"
"BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched
  EMR","Pediatric Emergency Department (PED) overcrowding presents a significant
global challenge, prompting the need for efficient solutions. This paper
introduces the BioBridge framework, a novel approach that applies Natural
Language Processing (NLP) to Electronic Medical Records (EMRs) in written
free-text form to enhance decision-making in PED. In non-English speaking
countries, such as South Korea, EMR data is often written in a Code-Switching
(CS) format that mixes the native language with English, with most
code-switched English words having clinical significance. The BioBridge
framework consists of two core modules: ""bridging modality in context"" and
""unified bio-embedding."" The ""bridging modality in context"" module improves the
contextual understanding of bilingual and code-switched EMRs. In the ""unified
bio-embedding"" module, the knowledge of the model trained in the medical domain
is injected into the encoder-based model to bridge the gap between the medical
and general domains. Experimental results demonstrate that the proposed
BioBridge significantly performance traditional machine learning and
pre-trained encoder-based models on several metrics, including F1 score, area
under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM
achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,
along with a notable 3.04% decrease in the Brier score, demonstrating marked
improvements in accuracy, reliability, and prediction calibration over the
baseline XLM model. The source code will be made publicly available.",2024-12-16,"Jangyeong Jeon, Sangyeon Cho, Dongjoon Lee, Changhee Lee, Junyeong Kim"
Soft and Constrained Hypertree Width,"Hypertree decompositions provide a way to evaluate Conjunctive Queries (CQs)
in polynomial time, where the exponent of this polynomial is determined by the
width of the decomposition. In theory, the goal of efficient CQ evaluation
therefore has to be a minimisation of the width. However, in practical
settings, it turns out that there are also other properties of a decomposition
that influence the performance of query evaluation. It is therefore of interest
to restrict the computation of decompositions by constraints and to guide this
computation by preferences. To this end, we propose a novel framework based on
candidate tree decompositions, which allows us to introduce soft hypertree
width (shw). This width measure is a relaxation of hypertree width (hw); it is
never greater than hw and, in some cases, shw may actually be lower than hw.
ost importantly, shw preserves the tractability of deciding if a given CQ is
below some fixed bound, while offering more algorithmic flexibility. In
particular, it provides a natural way to incorporate preferences A prototype
implementation and preliminary experiments confirm that this novel framework
can indeed have a practical impact on query evaluation.",2024-12-16,"Matthias Lanzinger, Cem Okulmus, Reinhard Pichler, Alexander Selzer, Georg Gottlob"
Security and Fairness in Multi-Party Quantum Secret Sharing Protocol,"Quantum secret sharing (QSS) is a cryptographic protocol that leverages
quantum mechanics to distribute a secret among multiple parties. With respect
to the classical counterpart, in QSS the secret is encoded into quantum states
and shared by a dealer such that only an authorized subsets of participants,
i.e., the players, can reconstruct it. Several state-of-the-art studies aim to
transpose classical Secret Sharing into the quantum realm, while maintaining
their reliance on traditional network topologies (e.g., star, ring,
fully-connected) and require that all the n players calculate the secret. These
studies exploit the Greenberger-Horne-Zeilinger (GHZ) state, which is a type of
maximally entangled quantum state involving three or more qubits. However, none
of these works account for redundancy, enhanced security/privacy features or
authentication mechanisms able to fingerprint players. To address these gaps,
in this paper we introduce a new concept of QSS which leans on a generic
distributed quantum-network, based on a threshold scheme, where all the players
collaborate also to the routing of quantum information among them. The dealer,
by exploiting a custom flexible weighting system, takes advantage of a newly
defined quantum Dijkstra algorithm to select the most suitable subset of t
players, out of the entire set on n players, to involve in the computation. To
fingerprint and authenticate users, CRYSTAL-Kyber primitives are adopted, while
also protecting each player's privacy by hiding their identities. We show the
effectiveness and performance of the proposed protocol by testing it against
the main classical and quantum attacks, thereby improving the state-of-the-art
security measures.",2024-12-16,"Alessio Di Santo, Walter Tiberti, Dajana Cassioli"
"C3oT: Generating Shorter Chain-of-Thought without Compromising
  Effectiveness","Generating Chain-of-Thought (CoT) before deriving the answer can effectively
improve the reasoning capabilities of large language models (LLMs) and
significantly improve the accuracy of the generated answer. However, in most
cases, the length of the generated CoT is much longer than the desired final
answer, which results in additional decoding costs. Furthermore, existing
research has discovered that shortening the reasoning steps in CoT, even while
preserving the key information, diminishes LLMs' abilities. These phenomena
make it difficult to use LLMs and CoT in many real-world applications that only
require the final answer and are sensitive to latency, such as search and
recommendation. To reduce the costs of model decoding and shorten the length of
the generated CoT, this paper presents $\textbf{C}$onditioned
$\textbf{C}$ompressed $\textbf{C}$hain-of-$\textbf{T}$hought (C3oT), a CoT
compression framework that involves a compressor to compress an original longer
CoT into a shorter CoT while maintaining key information and interpretability,
a conditioned training method to train LLMs with both longer CoT and shorter
CoT simultaneously to learn the corresponding relationships between them, and a
conditioned inference method to gain the reasoning ability learned from longer
CoT by generating shorter CoT. We conduct experiments over four datasets from
arithmetic and commonsense scenarios, showing that the proposed method is
capable of compressing the length of generated CoT by up to more than 50%
without compromising its effectiveness.",2024-12-16,"Yu Kang, Xianghui Sun, Liangyu Chen, Wei Zou"
"Apollo-Forecast: Overcoming Aliasing and Inference Speed Challenges in
  Language Models for Time Series Forecasting","Encoding time series into tokens and using language models for processing has
been shown to substantially augment the models' ability to generalize to unseen
tasks. However, existing language models for time series forecasting encounter
several obstacles, including aliasing distortion and prolonged inference times,
primarily due to the limitations of quantization processes and the
computational demands of large models. This paper introduces Apollo-Forecast, a
novel framework that tackles these challenges with two key innovations: the
Anti-Aliasing Quantization Module (AAQM) and the Race Decoding (RD) technique.
AAQM adeptly encodes sequences into tokens while mitigating high-frequency
noise in the original signals, thus enhancing both signal fidelity and overall
quantization efficiency. RD employs a draft model to enable parallel processing
and results integration, which markedly accelerates the inference speed for
long-term predictions, particularly in large-scale models. Extensive
experiments on various real-world datasets show that Apollo-Forecast
outperforms state-of-the-art methods by 35.41\% and 18.99\% in WQL and MASE
metrics, respectively, in zero-shot scenarios. Furthermore, our method achieves
a 1.9X-2.7X acceleration in inference speed over baseline methods.",2024-12-16,"Tianyi Yin, Jingwei Wang, Yunlong Ma, Han Wang, Chenze Wang, Yukai Zhao, Min Liu, Weiming Shen, Yufeng Chen"
"Private Yet Social: How LLM Chatbots Support and Challenge Eating
  Disorder Recovery","Eating disorders (ED) are complex mental health conditions that require
long-term management and support. Recent advancements in large language model
(LLM)-based chatbots offer the potential to assist individuals in receiving
immediate support. Yet, concerns remain about their reliability and safety in
sensitive contexts such as ED. We explore the opportunities and potential harms
of using LLM-based chatbots for ED recovery. We observe the interactions
between 26 participants with ED and an LLM-based chatbot, WellnessBot, designed
to support ED recovery, over 10 days. We discovered that our participants have
felt empowered in recovery by discussing ED-related stories with the chatbot,
which served as a personal yet social avenue. However, we also identified
harmful chatbot responses, especially concerning individuals with ED, that went
unnoticed partly due to participants' unquestioning trust in the chatbot's
reliability. Based on these findings, we provide design implications for safe
and effective LLM-based interventions in ED management.",2024-12-16,"Ryuhaerang Choi, Taehan Kim, Subin Park, Jennifer G Kim, Sung-Ju Lee"
"Self-Adaptive Paraphrasing and Preference Learning for Improved Claim
  Verifiability","In fact-checking, structure and phrasing of claims critically influence a
model's ability to predict verdicts accurately. Social media content in
particular rarely serves as optimal input for verification systems, which
necessitates pre-processing to extract the claim from noisy context before fact
checking. Prior work suggests extracting a claim representation that humans
find to be checkworthy and verifiable. This has two limitations: (1) the format
may not be optimal for a fact-checking model, and (2), it requires annotated
data to learn the extraction task from. We address both issues and propose a
method to extract claims that is not reliant on labeled training data. Instead,
our self-adaptive approach only requires a black-box fact checking model and a
generative language model (LM). Given a tweet, we iteratively optimize the LM
to generate a claim paraphrase that increases the performance of a fact
checking model. By learning from preference pairs, we align the LM to the fact
checker using direct preference optimization. We show that this novel setup
extracts a claim paraphrase that is more verifiable than their original social
media formulations, and is on par with competitive baselines. For refuted
claims, our method consistently outperforms all baselines.",2024-12-16,"Amelie Wührl, Roman Klinger"
"SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning
  for Text Representation","Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.",2024-12-16,"Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li"
Introduction to AI Planning,"These are notes for lectures presented at the University of Stuttgart that
provide an introduction to key concepts and techniques in AI Planning.
Artificial Intelligence Planning, also known as Automated Planning, emerged
somewhere in 1966 from the need to give autonomy to a wheeled robot. Since
then, it has evolved into a flourishing research and development discipline,
often associated with scheduling. Over the decades, various approaches to
planning have been developed with characteristics that make them appropriate
for specific tasks and applications. Most approaches represent the world as a
state within a state transition system; then the planning problem becomes that
of searching a path in the state space from the current state to one which
satisfies the goals of the user. The notes begin by introducing the state model
and move on to exploring classical planning, the foundational form of planning,
and present fundamental algorithms for solving such problems. Subsequently, we
examine planning as a constraint satisfaction problem, outlining the mapping
process and describing an approach to solve such problems. The most extensive
section is dedicated to Hierarchical Task Network (HTN) planning, one of the
most widely used and powerful planning techniques in the field. The lecture
notes end with a bonus chapter on the Planning Domain Definition (PDDL)
Language, the de facto standard syntax for representing non-hierarchical
planning problems.",2024-12-16,"Marco Aiello, Ilche Georgievski"
SeSeMI: Secure Serverless Model Inference on Sensitive Data,"Model inference systems are essential for implementing end-to-end data
analytics pipelines that deliver the benefits of machine learning models to
users. Existing cloud-based model inference systems are costly, not easy to
scale, and must be trusted in handling the models and user request data.
Serverless computing presents a new opportunity, as it provides elasticity and
fine-grained pricing. Our goal is to design a serverless model inference system
that protects models and user request data from untrusted cloud providers. It
offers high performance and low cost, while requiring no intrusive changes to
the current serverless platforms. To realize our goal, we leverage trusted
hardware. We identify and address three challenges in using trusted hardware
for serverless model inference. These challenges arise from the high-level
abstraction of serverless computing, the performance overhead of trusted
hardware, and the characteristics of model inference workloads. We present
SeSeMI, a secure, efficient, and cost-effective serverless model inference
system. It adds three novel features non-intrusively to the existing serverless
infrastructure and nothing else.The first feature is a key service that
establishes secure channels between the user and the serverless instances,
which also provides access control to models and users' data. The second is an
enclave runtime that allows one enclave to process multiple concurrent
requests. The final feature is a model packer that allows multiple models to be
executed by one serverless instance. We build SeSeMI on top of Apache
OpenWhisk, and conduct extensive experiments with three popular machine
learning models. The results show that SeSeMI achieves low latency and low cost
at scale for realistic workloads.",2024-12-16,"Guoyu Hu, Yuncheng Wu, Gang Chen, Tien Tuan Anh Dinh, Beng Chin Ooi"
"High-speed and High-quality Vision Reconstruction of Spike Camera with
  Spike Stability Theorem","Neuromorphic vision sensors, such as the dynamic vision sensor (DVS) and
spike camera, have gained increasing attention in recent years. The spike
camera can detect fine textures by mimicking the fovea in the human visual
system, and output a high-frequency spike stream. Real-time high-quality vision
reconstruction from the spike stream can build a bridge to high-level vision
task applications of the spike camera. To realize high-speed and high-quality
vision reconstruction of the spike camera, we propose a new spike stability
theorem that reveals the relationship between spike stream characteristics and
stable light intensity. Based on the spike stability theorem, two
parameter-free algorithms are designed for the real-time vision reconstruction
of the spike camera. To demonstrate the performances of our algorithms, two
datasets (a public dataset PKU-Spike-High-Speed and a newly constructed dataset
SpikeCityPCL) are used to compare the reconstruction quality and speed of
various reconstruction methods. Experimental results show that, compared with
the current state-of-the-art (SOTA) reconstruction methods, our reconstruction
methods obtain the best tradeoff between the reconstruction quality and speed.
Additionally, we design the FPGA implementation method of our algorithms to
realize the real-time (running at 20,000 FPS) visual reconstruction. Our work
provides new theorem and algorithm foundations for the real-time edge-end
vision processing of the spike camera.",2024-12-16,"Wei Zhang, Weiquan Yan, Yun Zhao, Wenxiang Cheng, Gang Chen, Huihui Zhou, Yonghong Tian"
"QPruner: Probabilistic Decision Quantization for Structured Pruning in
  Large Language Models","The rise of large language models (LLMs) has significantly advanced various
natural language processing (NLP) tasks. However, the resource demands of these
models pose substantial challenges. Structured pruning is an effective approach
to reducing model size, but it often results in significant accuracy
degradation, necessitating parameter updates to adapt. Unfortunately, such
fine-tuning requires substantial memory, which limits its applicability. To
address these challenges, we introduce quantization into the structured pruning
framework to reduce memory consumption during both fine-tuning and inference.
However, the combined errors from pruning and quantization increase the
difficulty of fine-tuning, requiring a more refined quantization scheme. To
this end, we propose QPruner, a novel framework that employs structured pruning
to reduce model size, followed by a layer-wise mixed-precision quantization
scheme. Quantization precisions are assigned to each layer based on their
importance to the target task, and Bayesian optimization is employed to refine
precision allocation strategies, ensuring a balance between model accuracy and
memory efficiency. Extensive experiments on benchmark datasets demonstrate that
QPruner significantly outperforms existing methods in memory savings while
maintaining or improving model performance.",2024-12-16,"Changhai Zhou, Yuhua Zhou, Shijie Han, Qian Qiao, Hongguang Li"
MT-LENS: An all-in-one Toolkit for Better Machine Translation Evaluation,"We introduce MT-LENS, a framework designed to evaluate Machine Translation
(MT) systems across a variety of tasks, including translation quality, gender
bias detection, added toxicity, and robustness to misspellings. While several
toolkits have become very popular for benchmarking the capabilities of Large
Language Models (LLMs), existing evaluation tools often lack the ability to
thoroughly assess the diverse aspects of MT performance. MT-LENS addresses
these limitations by extending the capabilities of LM-eval-harness for MT,
supporting state-of-the-art datasets and a wide range of evaluation metrics. It
also offers a user-friendly platform to compare systems and analyze
translations with interactive visualizations. MT-LENS aims to broaden access to
evaluation strategies that go beyond traditional translation quality
evaluation, enabling researchers and engineers to better understand the
performance of a NMT model and also easily measure system's biases.",2024-12-16,"Javier García Gilabert, Carlos Escolano, Audrey Mash, Xixian Liao, Maite Melero"
"3D$^2$-Actor: Learning Pose-Conditioned 3D-Aware Denoiser for Realistic
  Gaussian Avatar Modeling","Advancements in neural implicit representations and differentiable rendering
have markedly improved the ability to learn animatable 3D avatars from sparse
multi-view RGB videos. However, current methods that map observation space to
canonical space often face challenges in capturing pose-dependent details and
generalizing to novel poses. While diffusion models have demonstrated
remarkable zero-shot capabilities in 2D image generation, their potential for
creating animatable 3D avatars from 2D inputs remains underexplored. In this
work, we introduce 3D$^2$-Actor, a novel approach featuring a pose-conditioned
3D-aware human modeling pipeline that integrates iterative 2D denoising and 3D
rectifying steps. The 2D denoiser, guided by pose cues, generates detailed
multi-view images that provide the rich feature set necessary for high-fidelity
3D reconstruction and pose rendering. Complementing this, our Gaussian-based 3D
rectifier renders images with enhanced 3D consistency through a two-stage
projection strategy and a novel local coordinate representation. Additionally,
we propose an innovative sampling strategy to ensure smooth temporal continuity
across frames in video synthesis. Our method effectively addresses the
limitations of traditional numerical solutions in handling ill-posed mappings,
producing realistic and animatable 3D human avatars. Experimental results
demonstrate that 3D$^2$-Actor excels in high-fidelity avatar modeling and
robustly generalizes to novel poses. Code is available at:
https://github.com/silence-tang/GaussianActor.",2024-12-16,"Zichen Tang, Hongyu Yang, Hanchen Zhang, Jiaxin Chen, Di Huang"
"Aligning Visual and Semantic Interpretability through Visually Grounded
  Concept Bottleneck Models","The performance of neural networks increases steadily, but our understanding
of their decision-making lags behind. Concept Bottleneck Models (CBMs) address
this issue by incorporating human-understandable concepts into the prediction
process, thereby enhancing transparency and interpretability. Since existing
approaches often rely on large language models (LLMs) to infer concepts, their
results may contain inaccurate or incomplete mappings, especially in complex
visual domains. We introduce visually Grounded Concept Bottleneck Models
(GCBM), which derive concepts on the image level using segmentation and
detection foundation models. Our method generates inherently interpretable
concepts, which can be grounded in the input image using attribution methods,
allowing interpretations to be traced back to the image plane. We show that
GCBM concepts are meaningful interpretability vehicles, which aid our
understanding of model embedding spaces. GCBMs allow users to control the
granularity, number, and naming of concepts, providing flexibility and are
easily adaptable to new datasets without pre-training or additional data
needed. Prediction accuracy is within 0.3-6% of the linear probe and GCBMs
perform especially well for fine-grained classification interpretability on
CUB, due to their dataset specificity. Our code is available on
https://github.com/KathPra/GCBM.",2024-12-16,"Patrick Knab, Katharina Prasse, Sascha Marton, Christian Bartelt, Margret Keuper"
"Can video generation replace cinematographers? Research on the cinematic
  language of generated video","Recent advancements in text-to-video (T2V) generation have leveraged
diffusion models to enhance the visual coherence of videos generated from
textual descriptions. However, most research has primarily focused on object
motion, with limited attention given to cinematic language in videos, which is
crucial for cinematographers to convey emotion and narrative pacing. To address
this limitation, we propose a threefold approach to enhance the ability of T2V
models to generate controllable cinematic language. Specifically, we introduce
a cinematic language dataset that encompasses shot framing, angle, and camera
movement, enabling models to learn diverse cinematic styles. Building on this,
to facilitate robust cinematic alignment evaluation, we present CameraCLIP, a
model fine-tuned on the proposed dataset that excels in understanding complex
cinematic language in generated videos and can further provide valuable
guidance in the multi-shot composition process. Finally, we propose CLIPLoRA, a
cost-guided dynamic LoRA composition method that facilitates smooth transitions
and realistic blending of cinematic language by dynamically fusing multiple
pre-trained cinematic LoRAs within a single video. Our experiments demonstrate
that CameraCLIP outperforms existing models in assessing the alignment between
cinematic language and video, achieving an R@1 score of 0.81. Additionally,
CLIPLoRA improves the ability for multi-shot composition, potentially bridging
the gap between automatically generated videos and those shot by professional
cinematographers.",2024-12-16,"Xiaozhe Li, Kai WU, Siyi Yang, YiZhan Qu, Guohua. Zhang, Zhiyu Chen, Jiayao Li, Jiangchuan Mu, Xiaobin Hu, Wen Fang, Mingliang Xiong, Hao Deng, Qingwen Liu, Gang Li, Bin He"
"OTA-Key: Over the Air Key Management for Flexible and Reliable IoT
  Device Provision","As the Internet of Things (IoT) industry advances, the imperative to secure
IoT devices has become increasingly critical. Current practices in both
industry and academia advocate for the enhancement of device security through
key installation. However, it has been observed that, in practice, IoT vendors
frequently assign shared keys to batches of devices. This practice can expose
devices to risks, such as data theft by attackers or large-scale Distributed
Denial of Service (DDoS) attacks. To address this issue, our intuition is to
assign a unique key to each device. Unfortunately, this strategy proves to be
highly complex within the IoT context, as existing keys are typically hardcoded
into the firmware, necessitating the creation of bespoke firmware for each
device. Furthermore, correct pairing of device keys with their respective
devices is crucial. Errors in this pairing process would incur substantial
human and temporal resources to rectify and require extensive communication
between IoT vendors, device manufacturers, and cloud platforms, leading to
significant communication overhead. To overcome these challenges, we propose
the OTA-Key scheme. This approach fundamentally decouples device keys from the
firmware features stored in flash memory, utilizing an intermediary server to
allocate unique device keys in two distinct stages and update keys. We
conducted a formal security verification of our scheme using ProVerif and
assessed its performance through a series of evaluations. The results
demonstrate that our scheme is secure and effectively manages the large-scale
distribution and updating of unique device keys. Additionally, it achieves
significantly lower update times and data transfer volumes compared to other
schemes.",2024-12-16,"Qian Zhang, Yi He, Yue Xiao, Xiaoli Zhang, Chunhua Song"
"RADARSAT Constellation Mission Compact Polarisation SAR Data for Burned
  Area Mapping with Deep Learning","Monitoring wildfires has become increasingly critical due to the sharp rise
in wildfire incidents in recent years. Optical satellites like Sentinel-2 and
Landsat are extensively utilized for mapping burned areas. However, the
effectiveness of optical sensors is compromised by clouds and smoke, which
obstruct the detection of burned areas. Thus, satellites equipped with
Synthetic Aperture Radar (SAR), such as dual-polarization Sentinel-1 and
quad-polarization RADARSAT-1/-2 C-band SAR, which can penetrate clouds and
smoke, are investigated for mapping burned areas. However, there is limited
research on using compact polarisation (compact-pol) C-band RADARSAT
Constellation Mission (RCM) SAR data for this purpose. This study aims to
investigate the capacity of compact polarisation RCM data for burned area
mapping through deep learning. Compact-pol m-chi decomposition and Compact-pol
Radar Vegetation Index (CpRVI) are derived from the RCM Multi-look Complex
product. A deep-learning-based processing pipeline incorporating ConvNet-based
and Transformer-based models is applied for burned area mapping, with three
different input settings: using only log-ratio dual-polarization intensity
images images, using only compact-pol decomposition plus CpRVI, and using all
three data sources. The results demonstrate that compact-pol m-chi
decomposition and CpRVI images significantly complement log-ratio images for
burned area mapping. The best-performing Transformer-based model, UNETR,
trained with log-ratio, m-chi decomposition, and CpRVI data, achieved an F1
Score of 0.718 and an IoU Score of 0.565, showing a notable improvement
compared to the same model trained using only log-ratio images.",2024-12-16,"Yu Zhao, Yifang Ban"
"Learning Massive-scale Partial Correlation Networks in Clinical
  Multi-omics Studies with HP-ACCORD","Graphical model estimation from modern multi-omics data requires a balance
between statistical estimation performance and computational scalability. We
introduce a novel pseudolikelihood-based graphical model framework that
reparameterizes the target precision matrix while preserving sparsity pattern
and estimates it by minimizing an $\ell_1$-penalized empirical risk based on a
new loss function. The proposed estimator maintains estimation and selection
consistency in various metrics under high-dimensional assumptions. The
associated optimization problem allows for a provably fast computation
algorithm using a novel operator-splitting approach and communication-avoiding
distributed matrix multiplication. A high-performance computing implementation
of our framework was tested in simulated data with up to one million variables
demonstrating complex dependency structures akin to biological networks.
Leveraging this scalability, we estimated partial correlation network from a
dual-omic liver cancer data set. The co-expression network estimated from the
ultrahigh-dimensional data showed superior specificity in prioritizing key
transcription factors and co-activators by excluding the impact of epigenomic
regulation, demonstrating the value of computational scalability in multi-omic
data analysis. %derived from the gene expression data.",2024-12-16,"Sungdong Lee, Joshua Bang, Youngrae Kim, Hyungwon Choi, Sang-Yun Oh, Joong-Ho Won"
"Efficient Avoidance of Ellipsoidal Obstacles with Model Predictive
  Control for Mobile Robots and Vehicles","In real-world applications of mobile robots, collision avoidance is of
critical importance. Typically, global motion planning in constrained
environments is addressed through high-level control schemes. However,
additionally integrating local collision avoidance into robot motion control
offers significant advantages. For instance, it reduces the reliance on
heuristics and conservatism that can arise from a two-stage approach separating
local collision avoidance and control. Moreover, using model predictive control
(MPC), a robot's full potential can be harnessed by considering jointly local
collision avoidance, the robot's dynamics, and actuation constraints. In this
context, the present paper focuses on obstacle avoidance for wheeled mobile
robots, where both the robot's and obstacles' occupied volumes are modeled as
ellipsoids. To this end, a computationally efficient overlap test, that works
for arbitrary ellipsoids, is conducted and novelly integrated into the MPC
framework. We propose a particularly efficient implementation tailored to
robots moving in the plane. The functionality of the proposed obstacle-avoiding
MPC is demonstrated for two exemplary types of kinematics by means of
simulations. A hardware experiment using a real-world wheeled mobile robot
shows transferability to reality and real-time applicability. The general
computational approach to ellipsoidal obstacle avoidance can also be applied to
other robotic systems and vehicles as well as three-dimensional scenarios.",2024-12-16,"Mario Rosenfelder, Hendrik Carius, Markus Herrmann-Wicklmayr, Peter Eberhard, Kathrin Flaßkamp, Henrik Ebel"
"THESAURUS: Contrastive Graph Clustering by Swapping Fused
  Gromov-Wasserstein Couplings","Graph node clustering is a fundamental unsupervised task. Existing methods
typically train an encoder through selfsupervised learning and then apply
K-means to the encoder output. Some methods use this clustering result directly
as the final assignment, while others initialize centroids based on this
initial clustering and then finetune both the encoder and these learnable
centroids. However, due to their reliance on K-means, these methods inherit its
drawbacks when the cluster separability of encoder output is low, facing
challenges from the Uniform Effect and Cluster Assimilation. We summarize three
reasons for the low cluster separability in existing methods: (1) lack of
contextual information prevents discrimination between similar nodes from
different clusters; (2) training tasks are not sufficiently aligned with the
downstream clustering task; (3) the cluster information in the graph structure
is not appropriately exploited. To address these issues, we propose conTrastive
grapH clustEring by SwApping fUsed gRomov-wasserstein coUplingS (THESAURUS).
Our method introduces semantic prototypes to provide contextual information,
and employs a cross-view assignment prediction pretext task that aligns well
with the downstream clustering task. Additionally, it utilizes
Gromov-Wasserstein Optimal Transport (GW-OT) along with the proposed prototype
graph to thoroughly exploit cluster information in the graph structure. To
adapt to diverse real-world data, THESAURUS updates the prototype graph and the
prototype marginal distribution in OT by using momentum. Extensive experiments
demonstrate that THESAURUS achieves higher cluster separability than the prior
art, effectively mitigating the Uniform Effect and Cluster Assimilation issues",2024-12-16,"Bowen Deng, Tong Wang, Lele Fu, Sheng Huang, Chuan Chen, Tao Zhang"
"MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion
  Models","Diffusion models have received wide attention in generation tasks. However,
the expensive computation cost prevents the application of diffusion models in
resource-constrained scenarios. Quantization emerges as a practical solution
that significantly saves storage and computation by reducing the bit-width of
parameters. However, the existing quantization methods for diffusion models
still cause severe degradation in performance, especially under extremely low
bit-widths (2-4 bit). The primary decrease in performance comes from the
significant discretization of activation values at low bit quantization. Too
few activation candidates are unfriendly for outlier significant weight channel
quantization, and the discretized features prevent stable learning over
different time steps of the diffusion model. This paper presents MPQ-DM, a
Mixed-Precision Quantization method for Diffusion Models. The proposed MPQ-DM
mainly relies on two techniques:(1) To mitigate the quantization error caused
by outlier severe weight channels, we propose an Outlier-Driven Mixed
Quantization (OMQ) technique that uses $Kurtosis$ to quantify outlier salient
channels and apply optimized intra-layer mixed-precision bit-width allocation
to recover accuracy performance within target efficiency.(2) To robustly learn
representations crossing time steps, we construct a Time-Smoothed Relation
Distillation (TRD) scheme between the quantized diffusion model and its
full-precision counterpart, transferring discrete and continuous latent to a
unified relation space to reduce the representation inconsistency.
Comprehensive experiments demonstrate that MPQ-DM achieves significant accuracy
gains under extremely low bit-widths compared with SOTA quantization methods.
MPQ-DM achieves a 58\% FID decrease under W2A4 setting compared with baseline,
while all other methods even collapse.",2024-12-16,"Weilun Feng, Haotong Qin, Chuanguang Yang, Zhulin An, Libo Huang, Boyu Diao, Fei Wang, Renshuai Tao, Yongjun Xu, Michele Magno"
Meta Curvature-Aware Minimization for Domain Generalization,"Domain generalization (DG) aims to enhance the ability of models trained on
source domains to generalize effectively to unseen domains. Recently,
Sharpness-Aware Minimization (SAM) has shown promise in this area by reducing
the sharpness of the loss landscape to obtain more generalized models. However,
SAM and its variants sometimes fail to guide the model toward a flat minimum,
and their training processes exhibit limitations, hindering further
improvements in model generalization. In this paper, we first propose an
improved model training process aimed at encouraging the model to converge to a
flat minima. To achieve this, we design a curvature metric that has a minimal
effect when the model is far from convergence but becomes increasingly
influential in indicating the curvature of the minima as the model approaches a
local minimum. Then we derive a novel algorithm from this metric, called Meta
Curvature-Aware Minimization (MeCAM), to minimize the curvature around the
local minima. Specifically, the optimization objective of MeCAM simultaneously
minimizes the regular training loss, the surrogate gap of SAM, and the
surrogate gap of meta-learning. We provide theoretical analysis on MeCAM's
generalization error and convergence rate, and demonstrate its superiority over
existing DG methods through extensive experiments on five benchmark DG
datasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code
will be available on GitHub.",2024-12-16,"Ziyang Chen, Yiwen Ye, Feilong Tang, Yongsheng Pan, Yong Xia"
SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer,"In 3D understanding, point transformers have yielded significant advances in
broadening the receptive field. However, further enhancement of the receptive
field is hindered by the constraints of grouping attention. The proxy-based
model, as a hot topic in image and language feature extraction, uses global or
local proxies to expand the model's receptive field. But global proxy-based
methods fail to precisely determine proxy positions and are not suited for
tasks like segmentation and detection in the point cloud, and exist local
proxy-based methods for image face difficulties in global-local balance, proxy
sampling in various point clouds, and parallel cross-attention computation for
sparse association. In this paper, we present SP$^2$T, a local proxy-based dual
stream point transformer, which promotes global receptive field while
maintaining a balance between local and global information. To tackle robust 3D
proxy sampling, we propose a spatial-wise proxy sampling with vertex-based
point proxy associations, ensuring robust point-cloud sampling in many scales
of point cloud. To resolve economical association computation, we introduce
sparse proxy attention combined with table-based relative bias, which enables
low-cost and precise interactions between proxy and point features.
Comprehensive experiments across multiple datasets reveal that our model
achieves SOTA performance in downstream tasks. The code has been released in
https://github.com/TerenceWallel/Sparse-Proxy-Point-Transformer .",2024-12-16,"Jiaxu Wan, Hong Zhang, Ziqi He, Qishu Wang, Ding Yuan, Yifan Yang"
Towards a Speech Foundation Model for Singapore and Beyond,"This technical report describes the MERaLiON Speech Encoder, a foundation
model designed to support a wide range of downstream speech applications.
Developed as part of Singapore's National Multimodal Large Language Model
Programme, the MERaLiON Speech Encoder is tailored to address the speech
processing needs in Singapore and the surrounding Southeast Asian region. The
model currently supports mainly English, including the variety spoken in
Singapore. We are actively expanding our datasets to gradually cover other
languages in subsequent releases. The MERaLiON Speech Encoder was pre-trained
from scratch on 200K hours of unlabelled speech data using a self-supervised
learning approach based on masked language modelling. We describe our training
procedure and hyperparameter tuning experiments in detail below. Our evaluation
demonstrates improvements to spontaneous and Singapore speech benchmarks for
speech recognition, while remaining competitive to other state-of-the-art
speech encoders across ten other speech tasks. We commit to releasing our
model, supporting broader research endeavours, both in Singapore and beyond.",2024-12-16,"Muhammad Huzaifah, Tianchi Liu, Hardik B. Sailor, Kye Min Tan, Tarun K. Vangani, Qiongqiong Wang, Jeremy H. M. Wong, Nancy F. Chen, Ai Ti Aw"
"Near Large Far Small: Relative Distance Based Partition Learning for
  UAV-view Geo-Localization","UAV-view Geo-Localization (UVGL) presents substantial challenges, primarily
due to appearance differences between drone-view and satellite-view. Existing
methods develop partition learning strategies aimed at mining more
comprehensive information by constructing diverse part-level feature
representations, which rely on consistent cross-view scales. However,
variations of UAV flight state leads to the scale mismatch of cross-views,
resulting in serious performance degradation of partition-based methods. To
overcome this issue, we propose a partition learning framework based on
relative distance, which alleviates the dependence on scale consistency while
mining fine-grained features. Specifically, we propose a distance guided
dynamic partition learning strategy (DGDPL), consisting of a square partition
strategy and a dynamic-guided adjustment strategy. The former is utilized to
extract fine-grained features and global features in a simple manner. The
latter calculates the relative distance ratio between drone- and satellite-view
to adjust the partition size, thereby aligning the semantic information between
partition pairs. Furthermore, we propose a saliency-guided refinement strategy
to refine part-level features, so as to further improve the retrieval accuracy.
Extensive experiments show that our approach achieves superior geo-localization
accuracy across various scale-inconsistent scenarios, and exhibits remarkable
robustness against scale variations. The code will be released.",2024-12-16,"Quan Chen, Tingyu Wang, Rongfeng Lu, Bolun Zheng, Zhedong Zheng, Chenggang Yan"
"Cross-View Geo-Localization with Street-View and VHR Satellite Imagery
  in Decentrality Settings","Cross-View Geo-Localization tackles the problem of image geo-localization in
GNSS-denied environments by matching street-view query images with geo-tagged
aerial-view reference images. However, existing datasets and methods often
assume center-aligned settings or only consider limited decentrality (i.e., the
offset of the query image from the reference image center). This assumption
overlooks the challenges present in real-world applications, where large
decentrality can significantly enhance localization efficiency but
simultaneously lead to a substantial degradation in localization accuracy. To
address this limitation, we introduce CVSat, a novel dataset designed to
evaluate cross-view geo-localization with a large geographic scope and diverse
landscapes, emphasizing the decentrality issue. Meanwhile, we propose AuxGeo
(Auxiliary Enhanced Geo-Localization), which leverages a multi-metric
optimization strategy with two novel modules: the Bird's-eye view Intermediary
Module (BIM) and the Position Constraint Module (PCM). BIM uses bird's-eye view
images derived from street-view panoramas as an intermediary, simplifying the
cross-view challenge with decentrality to a cross-view problem and a
decentrality problem. PCM leverages position priors between cross-view images
to establish multi-grained alignment constraints. These modules improve the
performance of cross-view geo-localization with the decentrality problem.
Extensive experiments demonstrate that AuxGeo outperforms previous methods on
our proposed CVSat dataset, mitigating the issue of large decentrality, and
also achieves state-of-the-art performance on existing public datasets such as
CVUSA, CVACT, and VIGOR.",2024-12-16,"Panwang Xia, Lei Yu, Yi Wan, Qiong Wu, Peiqi Chen, Liheng Zhong, Yongxiang Yao, Dong Wei, Xinyi Liu, Lixiang Ru, Yingying Zhang, Jiangwei Lao, Jingdong Chen, Ming Yang, Yongjun Zhang"
ON as ALC: Active Loop Closing Object Goal Navigation,"In simultaneous localization and mapping, active loop closing (ALC) is an
active vision problem that aims to visually guide a robot to maximize the
chances of revisiting previously visited points, thereby resetting the drift
errors accumulated in the incrementally built map during travel. However,
current mainstream navigation strategies that leverage such incomplete maps as
workspace prior knowledge often fail in modern long-term autonomy long-distance
travel scenarios where map accumulation errors become significant. To address
these limitations of map-based navigation, this paper is the first to explore
mapless navigation in the embodied AI field, in particular, to utilize
object-goal navigation (commonly abbreviated as ON, ObjNav, or OGN) techniques
that efficiently explore target objects without using such a prior map.
Specifically, in this work, we start from an off-the-shelf mapless ON planner,
extend it to utilize a prior map, and further show that the performance in
long-distance ALC (LD-ALC) can be maximized by minimizing ``ALC loss"" and ``ON
loss"". This study highlights a simple and effective approach, called ALC-ON
(ALCON), to accelerate the progress of challenging long-distance ALC technology
by leveraging the growing frontier-guided, data-driven, and LLM-guided ON
technologies.",2024-12-16,"Daiki Iwata, Kanji Tanaka, Shoya Miyazaki, Kouki Terashima"
"On the Ability of Deep Networks to Learn Symmetries from Data: A Neural
  Kernel Theory","Symmetries (transformations by group actions) are present in many datasets,
and leveraging them holds significant promise for improving predictions in
machine learning. In this work, we aim to understand when and how deep networks
can learn symmetries from data. We focus on a supervised classification
paradigm where data symmetries are only partially observed during training:
some classes include all transformations of a cyclic group, while others
include only a subset. We ask: can deep networks generalize symmetry invariance
to the partially sampled classes? In the infinite-width limit, where kernel
analogies apply, we derive a neural kernel theory of symmetry learning to
address this question. The group-cyclic nature of the dataset allows us to
analyze the spectrum of neural kernels in the Fourier domain; here we find a
simple characterization of the generalization error as a function of the
interaction between class separation (signal) and class-orbit density (noise).
We observe that generalization can only be successful when the local structure
of the data prevails over its non-local, symmetric, structure, in the kernel
space defined by the architecture. This occurs when (1) classes are
sufficiently distinct and (2) class orbits are sufficiently dense. Our
framework also applies to equivariant architectures (e.g., CNNs), and recovers
their success in the special case where the architecture matches the inherent
symmetry of the data. Empirically, our theory reproduces the generalization
failure of finite-width networks (MLP, CNN, ViT) trained on partially observed
versions of rotated-MNIST. We conclude that conventional networks trained with
supervision lack a mechanism to learn symmetries that have not been explicitly
embedded in their architecture a priori. Our framework could be extended to
guide the design of architectures and training procedures able to learn
symmetries from data.",2024-12-16,"Andrea Perin, Stephane Deny"
"SpatialMe: Stereo Video Conversion Using Depth-Warping and
  Blend-Inpainting","Stereo video conversion aims to transform monocular videos into immersive
stereo format. Despite the advancements in novel view synthesis, it still
remains two major challenges: i) difficulty of achieving high-fidelity and
stable results, and ii) insufficiency of high-quality stereo video data. In
this paper, we introduce SpatialMe, a novel stereo video conversion framework
based on depth-warping and blend-inpainting. Specifically, we propose a
mask-based hierarchy feature update (MHFU) refiner, which integrate and refine
the outputs from designed multi-branch inpainting module, using feature update
unit (FUU) and mask mechanism. We also propose a disparity expansion strategy
to address the problem of foreground bleeding. Furthermore, we conduct a
high-quality real-world stereo video dataset -- StereoV1K, to alleviate the
data shortage. It contains 1000 stereo videos captured in real-world at a
resolution of 1180 x 1180, covering various indoor and outdoor scenes.
Extensive experiments demonstrate the superiority of our approach in generating
stereo videos over state-of-the-art methods.",2024-12-16,"Jiale Zhang, Qianxi Jia, Yang Liu, Wei Zhang, Wei Wei, Xin Tian"
"Visual-Based Forklift Learning System Enabling Zero-Shot Sim2Real
  Without Real-World Data","Forklifts are used extensively in various industrial settings and are in high
demand for automation. In particular, counterbalance forklifts are highly
versatile and employed in diverse scenarios. However, efforts to automate these
processes are lacking, primarily owing to the absence of a safe and
performance-verifiable development environment. This study proposes a learning
system that combines a photorealistic digital learning environment with a
1/14-scale robotic forklift environment to address this challenge. Inspired by
the training-based learning approach adopted by forklift operators, we employ
an end-to-end vision-based deep reinforcement learning approach. The learning
is conducted in a digitalized environment created from CAD data, making it safe
and eliminating the need for real-world data. In addition, we safely validate
the method in a physical setting utilizing a 1/14-scale robotic forklift with a
configuration similar to that of a real forklift. We achieved a 60% success
rate in pallet loading tasks in real experiments using a robotic forklift. Our
approach demonstrates zero-shot sim2real with a simple method that does not
require heuristic additions. This learning-based approach is considered a first
step towards the automation of counterbalance forklifts.",2024-12-16,"Koshi Oishi, Teruki Kato, Hiroya Makino, Seigo Ito"
Exploring More from Multiple Gait Modalities for Human Identification,"The gait, as a kind of soft biometric characteristic, can reflect the
distinct walking patterns of individuals at a distance, exhibiting a promising
technique for unrestrained human identification. With largely excluding
gait-unrelated cues hidden in RGB videos, the silhouette and skeleton, though
visually compact, have acted as two of the most prevailing gait modalities for
a long time. Recently, several attempts have been made to introduce more
informative data forms like human parsing and optical flow images to capture
gait characteristics, along with multi-branch architectures. However, due to
the inconsistency within model designs and experiment settings, we argue that a
comprehensive and fair comparative study among these popular gait modalities,
involving the representational capacity and fusion strategy exploration, is
still lacking. From the perspectives of fine vs. coarse-grained shape and whole
vs. pixel-wise motion modeling, this work presents an in-depth investigation of
three popular gait representations, i.e., silhouette, human parsing, and
optical flow, with various fusion evaluations, and experimentally exposes their
similarities and differences. Based on the obtained insights, we further
develop a C$^2$Fusion strategy, consequently building our new framework
MultiGait++. C$^2$Fusion preserves commonalities while highlighting differences
to enrich the learning of gait features. To verify our findings and
conclusions, extensive experiments on Gait3D, GREW, CCPG, and SUSTech1K are
conducted. The code is available at https://github.com/ShiqiYu/OpenGait.",2024-12-16,"Dongyang Jin, Chao Fan, Weihua Chen, Shiqi Yu"
"HGSFusion: Radar-Camera Fusion with Hybrid Generation and
  Synchronization for 3D Object Detection","Millimeter-wave radar plays a vital role in 3D object detection for
autonomous driving due to its all-weather and all-lighting-condition
capabilities for perception. However, radar point clouds suffer from pronounced
sparsity and unavoidable angle estimation errors. To address these limitations,
incorporating a camera may partially help mitigate the shortcomings.
Nevertheless, the direct fusion of radar and camera data can lead to negative
or even opposite effects due to the lack of depth information in images and
low-quality image features under adverse lighting conditions. Hence, in this
paper, we present the radar-camera fusion network with Hybrid Generation and
Synchronization (HGSFusion), designed to better fuse radar potentials and image
features for 3D object detection. Specifically, we propose the Radar Hybrid
Generation Module (RHGM), which fully considers the Direction-Of-Arrival (DOA)
estimation errors in radar signal processing. This module generates denser
radar points through different Probability Density Functions (PDFs) with the
assistance of semantic information. Meanwhile, we introduce the Dual Sync
Module (DSM), comprising spatial sync and modality sync, to enhance image
features with radar positional information and facilitate the fusion of
distinct characteristics in different modalities. Extensive experiments
demonstrate the effectiveness of our approach, outperforming the
state-of-the-art methods in the VoD and TJ4DRadSet datasets by $6.53\%$ and
$2.03\%$ in RoI AP and BEV AP, respectively. The code is available at
https://github.com/garfield-cpp/HGSFusion.",2024-12-16,"Zijian Gu, Jianwei Ma, Yan Huang, Honghao Wei, Zhanye Chen, Hui Zhang, Wei Hong"
"Counting Butterflies over Streaming Bipartite Graphs with Duplicate
  Edges","Bipartite graphs are commonly used to model relationships between two
distinct entities in real-world applications, such as user-product
interactions, user-movie ratings and collaborations between authors and
publications. A butterfly (a 2x2 bi-clique) is a critical substructure in
bipartite graphs, playing a significant role in tasks like community detection,
fraud detection, and link prediction. As more real-world data is presented in a
streaming format, efficiently counting butterflies in streaming bipartite
graphs has become increasingly important. However, most existing algorithms
typically assume that duplicate edges are absent, which is hard to hold in
real-world graph streams, as a result, they tend to sample edges that appear
multiple times, leading to inaccurate results. The only algorithm designed to
handle duplicate edges is FABLE, but it suffers from significant limitations,
including high variance, substantial time complexity, and memory inefficiency
due to its reliance on a priority queue. To overcome these limitations, we
introduce DEABC (Duplicate-Edge-Aware Butterfly Counting), an innovative method
that uses bucket-based priority sampling to accurately estimate the number of
butterflies, accounting for duplicate edges. Compared to existing methods,
DEABC significantly reduces memory usage by storing only the essential sampled
edge data while maintaining high accuracy. We provide rigorous proofs of the
unbiasedness and variance bounds for DEABC, ensuring they achieve high
accuracy. We compare DEABC with state-of-the-art algorithms on real-world
streaming bipartite graphs. The results show that our DEABC outperforms
existing methods in memory efficiency and accuracy, while also achieving
significantly higher throughput.",2024-12-16,"Lingkai Meng, Long Yuan, Xuemin Lin, Chengjie Li, Kai Wang, Wenjie Zhang"
"Efficient Policy Adaptation with Contrastive Prompt Ensemble for
  Embodied Agents","For embodied reinforcement learning (RL) agents interacting with the
environment, it is desirable to have rapid policy adaptation to unseen visual
observations, but achieving zero-shot adaptation capability is considered as a
challenging problem in the RL context. To address the problem, we present a
novel contrastive prompt ensemble (ConPE) framework which utilizes a pretrained
vision-language model and a set of visual prompts, thus enabling efficient
policy learning and adaptation upon a wide range of environmental and physical
changes encountered by embodied agents. Specifically, we devise a
guided-attention-based ensemble approach with multiple visual prompts on the
vision-language model to construct robust state representations. Each prompt is
contrastively learned in terms of an individual domain factor that
significantly affects the agent's egocentric perception and observation. For a
given task, the attention-based ensemble and policy are jointly learned so that
the resulting state representations not only generalize to various domains but
are also optimized for learning the task. Through experiments, we show that
ConPE outperforms other state-of-the-art algorithms for several embodied agent
tasks including navigation in AI2THOR, manipulation in egocentric-Metaworld,
and autonomous driving in CARLA, while also improving the sample efficiency of
policy learning and adaptation.",2024-12-16,"Wonje Choi, Woo Kyung Kim, SeungHyun Kim, Honguk Woo"
"Wireless Environmental Information Theory: A New Paradigm towards 6G
  Online and Proactive Environment Intelligence Communication","The channel is one of the five critical components of a communication system,
and its ergodic capacity is based on all realizations of statistic channel
model. This statistical paradigm has successfully guided the design of mobile
communication systems from 1G to 5G. However, this approach relies on offline
channel measurements in specific environments, and the system passively adapts
to new environments, resulting in deviation from the optimal performance. With
the pursuit of higher capacity and data rate of 6G, especially facing the
ubiquitous environments, there is an urgent need for a new paradigm to combat
the randomness of channel, i.e., more proactive and online manner. Motivated by
this, we propose an environment intelligence communication (EIC) based on
wireless environmental information theory (WEIT) for 6G. The proposed EIC
architecture is composed of three steps: Firstly, wireless environmental
information (WEI) is acquired using sensing techniques. Then, leveraging WEI
and channel data, AI techniques are employed to predict channel fading, thereby
mitigating channel uncertainty. Thirdly, the communication system autonomously
determines the optimal air-interface transmission strategy based on real-time
channel predictions, enabling intelligent interaction with the physical
environment. To make this attractive paradigm shift from theory to practice, we
answer three key problems to establish WEIT for the first time. How should WEI
be defined? Can it be quantified? Does it hold the same properties as
statistical communication information? Furthermore, EIC aided by WEI (EIC-WEI)
is validated across multiple air-interface tasks, including CSI prediction,
beam prediction, and radio resource management. Simulation results demonstrate
that the proposed EIC-WEI significantly outperforms the statistical paradigm in
decreasing overhead and performance optimization.",2024-12-16,"Jianhua Zhang, Li Yu, Shaoyi Liu, Yichen Cai, Yuxiang Zhang, Hongbo Xing, Tao jiang"
"NoteContrast: Contrastive Language-Diagnostic Pretraining for Medical
  Text","Accurate diagnostic coding of medical notes is crucial for enhancing patient
care, medical research, and error-free billing in healthcare organizations.
Manual coding is a time-consuming task for providers, and diagnostic codes
often exhibit low sensitivity and specificity, whereas the free text in medical
notes can be a more precise description of a patients status. Thus, accurate
automated diagnostic coding of medical notes has become critical for a learning
healthcare system. Recent developments in long-document transformer
architectures have enabled attention-based deep-learning models to adjudicate
medical notes. In addition, contrastive loss functions have been used to
jointly pre-train large language and image models with noisy labels. To further
improve the automated adjudication of medical notes, we developed an approach
based on i) models for ICD-10 diagnostic code sequences using a large
real-world data set, ii) large language models for medical notes, and iii)
contrastive pre-training to build an integrated model of both ICD-10 diagnostic
codes and corresponding medical text. We demonstrate that a contrastive
approach for pre-training improves performance over prior state-of-the-art
models for the MIMIC-III-50, MIMIC-III-rare50, and MIMIC-III-full diagnostic
coding tasks.",2024-12-16,"Prajwal Kailas, Max Homilius, Rahul C. Deo, Calum A. MacRae"
Neural Double Auction Mechanism,"Mechanism design, a branch of economics, aims to design rules that can
autonomously achieve desired outcomes in resource allocation and public
decision making. The research on mechanism design using machine learning is
called automated mechanism design or mechanism learning. In our research, we
constructed a new network based on the existing method for single auctions and
aimed to automatically design a mechanism by applying it to double auctions. In
particular, we focused on the following four desirable properties for the
mechanism: individual rationality, balanced budget, Pareto efficiency, and
incentive compatibility. We conducted experiments assuming a small-scale double
auction and clarified how deterministic the trade matching of the obtained
mechanism is. We also confirmed how much the learnt mechanism satisfies the
four properties compared to two representative protocols. As a result, we
verified that the mechanism is more budget-balanced than the VCG protocol and
more economically efficient than the MD protocol, with the incentive
compatibility mostly guaranteed.",2024-12-16,"Tsuyoshi Suehara, Koh Takeuchi, Hisashi Kashima, Satoshi Oyama, Yuko Sakurai, Makoto Yokoo"
Unsupervised Anomaly Detection for Tabular Data Using Noise Evaluation,"Unsupervised anomaly detection (UAD) plays an important role in modern data
analytics and it is crucial to provide simple yet effective and guaranteed UAD
algorithms for real applications. In this paper, we present a novel UAD method
for tabular data by evaluating how much noise is in the data. Specifically, we
propose to learn a deep neural network from the clean (normal) training dataset
and a noisy dataset, where the latter is generated by adding highly diverse
noises to the clean data. The neural network can learn a reliable decision
boundary between normal data and anomalous data when the diversity of the
generated noisy data is sufficiently high so that the hard abnormal samples lie
in the noisy region. Importantly, we provide theoretical guarantees, proving
that the proposed method can detect anomalous data successfully, although the
method does not utilize any real anomalous data in the training stage.
Extensive experiments through more than 60 benchmark datasets demonstrate the
effectiveness of the proposed method in comparison to 12 baselines of UAD. Our
method obtains a 92.27\% AUC score and a 1.68 ranking score on average.
Moreover, compared to the state-of-the-art UAD methods, our method is easier to
implement.",2024-12-16,"Wei Dai, Kai Hwang, Jicong Fan"
"HResFormer: Hybrid Residual Transformer for Volumetric Medical Image
  Segmentation","Vision Transformer shows great superiority in medical image segmentation due
to the ability in learning long-range dependency. For medical image
segmentation from 3D data, such as computed tomography (CT), existing methods
can be broadly classified into 2D-based and 3D-based methods. One key
limitation in 2D-based methods is that the intra-slice information is ignored,
while the limitation in 3D-based methods is the high computation cost and
memory consumption, resulting in a limited feature representation for
inner-slice information. During the clinical examination, radiologists
primarily use the axial plane and then routinely review both axial and coronal
planes to form a 3D understanding of anatomy. Motivated by this fact, our key
insight is to design a hybrid model which can first learn fine-grained
inner-slice information and then generate a 3D understanding of anatomy by
incorporating 3D information. We present a novel \textbf{H}ybrid
\textbf{Res}idual trans\textbf{Former} \textbf{(HResFormer)} for 3D medical
image segmentation. Building upon standard 2D and 3D Transformer backbones,
HResFormer involves two novel key designs: \textbf{(1)} a \textbf{H}ybrid
\textbf{L}ocal-\textbf{G}lobal fusion \textbf{M}odule \textbf{(HLGM)} to
effectively and adaptively fuse inner-slice information from 2D Transformer and
intra-slice information from 3D volumes for 3D Transformer with local
fine-grained and global long-range representation. \textbf{(2)} a residual
learning of the hybrid model, which can effectively leverage the inner-slice
and intra-slice information for better 3D understanding of anatomy. Experiments
show that our HResFormer outperforms prior art on widely-used medical image
segmentation benchmarks. This paper sheds light on an important but neglected
way to design Transformers for 3D medical image segmentation.",2024-12-16,"Sucheng Ren, Xiaomeng Li"
"GroupFace: Imbalanced Age Estimation Based on Multi-hop Attention Graph
  Convolutional Network and Group-aware Margin Optimization","With the recent advances in computer vision, age estimation has significantly
improved in overall accuracy. However, owing to the most common methods do not
take into account the class imbalance problem in age estimation datasets, they
suffer from a large bias in recognizing long-tailed groups. To achieve
high-quality imbalanced learning in long-tailed groups, the dominant solution
lies in that the feature extractor learns the discriminative features of
different groups and the classifier is able to provide appropriate and unbiased
margins for different groups by the discriminative features. Therefore, in this
novel, we propose an innovative collaborative learning framework (GroupFace)
that integrates a multi-hop attention graph convolutional network and a dynamic
group-aware margin strategy based on reinforcement learning. Specifically, to
extract the discriminative features of different groups, we design an enhanced
multi-hop attention graph convolutional network. This network is capable of
capturing the interactions of neighboring nodes at different distances, fusing
local and global information to model facial deep aging, and exploring diverse
representations of different groups. In addition, to further address the class
imbalance problem, we design a dynamic group-aware margin strategy based on
reinforcement learning to provide appropriate and unbiased margins for
different groups. The strategy divides the sample into four age groups and
considers identifying the optimum margins for various age groups by employing a
Markov decision process. Under the guidance of the agent, the feature
representation bias and the classification margin deviation between different
groups can be reduced simultaneously, balancing inter-class separability and
intra-class proximity. After joint optimization, our architecture achieves
excellent performance on several age estimation benchmark datasets.",2024-12-16,"Yiping Zhang, Yuntao Shou, Wei Ai, Tao Meng, Keqin Li"
"Universal Domain Adaptive Object Detection via Dual Probabilistic
  Alignment","Domain Adaptive Object Detection (DAOD) transfers knowledge from a labeled
source domain to an unannotated target domain under closed-set assumption.
Universal DAOD (UniDAOD) extends DAOD to handle open-set, partial-set, and
closed-set domain adaptation. In this paper, we first unveil two issues:
domain-private category alignment is crucial for global-level features, and the
domain probability heterogeneity of features across different levels. To
address these issues, we propose a novel Dual Probabilistic Alignment (DPA)
framework to model domain probability as Gaussian distribution, enabling the
heterogeneity domain distribution sampling and measurement. The DPA consists of
three tailored modules: the Global-level Domain Private Alignment (GDPA), the
Instance-level Domain Shared Alignment (IDSA), and the Private Class Constraint
(PCC). GDPA utilizes the global-level sampling to mine domain-private category
samples and calculate alignment weight through a cumulative distribution
function to address the global-level private category alignment. IDSA utilizes
instance-level sampling to mine domain-shared category samples and calculates
alignment weight through Gaussian distribution to conduct the domain-shared
category domain alignment to address the feature heterogeneity. The PCC
aggregates domain-private category centroids between feature and probability
spaces to mitigate negative transfer. Extensive experiments demonstrate that
our DPA outperforms state-of-the-art UniDAOD and DAOD methods across various
datasets and scenarios, including open, partial, and closed sets. Codes are
available at \url{https://github.com/zyfone/DPA}.",2024-12-16,"Yuanfan Zheng, Jinlin Wu, Wuyang Li, Zhen Chen"
"UIBDiffusion: Universal Imperceptible Backdoor Attack for Diffusion
  Models","Recent studies show that diffusion models (DMs) are vulnerable to backdoor
attacks. Existing backdoor attacks impose unconcealed triggers (e.g., a gray
box and eyeglasses) that contain evident patterns, rendering remarkable attack
effects yet easy detection upon human inspection and defensive algorithms.
While it is possible to improve stealthiness by reducing the strength of the
backdoor, doing so can significantly compromise its generality and
effectiveness. In this paper, we propose UIBDiffusion, the universal
imperceptible backdoor attack for diffusion models, which allows us to achieve
superior attack and generation performance while evading state-of-the-art
defenses. We propose a novel trigger generation approach based on universal
adversarial perturbations (UAPs) and reveal that such perturbations, which are
initially devised for fooling pre-trained discriminative models, can be adapted
as potent imperceptible backdoor triggers for DMs. We evaluate UIBDiffusion on
multiple types of DMs with different kinds of samplers across various datasets
and targets. Experimental results demonstrate that UIBDiffusion brings three
advantages: 1) Universality, the imperceptible trigger is universal (i.e.,
image and model agnostic) where a single trigger is effective to any images and
all diffusion models with different samplers; 2) Utility, it achieves
comparable generation quality (e.g., FID) and even better attack success rate
(i.e., ASR) at low poison rates compared to the prior works; and 3)
Undetectability, UIBDiffusion is plausible to human perception and can bypass
Elijah and TERD, the SOTA defenses against backdoors for DMs. We will release
our backdoor triggers and code.",2024-12-16,"Yuning Han, Bingyin Zhao, Rui Chu, Feng Luo, Biplab Sikdar, Yingjie Lao"
Auto-bidding in real-time auctions via Oracle Imitation Learning (OIL),"Online advertising has become one of the most successful business models of
the internet era. Impression opportunities are typically allocated through
real-time auctions, where advertisers bid to secure advertisement slots.
Deciding the best bid for an impression opportunity is challenging, due to the
stochastic nature of user behavior and the variability of advertisement traffic
over time. In this work, we propose a framework for training auto-bidding
agents in multi-slot second-price auctions to maximize acquisitions (e.g.,
clicks, conversions) while adhering to budget and cost-per-acquisition (CPA)
constraints. We exploit the insight that, after an advertisement campaign
concludes, determining the optimal bids for each impression opportunity can be
framed as a multiple-choice knapsack problem (MCKP) with a nonlinear objective.
We propose an ""oracle"" algorithm that identifies a near-optimal combination of
impression opportunities and advertisement slots, considering both past and
future advertisement traffic data. This oracle solution serves as a training
target for a student network which bids having access only to real-time
information, a method we term Oracle Imitation Learning (OIL). Through
numerical experiments, we demonstrate that OIL achieves superior performance
compared to both online and offline reinforcement learning algorithms, offering
improved sample efficiency. Notably, OIL shifts the complexity of training
auto-bidding agents from crafting sophisticated learning algorithms to solving
a nonlinear constrained optimization problem efficiently.",2024-12-16,"Alberto Silvio Chiappa, Briti Gangopadhyay, Zhao Wang, Shingo Takamatsu"
"View Transformation Robustness for Multi-View 3D Object Reconstruction
  with Reconstruction Error-Guided View Selection","View transformation robustness (VTR) is critical for deep-learning-based
multi-view 3D object reconstruction models, which indicates the methods'
stability under inputs with various view transformations. However, existing
research seldom focused on view transformation robustness in multi-view 3D
object reconstruction. One direct way to improve the models' VTR is to produce
data with more view transformations and add them to model training. Recent
progress on large vision models, particularly Stable Diffusion models, has
provided great potential for generating 3D models or synthesizing novel view
images with only a single image input. Directly deploying these models at
inference consumes heavy computation resources and their robustness to view
transformations is not guaranteed either. To fully utilize the power of Stable
Diffusion models without extra inference computation burdens, we propose to
generate novel views with Stable Diffusion models for better view
transformation robustness. Instead of synthesizing random views, we propose a
reconstruction error-guided view selection method, which considers the
reconstruction errors' spatial distribution of the 3D predictions and chooses
the views that could cover the reconstruction errors as much as possible. The
methods are trained and tested on sets with large view transformations to
validate the 3D reconstruction models' robustness to view transformations.
Extensive experiments demonstrate that the proposed method can outperform
state-of-the-art 3D reconstruction methods and other view transformation
robustness comparison methods.",2024-12-16,"Qi Zhang, Zhouhang Luo, Tao Yu, Hui Huang"
"From Automation to Cognition: Redefining the Roles of Educators and
  Generative AI in Computing Education","Generative Artificial Intelligence (GenAI) offers numerous opportunities to
revolutionise teaching and learning in Computing Education (CE). However,
educators have expressed concerns that students may over-rely on GenAI and use
these tools to generate solutions without engaging in the learning process.
While substantial research has explored GenAI use in CE, and many Computer
Science (CS) educators have expressed their opinions and suggestions on the
subject, there remains little consensus on implementing curricula and
assessment changes. In this paper, we describe our experiences with using GenAI
in CS-focused educational settings and the changes we have implemented
accordingly in our teaching in recent years since the popularisation of GenAI.
From our experiences, we propose two primary actions for the CE community: 1)
redesign take-home assignments to incorporate GenAI use and assess students on
their process of using GenAI to solve a task rather than simply on the final
product; 2) redefine the role of educators to emphasise metacognitive aspects
of learning, such as critical thinking and self-evaluation. This paper presents
and discusses these stances and outlines several practical methods to implement
these strategies in CS classrooms. Then, we advocate for more research
addressing the concrete impacts of GenAI on CE, especially those evaluating the
validity and effectiveness of new teaching practices.",2024-12-16,"Tony Haoran Feng, Andrew Luxton-Reilly, Burkhard C. Wünsche, Paul Denny"
"RL-LLM-DT: An Automatic Decision Tree Generation Method Based on RL
  Evaluation and LLM Enhancement","Traditionally, AI development for two-player zero-sum games has relied on two
primary techniques: decision trees and reinforcement learning (RL). A common
approach involves using a fixed decision tree as one player's strategy while
training an RL agent as the opponent to identify vulnerabilities in the
decision tree, thereby improving its strategic strength iteratively. However,
this process often requires significant human intervention to refine the
decision tree after identifying its weaknesses, resulting in inefficiencies and
hindering full automation of the strategy enhancement process. Fortunately, the
advent of Large Language Models (LLMs) offers a transformative opportunity to
automate the process. We propose RL-LLM-DT, an automatic decision tree
generation method based on RL Evaluation and LLM Enhancement. Given an initial
decision tree, the method involves two important iterative steps. Response
Policy Search: RL is used to discover counter-strategies targeting the decision
tree. Policy Improvement: LLMs analyze failure scenarios and generate improved
decision tree code. In our method, RL focuses on finding the decision tree's
flaws while LLM is prompted to generate an improved version of the decision
tree. The iterative refinement process terminates when RL can't find any flaw
of the tree or LLM fails to improve the tree. To evaluate the effectiveness of
this integrated approach, we conducted experiments in a curling game. After
iterative refinements, our curling AI based on the decision tree ranks first on
the Jidi platform among 34 curling AIs in total, which demonstrates that LLMs
can significantly enhance the robustness and adaptability of decision trees,
representing a substantial advancement in the field of Game AI. Our code is
available at https://github.com/Linjunjie99/RL-LLM-DT.",2024-12-16,"Junjie Lin, Jian Zhao, Lin Liu, Yue Deng, Youpeng Zhao, Lanxiao Huang, Xia Lin, Wengang Zhou, Houqiang Li"
"Biased or Flawed? Mitigating Stereotypes in Generative Language Models
  by Addressing Task-Specific Flaws","Recent studies have shown that generative language models often reflect and
amplify societal biases in their outputs. However, these studies frequently
conflate observed biases with other task-specific shortcomings, such as
comprehension failure. For example, when a model misinterprets a text and
produces a response that reinforces a stereotype, it becomes difficult to
determine whether the issue arises from inherent bias or from a
misunderstanding of the given content. In this paper, we conduct a
multi-faceted evaluation that distinctly disentangles bias from flaws within
the reading comprehension task. We propose a targeted stereotype mitigation
framework that implicitly mitigates observed stereotypes in generative models
through instruction-tuning on general-purpose datasets. We reduce stereotypical
outputs by over 60% across multiple dimensions -- including nationality, age,
gender, disability, and physical appearance -- by addressing
comprehension-based failures, and without relying on explicit debiasing
techniques. We evaluate several state-of-the-art generative models to
demonstrate the effectiveness of our approach while maintaining the overall
utility. Our findings highlight the need to critically disentangle the concept
of `bias' from other types of errors to build more targeted and effective
mitigation strategies. CONTENT WARNING: Some examples contain offensive
stereotypes.",2024-12-16,"Akshita Jha, Sanchit Kabra, Chandan K. Reddy"
"V-MIND: Building Versatile Monocular Indoor 3D Detector with Diverse 2D
  Annotations","The field of indoor monocular 3D object detection is gaining significant
attention, fueled by the increasing demand in VR/AR and robotic applications.
However, its advancement is impeded by the limited availability and diversity
of 3D training data, owing to the labor-intensive nature of 3D data collection
and annotation processes. In this paper, we present V-MIND (Versatile Monocular
INdoor Detector), which enhances the performance of indoor 3D detectors across
a diverse set of object classes by harnessing publicly available large-scale 2D
datasets. By leveraging well-established monocular depth estimation techniques
and camera intrinsic predictors, we can generate 3D training data by converting
large-scale 2D images into 3D point clouds and subsequently deriving pseudo 3D
bounding boxes. To mitigate distance errors inherent in the converted point
clouds, we introduce a novel 3D self-calibration loss for refining the pseudo
3D bounding boxes during training. Additionally, we propose a novel ambiguity
loss to address the ambiguity that arises when introducing new classes from 2D
datasets. Finally, through joint training with existing 3D datasets and pseudo
3D bounding boxes derived from 2D datasets, V-MIND achieves state-of-the-art
object detection performance across a wide range of classes on the Omni3D
indoor dataset.",2024-12-16,"Jin-Cheng Jhang, Tao Tu, Fu-En Wang, Ke Zhang, Min Sun, Cheng-Hao Kuo"
"MGDA: Model-based Goal Data Augmentation for Offline Goal-conditioned
  Weighted Supervised Learning","Recently, a state-of-the-art family of algorithms, known as Goal-Conditioned
Weighted Supervised Learning (GCWSL) methods, has been introduced to tackle
challenges in offline goal-conditioned reinforcement learning (RL). GCWSL
optimizes a lower bound of the goal-conditioned RL objective and has
demonstrated outstanding performance across diverse goal-reaching tasks,
providing a simple, effective, and stable solution. However, prior research has
identified a critical limitation of GCWSL: the lack of trajectory stitching
capabilities. To address this, goal data augmentation strategies have been
proposed to enhance these methods. Nevertheless, existing techniques often
struggle to sample suitable augmented goals for GCWSL effectively. In this
paper, we establish unified principles for goal data augmentation, focusing on
goal diversity, action optimality, and goal reachability. Based on these
principles, we propose a Model-based Goal Data Augmentation (MGDA) approach,
which leverages a learned dynamics model to sample more suitable augmented
goals. MGDA uniquely incorporates the local Lipschitz continuity assumption
within the learned model to mitigate the impact of compounding errors.
Empirical results show that MGDA significantly enhances the performance of
GCWSL methods on both state-based and vision-based maze datasets, surpassing
previous goal data augmentation techniques in improving stitching capabilities.",2024-12-16,"Xing Lei, Xuetao Zhang, Donglin Wang"
"Federated Domain Generalization with Label Smoothing and Balanced
  Decentralized Training","In this paper, we propose a novel approach, Federated Domain Generalization
with Label Smoothing and Balanced Decentralized Training (FedSB), to address
the challenges of data heterogeneity within a federated learning framework.
FedSB utilizes label smoothing at the client level to prevent overfitting to
domain-specific features, thereby enhancing generalization capabilities across
diverse domains when aggregating local models into a global model.
Additionally, FedSB incorporates a decentralized budgeting mechanism which
balances training among clients, which is shown to improve the performance of
the aggregated global model. Extensive experiments on four commonly used
multi-domain datasets, PACS, VLCS, OfficeHome, and TerraInc, demonstrate that
FedSB outperforms competing methods, achieving state-of-the-art results on
three out of four datasets, indicating the effectiveness of FedSB in addressing
data heterogeneity.",2024-12-16,"Milad Soltany, Farhad Pourpanah, Mahdiyar Molahasani, Michael Greenspan, Ali Etemad"
Modeling Inter-Intra Heterogeneity for Graph Federated Learning,"Heterogeneity is a fundamental and challenging issue in federated learning,
especially for the graph data due to the complex relationships among the graph
nodes. To deal with the heterogeneity, lots of existing methods perform the
weighted federation based on their calculated similarities between pairwise
clients (i.e., subgraphs). However, their inter-subgraph similarities estimated
with the outputs of local models are less reliable, because the final outputs
of local models may not comprehensively represent the real distribution of
subgraph data. In addition, they ignore the critical intra-heterogeneity which
usually exists within each subgraph itself. To address these issues, we propose
a novel Federated learning method by integrally modeling the Inter-Intra
Heterogeneity (FedIIH). For the inter-subgraph relationship, we propose a novel
hierarchical variational model to infer the whole distribution of subgraph data
in a multi-level form, so that we can accurately characterize the
inter-subgraph similarities with the global perspective. For the
intra-heterogeneity, we disentangle the subgraph into multiple latent factors
and partition the model parameters into multiple parts, where each part
corresponds to a single latent factor. Our FedIIH not only properly computes
the distribution similarities between subgraphs, but also learns disentangled
representations that are robust to irrelevant factors within subgraphs, so that
it successfully considers the inter- and intra- heterogeneity simultaneously.
Extensive experiments on six homophilic and five heterophilic graph datasets in
both non-overlapping and overlapping settings demonstrate the effectiveness of
our method when compared with nine state-of-the-art methods. Specifically,
FedIIH averagely outperforms the second-best method by a large margin of 5.79%
on all heterophilic datasets.",2024-12-16,"Wentao Yu, Shuo Chen, Yongxin Tong, Tianlong Gu, Chen Gong"
"Quantization of Climate Change Impacts on Renewable Energy Generation
  Capacity: A Super-Resolution Recurrent Diffusion Model","Driven by global climate change and the ongoing energy transition, the
coupling between power supply capabilities and meteorological factors has
become increasingly significant. Over the long term, accurately quantifying the
power generation capacity of renewable energy under the influence of climate
change is essential for the development of sustainable power systems. However,
due to interdisciplinary differences in data requirements, climate data often
lacks the necessary hourly resolution to capture the short-term variability and
uncertainties of renewable energy resources. To address this limitation, a
super-resolution recurrent diffusion model (SRDM) has been developed to enhance
the temporal resolution of climate data and model the short-term uncertainty.
The SRDM incorporates a pre-trained decoder and a denoising network, that
generates long-term, high-resolution climate data through a recurrent coupling
mechanism. The high-resolution climate data is then converted into power value
using the mechanism model, enabling the simulation of wind and photovoltaic
(PV) power generation capacity on future long-term scales. Case studies were
conducted in the Ejina region of Inner Mongolia, China, using fifth-generation
reanalysis (ERA5) and coupled model intercomparison project (CMIP6) data under
two climate pathways: SSP126 and SSP585. The results demonstrate that the SRDM
outperforms existing generative models in generating super-resolution climate
data. For the Ejina region, under a high-emission pathway, the annual
utilization hours of wind power are projected to decrease by 2.82 hours/year,
while those for PV power are projected to decrease by 0.26 hours/year.
Furthermore, the research highlights the estimation biases introduced when
low-resolution climate data is used for power conversion.",2024-12-16,"Xiaochong Dong, Jun Dan, Yingyun Sun, Yang Liu, Xuemin Zhang, Shengwei Mei"
Relation-Guided Adversarial Learning for Data-free Knowledge Transfer,"Data-free knowledge distillation transfers knowledge by recovering training
data from a pre-trained model. Despite the recent success of seeking global
data diversity, the diversity within each class and the similarity among
different classes are largely overlooked, resulting in data homogeneity and
limited performance. In this paper, we introduce a novel Relation-Guided
Adversarial Learning method with triplet losses, which solves the homogeneity
problem from two aspects. To be specific, our method aims to promote both
intra-class diversity and inter-class confusion of the generated samples. To
this end, we design two phases, an image synthesis phase and a student training
phase. In the image synthesis phase, we construct an optimization process to
push away samples with the same labels and pull close samples with different
labels, leading to intra-class diversity and inter-class confusion,
respectively. Then, in the student training phase, we perform an opposite
optimization, which adversarially attempts to reduce the distance of samples of
the same classes and enlarge the distance of samples of different classes. To
mitigate the conflict of seeking high global diversity and keeping inter-class
confusing, we propose a focal weighted sampling strategy by selecting the
negative in the triplets unevenly within a finite range of distance. RGAL shows
significant improvement over previous state-of-the-art methods in accuracy and
data efficiency. Besides, RGAL can be inserted into state-of-the-art methods on
various data-free knowledge transfer applications. Experiments on various
benchmarks demonstrate the effectiveness and generalizability of our proposed
method on various tasks, specially data-free knowledge distillation, data-free
quantization, and non-exemplar incremental learning. Our code is available at
https://github.com/Sharpiless/RGAL.",2024-12-16,"Yingping Liang, Ying Fu"
"Improving Automatic Fetal Biometry Measurement with Swoosh Activation
  Function","The measurement of fetal thalamus diameter (FTD) and fetal head circumference
(FHC) are crucial in identifying abnormal fetal thalamus development as it may
lead to certain neuropsychiatric disorders in later life. However, manual
measurements from 2D-US images are laborious, prone to high inter-observer
variability, and complicated by the high signal-to-noise ratio nature of the
images. Deep learning-based landmark detection approaches have shown promise in
measuring biometrics from US images, but the current state-of-the-art (SOTA)
algorithm, BiometryNet, is inadequate for FTD and FHC measurement due to its
inability to account for the fuzzy edges of these structures and the complex
shape of the FTD structure. To address these inadequacies, we propose a novel
Swoosh Activation Function (SAF) designed to enhance the regularization of
heatmaps produced by landmark detection algorithms. Our SAF serves as a
regularization term to enforce an optimum mean squared error (MSE) level
between predicted heatmaps, reducing the dispersiveness of hotspots in
predicted heatmaps. Our experimental results demonstrate that SAF significantly
improves the measurement performances of FTD and FHC with higher intraclass
correlation coefficient scores in FTD and lower mean difference scores in FHC
measurement than those of the current SOTA algorithm BiometryNet. Moreover, our
proposed SAF is highly generalizable and architecture-agnostic. The SAF's
coefficients can be configured for different tasks, making it highly
customizable. Our study demonstrates that the SAF activation function is a
novel method that can improve measurement accuracy in fetal biometry landmark
detection. This improvement has the potential to contribute to better fetal
monitoring and improved neonatal outcomes.",2024-12-16,"Shijia Zhou, Euijoon Ahn, Hao Wang, Ann Quinton, Narelle Kennedy, Pradeeba Sridar, Ralph Nanan, Jinman Kim"
Codenames as a Benchmark for Large Language Models,"In this paper, we propose the use of the popular word-based board game
Codenames as a suitable benchmark for evaluating the reasoning capabilities of
Large Language Models (LLMs). Codenames presents a highly interesting challenge
for achieving successful AI performance, requiring both a sophisticated
understanding of language, theory of mind, and epistemic reasoning
capabilities. Prior attempts to develop agents for Codenames have largely
relied on word embedding techniques, which have a limited vocabulary range and
perform poorly when paired with differing approaches. LLMs have demonstrated
enhanced reasoning and comprehension capabilities for language-based tasks, but
can still suffer in lateral thinking challenges. We evaluate the capabilities
of several state-of-the-art LLMs, including GPT-4o, Gemini 1.5, Claude 3.5
Sonnet, and Llama 3.1, across a variety of board setups. Our results indicate
that while certain LLMs perform better than others overall, different models
exhibit varying emergent behaviours during gameplay and excel at specific
roles. We also evaluate the performance of different combinations of LLMs when
playing cooperatively together, demonstrating that LLM agents are more
generalisable to a wider range of teammates than prior techniques.",2024-12-16,"Matthew Stephenson, Matthew Sidji, Benoît Ronval"
"Individual Bus Trip Chain Prediction and Pattern Identification
  Considering Similarities","Predicting future bus trip chains for an existing user is of great
significance for operators of public transit systems. Existing methods always
treat this task as a time-series prediction problem, but the 1-dimensional time
series structure cannot express the complex relationship between trips. To
better capture the inherent patterns in bus travel behavior, this paper
proposes a novel approach that synthesizes future bus trip chains based on
those from similar days. Key similarity patterns are defined and tested using
real-world data, and a similarity function is then developed to capture these
patterns. Afterwards, a graph is constructed where each day is represented as a
node and edge weight reflects the similarity between days. Besides, the trips
on a given day can be regarded as labels for each node, transferring the bus
trip chain prediction problem to a semi-supervised classification problem on a
graph. To address this, we propose several methods and validate them on a
real-world dataset of 10000 bus users, achieving state-of-the-art prediction
results. Analyzing the parameters of similarity function reveals some
interesting bus usage patterns, allowing us can to cluster bus users into three
types: repeat-dominated, evolve-dominate and repeat-evolve balanced. In
summary, our work demonstrates the effectiveness of similarity-based prediction
for bus trip chains and provides a new perspective for analyzing individual bus
travel patterns. The code for our prediction model is publicly available.",2024-12-16,"Xiannan Huang, Yixin Chen, Quan Yuan, Chao Yang"
"Temporal Logic Control for Nonlinear Stochastic Systems Under Unknown
  Disturbances","In this paper, we present a novel framework to synthesize robust strategies
for discrete-time nonlinear systems with random disturbances that are unknown,
against temporal logic specifications. The proposed framework is data-driven
and abstraction-based: leveraging observations of the system, our approach
learns a high-confidence abstraction of the system in the form of an uncertain
Markov decision process (UMDP). The uncertainty in the resulting UMDP is used
to formally account for both the error in abstracting the system and for the
uncertainty coming from the data. Critically, we show that for any given
state-action pair in the resulting UMDP, the uncertainty in the transition
probabilities can be represented as a convex polytope obtained by a two-layer
state discretization and concentration inequalities. This allows us to obtain
tighter uncertainty estimates compared to existing approaches, and guarantees
efficiency, as we tailor a synthesis algorithm exploiting the structure of this
UMDP. We empirically validate our approach on several case studies, showing
substantially improved performance compared to the state-of-the-art.",2024-12-15,"Ibon Gracia, Luca Laurenti, Manuel Mazo Jr., Alessandro Abate, Morteza Lahijanian"
"Modality-Driven Design for Multi-Step Dexterous Manipulation: Insights
  from Neuroscience","Multi-step dexterous manipulation is a fundamental skill in household
scenarios, yet remains an underexplored area in robotics. This paper proposes a
modular approach, where each step of the manipulation process is addressed with
dedicated policies based on effective modality input, rather than relying on a
single end-to-end model. To demonstrate this, a dexterous robotic hand performs
a manipulation task involving picking up and rotating a box. Guided by insights
from neuroscience, the task is decomposed into three sub-skills, 1)reaching,
2)grasping and lifting, and 3)in-hand rotation, based on the dominant sensory
modalities employed in the human brain. Each sub-skill is addressed using
distinct methods from a practical perspective: a classical controller, a
Vision-Language-Action model, and a reinforcement learning policy with force
feedback, respectively. We tested the pipeline on a real robot to demonstrate
the feasibility of our approach. The key contribution of this study lies in
presenting a neuroscience-inspired, modality-driven methodology for multi-step
dexterous manipulation.",2024-12-15,"Naoki Wake, Atsushi Kanehira, Daichi Saito, Jun Takamatsu, Kazuhiro Sasabuchi, Hideki Koike, Katsushi Ikeuchi"
The AI Black-Scholes: Finance-Informed Neural Network,"In the realm of option pricing, existing models are typically classified into
principle-driven methods, such as solving partial differential equations (PDEs)
that pricing function satisfies, and data-driven approaches, such as machine
learning (ML) techniques that parameterize the pricing function directly. While
principle-driven models offer a rigorous theoretical framework, they often rely
on unrealistic assumptions, such as asset processes adhering to fixed
stochastic differential equations (SDEs). Moreover, they can become
computationally intensive, particularly in high-dimensional settings when
analytical solutions are not available and thus numerical solutions are needed.
In contrast, data-driven models excel in capturing market data trends, but they
often lack alignment with core financial principles, raising concerns about
interpretability and predictive accuracy, especially when dealing with limited
or biased datasets. This work proposes a hybrid approach to address these
limitations by integrating the strengths of both principled and data-driven
methodologies. Our framework combines the theoretical rigor and
interpretability of PDE-based models with the adaptability of machine learning
techniques, yielding a more versatile methodology for pricing a broad spectrum
of options. We validate our approach across different volatility modeling
approaches-both with constant volatility (Black-Scholes) and stochastic
volatility (Heston), demonstrating that our proposed framework,
Finance-Informed Neural Network (FINN), not only enhances predictive accuracy
but also maintains adherence to core financial principles. FINN presents a
promising tool for practitioners, offering robust performance across a variety
of market conditions.",2024-12-15,"Amine M. Aboussalah, Xuanze Li, Cheng Chi, Raj Patel"
"Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image
  Prompts with Text Summarization","Text-to-image models are vulnerable to the stepwise ""Divide-and-Conquer
Attack"" (DACA) that utilize a large language model to obfuscate inappropriate
content in prompts by wrapping sensitive text in a benign narrative. To
mitigate stepwise DACA attacks, we propose a two-layer method involving text
summarization followed by binary classification. We assembled the Adversarial
Text-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated
and non-obfuscated prompts. From the ATTIP dataset, we created two summarized
versions: one generated by a small encoder model and the other by a large
language model. Then, we used an encoder classifier and a GPT-4o classifier to
perform content moderation on the summarized and unsummarized prompts. When
compared with a classifier that operated over the unsummarized data, our method
improved F1 score performance by 31%. Further, the highest recorded F1 score
achieved (98%) was produced by the encoder classifier on a summarized ATTIP
variant. This study indicates that pre-classification text summarization can
inoculate content detection models against stepwise DACA obfuscations.",2024-12-15,"Portia Cooper, Harshita Narnoli, Mihai Surdeanu"
Generics are puzzling. Can language models find the missing piece?,"Generic sentences express generalisations about the world without explicit
quantification. Although generics are central to everyday communication,
building a precise semantic framework has proven difficult, in part because
speakers use generics to generalise properties with widely different
statistical prevalence. In this work, we study the implicit quantification and
context-sensitivity of generics by leveraging language models as models of
language. We create ConGen, a dataset of 2873 naturally occurring generic and
quantified sentences in context, and define p-acceptability, a metric based on
surprisal that is sensitive to quantification. Our experiments show generics
are more context-sensitive than determiner quantifiers and about 20% of
naturally occurring generics we analyze express weak generalisations. We also
explore how human biases in stereotypes can be observed in language models.",2024-12-15,"Gustavo Cilleruelo Calderón, Emily Allaway, Barry Haddow, Alexandra Birch"
"GAP: Game Theory-Based Approach for Reliability and Power Management in
  Emerging Fog Computing","Fog computing brings about a transformative shift in data management,
presenting unprecedented opportunities for enhanced performance and reduced
latency. However, one of the key aspects of fog computing revolves around
ensuring efficient power and reliability management. To address this challenge,
we have introduced a novel model that proposes a non-cooperative game
theory-based strategy to strike a balance between power consumption and
reliability in decision-making processes. Our proposed model capitalizes on the
Cold Primary/Backup strategy (CPB) to guarantee reliability target by
re-executing tasks to different nodes when a fault occurs, while also
leveraging Dynamic Voltage and Frequency Scaling (DVFS) to reduce power
consumption during task execution and maximizing overall efficiency.
Non-cooperative game theory plays a pivotal role in our model, as it
facilitates the development of strategies and solutions that uphold reliability
while reducing power consumption. By treating the trade-off between power and
reliability as a non-cooperative game, our proposed method yields significant
energy savings, with up to a 35% reduction in energy consumption, 41% decrease
in wait time, and 31% shorter completion time compared to state-of-the-art
approaches. Our findings underscore the value of game theory in optimizing
power and reliability within fog computing environments, demonstrating its
potential for driving substantial improvements",2024-12-15,"Abolfazl Younesi, Mohsen Ansari, Alireza Ejlali, Mohammad Amin Fazli, Muhammad Shafique, Jörg Henkel"
"Sequence-Level Analysis of Leakage Risk of Training Data in Large
  Language Models","This work advocates for the use of sequence level probabilities for
quantifying the risk of extraction training data from Large Language Models
(LLMs) as they provide much finer-grained information than has been previously
obtained. We re-analyze the effects of decoding schemes, model-size, prefix
length, partial sequence leakages, and token positions to uncover new insights
that have were not possible in prior work due to their choice of metrics. We
perform this study on two pre-trained models, LLaMa and OPT, trained on the
Common Crawl and Pile respectively. We discover that 1) Extraction rate, the
predominant metric used in prior quantification work, underestimates the threat
of leakage of training data in randomized LLMs by as much as 2.14x. 2) Though,
on average, larger models and longer prefixes can extract more data, this is
not true with a substantial portion of individual sequences. 30.4-41.5% of our
sequences are easier to extract with either shorter prefixes or smaller models.
3) Contrary to prior belief, partial leakage in the commonly used decoding
schemes like top-k and top-p are not easier than leaking verbatim training
data. 4) Extracting later tokens in a sequence is as much as 912% easier than
extracting earlier tokens. The insights gained from our analysis show that it
is important to look at leakage of training data on a per-sequence basis.",2024-12-15,"Trishita Tiwari, G. Edward Suh"
"How not to Stitch Representations to Measure Similarity: Task Loss
  Matching versus Direct Matching","Measuring the similarity of the internal representations of deep neural
networks is an important and challenging problem. Model stitching has been
proposed as a possible approach, where two half-networks are connected by
mapping the output of the first half-network to the input of the second one.
The representations are considered functionally similar if the resulting
stitched network achieves good task-specific performance. The mapping is
normally created by training an affine stitching layer on the task at hand
while freezing the two half-networks, a method called task loss matching. Here,
we argue that task loss matching may be very misleading as a similarity index.
For example, it can indicate very high similarity between very distant layers,
whose representations are known to have different functional properties.
Moreover, it can indicate very distant layers to be more similar than
architecturally corresponding layers. Even more surprisingly, when comparing
layers within the same network, task loss matching often indicates that some
layers are more similar to a layer than itself. We argue that the main reason
behind these problems is that task loss matching tends to create
out-of-distribution representations to improve task-specific performance. We
demonstrate that direct matching (when the mapping minimizes the distance
between the stitched representations) does not suffer from these problems. We
compare task loss matching, direct matching, and well-known similarity indices
such as CCA and CKA. We conclude that direct matching strikes a good balance
between the structural and functional requirements for a good similarity index.",2024-12-15,"András Balogh, Márk Jelasity"
Continuously Learning Bug Locations,"Automatically locating buggy changesets associated with bug reports is
crucial in the software development process. Deep Learning (DL)-based
techniques show promising results by leveraging structural information from the
code and learning links between changesets and bug reports. However, since
source code associated with changesets evolves, the performance of such models
tends to degrade over time due to concept drift. Aiming to address this
challenge, in this paper, we evaluate the potential of using Continual Learning
(CL) techniques in multiple sub-tasks setting for bug localization (each of
which operates on either stationary or non-stationary data), comparing it
against a bug localization technique that leverages the BERT model, a deep
reinforcement learning-based technique that leverages the A2C algorithm, and a
DL-based function-level interaction model for semantic bug localization.
Additionally, we enhanced the CL techniques by using logistic regression to
identify and integrate the most significant bug-inducing factors. Our empirical
evaluation across seven widely used software projects shows that CL techniques
perform better than DL-based techniques by up to 61% in terms of Mean
Reciprocal Rank (MRR), 44% in terms of Mean Average Precision (MAP), 83% in
terms of top@1, 56% in terms of top@5, and 66% in terms of top@10 metrics in
non-stationary setting. Further, we show that the CL techniques we studied are
effective at localizing changesets relevant to a bug report while being able to
mitigate catastrophic forgetting across the studied tasks and require up to 5x
less computational effort during training. Our findings demonstrate the
potential of adopting CL for bug localization in non-stationary settings, and
we hope it helps to improve bug localization activities in Software Engineering
using CL techniques.",2024-12-15,"Paulina Stevia Nouwou Mindom, Leuson Da Silva, Amin Nikanjam, Foutse Khomh"
Multi-robot workspace design and motion planning for package sorting,"Robotic systems are routinely used in the logistics industry to enhance
operational efficiency, but the design of robot workspaces remains a complex
and manual task, which limits the system's flexibility to changing demands.
This paper aims to automate robot workspace design by proposing a computational
framework to generate a budget-minimizing layout by selectively placing
stationary robots on a floor grid, which includes robotic arms and conveyor
belts, and plan their cooperative motions to sort packages from given input and
output locations. We propose a hierarchical solving strategy that first
optimizes the layout to minimize the hardware budget with a subgraph
optimization subject to network flow constraints, followed by task allocation
and motion planning based on the generated layout. In addition, we demonstrate
how to model conveyor belts as manipulators with multiple end effectors to
integrate them into our design and planning framework. We evaluated our
framework on a set of simulated scenarios and showed that it can generate
optimal layouts and collision-free motion trajectories, adapting to different
available robots, cost assignments, and box payloads.",2024-12-15,"Peiyu Zeng, Yijiang Huang, Simon Huber, Stelian Coros"
"Wearable Accelerometer Foundation Models for Health via Knowledge
  Distillation","Modern wearable devices can conveniently and continuously record various
biosignals in the many different environments of daily living, ultimately
enabling a rich view of individual health. However, not all biosignals are the
same: high-fidelity measurements, such as photoplethysmography (PPG), contain
more physiological information, but require optical sensors with a high power
footprint. In a resource-constrained setting, such biosignals may be
unavailable. Alternatively, a lower-fidelity biosignal, such as accelerometry
that captures minute cardiovascular information during low-motion periods, has
a significantly smaller power footprint and is available in almost any wearable
device. Here, we demonstrate that we can distill representational knowledge
across biosignals, i.e., from PPG to accelerometry, using 20 million minutes of
unlabeled data, collected from ~172K participants in the Apple Heart and
Movement Study under informed consent. We first pre-train PPG encoders via
self-supervised learning, and then distill their representational knowledge to
accelerometry encoders. We demonstrate strong cross-modal alignment on unseen
data, e.g., 99.2% top-1 accuracy for retrieving PPG embeddings from
accelerometry embeddings. We show that distilled accelerometry encoders have
significantly more informative representations compared to self-supervised or
supervised encoders trained directly on accelerometry data, observed by at
least 23%-49% improved performance for predicting heart rate and heart rate
variability. We also show that distilled accelerometry encoders are readily
predictive of a wide array of downstream health targets, i.e., they are
generalist foundation models. We believe accelerometry foundation models for
health may unlock new opportunities for developing digital biomarkers from any
wearable device, and help individuals track their health more frequently and
conveniently.",2024-12-15,"Salar Abbaspourazad, Anshuman Mishra, Joseph Futoma, Andrew C. Miller, Ian Shapiro"
"Monte Carlo Tree Search with Spectral Expansion for Planning with
  Dynamical Systems","The ability of a robot to plan complex behaviors with real-time computation,
rather than adhering to predesigned or offline-learned routines, alleviates the
need for specialized algorithms or training for each problem instance. Monte
Carlo Tree Search is a powerful planning algorithm that strategically explores
simulated future possibilities, but it requires a discrete problem
representation that is irreconcilable with the continuous dynamics of the
physical world. We present Spectral Expansion Tree Search (SETS), a real-time,
tree-based planner that uses the spectrum of the locally linearized system to
construct a low-complexity and approximately equivalent discrete representation
of the continuous world. We prove SETS converges to a bound of the globally
optimal solution for continuous, deterministic and differentiable Markov
Decision Processes, a broad class of problems that includes underactuated
nonlinear dynamics, non-convex reward functions, and unstructured environments.
We experimentally validate SETS on drone, spacecraft, and ground vehicle robots
and one numerical experiment, each of which is not directly solvable with
existing methods. We successfully show SETS automatically discovers a diverse
set of optimal behaviors and motion trajectories in real time.",2024-12-15,"Benjamin Riviere, John Lathrop, Soon-Jo Chung"
"GaussianProperty: Integrating Physical Properties to 3D Gaussians with
  LMMs","Estimating physical properties for visual data is a crucial task in computer
vision, graphics, and robotics, underpinning applications such as augmented
reality, physical simulation, and robotic grasping. However, this area remains
under-explored due to the inherent ambiguities in physical property estimation.
To address these challenges, we introduce GaussianProperty, a training-free
framework that assigns physical properties of materials to 3D Gaussians.
Specifically, we integrate the segmentation capability of SAM with the
recognition capability of GPT-4V(ision) to formulate a global-local physical
property reasoning module for 2D images. Then we project the physical
properties from multi-view 2D images to 3D Gaussians using a voting strategy.
We demonstrate that 3D Gaussians with physical property annotations enable
applications in physics-based dynamic simulation and robotic grasping. For
physics-based dynamic simulation, we leverage the Material Point Method (MPM)
for realistic dynamic simulation. For robot grasping, we develop a grasping
force prediction strategy that estimates a safe force range required for object
grasping based on the estimated physical properties. Extensive experiments on
material segmentation, physics-based dynamic simulation, and robotic grasping
validate the effectiveness of our proposed method, highlighting its crucial
role in understanding physical properties from visual data. Online demo, code,
more cases and annotated datasets are available on
\href{https://Gaussian-Property.github.io}{this https URL}.",2024-12-15,"Xinli Xu, Wenhang Ge, Dicong Qiu, ZhiFei Chen, Dongyu Yan, Zhuoyun Liu, Haoyu Zhao, Hanfeng Zhao, Shunsi Zhang, Junwei Liang, Ying-Cong Chen"
AI-Driven Innovations in Volumetric Video Streaming: A Review,"Recent efforts to enhance immersive and interactive user experiences have
driven the development of volumetric video, a form of 3D content that enables 6
DoF. Unlike traditional 2D content, volumetric content can be represented in
various ways, such as point clouds, meshes, or neural representations. However,
due to its complex structure and large amounts of data size, deploying this new
form of 3D data presents significant challenges in transmission and rendering.
These challenges have hindered the widespread adoption of volumetric video in
daily applications. In recent years, researchers have proposed various
AI-driven techniques to address these challenges and improve the efficiency and
quality of volumetric content streaming. This paper provides a comprehensive
overview of recent advances in AI-driven approaches to facilitate volumetric
content streaming. Through this review, we aim to offer insights into the
current state-of-the-art and suggest potential future directions for advancing
the deployment of volumetric video streaming in real-world applications.",2024-12-15,"Erfan Entezami, Hui Guan"
Do Tutors Learn from Equity Training and Can Generative AI Assess It?,"Equity is a core concern of learning analytics. However, applications that
teach and assess equity skills, particularly at scale are lacking, often due to
barriers in evaluating language. Advances in generative AI via large language
models (LLMs) are being used in a wide range of applications, with this present
work assessing its use in the equity domain. We evaluate tutor performance
within an online lesson on enhancing tutors' skills when responding to students
in potentially inequitable situations. We apply a mixed-method approach to
analyze the performance of 81 undergraduate remote tutors. We find marginally
significant learning gains with increases in tutors' self-reported confidence
in their knowledge in responding to middle school students experiencing
possible inequities from pretest to posttest. Both GPT-4o and GPT-4-turbo
demonstrate proficiency in assessing tutors ability to predict and explain the
best approach. Balancing performance, efficiency, and cost, we determine that
few-shot learning using GPT-4o is the preferred model. This work makes
available a dataset of lesson log data, tutor responses, rubrics for human
annotation, and generative AI prompts. Future work involves leveling the
difficulty among scenarios and enhancing LLM prompts for large-scale grading
and assessment.",2024-12-15,"Danielle R. Thomas, Conrad Borchers, Sanjit Kakarla, Jionghao Lin, Shambhavi Bhushan, Boyuan Guo, Erin Gatz, Kenneth R. Koedinger"
Are Expressive Models Truly Necessary for Offline RL?,"Among various branches of offline reinforcement learning (RL) methods,
goal-conditioned supervised learning (GCSL) has gained increasing popularity as
it formulates the offline RL problem as a sequential modeling task, therefore
bypassing the notoriously difficult credit assignment challenge of value
learning in conventional RL paradigm. Sequential modeling, however, requires
capturing accurate dynamics across long horizons in trajectory data to ensure
reasonable policy performance. To meet this requirement, leveraging large,
expressive models has become a popular choice in recent literature, which,
however, comes at the cost of significantly increased computation and inference
latency. Contradictory yet promising, we reveal that lightweight models as
simple as shallow 2-layer MLPs, can also enjoy accurate dynamics consistency
and significantly reduced sequential modeling errors against large expressive
models by adopting a simple recursive planning scheme: recursively planning
coarse-grained future sub-goals based on current and target information, and
then executes the action with a goal-conditioned policy learned from data
rela-beled with these sub-goal ground truths. We term our method Recursive
Skip-Step Planning (RSP). Simple yet effective, RSP enjoys great efficiency
improvements thanks to its lightweight structure, and substantially outperforms
existing methods, reaching new SOTA performances on the D4RL benchmark,
especially in multi-stage long-horizon tasks.",2024-12-15,"Guan Wang, Haoyi Niu, Jianxiong Li, Li Jiang, Jianming Hu, Xianyuan Zhan"
"Multimodal Class-aware Semantic Enhancement Network for Audio-Visual
  Video Parsing","The Audio-Visual Video Parsing task aims to recognize and temporally localize
all events occurring in either the audio or visual stream, or both. Capturing
accurate event semantics for each audio/visual segment is vital. Prior works
directly utilize the extracted holistic audio and visual features for intra-
and cross-modal temporal interactions. However, each segment may contain
multiple events, resulting in semantically mixed holistic features that can
lead to semantic interference during intra- or cross-modal interactions: the
event semantics of one segment may incorporate semantics of unrelated events
from other segments. To address this issue, our method begins with a
Class-Aware Feature Decoupling (CAFD) module, which explicitly decouples the
semantically mixed features into distinct class-wise features, including
multiple event-specific features and a dedicated background feature. The
decoupled class-wise features enable our model to selectively aggregate useful
semantics for each segment from clearly matched classes contained in other
segments, preventing semantic interference from irrelevant classes.
Specifically, we further design a Fine-Grained Semantic Enhancement module for
encoding intra- and cross-modal relations. It comprises a Segment-wise Event
Co-occurrence Modeling (SECM) block and a Local-Global Semantic Fusion (LGSF)
block. The SECM exploits inter-class dependencies of concurrent events within
the same timestamp with the aid of a new event co-occurrence loss. The LGSF
further enhances the event semantics of each segment by incorporating relevant
semantics from more informative global video features. Extensive experiments
validate the effectiveness of the proposed modules and loss functions,
resulting in a new state-of-the-art parsing performance.",2024-12-15,"Pengcheng Zhao, Jinxing Zhou, Yang Zhao, Dan Guo, Yanxiang Chen"
"Volumetric Mapping with Panoptic Refinement via Kernel Density
  Estimation for Mobile Robots","Reconstructing three-dimensional (3D) scenes with semantic understanding is
vital in many robotic applications. Robots need to identify which objects,
along with their positions and shapes, to manipulate them precisely with given
tasks. Mobile robots, especially, usually use lightweight networks to segment
objects on RGB images and then localize them via depth maps; however, they
often encounter out-of-distribution scenarios where masks over-cover the
objects. In this paper, we address the problem of panoptic segmentation quality
in 3D scene reconstruction by refining segmentation errors using non-parametric
statistical methods. To enhance mask precision, we map the predicted masks into
a depth frame to estimate their distribution via kernel densities. The outliers
in depth perception are then rejected without the need for additional
parameters in an adaptive manner to out-of-distribution scenarios, followed by
3D reconstruction using projective signed distance functions (SDFs). We
validate our method on a synthetic dataset, which shows improvements in both
quantitative and qualitative results for panoptic mapping. Through real-world
testing, the results furthermore show our method's capability to be deployed on
a real-robot system. Our source code is available at:
https://github.com/mkhangg/refined panoptic mapping.",2024-12-15,"Khang Nguyen, Tuan Dang, Manfred Huber"
Proportionally Fair Matching via Randomized Rounding,"Given an edge-colored graph, the goal of the proportional fair matching
problem is to find a maximum weight matching
  while ensuring proportional representation (with respect to the number of
edges) of each color. The colors may correspond to demographic groups or other
protected traits where we seek to ensure
  roughly equal representation from each group.
  It is known that, assuming ETH, it is impossible to approximate the problem
with $\ell$ colors in time $2^{o(\ell)} n^{\mathcal{O}(1)}$ (i.e.,
subexponential in $\ell$) even on \emph{unweighted path graphs}. Further, even
determining the existence of a non-empty matching satisfying proportionality is
NP-Hard.
  To overcome this hardness, we relax the stringent
  proportional fairness constraints to a probabilistic notion. We introduce a
notion we call $\delta$-\textsc{ProbablyAlmostFair}, where we ensure
proportionality up to a factor of at most $(1 \pm \delta)$ for some small
$\delta >0$ with high probability. The violation $\delta$ can be brought
arbitrarily close to $0$ for some \emph{good} instances with large values of
matching size.
  We propose and analyze simple and fast algorithms for bipartite graphs that
achieve
  constant-factor approximation guarantees, and return a
$\delta$-\textsc{ProbablyAlmostFair} matching.",2024-12-15,"Sharmila Duppala, Nathaniel Grammel, Juan Luque, Calum MacRury, Aravind Srinivasan"
"On the Generalizability of Iterative Patch Selection for
  Memory-Efficient High-Resolution Image Classification","Classifying large images with small or tiny regions of interest (ROI) is
challenging due to computational and memory constraints. Weakly supervised
memory-efficient patch selectors have achieved results comparable with strongly
supervised methods. However, low signal-to-noise ratios and low entropy
attention still cause overfitting. We explore these issues using a novel
testbed on a memory-efficient cross-attention transformer with Iterative Patch
Selection (IPS) as the patch selection module. Our testbed extends the
megapixel MNIST benchmark to four smaller O2I (object-to-image) ratios ranging
from 0.01% to 0.14% while keeping the canvas size fixed and introducing a noise
generation component based on B\'ezier curves. Experimental results generalize
the observations made on CNNs to IPS whereby the O2I threshold below which the
classifier fails to generalize is affected by the training dataset size. We
further observe that the magnitude of this interaction differs for each task of
the Megapixel MNIST. For tasks ""Maj"" and ""Top"", the rate is at its highest,
followed by tasks ""Max"" and ""Multi"" where in the latter, this rate is almost at
0. Moreover, results show that in a low data setting, tuning the patch size to
be smaller relative to the ROI improves generalization, resulting in an
improvement of + 15% for the megapixel MNIST and + 5% for the Swedish traffic
signs dataset compared to the original object-to-patch ratios in IPS. Further
outcomes indicate that the similarity between the thickness of the noise
component and the digits in the megapixel MNIST gradually causes IPS to fail to
generalize, contributing to previous suspicions.",2024-12-15,"Max Riffi-Aslett, Christina Fell"
Logarithmic Positional Partition Interval Encoding,"One requirement of maintaining digital information is storage. With the
latest advances in the digital world, new emerging media types have required
even more storage space to be kept than before. In fact, in many cases it is
required to have larger amounts of storage to keep up with protocols that
support more types of information at the same time. In contrast, compression
algorithms have been integrated to facilitate the transfer of larger data.
Numerical representations are construed as embodiments of information. However,
this correct association of a sequence could feasibly be inverted to signify an
elongated series of numerals. In this work, a novel mathematical paradigm was
introduced to engineer a methodology reliant on iterative logarithmic
transformations, finely tuned to numeric sequences. Through this fledgling
approach, an intricate interplay of polymorphic numeric manipulations was
conducted. By applying repeated logarithmic operations, the data were condensed
into a minuscule representation. Approximately thirteen times surpassed the
compression method, ZIP. Such extreme compaction, achieved through iterative
reduction of expansive integers until they manifested as single-digit entities,
conferred a novel sense of informational embodiment. Instead of relegating data
to classical discrete encodings, this method transformed them into a
quasi-continuous, logarithmically. By contrast, this introduced approach
revealed that morphing data into deeply compressed numerical substrata beyond
conventional boundaries was feasible. A holistic perspective emerges,
validating that numeric data can be recalibrated into ephemeral sequences of
logarithmic impressions. It was not merely a matter of reducing digits, but of
reinterpreting data through a resolute numeric vantage.",2024-12-15,"Vasileios Alevizos, Nikitas Gerolimos, Sabrina Edralin, Clark Xu, Akebu Simasiku, Georgios Priniotakis, George Papakostas, Zongliang Yue"
Grey Wolf-Based Task Scheduling in Vehicular Fog Computing Systems,"Vehicular fog computing (VFC) can be considered as an important alternative
to address the existing challenges in intelligent transportation systems (ITS).
The main purpose of VFC is to perform computational tasks through various
vehicles. At present, VFCs include powerful computing resources that bring the
computational resources nearer to the requesting devices. This paper presents a
new algorithm based on meta-heuristic optimization method for task scheduling
problem in VFC. The task scheduling in VFC is formulated as a multi-objective
optimization problem, which aims to reduce makespan and monetary cost. The
proposed method utilizes the grey wolf optimization (GWO) and assigns the
different priorities to static and dynamic fog nodes. Dynamic fog nodes
represent the parked or moving vehicles and static fog nodes show the
stationary servers. Afterwards, the tasks that require the most processing
resources are chosen and allocated to fog nodes. The GWO-based method is
extensively evaluated in more details. Furthermore, the effectiveness of
various parameters in GWO algorithm is analyzed. We also assess the proposed
algorithm on real application and random data. The outcomes of our experiments
confirm that, in comparison to previous works, our algorithm is capable of
offering the lowest monetary cost.",2024-12-15,"Maryam Taghizadeh, Mahmood Ahmadi"
Uni-AdaFocus: Spatial-temporal Dynamic Computation for Video Recognition,"This paper presents a comprehensive exploration of the phenomenon of data
redundancy in video understanding, with the aim to improve computational
efficiency. Our investigation commences with an examination of spatial
redundancy, which refers to the observation that the most informative region in
each video frame usually corresponds to a small image patch, whose shape, size
and location shift smoothly across frames. Motivated by this phenomenon, we
formulate the patch localization problem as a dynamic decision task, and
introduce a spatially adaptive video recognition approach, termed AdaFocus. In
specific, a lightweight encoder is first employed to quickly process the full
video sequence, whose features are then utilized by a policy network to
identify the most task-relevant regions. Subsequently, the selected patches are
inferred by a high-capacity deep network for the final prediction. The full
model can be trained in end-to-end conveniently. Furthermore, AdaFocus can be
extended by further considering temporal and sample-wise redundancies, i.e.,
allocating the majority of computation to the most task-relevant frames, and
minimizing the computation spent on relatively ""easier"" videos. Our resulting
approach, Uni-AdaFocus, establishes a comprehensive framework that seamlessly
integrates spatial, temporal, and sample-wise dynamic computation, while it
preserves the merits of AdaFocus in terms of efficient end-to-end training and
hardware friendliness. In addition, Uni-AdaFocus is general and flexible as it
is compatible with off-the-shelf efficient backbones (e.g., TSM and X3D), which
can be readily deployed as our feature extractor, yielding a significantly
improved computational efficiency. Empirically, extensive experiments based on
seven benchmark datasets and three application scenarios substantiate that
Uni-AdaFocus is considerably more efficient than the competitive baselines.",2024-12-15,"Yulin Wang, Haoji Zhang, Yang Yue, Shiji Song, Chao Deng, Junlan Feng, Gao Huang"
GenLit: Reformulating Single-Image Relighting as Video Generation,"Manipulating the illumination within a single image represents a fundamental
challenge in computer vision and graphics. This problem has been traditionally
addressed using inverse rendering techniques, which require explicit 3D asset
reconstruction and costly ray tracing simulations. Meanwhile, recent
advancements in visual foundation models suggest that a new paradigm could soon
be practical and possible -- one that replaces explicit physical models with
networks that are trained on massive amounts of image and video data. In this
paper, we explore the potential of exploiting video diffusion models, and in
particular Stable Video Diffusion (SVD), in understanding the physical world to
perform relighting tasks given a single image. Specifically, we introduce
GenLit, a framework that distills the ability of a graphics engine to perform
light manipulation into a video generation model, enabling users to directly
insert and manipulate a point light in the 3D world within a given image and
generate the results directly as a video sequence. We find that a model
fine-tuned on only a small synthetic dataset (270 objects) is able to
generalize to real images, enabling single-image relighting with realistic ray
tracing effects and cast shadows. These results reveal the ability of video
foundation models to capture rich information about lighting, material, and
shape. Our findings suggest that such models, with minimal training, can be
used for physically-based rendering without explicit physically asset
reconstruction and complex ray tracing. This further suggests the potential of
such models for controllable and physically accurate image synthesis tasks.",2024-12-15,"Shrisha Bharadwaj, Haiwen Feng, Victoria Abrevaya, Michael J. Black"
"A Syntactic Approach to Computing Complete and Sound Abstraction in the
  Situation Calculus","Abstraction is an important and useful concept in the field of artificial
intelligence. To the best of our knowledge, there is no syntactic method to
compute a sound and complete abstraction from a given low-level basic action
theory and a refinement mapping. This paper aims to address this issue.To this
end, we first present a variant of situation calculus,namely linear integer
situation calculus, which serves as the formalization of high-level basic
action theory. We then migrate Banihashemi, De Giacomo, and Lesp\'erance's
abstraction framework to one from linear integer situation calculus to extended
situation calculus. Furthermore, we identify a class of Golog programs, namely
guarded actions,that is used to restrict low-level Golog programs, and impose
some restrictions on refinement mappings. Finally, we design a syntactic
approach to computing a sound and complete abstraction from a low-level basic
action theory and a restricted refinement mapping.",2024-12-15,"Liangda Fang, Xiaoman Wang, Zhang Chen, Kailun Luo, Zhenhe Cui, Quanlong Guan"
Distribution-Consistency-Guided Multi-modal Hashing,"Multi-modal hashing methods have gained popularity due to their fast speed
and low storage requirements. Among them, the supervised methods demonstrate
better performance by utilizing labels as supervisory signals compared with
unsupervised methods. Currently, for almost all supervised multi-modal hashing
methods, there is a hidden assumption that training sets have no noisy labels.
However, labels are often annotated incorrectly due to manual labeling in
real-world scenarios, which will greatly harm the retrieval performance. To
address this issue, we first discover a significant distribution consistency
pattern through experiments, i.e., the 1-0 distribution of the presence or
absence of each category in the label is consistent with the high-low
distribution of similarity scores of the hash codes relative to category
centers. Then, inspired by this pattern, we propose a novel
Distribution-Consistency-Guided Multi-modal Hashing (DCGMH), which aims to
filter and reconstruct noisy labels to enhance retrieval performance.
Specifically, the proposed method first randomly initializes several category
centers, which are used to compute the high-low distribution of similarity
scores; Noisy and clean labels are then separately filtered out via the
discovered distribution consistency pattern to mitigate the impact of noisy
labels; Subsequently, a correction strategy, which is indirectly designed via
the distribution consistency pattern, is applied to the filtered noisy labels,
correcting high-confidence ones while treating low-confidence ones as unlabeled
for unsupervised learning, thereby further enhancing the model's performance.
Extensive experiments on three widely used datasets demonstrate the superiority
of the proposed method compared to state-of-the-art baselines in multi-modal
retrieval tasks. The code is available at
https://github.com/LiuJinyu1229/DCGMH.",2024-12-15,"Jin-Yu Liu, Xian-Ling Mao, Tian-Yi Che, Rong-Cheng Tu"
Light-T2M: A Lightweight and Fast Model for Text-to-motion Generation,"Despite the significant role text-to-motion (T2M) generation plays across
various applications, current methods involve a large number of parameters and
suffer from slow inference speeds, leading to high usage costs. To address
this, we aim to design a lightweight model to reduce usage costs. First, unlike
existing works that focus solely on global information modeling, we recognize
the importance of local information modeling in the T2M task by reconsidering
the intrinsic properties of human motion, leading us to propose a lightweight
Local Information Modeling Module. Second, we introduce Mamba to the T2M task,
reducing the number of parameters and GPU memory demands, and we have designed
a novel Pseudo-bidirectional Scan to replicate the effects of a bidirectional
scan without increasing parameter count. Moreover, we propose a novel Adaptive
Textual Information Injector that more effectively integrates textual
information into the motion during generation. By integrating the
aforementioned designs, we propose a lightweight and fast model named
Light-T2M. Compared to the state-of-the-art method, MoMask, our Light-T2M model
features just 10\% of the parameters (4.48M vs 44.85M) and achieves a 16\%
faster inference time (0.152s vs 0.180s), while surpassing MoMask with an FID
of \textbf{0.040} (vs. 0.045) on HumanML3D dataset and 0.161 (vs. 0.228) on
KIT-ML dataset. The code is available at
https://github.com/qinghuannn/light-t2m.",2024-12-15,"Ling-An Zeng, Guohong Huang, Gaojie Wu, Wei-Shi Zheng"
"Leveraging Large Language Models for Active Merchant Non-player
  Characters","We highlight two significant issues leading to the passivity of current
merchant non-player characters (NPCs): pricing and communication. While
immersive interactions have been a focus, negotiations between merchant NPCs
and players on item prices have not received sufficient attention. First, we
define passive pricing as the limited ability of merchants to modify predefined
item prices. Second, passive communication means that merchants can only
interact with players in a scripted manner. To tackle these issues and create
an active merchant NPC, we propose a merchant framework based on large language
models (LLMs), called MART, which consists of an appraiser module and a
negotiator module. We conducted two experiments to guide game developers in
selecting appropriate implementations by comparing different training methods
and LLM sizes. Our findings indicate that finetuning methods, such as
supervised finetuning (SFT) and knowledge distillation (KD), are effective in
using smaller LLMs to implement active merchant NPCs. Additionally, we found
three irregular cases arising from the responses of LLMs. We expect our
findings to guide developers in using LLMs for developing active merchant NPCs.",2024-12-15,"Byungjun Kim, Minju Kim, Dayeon Seo, Bugeun Kim"
"OccScene: Semantic Occupancy-based Cross-task Mutual Learning for 3D
  Scene Generation","Recent diffusion models have demonstrated remarkable performance in both 3D
scene generation and perception tasks. Nevertheless, existing methods typically
separate these two processes, acting as a data augmenter to generate synthetic
data for downstream perception tasks. In this work, we propose OccScene, a
novel mutual learning paradigm that integrates fine-grained 3D perception and
high-quality generation in a unified framework, achieving a cross-task win-win
effect. OccScene generates new and consistent 3D realistic scenes only
depending on text prompts, guided with semantic occupancy in a joint-training
diffusion framework. To align the occupancy with the diffusion latent, a
Mamba-based Dual Alignment module is introduced to incorporate fine-grained
semantics and geometry as perception priors. Within OccScene, the perception
module can be effectively improved with customized and diverse generated
scenes, while the perception priors in return enhance the generation
performance for mutual benefits. Extensive experiments show that OccScene
achieves realistic 3D scene generation in broad indoor and outdoor scenarios,
while concurrently boosting the perception models to achieve substantial
performance improvements in the 3D perception task of semantic occupancy
prediction.",2024-12-15,"Bohan Li, Xin Jin, Jianan Wang, Yukai Shi, Yasheng Sun, Xiaofeng Wang, Zhuang Ma, Baao Xie, Chao Ma, Xiaokang Yang, Wenjun Zeng"
GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation,"Graph Neural Networks (GNNs) are fundamental to graph-based learning and
excel in node classification tasks. However, GNNs suffer from scalability
issues due to the need for multi-hop data during inference, limiting their use
in latency-sensitive applications. Recent studies attempt to distill GNNs into
multi-layer perceptrons (MLPs) for faster inference. They typically treat GNN
and MLP models as single units for distillation, insufficiently utilizing the
fine-grained knowledge within GNN layers. In this paper, we propose TINED, a
novel method that distills GNNs to MLPs layer-wise through Teacher Injection
with fine-tuning and Dirichlet Energy Distillation techniques. We analyze key
operations in GNN layers, feature transformation (FT) and graph propagation
(GP), and identify that an FT performs the same computation as a
fully-connected (FC) layer in MLPs. Thus, we propose directly injecting
valuable teacher parameters of an FT in a GNN into an FC layer of the student
MLP, assisted by fine-tuning. In TINED, FC layers in an MLP mirror the order of
the corresponding FTs and GPs in GNN. We provide a theoretical bound on the
approximation of GPs. Moreover, we observe that in a GNN layer, FT and GP
operations often have opposing smoothing effects: GP is aggressive, while FT is
conservative, in smoothing. Using Dirichlet energy, we design a DE ratio to
quantify these smoothing effects and propose Dirichlet Energy Distillation to
distill these characteristics from GNN layers to MLP layers. Extensive
experiments demonstrate that TINED achieves superior performance over GNNs and
state-of-the-art distillation methods under various settings across seven
datasets. The code is in supplementary material.",2024-12-15,"Ziang Zhou, Zhihao Ding, Jieming Shi, Qing Li, Shiqi Shen"
"A Progressive Transformer for Unifying Binary Code Embedding and
  Knowledge Transfer","Language model approaches have recently been integrated into binary analysis
tasks, such as function similarity detection and function signature recovery.
These models typically employ a two-stage training process: pre-training via
Masked Language Modeling (MLM) on machine code and fine-tuning for specific
tasks. While MLM helps to understand binary code structures, it ignores
essential code characteristics, including control and data flow, which
negatively affect model generalization. Recent work leverages domain-specific
features (e.g., control flow graphs and dynamic execution traces) in
transformer-based approaches to improve binary code semantic understanding.
However, this approach involves complex feature engineering, a cumbersome and
time-consuming process that can introduce predictive uncertainty when dealing
with stripped or obfuscated code, leading to a performance drop. In this paper,
we introduce ProTST, a novel transformer-based methodology for binary code
embedding. ProTST employs a hierarchical training process based on a unique
tree-like structure, where knowledge progressively flows from fundamental tasks
at the root to more specialized tasks at the leaves. This progressive
teacher-student paradigm allows the model to build upon previously learned
knowledge, resulting in high-quality embeddings that can be effectively
leveraged for diverse downstream binary analysis tasks. The effectiveness of
ProTST is evaluated in seven binary analysis tasks, and the results show that
ProTST yields an average validation score (F1, MRR, and Recall@1) improvement
of 14.8% compared to traditional two-stage training and an average validation
score of 10.7% compared to multimodal two-stage frameworks.",2024-12-15,"Hanxiao Lu, Hongyu Cai, Yiming Liang, Antonio Bianchi, Z. Berkay Celik"
Design Challenges for Robots in Industrial Applications,"Nowadays, electric robots play big role in many fields as they can replace
humans and/or decrease the amount of load on humans. There are several types of
robots that are present in the daily life, some of them are fully controlled by
humans while others are programmed to be self-controlled. In addition there are
self-control robots with partial human control. Robots can be classified into
three major kinds: industry robots, autonomous robots and mobile robots.
Industry robots are used in industries and factories to perform mankind tasks
in the easier and faster way which will help in developing products. Typically
industrial robots perform difficult and dangerous tasks, as they lift heavy
objects, handle chemicals, paint and assembly work and so on. They are working
all the time hour after hour, day by day with the same precision and they do
not get tired which means that they do not make errors due to fatigue. Indeed,
they are ideally suited to complete repetitive tasks.",2024-12-15,Nesreen Mufid
"Partial Identifiability in Inverse Reinforcement Learning For Agents
  With Non-Exponential Discounting","The aim of inverse reinforcement learning (IRL) is to infer an agent's
preferences from observing their behaviour. Usually, preferences are modelled
as a reward function, $R$, and behaviour is modelled as a policy, $\pi$. One of
the central difficulties in IRL is that multiple preferences may lead to the
same observed behaviour. That is, $R$ is typically underdetermined by $\pi$,
which means that $R$ is only partially identifiable. Recent work has
characterised the extent of this partial identifiability for different types of
agents, including optimal and Boltzmann-rational agents. However, work so far
has only considered agents that discount future reward exponentially: this is a
serious limitation, especially given that extensive work in the behavioural
sciences suggests that humans are better modelled as discounting
hyperbolically. In this work, we newly characterise partial identifiability in
IRL for agents with non-exponential discounting: our results are in particular
relevant for hyperbolical discounting, but they also more generally apply to
agents that use other types of (non-exponential) discounting. We significantly
show that generally IRL is unable to infer enough information about $R$ to
identify the correct optimal policy, which entails that IRL alone can be
insufficient to adequately characterise the preferences of such agents.",2024-12-15,"Joar Skalse, Alessandro Abate"
"From Easy to Hard: Progressive Active Learning Framework for Infrared
  Small Target Detection with Single Point Supervision","Recently, single-frame infrared small target (SIRST) detection with single
point supervision has drawn wide-spread attention. However, the latest label
evolution with single point supervision (LESPS) framework suffers from
instability, excessive label evolution, and difficulty in exerting embedded
network performance. Therefore, we construct a Progressive Active Learning
(PAL) framework. Specifically, inspired by organisms gradually adapting to
their environment and continuously accumulating knowledge, we propose an
innovative progressive active learning idea, which emphasizes that the network
progressively and actively recognizes and learns more hard samples to achieve
continuous performance enhancement. Based on this, on the one hand, we propose
a model pre-start concept, which focuses on selecting a portion of easy samples
and can help models have basic task-specific learning capabilities. On the
other hand, we propose a refined dual-update strategy, which can promote
reasonable learning of harder samples and continuous refinement of
pseudo-labels. In addition, to alleviate the risk of excessive label evolution,
a decay factor is reasonably introduced, which helps to achieve a dynamic
balance between the expansion and contraction of target annotations. Extensive
experiments show that convolutional neural networks (CNNs) equipped with our
PAL framework have achieved state-of-the-art (SOTA) results on multiple public
datasets. Furthermore, our PAL framework can build a efficient and stable
bridge between full supervision and point supervision tasks. Our code are
available at https://github.com/YuChuang1205/PAL.",2024-12-15,"Chuang Yu, Jinmiao Zhao, Yunpeng Liu, Sicheng Zhao, Xiangyu Yue"
"A Comprehensive Survey of Action Quality Assessment: Method and
  Benchmark","Action Quality Assessment (AQA) quantitatively evaluates the quality of human
actions, providing automated assessments that reduce biases in human judgment.
Its applications span domains such as sports analysis, skill assessment, and
medical care. Recent advances in AQA have introduced innovative methodologies,
but similar methods often intertwine across different domains, highlighting the
fragmented nature that hinders systematic reviews. In addition, the lack of a
unified benchmark and limited computational comparisons hinder consistent
evaluation and fair assessment of AQA approaches. In this work, we address
these gaps by systematically analyzing over 150 AQA-related papers to develop a
hierarchical taxonomy, construct a unified benchmark, and provide an in-depth
analysis of current trends, challenges, and future directions. Our hierarchical
taxonomy categorizes AQA methods based on input modalities (video, skeleton,
multi-modal) and their specific characteristics, highlighting the evolution and
interrelations across various approaches. To promote standardization, we
present a unified benchmark, integrating diverse datasets to evaluate the
assessment precision and computational efficiency. Finally, we review emerging
task-specific applications and identify under-explored challenges in AQA,
providing actionable insights into future research directions. This survey aims
to deepen understanding of AQA progress, facilitate method comparison, and
guide future innovations. The project web page can be found at
https://ZhouKanglei.github.io/AQA-Survey.",2024-12-15,"Kanglei Zhou, Ruizhi Cai, Liyuan Wang, Hubert P. H. Shum, Xiaohui Liang"
"Redefining Normal: A Novel Object-Level Approach for Multi-Object
  Novelty Detection","In the realm of novelty detection, accurately identifying outliers in data
without specific class information poses a significant challenge. While current
methods excel in single-object scenarios, they struggle with multi-object
situations due to their focus on individual objects. Our paper suggests a novel
approach: redefining `normal' at the object level in training datasets. Rather
than the usual image-level view, we consider the most dominant object in a
dataset as the norm, offering a perspective that is more effective for
real-world scenarios. Adapting to our object-level definition of `normal', we
modify knowledge distillation frameworks, where a student network learns from a
pre-trained teacher network. Our first contribution, DeFeND(Dense Feature
Fine-tuning on Normal Data), integrates dense feature fine-tuning into the
distillation process, allowing the teacher network to focus on object-level
features with a self-supervised loss. The second is masked knowledge
distillation, where the student network works with partially hidden inputs,
honing its ability to deduce and generalize from incomplete data. This approach
not only fares well in single-object novelty detection but also considerably
surpasses existing methods in multi-object contexts. The implementation is
available at: https://github.com/SMSD75/Redefining_Normal_ACCV24/tree/main",2024-12-15,"Mohammadreza Salehi, Nikolaos Apostolikas, Efstratios Gavves, Cees G. M. Snoek, Yuki M. Asano"
The Superalignment of Superhuman Intelligence with Large Language Models,"We have witnessed superhuman intelligence thanks to the fast development of
large language models and multimodal language models. As the application of
such superhuman models becomes more and more common, a critical question rises
here: how can we ensure superhuman models are still safe, reliable and aligned
well to human values? In this position paper, we discuss the concept of
superalignment from the learning perspective to answer this question by
outlining the learning paradigm shift from large-scale pretraining, supervised
fine-tuning, to alignment training. We define superalignment as designing
effective and efficient alignment algorithms to learn from noisy-labeled data
(point-wise samples or pair-wise preference data) in a scalable way when the
task becomes very complex for human experts to annotate and the model is
stronger than human experts. We highlight some key research problems in
superalignment, namely, weak-to-strong generalization, scalable oversight, and
evaluation. We then present a conceptual framework for superalignment, which
consists of three modules: an attacker which generates adversary queries trying
to expose the weaknesses of a learner model; a learner which will refine itself
by learning from scalable feedbacks generated by a critic model along with
minimal human experts; and a critic which generates critics or explanations for
a given query-response pair, with a target of improving the learner by
criticizing. We discuss some important research problems in each component of
this framework and highlight some interesting research ideas that are closely
related to our proposed framework, for instance, self-alignment, self-play,
self-refinement, and more. Last, we highlight some future research directions
for superalignment, including identification of new emergent risks and
multi-dimensional alignment.",2024-12-15,"Minlie Huang, Yingkang Wang, Shiyao Cui, Pei Ke, Jie Tang"
ViSymRe: Vision-guided Multimodal Symbolic Regression,"Symbolic regression automatically searches for mathematical equations to
reveal underlying mechanisms within datasets, offering enhanced
interpretability compared to black box models. Traditionally, symbolic
regression has been considered to be purely numeric-driven, with insufficient
attention given to the potential contributions of visual information in
augmenting this process. When dealing with high-dimensional and complex
datasets, existing symbolic regression models are often inefficient and tend to
generate overly complex equations, making subsequent mechanism analysis
complicated. In this paper, we propose the vision-guided multimodal symbolic
regression model, called ViSymRe, that systematically explores how visual
information can improve various metrics of symbolic regression. Compared to
traditional models, our proposed model has the following innovations: (1) It
integrates three modalities: vision, symbol and numeric to enhance symbolic
regression, enabling the model to benefit from the strengths of each modality;
(2) It establishes a meta-learning framework that can learn from historical
experiences to efficiently solve new symbolic regression problems; (3) It
emphasizes the simplicity and structural rationality of the equations rather
than merely numerical fitting. Extensive experiments show that our proposed
model exhibits strong generalization capability and noise resistance. The
equations it generates outperform state-of-the-art numeric-only baselines in
terms of fitting effect, simplicity and structural accuracy, thus being able to
facilitate accurate mechanism analysis and the development of theoretical
models.",2024-12-15,"Da Li, Junping Yin, Jin Xu, Xinxin Li, Juan Zhang"
"Decoding Drug Discovery: Exploring A-to-Z In silico Methods for
  Beginners","The drug development process is a critical challenge in the pharmaceutical
industry due to its time-consuming nature and the need to discover new drug
potentials to address various ailments. The initial step in drug development,
drug target identification, often consumes considerable time. While valid,
traditional methods such as in vivo and in vitro approaches are limited in
their ability to analyze vast amounts of data efficiently, leading to wasteful
outcomes. To expedite and streamline drug development, an increasing reliance
on computer-aided drug design (CADD) approaches has merged. These sophisticated
in silico methods offer a promising avenue for efficiently identifying viable
drug candidates, thus providing pharmaceutical firms with significant
opportunities to uncover new prospective drug targets. The main goal of this
work is to review in silico methods used in the drug development process with a
focus on identifying therapeutic targets linked to specific diseases at the
genetic or protein level. This article thoroughly discusses A-to-Z in silico
techniques, which are essential for identifying the targets of bioactive
compounds and their potential therapeutic effects. This review intends to
improve drug discovery processes by illuminating the state of these
cutting-edge approaches, thereby maximizing the effectiveness and duration of
clinical trials for novel drug target investigation.",2024-12-15,"Hezha O. Rasul, Dlzar D. Ghafour, Bakhtyar K. Aziz, Bryar A. Hassan, Tarik A. Rashid, Arif Kivrak"
"Entropy conservative and entropy stable solid wall boundary conditions
  for the resistive magnetohydrodynamic equations","We present a novel technique for imposing non-linear entropy conservative and
entropy stable wall boundary conditions for the resistive magnetohydrodynamic
equations in the presence of an adiabatic wall or a wall with a prescribed heat
entropy flow, addressing three scenarios: electrically insulating walls, thin
walls with finite conductivity, and perfectly conducting walls. The procedure
relies on the formalism and mimetic properties of diagonal-norm,
summation-by-parts, and simultaneous-approximation-term operators. Using the
method of lines, a semi-discrete entropy estimate for the entire domain is
obtained when the proposed numerical imposition of boundary conditions is
coupled with an entropy-conservative or entropy-stable discrete interior
operator. The resulting estimate mimics the global entropy estimate obtained at
the continuous level. The boundary data at the wall are weakly imposed using a
penalty flux approach and a simultaneous-approximation-term technique for both
the conservative variables and the gradient of the entropy variables.
Discontinuous spectral collocation operators (mass lumped nodal discontinuous
Galerkin operators) on high-order unstructured grids are used to demonstrate
the new procedure's accuracy, robustness, and efficacy for weakly enforcing
boundary conditions. Numerical simulations confirm the non-linear stability of
the proposed technique, with applications to three-dimensional flows. The
procedure described is compatible with any diagonal-norm summation-by-parts
spatial operator, including finite element, finite difference, finite volume,
nodal and modal discontinuous Galerkin, and flux reconstruction schemes.",2024-12-15,"Vladimir Pimanov, Lisandro Dalcin, Matteo Parsani"
"A multi-theoretical kernel-based approach to social network-based
  recommendation","Recommender systems are a critical component of e-commercewebsites. The rapid
development of online social networking services provides an opportunity to
explore social networks together with information used in traditional
recommender systems, such as customer demographics, product characteristics,
and transactions. It also provides more applications for recommender systems.
To tackle this social network-based recommendation problem, previous studies
generally built trust models in light of the social influence theory. This
study inspects a spectrumof social network theories to systematicallymodel
themultiple facets of a social network and infer user preferences. In order to
effectively make use of these heterogonous theories, we take a kernel-based
machine learning paradigm, design and select kernels describing individual
similarities according to social network theories, and employ a non-linear
multiple kernel learning algorithm to combine the kernels into a unified model.
This design also enables us to consider multiple theories' interactions in
assessing individual behaviors. We evaluate our proposed approach on a
real-world movie review data set. The experiments show that our approach
provides more accurate recommendations than trust-based methods and the
collaborative filtering approach. Further analysis shows that kernels derived
from contagion theory and homophily theory contribute a larger portion of the
model.",2024-12-15,"Xin Li, Mengyue Wang, T. -P. Liang"
"Latent Reward: LLM-Empowered Credit Assignment in Episodic Reinforcement
  Learning","Reinforcement learning (RL) often encounters delayed and sparse feedback in
real-world applications, even with only episodic rewards. Previous approaches
have made some progress in reward redistribution for credit assignment but
still face challenges, including training difficulties due to redundancy and
ambiguous attributions stemming from overlooking the multifaceted nature of
mission performance evaluation. Hopefully, Large Language Model (LLM)
encompasses fruitful decision-making knowledge and provides a plausible tool
for reward redistribution. Even so, deploying LLM in this case is non-trivial
due to the misalignment between linguistic knowledge and the symbolic form
requirement, together with inherent randomness and hallucinations in inference.
To tackle these issues, we introduce LaRe, a novel LLM-empowered symbolic-based
decision-making framework, to improve credit assignment. Key to LaRe is the
concept of the Latent Reward, which works as a multi-dimensional performance
evaluation, enabling more interpretable goal attainment from various
perspectives and facilitating more effective reward redistribution. We examine
that semantically generated code from LLM can bridge linguistic knowledge and
symbolic latent rewards, as it is executable for symbolic objects. Meanwhile,
we design latent reward self-verification to increase the stability and
reliability of LLM inference. Theoretically, reward-irrelevant redundancy
elimination in the latent reward benefits RL performance from more accurate
reward estimation. Extensive experimental results witness that LaRe (i)
achieves superior temporal credit assignment to SOTA methods, (ii) excels in
allocating contributions among multiple agents, and (iii) outperforms policies
trained with ground truth rewards for certain tasks.",2024-12-15,"Yun Qu, Yuhang Jiang, Boyuan Wang, Yixiu Mao, Cheems Wang, Chang Liu, Xiangyang Ji"
"Populating cellular metamaterials on the extrema of attainable
  elasticity through neuroevolution","The trade-offs between different mechanical properties of materials pose
fundamental challenges in engineering material design, such as balancing
stiffness versus toughness, weight versus energy-absorbing capacity, and among
the various elastic coefficients. Although gradient-based topology optimization
approaches have been effective in finding specific designs and properties, they
are not efficient tools for surveying the vast design space of metamaterials,
and thus unable to reveal the attainable bound of interdependent material
properties. Other common methods, such as parametric design or data-driven
approaches, are limited by either the lack of diversity in geometry or the
difficulty to extrapolate from known data, respectively. In this work, we
formulate the simultaneous exploration of multiple competing material
properties as a multi-objective optimization (MOO) problem and employ a
neuroevolution algorithm to efficiently solve it. The Compositional
Pattern-Producing Networks (CPPNs) is used as the generative model for unit
cell designs, which provide very compact yet lossless encoding of geometry. A
modified Neuroevolution of Augmenting Topologies (NEAT) algorithm is employed
to evolve the CPPNs such that they create metamaterial designs on the Pareto
front of the MOO problem, revealing empirical bounds of different combinations
of elastic properties. Looking ahead, our method serves as a universal
framework for the computational discovery of diverse metamaterials across a
range of fields, including robotics, biomedicine, thermal engineering, and
photonics.",2024-12-15,"Maohua Yan, Ruicheng Wang, Ke Liu"
Plug-and-Play Priors as a Score-Based Method,"Plug-and-play (PnP) methods are extensively used for solving imaging inverse
problems by integrating physical measurement models with pre-trained deep
denoisers as priors. Score-based diffusion models (SBMs) have recently emerged
as a powerful framework for image generation by training deep denoisers to
represent the score of the image prior. While both PnP and SBMs use deep
denoisers, the score-based nature of PnP is unexplored in the literature due to
its distinct origins rooted in proximal optimization. This letter introduces a
novel view of PnP as a score-based method, a perspective that enables the
re-use of powerful SBMs within classical PnP algorithms without retraining. We
present a set of mathematical relationships for adapting popular SBMs as priors
within PnP. We show that this approach enables a direct comparison between PnP
and SBM-based reconstruction methods using the same neural network as the
prior. Code is available at https://github.com/wustl-cig/score_pnp.",2024-12-15,"Chicago Y. Park, Yuyang Hu, Michael T. McCann, Cristina Garcia-Cardona, Brendt Wohlberg, Ulugbek S. Kamilov"
"Multi-Graph Co-Training for Capturing User Intent in Session-based
  Recommendation","Session-based recommendation focuses on predicting the next item a user will
interact with based on sequences of anonymous user sessions. A significant
challenge in this field is data sparsity due to the typically short-term
interactions. Most existing methods rely heavily on users' current
interactions, overlooking the wealth of auxiliary information available. To
address this, we propose a novel model, the Multi-Graph Co-Training model
(MGCOT), which leverages not only the current session graph but also similar
session graphs and a global item relation graph. This approach allows for a
more comprehensive exploration of intrinsic relationships and better captures
user intent from multiple views, enabling session representations to complement
each other. Additionally, MGCOT employs multi-head attention mechanisms to
effectively capture relevant session intent and uses contrastive learning to
form accurate and robust session representations. Extensive experiments on
three datasets demonstrate that MGCOT significantly enhances the performance of
session-based recommendations, particularly on the Diginetica dataset,
achieving improvements up to 2.00% in P@20 and 10.70% in MRR@20. Resources have
been made publicly available in our GitHub repository
https://github.com/liang-tian-tian/MGCOT.",2024-12-15,"Zhe Yang, Tiantian Liang"
Empowering LLMs to Understand and Generate Complex Vector Graphics,"The unprecedented advancements in Large Language Models (LLMs) have
profoundly impacted natural language processing but have yet to fully embrace
the realm of scalable vector graphics (SVG) generation. While LLMs encode
partial knowledge of SVG data from web pages during training, recent findings
suggest that semantically ambiguous and tokenized representations within LLMs
may result in hallucinations in vector primitive predictions. Additionally, LLM
training typically lacks modeling and understanding of the rendering sequence
of vector paths, which can lead to occlusion between output vector primitives.
In this paper, we present LLM4SVG, an initial yet substantial step toward
bridging this gap by enabling LLMs to better understand and generate vector
graphics. LLM4SVG facilitates a deeper understanding of SVG components through
learnable semantic tokens, which precisely encode these tokens and their
corresponding properties to generate semantically aligned SVG outputs. Using a
series of learnable semantic tokens, a structured dataset for instruction
following is developed to support comprehension and generation across two
primary tasks. Our method introduces a modular architecture to existing large
language models, integrating semantic tags, vector instruction encoders,
fine-tuned commands, and powerful LLMs to tightly combine geometric,
appearance, and language information. To overcome the scarcity of SVG-text
instruction data, we developed an automated data generation pipeline that
collected a massive dataset of more than 250k SVG data and 580k SVG-text
instructions, which facilitated the adoption of the two-stage training strategy
popular in LLM development. By exploring various training strategies, we
developed LLM4SVG, which significantly moves beyond optimized rendering-based
approaches and language-model-based baselines to achieve remarkable results in
human evaluation tasks.",2024-12-15,"Ximing Xing, Juncheng Hu, Guotao Liang, Jing Zhang, Dong Xu, Qian Yu"
"Reliably Learn to Trim Multiparametric Quadratic Programs via Constraint
  Removal","In a wide range of applications, we are required to rapidly solve a sequence
of convex multiparametric quadratic programs (mp-QPs) on resource-limited
hardwares. This is a nontrivial task and has been an active topic for decades
in control and optimization communities. Observe that the main computational
cost of existing solution algorithms lies in addressing many linear inequality
constraints, though their majority are redundant and removing them will not
change the optimal solution. This work learns from the results of previously
solved mp-QP(s), based on which we propose novel methods to reliably trim
(unsolved) mp-QPs via constraint removal, and the trimmed mp-QPs can be much
cheaper to solve. Then, we extend to trim mp-QPs of model predictive control
(MPC) whose parameter vectors are sampled from linear systems. Importantly,
both online and offline solved mp-QPs can be utilized to adaptively trim mp-QPs
in the closed-loop system. We show that the number of linear inequalities in
the trimmed mp-QP of MPC decreases to zero in a finite timestep, which also can
be reduced by increasing offline computation. Finally, simulations are
performed to demonstrate the efficiency of our trimming method in removing
redundant constraints.",2024-12-15,"Zhinan Hou, Keyou You"
"Seeing the Forest and the Trees: Solving Visual Graph and Tree Based
  Data Structure Problems using Large Multimodal Models","Recent advancements in generative AI systems have raised concerns about
academic integrity among educators. Beyond excelling at solving programming
problems and text-based multiple-choice questions, recent research has also
found that large multimodal models (LMMs) can solve Parsons problems based only
on an image. However, such problems are still inherently text-based and rely on
the capabilities of the models to convert the images of code blocks to their
corresponding text. In this paper, we further investigate the capabilities of
LMMs to solve graph and tree data structure problems based only on images. To
achieve this, we computationally construct and evaluate a novel benchmark
dataset comprising 9,072 samples of diverse graph and tree data structure tasks
to assess the performance of the GPT-4o, GPT-4v, Gemini 1.5 Pro, Gemini 1.5
Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT-4o and Gemini
1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved
87.6% accuracy on tree samples, while Gemini 1.5 Flash, achieved 56.2% accuracy
on graph samples. Our findings highlight the influence of structural and visual
variations on model performance. This research not only introduces an LMM
benchmark to facilitate replication and further exploration but also
underscores the potential of LMMs in solving complex computing problems, with
important implications for pedagogy and assessment practices.",2024-12-15,"Sebastian Gutierrez, Irene Hou, Jihye Lee, Kenneth Angelikas, Owen Man, Sophia Mettille, James Prather, Paul Denny, Stephen MacNeil"
"GraphMoRE: Mitigating Topological Heterogeneity via Mixture of
  Riemannian Experts","Real-world graphs have inherently complex and diverse topological patterns,
known as topological heterogeneity. Most existing works learn graph
representation in a single constant curvature space that is insufficient to
match the complex geometric shapes, resulting in low-quality embeddings with
high distortion. This also constitutes a critical challenge for graph
foundation models, which are expected to uniformly handle a wide variety of
diverse graph data. Recent studies have indicated that product manifold gains
the possibility to address topological heterogeneity. However, the product
manifold is still homogeneous, which is inadequate and inflexible for
representing the mixed heterogeneous topology. In this paper, we propose a
novel Graph Mixture of Riemannian Experts (GraphMoRE) framework to effectively
tackle topological heterogeneity by personalized fine-grained topology geometry
pattern preservation. Specifically, to minimize the embedding distortion, we
propose a topology-aware gating mechanism to select the optimal embedding space
for each node. By fusing the outputs of diverse Riemannian experts with learned
gating weights, we construct personalized mixed curvature spaces for nodes,
effectively embedding the graph into a heterogeneous manifold with varying
curvatures at different points. Furthermore, to fairly measure pairwise
distances between different embedding spaces, we present a concise and
effective alignment strategy. Extensive experiments on real-world and synthetic
datasets demonstrate that our method achieves superior performance with lower
distortion, highlighting its potential for modeling complex graphs with
topological heterogeneity, and providing a novel architectural perspective for
graph foundation models.",2024-12-15,"Zihao Guo, Qingyun Sun, Haonan Yuan, Xingcheng Fu, Min Zhou, Yisen Gao, Jianxin Li"
"MAP-UOT: A Memory-Efficient Approach to Unbalanced Optimal Transport
  Implementation","Unbalanced optimal transport (UOT) has been widely used as a fundamental tool
in many application domains, where it often dominates the application running
time. While many researchers have proposed various optimizations for UOT, few
have attempted to optimize it from a computer architecture's perspective. In
this paper, we first study the performance bottlenecks of UOT through a series
of experiments, which reveals that UOT is heavily memory-bound. Guided by these
findings, we propose MAP-UOT, a Memory-efficient APproach to the implementation
and optimization of UOT on CPU and GPU platforms. Our experimental evaluations
show that the proposed strategy consistently and significantly outperforms the
state-of-the-art (SOTA) implementations. Specifically, it provides
single-threaded performance improvement over POT/COFFEE by up to 2.9X/2.4X,
with an average of 1.9X/1.6X. At the same time, it provides parallelized
performance improvement over POT/COFFEE by up to 2.4X/1.9X, with an average of
2.2X/1.8X, on Intel Core i9-12900K; and over POT by up to 3.5X, with an average
of 1.6X, on Nvidia GeForce RTX 3090 Ti. MAP-UOT also shows great performance
improvement on the Tianhe-1 supercomputer.",2024-12-15,"Chengyu Sun, Jinyu Hu, Hong Jiang"
"Reason-before-Retrieve: One-Stage Reflective Chain-of-Thoughts for
  Training-Free Zero-Shot Composed Image Retrieval","Composed Image Retrieval (CIR) aims to retrieve target images that closely
resemble a reference image while integrating user-specified textual
modifications, thereby capturing user intent more precisely. Existing
training-free zero-shot CIR (ZS-CIR) methods often employ a two-stage process:
they first generate a caption for the reference image and then use Large
Language Models for reasoning to obtain a target description. However, these
methods suffer from missing critical visual details and limited reasoning
capabilities, leading to suboptimal retrieval performance. To address these
challenges, we propose a novel, training-free one-stage method, One-Stage
Reflective Chain-of-Thought Reasoning for ZS-CIR (OSrCIR), which employs
Multimodal Large Language Models to retain essential visual information in a
single-stage reasoning process, eliminating the information loss seen in
two-stage methods. Our Reflective Chain-of-Thought framework further improves
interpretative accuracy by aligning manipulation intent with contextual cues
from reference images. OSrCIR achieves performance gains of 1.80% to 6.44% over
existing training-free methods across multiple tasks, setting new
state-of-the-art results in ZS-CIR and enhancing its utility in vision-language
applications. Our code will be available at
https://github.com/Pter61/osrcir2024/.",2024-12-15,"Yuanmin Tang, Xiaoting Qin, Jue Zhang, Jing Yu, Gaopeng Gou, Gang Xiong, Qingwei Ling, Saravan Rajmohan, Dongmei Zhang, Qi Wu"
Navigating Towards Fairness with Data Selection,"Machine learning algorithms often struggle to eliminate inherent data biases,
particularly those arising from unreliable labels, which poses a significant
challenge in ensuring fairness. Existing fairness techniques that address label
bias typically involve modifying models and intervening in the training
process, but these lack flexibility for large-scale datasets. To address this
limitation, we introduce a data selection method designed to efficiently and
flexibly mitigate label bias, tailored to more practical needs. Our approach
utilizes a zero-shot predictor as a proxy model that simulates training on a
clean holdout set. This strategy, supported by peer predictions, ensures the
fairness of the proxy model and eliminates the need for an additional holdout
set, which is a common requirement in previous methods. Without altering the
classifier's architecture, our modality-agnostic method effectively selects
appropriate training data and has proven efficient and effective in handling
label bias and improving fairness across diverse datasets in experimental
evaluations.",2024-12-15,"Yixuan Zhang, Zhidong Li, Yang Wang, Fang Chen, Xuhui Fan, Feng Zhou"
"RecSys Arena: Pair-wise Recommender System Evaluation with Large
  Language Models","Evaluating the quality of recommender systems is critical for algorithm
design and optimization. Most evaluation methods are computed based on offline
metrics for quick algorithm evolution, since online experiments are usually
risky and time-consuming. However, offline evaluation usually cannot fully
reflect users' preference for the outcome of different recommendation
algorithms, and the results may not be consistent with online A/B test.
Moreover, many offline metrics such as AUC do not offer sufficient information
for comparing the subtle differences between two competitive recommender
systems in different aspects, which may lead to substantial performance
differences in long-term online serving. Fortunately, due to the strong
commonsense knowledge and role-play capability of large language models (LLMs),
it is possible to obtain simulated user feedback on offline recommendation
results. Motivated by the idea of LLM Chatbot Arena, in this paper we present
the idea of RecSys Arena, where the recommendation results given by two
different recommender systems in each session are evaluated by an LLM judger to
obtain fine-grained evaluation feedback. More specifically, for each sample we
use LLM to generate a user profile description based on user behavior history
or off-the-shelf profile features, which is used to guide LLM to play the role
of this user and evaluate the relative preference for two recommendation
results generated by different models. Through extensive experiments on two
recommendation datasets in different scenarios, we demonstrate that many
different LLMs not only provide general evaluation results that are highly
consistent with canonical offline metrics, but also provide rich insight in
many subjective aspects. Moreover, it can better distinguish different
algorithms with comparable performance in terms of AUC and nDCG.",2024-12-15,"Zhuo Wu, Qinglin Jia, Chuhan Wu, Zhaocheng Du, Shuai Wang, Zan Wang, Zhenhua Dong"
Set-Valued Sensitivity Analysis of Deep Neural Networks,"This paper proposes a sensitivity analysis framework based on set valued
mapping for deep neural networks (DNN) to understand and compute how the
solutions (model weights) of DNN respond to perturbations in the training data.
As a DNN may not exhibit a unique solution (minima) and the algorithm of
solving a DNN may lead to different solutions with minor perturbations to input
data, we focus on the sensitivity of the solution set of DNN, instead of
studying a single solution. In particular, we are interested in the expansion
and contraction of the set in response to data perturbations. If the change of
solution set can be bounded by the extent of the data perturbation, the model
is said to exhibit the Lipschitz like property. This ""set-to-set"" analysis
approach provides a deeper understanding of the robustness and reliability of
DNNs during training. Our framework incorporates both isolated and non-isolated
minima, and critically, does not require the assumption that the Hessian of
loss function is non-singular. By developing set-level metrics such as distance
between sets, convergence of sets, derivatives of set-valued mapping, and
stability across the solution set, we prove that the solution set of the Fully
Connected Neural Network holds Lipschitz-like properties. For general neural
networks (e.g., Resnet), we introduce a graphical-derivative-based method to
estimate the new solution set following data perturbation without retraining.",2024-12-15,"Xin Wang, Feilong Wang, Xuegang Ban"
Overview of TREC 2024 Medical Video Question Answering (MedVidQA) Track,"One of the key goals of artificial intelligence (AI) is the development of a
multimodal system that facilitates communication with the visual world (image
and video) using a natural language query. Earlier works on medical question
answering primarily focused on textual and visual (image) modalities, which may
be inefficient in answering questions requiring demonstration. In recent years,
significant progress has been achieved due to the introduction of large-scale
language-vision datasets and the development of efficient deep neural
techniques that bridge the gap between language and visual understanding.
Improvements have been made in numerous vision-and-language tasks, such as
visual captioning visual question answering, and natural language video
localization. Most of the existing work on language vision focused on creating
datasets and developing solutions for open-domain applications. We believe
medical videos may provide the best possible answers to many first aid, medical
emergency, and medical education questions. With increasing interest in AI to
support clinical decision-making and improve patient engagement, there is a
need to explore such challenges and develop efficient algorithms for medical
language-video understanding and generation. Toward this, we introduced new
tasks to foster research toward designing systems that can understand medical
videos to provide visual answers to natural language questions, and are
equipped with multimodal capability to generate instruction steps from the
medical video. These tasks have the potential to support the development of
sophisticated downstream applications that can benefit the public and medical
professionals.",2024-12-15,"Deepak Gupta, Dina Demner-Fushman"
NITRO: LLM Inference on Intel Laptop NPUs,"Large Language Models (LLMs) have become essential tools in natural language
processing, finding large usage in chatbots such as ChatGPT and Gemini, and are
a central area of research. A particular area of interest includes designing
hardware specialized for these AI applications, with one such example being the
neural processing unit (NPU). In 2023, Intel released the Intel Core Ultra
processor with codename Meteor Lake, featuring a CPU, GPU, and NPU
system-on-chip. However, official software support for the NPU through Intel's
OpenVINO framework is limited to static model inference. The dynamic nature of
autoregressive token generation in LLMs is therefore not supported out of the
box. To address this shortcoming, we present NITRO (NPU Inference for
Transformers Optimization), a Python-based framework built on top of OpenVINO
to support text and chat generation on NPUs. In this paper, we discuss in
detail the key modifications made to the transformer architecture to enable
inference, some performance benchmarks, and future steps towards improving the
package. The code repository for NITRO can be found here:
https://github.com/abdelfattah-lab/nitro.",2024-12-15,"Anthony Fei, Mohamed S. Abdelfattah"
"RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous
  Driving with Vision-Language Models","Understanding and addressing corner cases is essential for ensuring the
safety and reliability of autonomous driving systems. Vision-Language Models
(VLMs) play a crucial role in enhancing scenario comprehension, yet they face
significant challenges, such as hallucination and insufficient real-world
grounding, which compromise their performance in critical driving scenarios. In
this work, we propose RAC3, a novel framework designed to improve VLMs' ability
to handle corner cases effectively. The framework integrates
Retrieval-Augmented Generation (RAG) to mitigate hallucination by dynamically
incorporating context-specific external knowledge. A cornerstone of RAC3 is its
cross-modal alignment fine-tuning, which utilizes contrastive learning to embed
image-text pairs into a unified semantic space, enabling robust retrieval of
similar scenarios. We evaluate RAC3 through extensive experiments using a
curated dataset of corner case scenarios, demonstrating its ability to enhance
semantic alignment, improve hallucination mitigation, and achieve superior
performance metrics, such as Cosine Similarity and ROUGE-L scores. For example,
for the LLaVA-v1.6-34B VLM, the cosine similarity between the generated text
and the reference text has increased by 5.22\%. The F1-score in ROUGE-L has
increased by 39.91\%, the Precision has increased by 55.80\%, and the Recall
has increased by 13.74\%. This work underscores the potential of
retrieval-augmented VLMs to advance the robustness and safety of autonomous
driving in complex environments.",2024-12-15,"Yujin Wang, Quanfeng Liu, Jiaqi Fan, Jinlong Hong, Hongqing Chu, Mengjian Tian, Bingzhao Gao, Hong Chen"
Distributed Facility Location Games with Candidate Locations,"We study the distributed facility location games with candidate locations,
where agents on a line are partitioned into groups. Both desirable and
obnoxious facility location settings are discussed. In distributed location
problems, distortion can serve as a standard for quantifying performance,
measuring the degree of difference between the actual location plan and the
ideal location plan. For the desirable setting, under the max of sum cost
objective, we give a strategyproof distributed mechanism with $5$-distortion,
and prove that no strategyproof mechanism can have a distortion better than
$\sqrt{2}+1$. Under the sum of max cost objective, we give a strategyproof
distributed mechanism with $5$-distortion, and prove that no strategyproof
mechanism can have a distortion better than $\frac{\sqrt{5}+1}{2}$. Under the
max of max cost, we get a strategyproof distributed mechanism with
$3$-distortion, and prove that no strategyproof mechanism can have a distortion
better than $\frac{\sqrt{5}+1}{2}$. For the obnoxious setting, under three
social objectives, we present that there is no strategyproof mechanism with
bounded distortion in the case of discrete candidate locations, and no group
strategyproof mechanism with bounded distortion in the case of continuous
candidate locations.",2024-12-15,Feiyue Sun
Facial Surgery Preview Based on the Orthognathic Treatment Prediction,"Orthognathic surgery consultation is essential to help patients understand
the changes to their facial appearance after surgery. However, current
visualization methods are often inefficient and inaccurate due to limited pre-
and post-treatment data and the complexity of the treatment. To overcome these
challenges, this study aims to develop a fully automated pipeline that
generates accurate and efficient 3D previews of postsurgical facial appearances
for patients with orthognathic treatment without requiring additional medical
images. The study introduces novel aesthetic losses, such as mouth-convexity
and asymmetry losses, to improve the accuracy of facial surgery prediction.
Additionally, it proposes a specialized parametric model for 3D reconstruction
of the patient, medical-related losses to guide latent code prediction network
optimization, and a data augmentation scheme to address insufficient data. The
study additionally employs FLAME, a parametric model, to enhance the quality of
facial appearance previews by extracting facial latent codes and establishing
dense correspondences between pre- and post-surgery geometries. Quantitative
comparisons showed the algorithm's effectiveness, and qualitative results
highlighted accurate facial contour and detail predictions. A user study
confirmed that doctors and the public could not distinguish between machine
learning predictions and actual postoperative results. This study aims to offer
a practical, effective solution for orthognathic surgery consultations,
benefiting doctors and patients.",2024-12-15,"Huijun Han, Congyi Zhang, Lifeng Zhu, Pradeep Singh, Richard Tai Chiu Hsung, Yiu Yan Leung, Taku Komura, Wenping Wang, Min Gu"
"Semantic Steganography: A Framework for Robust and High-Capacity
  Information Hiding using Large Language Models","In the era of Large Language Models (LLMs), generative linguistic
steganography has become a prevalent technique for hiding information within
model-generated texts. However, traditional steganography methods struggle to
effectively align steganographic texts with original model-generated texts due
to the lower entropy of the predicted probability distribution of LLMs. This
results in a decrease in embedding capacity and poses challenges for decoding
stegos in real-world communication channels. To address these challenges, we
propose a semantic steganography framework based on LLMs, which construct a
semantic space and map secret messages onto this space using ontology-entity
trees. This framework offers robustness and reliability for transmission in
complex channels, as well as resistance to text rendering and word blocking.
Additionally, the stegos generated by our framework are indistinguishable from
the covers and achieve a higher embedding capacity compared to state-of-the-art
steganography methods, while producing higher quality stegos.",2024-12-15,"Minhao Bai, Jinshuai Yang, Kaiyi Pang, Yongfeng Huang, Yue Gao"
AURORA: Automated Unleash of 3D Room Outlines for VR Applications,"Creating realistic VR experiences is challenging due to the labor-intensive
process of accurately replicating real-world details into virtual scenes,
highlighting the need for automated methods that maintain spatial accuracy and
provide design flexibility. In this paper, we propose AURORA, a novel method
that leverages RGB-D images to automatically generate both purely virtual
reality (VR) scenes and VR scenes combined with real-world elements. This
approach can benefit designers by streamlining the process of converting
real-world details into virtual scenes. AURORA integrates advanced techniques
in image processing, segmentation, and 3D reconstruction to efficiently create
realistic and detailed interior designs from real-world environments. The
design of this integration ensures optimal performance and precision,
addressing key challenges in automated indoor design generation by uniquely
combining and leveraging the strengths of foundation models. We demonstrate the
effectiveness of our approach through experiments, both on self-captured data
and public datasets, showcasing its potential to enhance virtual reality (VR)
applications by providing interior designs that conform to real-world
positioning.",2024-12-15,"Huijun Han, Yongqing Liang, Yuanlong Zhou, Wenping Wang, Edgar J. Rojas-Munoz, Xin Li"
"How to Achieve Justice through Big Data: A Study Based on Credit Card
  Cases in Beijing","With the development of intelligence, the combination of big data and
judicial practice has become a hot research topic. There are fewer studies on
credit card contract disputes related to big data, which makes it difficult to
respond to the trend of Big data era. This paper uses the data source of credit
card disputes related to the protection of personal information in Beijing from
2022 to 2024, introduces a social network analysis methodology to analyse
validated judgements and creates a database. Through the analysis of the
relationship network indicators of applicable laws and regulations, it can
clearly show the laws and regulations applicable to this type of dispute in
China in terms of substantive and procedural matters. This paper provides a
methodology for combining big data with judicial trials and assisting judges in
trials. The effective use of social networks will help fill the gap in the
application of big data in judicial trials. The result and discussion of the
paper is also of practical significance for improving the efficiency of
judicial adjudication, constructing a database for searching classified cases,
constructing a holistic system for digital courts, and finally promoting
justice.",2024-12-15,"Cheng-To Lin, Chung-Han Tsai, Baowen Zhang, Qingyue Deng, Yunhui Zhao, Zhijia Song"
"SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph
  Generation","Dynamic scenes contain intricate spatio-temporal information, crucial for
mobile robots, UAVs, and autonomous driving systems to make informed decisions.
Parsing these scenes into semantic triplets <Subject-Predicate-Object> for
accurate Scene Graph Generation (SGG) is highly challenging due to the
fluctuating spatio-temporal complexity. Inspired by the reasoning capabilities
of Large Language Models (LLMs), we propose SceneLLM, a novel framework that
leverages LLMs as powerful scene analyzers for dynamic SGG. Our framework
introduces a Video-to-Language (V2L) mapping module that transforms video
frames into linguistic signals (scene tokens), making the input more
comprehensible for LLMs. To better encode spatial information, we devise a
Spatial Information Aggregation (SIA) scheme, inspired by the structure of
Chinese characters, which encodes spatial data into tokens. Using Optimal
Transport (OT), we generate an implicit language signal from the frame-level
token sequence that captures the video's spatio-temporal information. To
further improve the LLM's ability to process this implicit linguistic input, we
apply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a
transformer-based SGG predictor to decode the LLM's reasoning and predict
semantic triplets. Our method achieves state-of-the-art results on the Action
Genome (AG) benchmark, and extensive experiments show the effectiveness of
SceneLLM in understanding and generating accurate dynamic scene graphs.",2024-12-15,"Hang Zhang, Zhuoling Li, Jun Liu"
Towards Context-aware Convolutional Network for Image Restoration,"Image restoration (IR) is a long-standing task to recover a high-quality
image from its corrupted observation. Recently, transformer-based algorithms
and some attention-based convolutional neural networks (CNNs) have presented
promising results on several IR tasks. However, existing convolutional residual
building modules for IR encounter limited ability to map inputs into
high-dimensional and non-linear feature spaces, and their local receptive
fields have difficulty in capturing long-range context information like
Transformer. Besides, CNN-based attention modules for IR either face static
abundant parameters or have limited receptive fields. To address the first
issue, we propose an efficient residual star module (ERSM) that includes
context-aware ""star operation"" (element-wise multiplication) to contextually
map features into exceedingly high-dimensional and non-linear feature spaces,
which greatly enhances representation learning. To further boost the extraction
of contextual information, as for the second issue, we propose a large dynamic
integration module (LDIM) which possesses an extremely large receptive field.
Thus, LDIM can dynamically and efficiently integrate more contextual
information that helps to further significantly improve the reconstruction
performance. Integrating ERSM and LDIM into an U-shaped backbone, we propose a
context-aware convolutional network (CCNet) with powerful learning ability for
contextual high-dimensional mapping and abundant contextual information.
Extensive experiments show that our CCNet with low model complexity achieves
superior performance compared to other state-of-the-art IR methods on several
IR tasks, including image dehazing, image motion deblurring, and image
desnowing.",2024-12-15,"Fangwei Hao, Ji Du, Weiyun Liang, Jing Xu, Xiaoxuan Xu"
"FlashSparse: Minimizing Computation Redundancy for Fast Sparse Matrix
  Multiplications on Tensor Cores","Sparse Matrix-matrix Multiplication (SpMM) and Sampled Dense-dense Matrix
Multiplication (SDDMM) are important sparse operators in scientific computing
and deep learning. Tensor Core Units (TCUs) enhance modern accelerators with
superior computing power, which is promising to boost the performance of matrix
operators to a higher level. However, due to the irregularity of unstructured
sparse data, it is difficult to deliver practical speedups on TCUs. To this
end, we propose FlashSparse, a novel approach to bridge the gap between sparse
workloads and the TCU architecture. Specifically, FlashSparse minimizes the
sparse granularity for SpMM and SDDMM on TCUs through a novel
swap-and-transpose matrix multiplication strategy. Benefiting from the minimum
sparse granularity, the computation redundancy is remarkably reduced while the
computing power of TCUs is fully utilized. Besides, FlashSparse is equipped
with a memory-efficient thread mapping strategy for coalesced data access and a
sparse matrix storage format to save memory footprint. Extensive experimental
results on H100 and RTX 4090 GPUs show that FlashSparse sets a new
state-of-the-art for sparse matrix multiplications (geometric mean 5.5x speedup
over DTC-SpMM and 3.22x speedup over RoDe).",2024-12-15,"Jinliang Shi, Shigang Li, Youxuan Xu, Rongtian Fu, Xueying Wang, Tong Wu"
"Communications over Unlicensed sub-8 GHz Spectrum: Opportunities and
  Challenges","The utilization of unlicensed spectrum presents a promising solution to the
issue of spectrum scarcity in densely populated areas, while also offering a
cost-effective means to connect underserved regions. In response to this
potential, both academia and industry are actively exploring innovative
applications of unlicensed spectrum. This work offers a thorough overview of
unlicensed spectrum bands below 8 GHz, including TV White Spaces, Civil
Broadband Radio Services, Industrial Scientific Medical bands, and the
Unlicensed National Information Infrastructure. The paper focuses on three key
aspects: regulations, existing technologies, and applications. It is essential
to recognize that ""unlicensed"" does not equate to ""unregulated""; therefore, a
clear understanding of permissible and prohibited activities is crucial. From a
technological perspective, we examine the current technologies, their
capabilities, and relevant applications. Additionally, the shared nature of
this spectrum introduces challenges related to interference among users. These
collisions can be managed through two primary strategies, that we described: a
database-driven approach and coexistence mechanisms at the MAC and PHY layers.
This work may serve as a starting point for those who are interested in the
unlicensed spectrum, both in academia and industry.",2024-12-15,"Karim Saifullin, Hussein Al-Shatri, Mohamed-Slim Alouini"
"Mask Enhanced Deeply Supervised Prostate Cancer Detection on B-mode
  Micro-Ultrasound","Prostate cancer is a leading cause of cancer-related deaths among men. The
recent development of high frequency, micro-ultrasound imaging offers improved
resolution compared to conventional ultrasound and potentially a better ability
to differentiate clinically significant cancer from normal tissue. However, the
features of prostate cancer remain subtle, with ambiguous borders with normal
tissue and large variations in appearance, making it challenging for both
machine learning and humans to localize it on micro-ultrasound images.
  We propose a novel Mask Enhanced Deeply-supervised Micro-US network, termed
MedMusNet, to automatically and more accurately segment prostate cancer to be
used as potential targets for biopsy procedures. MedMusNet leverages predicted
masks of prostate cancer to enforce the learned features layer-wisely within
the network, reducing the influence of noise and improving overall consistency
across frames.
  MedMusNet successfully detected 76% of clinically significant cancer with a
Dice Similarity Coefficient of 0.365, significantly outperforming the baseline
Swin-M2F in specificity and accuracy (Wilcoxon test, Bonferroni correction,
p-value<0.05). While the lesion-level and patient-level analyses showed
improved performance compared to human experts and different baseline, the
improvements did not reach statistical significance, likely on account of the
small cohort.
  We have presented a novel approach to automatically detect and segment
clinically significant prostate cancer on B-mode micro-ultrasound images. Our
MedMusNet model outperformed other models, surpassing even human experts. These
preliminary results suggest the potential for aiding urologists in prostate
cancer diagnosis via biopsy and treatment decision-making.",2024-12-14,"Lichun Zhang, Steve Ran Zhou, Moon Hyung Choi, Jeong Hoon Lee, Shengtian Sang, Adam Kinnaird, Wayne G. Brisbane, Giovanni Lughezzani, Davide Maffei, Vittorio Fasulo, Patrick Albers, Sulaiman Vesal, Wei Shao, Ahmed N. El Kaffas, Richard E. Fan, Geoffrey A. Sonn, Mirabela Rusu"
"Serial Scammers and Attack of the Clones: How Scammers Coordinate
  Multiple Rug Pulls on Decentralized Exchanges","We explored in this work the ubiquitous phenomenon of serial scammers, who
deploy thousands of addresses to conduct a series of similar Rug Pulls on
popular decentralized exchanges (DEXs). We first constructed a list of about
384,000 scammer addresses behind all 1-day Rug Pulls on the two most popular
DEXs, Uniswap (Ethereum) and Pancakeswap (BSC), and identified many distinctive
scam patterns including star-shaped, chain-shaped, and majority-flow scam
clusters. We then proposed an algorithm to build a complete scam network from
given scammer addresses, which consists of not only scammer addresses but also
supporting addresses including depositors, withdrawers, transferrers,
coordinators, and most importantly, wash traders. We note that profit
estimations in existing works on Rug Pulls failed to capture the cost of wash
trading, leading to inflated figures. Knowing who the wash traders are, we
established a more accurate estimate for the true profit of individual scam
pools as well as of the entire (serial) scam network by taking into account the
wash-trading expenses.",2024-12-14,"Phuong Duy Huynh, Son Hoang Dau, Hong Yen Tran, Nick Huppert, Hoonie Sun, Joshua Cervenjak, Xiaodong Li, Emanuele Viterbo"
"On Scalable Design for User-Centric Multi-Modal Shared E-Mobility
  Systems using MILP and Modified Dijkstra's Algorithm","In the rapidly evolving landscape of urban transportation, shared e-mobility
services have emerged as a sustainable solution to meet growing demand for
flexible, eco-friendly travel. However, the existing literature lacks a
comprehensive multi-modal optimization framework with focus on user preferences
and real-world constraints. This paper presents a multi-modal optimization
framework for shared e-mobility, with a particular focus on e-mobility hubs
(e-hubs) with micromobility. We propose and evaluate two approaches: a
mixed-integer linear programming (MILP) solution, complemented by a heuristic
graph reduction technique to manage computational complexity in scenarios with
limited e-hubs, achieving a computational advantage of 93%, 72%, and 47% for
20, 50, and 100 e-hubs, respectively. Additionally, the modified Dijkstra's
algorithm offers a more scalable, real-time alternative for larger e-hub
networks, with median execution times consistently around 53 ms, regardless of
the number of e-hubs. Thorough experimental evaluation on real-world map and
simulated traffic data of Dublin City Centre reveals that both methods
seamlessly adapt to practical considerations and constraints such as
multi-modality, user-preferences and state of charge for different e-mobility
tools. While MILP offers greater flexibility for incorporating additional
objectives and constraints, the modified Dijkstra's algorithm is better suited
for large-scale, real-time applications due to its computational efficiency.",2024-12-14,"Maqsood Hussain Shah, Ji Li, Mingming Liu"
MedG-KRP: Medical Graph Knowledge Representation Probing,"Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.",2024-12-14,"Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann"
DCSEG: Decoupled 3D Open-Set Segmentation using Gaussian Splatting,"Open-set 3D segmentation represents a major point of interest for multiple
downstream robotics and augmented/virtual reality applications. Recent advances
introduce 3D Gaussian Splatting as a computationally efficient representation
of the underlying scene. They enable the rendering of novel views while
achieving real-time display rates and matching the quality of computationally
far more expensive methods. We present a decoupled 3D segmentation pipeline to
ensure modularity and adaptability to novel 3D representations and semantic
segmentation foundation models. The pipeline proposes class-agnostic masks
based on a 3D reconstruction of the scene. Given the resulting class-agnostic
masks, we use a class-aware 2D foundation model to add class annotations to the
3D masks. We test this pipeline with 3D Gaussian Splatting and different 2D
segmentation models and achieve better performance than more tailored
approaches while also significantly increasing the modularity.",2024-12-14,"Luis Wiedmann, Luca Wiehe, David Rozenberszki"
"Illustrating Transition Scenarios to Renewable Energy in Hawaii with
  ProjecTable","Creating engaging and immersive data visualization tools has become
increasingly significant for a wide range of users who want to display their
data in a meaningful way. However, this can be limiting for individuals with
varying levels of coding expertise. There are specific needs, such as
visualizing complex data in easily understandable ways, highlighting real-world
problems, or telling a story with data. The Makawalu Visualization Environment
(VE) package aims to address these needs through three distinct modular tools:
Author, Presenter, and Editor. These tools work together to facilitate
different use cases based on the user's requirements. This paper discusses the
latest version of the ProjecTable and focuses on the design and usage of the
Makawalu VE Author and Presenter tools.",2024-12-14,"Tracy Bui, Kari Noe, Marissa Halim, Nurit Kirshenbaum, Jason Leigh"
"PSMGD: Periodic Stochastic Multi-Gradient Descent for Fast
  Multi-Objective Optimization","Multi-objective optimization (MOO) lies at the core of many machine learning
(ML) applications that involve multiple, potentially conflicting objectives
(e.g., multi-task learning, multi-objective reinforcement learning, among many
others). Despite the long history of MOO, recent years have witnessed a surge
in interest within the ML community in the development of gradient manipulation
algorithms for MOO, thanks to the availability of gradient information in many
ML problems. However, existing gradient manipulation methods for MOO often
suffer from long training times, primarily due to the need for computing
dynamic weights by solving an additional optimization problem to determine a
common descent direction that can decrease all objectives simultaneously. To
address this challenge, we propose a new and efficient algorithm called
Periodic Stochastic Multi-Gradient Descent (PSMGD) to accelerate MOO. PSMGD is
motivated by the key observation that dynamic weights across objectives exhibit
small changes under minor updates over short intervals during the optimization
process. Consequently, our PSMGD algorithm is designed to periodically compute
these dynamic weights and utilizes them repeatedly, thereby effectively
reducing the computational overload. Theoretically, we prove that PSMGD can
achieve state-of-the-art convergence rates for strongly-convex, general convex,
and non-convex functions. Additionally, we introduce a new computational
complexity measure, termed backpropagation complexity, and demonstrate that
PSMGD could achieve an objective-independent backpropagation complexity.
Through extensive experiments, we verify that PSMGD can provide comparable or
superior performance to state-of-the-art MOO algorithms while significantly
reducing training time.",2024-12-14,"Mingjing Xu, Peizhong Ju, Jia Liu, Haibo Yang"
Sequential Diversification with Provable Guarantees,"Diversification is a useful tool for exploring large collections of
information items. It has been used to reduce redundancy and cover multiple
perspectives in information-search settings. Diversification finds applications
in many different domains, including presenting search results of
information-retrieval systems and selecting suggestions for recommender
systems.
  Interestingly, existing measures of diversity are defined over \emph{sets} of
items, rather than evaluating \emph{sequences} of items. This design choice
comes in contrast with commonly-used relevance measures, which are distinctly
defined over sequences of items, taking into account the ranking of items. The
importance of employing sequential measures is that information items are
almost always presented in a sequential manner, and during their
information-exploration activity users tend to prioritize items with
higher~ranking.
  In this paper, we study the problem of \emph{maximizing sequential
diversity}. This is a new measure of \emph{diversity}, which accounts for the
\emph{ranking} of the items, and incorporates \emph{item relevance} and
\emph{user behavior}. The overarching framework can be instantiated with
different diversity measures, and here we consider the measures of
\emph{sum~diversity} and \emph{coverage~diversity}. The problem was recently
proposed by Coppolillo et al.~\citep{coppolillo2024relevance}, where they
introduce empirical methods that work well in practice. Our paper is a
theoretical treatment of the problem: we establish the problem hardness and
present algorithms with constant approximation guarantees for both diversity
measures we consider. Experimentally, we demonstrate that our methods are
competitive against strong baselines.",2024-12-14,"Honglian Wang, Sijing Tu, Aristides Gionis"
Unconstrained Salient and Camouflaged Object Detection,"Visual Salient Object Detection (SOD) and Camouflaged Object Detection (COD)
are two interrelated yet distinct tasks. Both tasks model the human visual
system's ability to perceive the presence of objects. The traditional SOD
datasets and methods are designed for scenes where only salient objects are
present, similarly, COD datasets and methods are designed for scenes where only
camouflaged objects are present. However, scenes where both salient and
camouflaged objects coexist, or where neither is present, are not considered.
This simplifies the existing research on SOD and COD. In this paper, to explore
a more generalized approach to SOD and COD, we introduce a benchmark called
Unconstrained Salient and Camouflaged Object Detection (USCOD), which supports
the simultaneous detection of salient and camouflaged objects in unconstrained
scenes, regardless of their presence. Towards this, we construct a large-scale
dataset, CS12K, that encompasses a variety of scenes, including four distinct
types: only salient objects, only camouflaged objects, both, and neither. In
our benchmark experiments, we identify a major challenge in USCOD:
distinguishing between salient and camouflaged objects within the same scene.
To address this challenge, we propose USCNet, a baseline model for USCOD that
decouples the learning of attribute distinction from mask reconstruction. The
model incorporates an APG module, which learns both sample-generic and
sample-specific features to enhance the attribute differentiation between
salient and camouflaged objects. Furthermore, to evaluate models' ability to
distinguish between salient and camouflaged objects, we design a metric called
Camouflage-Saliency Confusion Score (CSCS). The proposed method achieves
state-of-the-art performance on the newly introduced USCOD task. The code and
dataset will be publicly available.",2024-12-14,"Zhangjun Zhou, Yiping Li, Chunlin Zhong, Jianuo Huang, Jialun Pei, He Tang"
"Warping the Edge: Where Instant Mobility in 5G Meets Stateful
  Applications","Edge computing is considered a key paradigm for supporting real-time
applications over 5G networks, as hosting applications at the network edge can
substantially reduce delays. A significant fraction of real-time applications
over 5G are expected to be highly mobile applications. However, one challenge
with hosting mobile applications on the network edge is ensuring that users
continue to get low latency as they move across different locations. This
requires the support to handover clients to different edge sites with
negligible application delays. However, many edge applications are stateful and
can experience significant downtime during state migration over 5G. This paper
addresses the problem of enabling stateful mobile edge applications in 5G
networks. We first identify the key architectural issues and then propose a new
system design, EdgeWarp, that mitigates delays during mobility through
proactive application state migration. To enable this, we extend the existing
edge data stores with the design of a novel two-step application state
synchronization protocol, that leverages the early prediction of the target
edge host. Additionally, EdgeWarp prioritizes the handover of latency-sensitive
edge applications by communicating their latency requirements to the 5G control
plane at the beginning of a data session. Our evaluation with real edge
applications shows up to a 15.4x reduction in application downtime under
mobility. We have made our anonymized code publicly accessible here.",2024-12-14,"Mukhtiar Ahmad, Faaiq Bilal, Mutahar Ali, Muhammad Ali Nawazish, Amir Salman, Shazer Ali, Fawad Ahmad, Zafar Ayyub Qazi"
"LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and
  De-identification of PHI Across Multiple Languages","The rise of chronic diseases and pandemics like COVID-19 has emphasized the
need for effective patient data processing while ensuring privacy through
anonymization and de-identification of protected health information (PHI).
Anonymized data facilitates research without compromising patient
confidentiality. This paper introduces expert small AI models developed using
the LLM-in-the-loop methodology to meet the demand for domain-specific
de-identification NER models. These models overcome the privacy risks
associated with large language models (LLMs) used via APIs by eliminating the
need to transmit or store sensitive data. More importantly, they consistently
outperform LLMs in de-identification tasks, offering superior performance and
reliability. Our de-identification NER models, developed in eight languages
(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)
achieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,
0.978, and 0.953 respectively. These results establish them as the most
accurate healthcare anonymization solutions, surpassing existing small models
and even general-purpose LLMs such as GPT-4o. While Part-1 of this series
introduced the LLM-in-the-loop methodology for bio-medical document
translation, this second paper showcases its success in developing
cost-effective expert small NER models in de-identification tasks. Our findings
lay the groundwork for future healthcare AI innovations, including biomedical
entity and relation extraction, demonstrating the value of specialized models
for domain-specific challenges.",2024-12-14,"Murat Gunay, Bunyamin Keles, Raife Hizlan"
"ST-FiT: Inductive Spatial-Temporal Forecasting with Limited Training
  Data","Spatial-temporal graphs are widely used in a variety of real-world
applications. Spatial-Temporal Graph Neural Networks (STGNNs) have emerged as a
powerful tool to extract meaningful insights from this data. However, in
real-world applications, most nodes may not possess any available temporal data
during training. For example, the pandemic dynamics of most cities on a
geographical graph may not be available due to the asynchronous nature of
outbreaks. Such a phenomenon disagrees with the training requirements of most
existing spatial-temporal forecasting methods, which jeopardizes their
effectiveness and thus blocks broader deployment. In this paper, we propose to
formulate a novel problem of inductive forecasting with limited training data.
In particular, given a spatial-temporal graph, we aim to learn a
spatial-temporal forecasting model that can be easily generalized onto those
nodes without any available temporal training data. To handle this problem, we
propose a principled framework named ST-FiT. ST-FiT consists of two key
learning components: temporal data augmentation and spatial graph topology
learning. With such a design, ST-FiT can be used on top of any existing STGNNs
to achieve superior performance on the nodes without training data. Extensive
experiments verify the effectiveness of ST-FiT in multiple key perspectives.",2024-12-14,"Zhenyu Lei, Yushun Dong, Jundong Li, Chen Chen"
"CEKER: A Generalizable LLM Framework for Literature Analysis with a Case
  Study in Unikernel Security","Literature reviews are a critical component of formulating and justifying new
research, but are a manual and often time-consuming process. This research
introduces a novel, generalizable approach to literature analysis called CEKER
which uses a three-step process to streamline the collection of literature, the
extraction of key insights, and the summarized analysis of key trends and gaps.
Leveraging Large Language Models (LLMs), this methodology represents a
significant shift from traditional manual literature reviews, offering a
scalable, flexible, and repeatable approach that can be applied across diverse
research domains.
  A case study on unikernel security illustrates CEKER's ability to generate
novel insights validated against previous manual methods. CEKER's analysis
highlighted reduced attack surface as the most prominent theme. Key security
gaps included the absence of Address Space Layout Randomization, missing
debugging tools, and limited entropy generation, all of which represent
important challenges to unikernel security. The study also revealed a reliance
on hypervisors as a potential attack vector and emphasized the need for dynamic
security adjustments to address real-time threats.",2024-12-14,"Alex Wollman, John Hastings"
"PEARL: Input-Agnostic Prompt Enhancement with Negative Feedback
  Regulation for Class-Incremental Learning","Class-incremental learning (CIL) aims to continuously introduce novel
categories into a classification system without forgetting previously learned
ones, thus adapting to evolving data distributions. Researchers are currently
focusing on leveraging the rich semantic information of pre-trained models
(PTMs) in CIL tasks. Prompt learning has been adopted in CIL for its ability to
adjust data distribution to better align with pre-trained knowledge. This paper
critically examines the limitations of existing methods from the perspective of
prompt learning, which heavily rely on input information. To address this
issue, we propose a novel PTM-based CIL method called Input-Agnostic Prompt
Enhancement with Negative Feedback Regulation (PEARL). In PEARL, we implement
an input-agnostic global prompt coupled with an adaptive momentum update
strategy to reduce the model's dependency on data distribution, thereby
effectively mitigating catastrophic forgetting. Guided by negative feedback
regulation, this adaptive momentum update addresses the parameter sensitivity
inherent in fixed-weight momentum updates. Furthermore, it fosters the
continuous enhancement of the prompt for new tasks by harnessing correlations
between different tasks in CIL. Experiments on six benchmarks demonstrate that
our method achieves state-of-the-art performance. The code is available at:
https://github.com/qinyongchun/PEARL.",2024-12-14,"Yongchun Qin, Pengfei Fang, Hui Xue"
"Multi-Class and Multi-Task Strategies for Neural Directed Link
  Prediction","Link Prediction is a foundational task in Graph Representation Learning,
supporting applications like link recommendation, knowledge graph completion
and graph generation. Graph Neural Networks have shown the most promising
results in this domain and are currently the de facto standard approach to
learning from graph data. However, a key distinction exists between Undirected
and Directed Link Prediction: the former just predicts the existence of an
edge, while the latter must also account for edge directionality and
bidirectionality. This translates to Directed Link Prediction (DLP) having
three sub-tasks, each defined by how training, validation and test sets are
structured. Most research on DLP overlooks this trichotomy, focusing solely on
the ""existence"" sub-task, where training and test sets are random, uncorrelated
samples of positive and negative directed edges. Even in the works that
recognize the aforementioned trichotomy, models fail to perform well across all
three sub-tasks. In this study, we experimentally demonstrate that training
Neural DLP (NDLP) models only on the existence sub-task, using methods adapted
from Neural Undirected Link Prediction, results in parameter configurations
that fail to capture directionality and bidirectionality, even after
rebalancing edge classes. To address this, we propose three strategies that
handle the three tasks simultaneously. Our first strategy, the Multi-Class
Framework for Neural Directed Link Prediction (MC-NDLP) maps NDLP to a
Multi-Class training objective. The second and third approaches adopt a
Multi-Task perspective, either with a Multi-Objective (MO-DLP) or a Scalarized
(S-DLP) strategy. Our results show that these methods outperform traditional
approaches across multiple datasets and models, achieving equivalent or
superior performance in addressing the three DLP sub-tasks.",2024-12-14,"Claudio Moroni, Claudio Borile, Carolina Mattsson, Michele Starnini, André Panisson"
Dynamic Network Discovery via Infection Tracing,"Researchers, policy makers, and engineers need to make sense of data from
spreading processes as diverse as rumor spreading in social networks, viral
infections, and water contamination. Classical questions include predicting
infection behavior in a given network or deducing the network structure from
infection data. Most of the research on network infections studies static
graphs, that is, the connections in the network are assumed to not change. More
recently, temporal graphs, in which connections change over time, have been
used to more accurately represent real-world infections, which rarely occur in
unchanging networks. We propose a model for temporal graph discovery that is
consistent with previous work on static graphs and embraces the greater
expressiveness of temporal graphs. For this model, we give algorithms and lower
bounds which are often tight. We analyze different variations of the problem,
which make our results widely applicable and it also clarifies which aspects of
temporal infections make graph discovery easier or harder. We round off our
analysis with an experimental evaluation of our algorithm on real-world
interaction data from the Stanford Network Analysis Project and on temporal
Erd\H{o}s-Renyi graphs. On Erd\H{o}s-Renyi graphs, we uncover a threshold
behavior, which can be explained by a novel connectivity parameter that we
introduce during our theoretical analysis.",2024-12-14,"Ben Bals, Michelle Döring, Nicolas Klodt, George Skretas"
"Adaptive Quantization Resolution and Power Control for Federated
  Learning over Cell-free Networks","Federated learning (FL) is a distributed learning framework where users train
a global model by exchanging local model updates with a server instead of raw
datasets, preserving data privacy and reducing communication overhead. However,
the latency grows with the number of users and the model size, impeding the
successful FL over traditional wireless networks with orthogonal access.
Cell-free massive multiple-input multipleoutput (CFmMIMO) is a promising
solution to serve numerous users on the same time/frequency resource with
similar rates. This architecture greatly reduces uplink latency through spatial
multiplexing but does not take application characteristics into account. In
this paper, we co-optimize the physical layer with the FL application to
mitigate the straggler effect. We introduce a novel adaptive mixed-resolution
quantization scheme of the local gradient vector updates, where only the most
essential entries are given high resolution. Thereafter, we propose a dynamic
uplink power control scheme to manage the varying user rates and mitigate the
straggler effect. The numerical results demonstrate that the proposed method
achieves test accuracy comparable to classic FL while reducing communication
overhead by at least 93% on the CIFAR-10, CIFAR-100, and Fashion-MNIST
datasets. We compare our methods against AQUILA, Top-q, and LAQ, using the
max-sum rate and Dinkelbach power control schemes. Our approach reduces the
communication overhead by 75% and achieves 10% higher test accuracy than these
benchmarks within a constrained total latency budget.",2024-12-14,"Afsaneh Mahmoudi, Emil Björnson"
"Fair AI-STA for Legacy Wi-Fi: Enhancing Sensing and Power Management
  with Deep Q-Learning","With the increasing complexity of Wi-Fi networks and the iterative evolution
of 802.11 protocols, the Carrier Sense Multiple Access with Collision Avoidance
(CSMA/CA) protocol faces significant challenges in achieving fair channel
access and efficient resource allocation between legacy and modern Wi-Fi
devices. To address these challenges, we propose an AI-driven Station (AI-STA)
equipped with a Deep Q-Learning (DQN) module that dynamically adjusts its
receive sensitivity threshold and transmit power. The AI-STA algorithm aims to
maximize fairness in resource allocation while ensuring diverse Quality of
Service (QoS) requirements are met. The performance of the AI-STA is evaluated
through discrete event simulations in a Wi-Fi network, demonstrating that it
outperforms traditional stations in fairness and QoS metrics. Although the
AI-STA does not exhibit exceptionally superior performance, it holds
significant potential for meeting QoS and fairness requirements with the
inclusion of additional MAC parameters. The proposed AI-driven Sensitivity and
Power algorithm offers a robust framework for optimizing sensitivity and power
control in AI-STA devices within legacy Wi-Fi networks.",2024-12-14,"Peini Yi, Wenchi Cheng, Zhanyu Ju, Jingqing Wang, Jinzhe Pan, Yuehui Ouyang, Wei Zhang"
Fully Test-time Adaptation for Tabular Data,"Tabular data plays a vital role in various real-world scenarios and finds
extensive applications. Although recent deep tabular models have shown
remarkable success, they still struggle to handle data distribution shifts,
leading to performance degradation when testing distributions change. To remedy
this, a robust tabular model must adapt to generalize to unknown distributions
during testing. In this paper, we investigate the problem of fully test-time
adaptation (FTTA) for tabular data, where the model is adapted using only the
testing data. We identify three key challenges: the existence of label and
covariate distribution shifts, the lack of effective data augmentation, and the
sensitivity of adaptation, which render existing FTTA methods ineffective for
tabular data. To this end, we propose the Fully Test-time Adaptation for
Tabular data, namely FTAT, which enables FTTA methods to robustly optimize the
label distribution of predictions, adapt to shifted covariate distributions,
and suit a variety of tasks and models effectively. We conduct comprehensive
experiments on six benchmark datasets, which are evaluated using three metrics.
The experimental results demonstrate that FTAT outperforms state-of-the-art
methods by a margin.",2024-12-14,"Zhi Zhou, Kun-Yang Yu, Lan-Zhe Guo, Yu-Feng Li"
"A Novel End-To-End Event Geolocation Method Leveraging Hyperbolic Space
  and Toponym Hierarchies","Timely detection and geolocation of events based on social data can provide
critical information for applications such as crisis response and resource
allocation. However, most existing methods are greatly affected by event
detection errors, leading to insufficient geolocation accuracy. To this end,
this paper proposes a novel end-to-end event geolocation method (GTOP)
leveraging Hyperbolic space and toponym hierarchies. Specifically, the proposed
method contains one event detection module and one geolocation module. The
event detection module constructs a heterogeneous information networks based on
social data, and then constructs a homogeneous message graph and combines it
with the text and time feature of the message to learning initial features of
nodes. Node features are updated in Hyperbolic space and then fed into a
classifier for event detection. To reduce the geolocation error, this paper
proposes a noise toponym filtering algorithm (HIST) based on the hierarchical
structure of toponyms. HIST analyzes the hierarchical structure of toponyms
mentioned in the event cluster, taking the highly frequent city-level locations
as the coarse-grained locations for events. By comparing the hierarchical
structure of the toponyms within the cluster against those of the
coarse-grained locations of events, HIST filters out noisy toponyms. To further
improve the geolocation accuracy, we propose a fine-grained pseudo toponyms
generation algorithm (FIT) based on the output of HIST, and combine generated
pseudo toponyms with filtered toponyms to locate events based on the geographic
center points of the combined toponyms. Extensive experiments are conducted on
the Chinese dataset constructed in this paper and another public English
dataset. The experimental results show that the proposed method is superior to
the state-of-the-art baselines.",2024-12-14,"Yaqiong Qiao, Guojun Huang"
TinySubNets: An efficient and low capacity continual learning strategy,"Continual Learning (CL) is a highly relevant setting gaining traction in
recent machine learning research. Among CL works, architectural and hybrid
strategies are particularly effective due to their potential to adapt the model
architecture as new tasks are presented. However, many existing solutions do
not efficiently exploit model sparsity, and are prone to capacity saturation
due to their inefficient use of available weights, which limits the number of
learnable tasks. In this paper, we propose TinySubNets (TSN), a novel
architectural CL strategy that addresses the issues through the unique
combination of pruning with different sparsity levels, adaptive quantization,
and weight sharing. Pruning identifies a subset of weights that preserve model
performance, making less relevant weights available for future tasks. Adaptive
quantization allows a single weight to be separated into multiple parts which
can be assigned to different tasks. Weight sharing between tasks boosts the
exploitation of capacity and task similarity, allowing for the identification
of a better trade-off between model accuracy and capacity. These features allow
TSN to efficiently leverage the available capacity, enhance knowledge transfer,
and reduce computational resource consumption. Experimental results involving
common benchmark CL datasets and scenarios show that our proposed strategy
achieves better results in terms of accuracy than existing state-of-the-art CL
strategies. Moreover, our strategy is shown to provide a significantly improved
model capacity exploitation. Code released at:
https://github.com/lifelonglab/tinysubnets.",2024-12-14,"Marcin Pietroń, Kamil Faber, Dominik Żurek, Roberto Corizzo"
The structure of rough sets defined by reflexive relations,"For several types of information relations, the induced rough sets system RS
does not form a lattice but only a partially ordered set. However, by studying
its Dedekind-MacNeille completion DM(RS), one may reveal new important
properties of rough set structures. Building upon D. Umadevi's work on
describing joins and meets in DM(RS), we previously investigated pseudo-Kleene
algebras defined on DM(RS) for reflexive relations. This paper delves deeper
into the order-theoretic properties of DM(RS) in the context of reflexive
relations. We describe the completely join-irreducible elements of DM(RS) and
characterize when DM(RS) is a spatial completely distributive lattice. We show
that even in the case of a non-transitive reflexive relation, DM(RS) can form a
Nelson algebra, a property generally associated with quasiorders. We introduce
a novel concept, the core of a relational neighborhood, and use it to provide a
necessary and sufficient condition for DM(RS) to determine a Nelson algebra.",2024-12-14,"Jouni Järvinen, Sándor Radeleczki"
"Economic MPC with an Online Reference Trajectory for Battery Scheduling
  Considering Demand Charge Management","Monthly demand charges form a significant portion of the electric bill for
microgrids with variable renewable energy generation. A battery energy storage
system (BESS) is commonly used to manage these demand charges. Economic model
predictive control (EMPC) with a reference trajectory can be used to dispatch
the BESS to optimize the microgrid operating cost. Since demand charges are
incurred monthly, EMPC requires a full-month reference trajectory for
asymptotic stability guarantees that result in optimal operating costs.
However, a full-month reference trajectory is unrealistic from a renewable
generation forecast perspective. Therefore, to construct a practical EMPC with
a reference trajectory, an EMPC formulation considering both non-coincident
demand and on-peak demand charges is designed in this work for 24 to 48 h
prediction horizons. The corresponding reference trajectory is computed at each
EMPC step by solving an optimal control problem over 24 to 48 h reference
(trajectory) horizon. Furthermore, BESS state of charge regulation constraints
are incorporated to guarantee the BESS energy level in the long term. Multiple
reference and prediction horizon lengths are compared for both shrinking and
rolling horizons with real-world data. The proposed EMPC with 48 h rolling
reference and prediction horizons outperforms the traditional EMPC benchmark
with a 2% reduction in the annual cost, proving its economic benefits.",2024-12-14,"Cristian Cortes-Aguirre, Yi-An Chen, Avik Ghosh, Jan Kleissl, Adil Khurram"
"Attention-driven GUI Grounding: Leveraging Pretrained Multimodal Large
  Language Models without Fine-Tuning","Recent advancements in Multimodal Large Language Models (MLLMs) have
generated significant interest in their ability to autonomously interact with
and interpret Graphical User Interfaces (GUIs). A major challenge in these
systems is grounding-accurately identifying critical GUI components such as
text or icons based on a GUI image and a corresponding text query.
Traditionally, this task has relied on fine-tuning MLLMs with specialized
training data to predict component locations directly. However, in this paper,
we propose a novel Tuning-free Attention-driven Grounding (TAG) method that
leverages the inherent attention patterns in pretrained MLLMs to accomplish
this task without the need for additional fine-tuning. Our method involves
identifying and aggregating attention maps from specific tokens within a
carefully constructed query prompt. Applied to MiniCPM-Llama3-V 2.5, a
state-of-the-art MLLM, our tuning-free approach achieves performance comparable
to tuning-based methods, with notable success in text localization.
Additionally, we demonstrate that our attention map-based grounding technique
significantly outperforms direct localization predictions from MiniCPM-Llama3-V
2.5, highlighting the potential of using attention maps from pretrained MLLMs
and paving the way for future innovations in this domain.",2024-12-14,"Hai-Ming Xu, Qi Chen, Lei Wang, Lingqiao Liu"
Deep Learning Models for Colloidal Nanocrystal Synthesis,"Colloidal synthesis of nanocrystals usually includes complex chemical
reactions and multi-step crystallization processes. Despite the great success
in the past 30 years, it remains challenging to clarify the correlations
between synthetic parameters of chemical reaction and physical properties of
nanocrystals. Here, we developed a deep learning-based nanocrystal synthesis
model that correlates synthetic parameters with the final size and shape of
target nanocrystals, using a dataset of 3500 recipes covering 348 distinct
nanocrystal compositions. The size and shape labels were obtained from
transmission electron microscope images using a segmentation model trained with
a semi-supervised algorithm on a dataset comprising 1.2 million nanocrystals.
By applying the reaction intermediate-based data augmentation method and
elaborated descriptors, the synthesis model was able to predict nanocrystal's
size with a mean absolute error of 1.39 nm, while reaching an 89% average
accuracy for shape classification. The synthesis model shows knowledge transfer
capabilities across different nanocrystals with inputs of new recipes. With
that, the influence of chemicals on the final size of nanocrystals was further
evaluated, revealing the importance order of nanocrystal composition, precursor
or ligand, and solvent. Overall, the deep learning-based nanocrystal synthesis
model offers a powerful tool to expedite the development of high-quality
nanocrystals.",2024-12-14,"Kai Gu, Yingping Liang, Jiaming Su, Peihan Sun, Jia Peng, Naihua Miao, Zhimei Sun, Ying Fu, Haizheng Zhong, Jun Zhang"
"A Diagrammatic Approach to Improve Computational Efficiency in Group
  Equivariant Neural Networks","Group equivariant neural networks are growing in importance owing to their
ability to generalise well in applications where the data has known underlying
symmetries. Recent characterisations of a class of these networks that use
high-order tensor power spaces as their layers suggest that they have
significant potential; however, their implementation remains challenging owing
to the prohibitively expensive nature of the computations that are involved. In
this work, we present a fast matrix multiplication algorithm for any
equivariant weight matrix that maps between tensor power layer spaces in these
networks for four groups: the symmetric, orthogonal, special orthogonal, and
symplectic groups. We obtain this algorithm by developing a diagrammatic
framework based on category theory that enables us to not only express each
weight matrix as a linear combination of diagrams but also makes it possible
for us to use these diagrams to factor the original computation into a series
of steps that are optimal. We show that this algorithm improves the Big-$O$
time complexity exponentially in comparison to a na\""{i}ve matrix
multiplication.",2024-12-14,"Edward Pearce-Crump, William J. Knottenbelt"
Unbiased General Annotated Dataset Generation,"Pre-training backbone networks on a general annotated dataset (e.g.,
ImageNet) that comprises numerous manually collected images with category
annotations has proven to be indispensable for enhancing the generalization
capacity of downstream visual tasks. However, those manually collected images
often exhibit bias, which is non-transferable across either categories or
domains, thus causing the model's generalization capacity degeneration. To
mitigate this problem, we present an unbiased general annotated dataset
generation framework (ubGen). Instead of expensive manual collection, we aim at
directly generating unbiased images with category annotations. To achieve this
goal, we propose to leverage the advantage of a multimodal foundation model
(e.g., CLIP), in terms of aligning images in an unbiased semantic space defined
by language. Specifically, we develop a bi-level semantic alignment loss, which
not only forces all generated images to be consistent with the semantic
distribution of all categories belonging to the target dataset in an
adversarial learning manner, but also requires each generated image to match
the semantic description of its category name. In addition, we further cast an
existing image quality scoring model into a quality assurance loss to preserve
the quality of the generated image. By leveraging these two loss functions, we
can obtain an unbiased image generation model by simply fine-tuning a
pre-trained diffusion model using only all category names in the target dataset
as input. Experimental results confirm that, compared with the manually labeled
dataset or other synthetic datasets, the utilization of our generated unbiased
datasets leads to stable generalization capacity enhancement of different
backbone networks across various tasks, especially in tasks where the manually
labeled samples are scarce.",2024-12-14,"Dengyang Jiang, Haoyu Wang, Lei Zhang, Wei Wei, Guang Dai, Mengmeng Wang, Jingdong Wang, Yanning Zhang"
"Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust
  and Efficient Lung Segmentation","Chest radiography is climacteric in identifying different pulmonary diseases,
yet radiologist workload and inefficiency can lead to misdiagnoses. Automatic,
accurate, and efficient segmentation of lung from X-ray images of chest is
paramount for early disease detection. This study develops a deep learning
framework using a Pix2pix Generative Adversarial Network (GAN) to segment
pulmonary abnormalities from CXR images. This framework's image preprocessing
and augmentation techniques were properly incorporated with a U-Net-inspired
generator-discriminator architecture. Initially, it loaded the CXR images and
manual masks from the Montgomery and Shenzhen datasets, after which
preprocessing and resizing were performed. A U-Net generator is applied to the
processed CXR images that yield segmented masks; then, a Discriminator Network
differentiates between the generated and real masks. Montgomery dataset served
as the model's training set in the study, and the Shenzhen dataset was used to
test its robustness, which was used here for the first time. An adversarial
loss and an L1 distance were used to optimize the model in training. All
metrics, which assess precision, recall, F1 score, and Dice coefficient, prove
the effectiveness of this framework in pulmonary abnormality segmentation. It,
therefore, sets the basis for future studies to be performed shortly using
diverse datasets that could further confirm its clinical applicability in
medical imaging.",2024-12-14,Sharmin Akter
Enhance Vision-Language Alignment with Noise,"With the advancement of pre-trained vision-language (VL) models, enhancing
the alignment between visual and linguistic modalities in downstream tasks has
emerged as a critical challenge. Different from existing fine-tuning methods
that add extra modules to these two modalities, we investigate whether the
frozen model can be fine-tuned by customized noise. Our approach is motivated
by the scientific study of beneficial noise, namely Positive-incentive Noise
(Pi-noise or $\pi$-noise) , which quantitatively analyzes the impact of noise.
It therefore implies a new scheme to learn beneficial noise distribution that
can be employed to fine-tune VL models. Focusing on few-shot classification
tasks based on CLIP, we reformulate the inference process of CLIP and apply
variational inference, demonstrating how to generate $\pi$-noise towards visual
and linguistic modalities. Then, we propose Positive-incentive Noise Injector
(PiNI), which can fine-tune CLIP via injecting noise into both visual and text
encoders. Since the proposed method can learn the distribution of beneficial
noise, we can obtain more diverse embeddings of vision and language to better
align these two modalities for specific downstream tasks within limited
computational resources. We evaluate different noise incorporation approaches
and network architectures of PiNI. The evaluation across 11 datasets
demonstrates its effectiveness.",2024-12-14,"Sida Huang, Hongyuan Zhang, Xuelong Li"
Hyper-Fusion Network for Semi-Automatic Segmentation of Skin Lesions,"Automatic skin lesion segmentation methods based on fully convolutional
networks (FCNs) are regarded as the state-of-the-art for accuracy. When there
are, however, insufficient training data to cover all the variations in skin
lesions, where lesions from different patients may have major differences in
size/shape/texture, these methods failed to segment the lesions that have image
characteristics, which are less common in the training datasets. FCN-based
semi-automatic segmentation methods, which fuse user-inputs with high-level
semantic image features derived from FCNs offer an ideal complement to overcome
limitations of automatic segmentation methods. These semi-automatic methods
rely on the automated state-of-the-art FCNs coupled with user-inputs for
refinements, and therefore being able to tackle challenging skin lesions.
However, there are a limited number of FCN-based semi-automatic segmentation
methods and all these methods focused on early-fusion, where the first few
convolutional layers are used to fuse image features and user-inputs and then
derive fused image features for segmentation. For early-fusion based methods,
because the user-input information can be lost after the first few
convolutional layers, consequently, the user-input information will have
limited guidance and constraint in segmenting the challenging skin lesions with
inhomogeneous textures and fuzzy boundaries. Hence, in this work, we introduce
a hyper-fusion network (HFN) to fuse the extracted user-inputs and image
features over multiple stages. We separately extract complementary features
which then allows for an iterative use of user-inputs along all the fusion
stages to refine the segmentation. We evaluated our HFN on ISIC 2017, ISIC 2016
and PH2 datasets, and our results show that the HFN is more accurate and
generalizable than the state-of-the-art methods.",2024-12-14,"Lei Bi, Michael Fulham, Jinman Kim"
"Anti-bullying Adaptive Cruise Control: A proactive right-of-way
  protection approach","The current Adaptive Cruise Control (ACC) systems are vulnerable to ""road
bully"" such as cut-ins. This paper proposed an Anti-bullying Adaptive Cruise
Control (AACC) approach with proactive right-of-way protection ability. It
bears the following features: i) with the enhanced capability of preventing
bullying from cut-ins; ii) optimal but not unsafe; iii) adaptive to various
driving styles of cut-in vehicles; iv) with real-time field implementation
capability. The proposed approach can identify other road users' driving styles
online and conduct game-based motion planning for right-of-way protection. A
detailed investigation of the simulation results shows that the proposed
approach can prevent bullying from cut-ins and be adaptive to different cut-in
vehicles' driving styles. The proposed approach is capable of enhancing travel
efficiency by up to 29.55% under different cut-in gaps and can strengthen
driving safety compared with the current ACC controller. The proposed approach
is flexible and robust against traffic congestion levels. It can improve
mobility by up to 11.93% and robustness by 8.74% in traffic flow. Furthermore,
the proposed approach can support real-time field implementation by ensuring
less than 50 milliseconds computation time.",2024-12-14,"Jia Hu, Zhexi Lian, Haoran Wang, Zihan Zhang, Ruoxi Qian, Duo Li, Jaehyun, So, Junnian Zheng"
Diffusion-based Method for Satellite Pattern-of-Life Identification,"Satellite pattern-of-life (PoL) identification is crucial for space safety
and satellite monitoring, involving the analysis of typical satellite behaviors
such as station-keeping, drift, etc. However, existing PoL identification
methods remain underdeveloped due to the complexity of aerospace systems,
variability in satellite behaviors, and fluctuating observation sampling rates.
In a first attempt, we developed a domain expertise-informed machine learning
method (Expert-ML) to combine satellite orbital movement knowledge and machine
learning models. The Expert-ML method achieved high accuracy results in
simulation data and real-world data with normal sampling rate. However, this
approach lacks of generality as it requires domain expertise and its
performance degraded significantly when data sampling rate varied. To achieve
generality, we propose a novel diffusion-based PoL identification method.
Distinct from prior approaches, the proposed method leverages a diffusion model
to achieve end-to-end identification without manual refinement or
domain-specific knowledge. Specifically, we employ a multivariate time-series
encoder to capture hidden representations of satellite positional data. The
encoded features are subsequently incorporated as conditional information in
the denoising process to generate PoL labels. Through experimentation across
real-world satellite settings, our proposed diffusion-based method demonstrates
its high identification quality and provides a robust solution even with
reduced data sampling rates, indicating its great potential in practical
satellite behavior pattern identification, tracking and related mission
deployment.",2024-12-14,"Yongchao Ye, Xinting Zhu, Xuejin Shen, Xiaoyu Chen, Lishuai Li, S. Joe Qin"
Improving Community-Participated Patrol for Anti-Poaching,"Community engagement plays a critical role in anti-poaching efforts, yet
existing mathematical models aimed at enhancing this engagement often overlook
direct participation by community members as alternative patrollers. Unlike
professional rangers, community members typically lack flexibility and
experience, resulting in new challenges in optimizing patrol resource
allocation. To address this gap, we propose a novel game-theoretic model for
community-participated patrol, where a conservation agency strategically
deploys both professional rangers and community members to safeguard wildlife
against a best-responding poacher. In addition to a mixed-integer linear
program formulation, we introduce a Two-Dimensional Binary Search algorithm and
a novel Hybrid Waterfilling algorithm to efficiently solve the game in
polynomial time. Through extensive experiments and a detailed case study
focused on a protected tiger habitat in Northeast China, we demonstrate the
effectiveness of our algorithms and the practical applicability of our model.",2024-12-14,"Yufei Wu, Yixuan Even Xu, Xuming Zhang, Duo Liu, Shibing Zhu, Fei Fang"
AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games,"Decision-making in large-scale games is an essential research area in
artificial intelligence (AI) with significant real-world impact. However, the
limited access to realistic large-scale game environments has hindered research
progress in this area. In this paper, we present \textbf{AuctionNet}, a
benchmark for bid decision-making in large-scale ad auctions derived from a
real-world online advertising platform. AuctionNet is composed of three parts:
an ad auction environment, a pre-generated dataset based on the environment,
and performance evaluations of several baseline bid decision-making algorithms.
More specifically, the environment effectively replicates the integrity and
complexity of real-world ad auctions through the interaction of several
modules: the ad opportunity generation module employs deep generative models to
bridge the gap between simulated and real-world data while mitigating the risk
of sensitive data exposure; the bidding module implements diverse auto-bidding
agents trained with different decision-making algorithms; and the auction
module is anchored in the classic Generalized Second Price (GSP) auction but
also allows for customization of auction mechanisms as needed. To facilitate
research and provide insights into the game environment, we have also
pre-generated a substantial dataset based on the environment. The dataset
contains trajectories involving 48 diverse agents competing with each other,
totaling over 500 million records and occupying 80GB of storage. Performance
evaluations of baseline algorithms such as linear programming, reinforcement
learning, and generative models for bid decision-making are also presented as
part of AuctionNet. We note that AuctionNet is applicable not only to research
on bid decision-making algorithms in ad auctions but also to the general area
of decision-making in large-scale games.",2024-12-14,"Kefan Su, Yusen Huo, Zhilin Zhang, Shuai Dou, Chuan Yu, Jian Xu, Zongqing Lu, Bo Zheng"
"Scaling Up Graph Propagation Computation on Large Graphs: A Local
  Chebyshev Approximation Approach","Graph propagation (GP) computation plays a crucial role in graph data
analysis, supporting various applications such as graph node similarity
queries, graph node ranking, graph clustering, and graph neural networks.
Existing methods, mainly relying on power iteration or push computation
frameworks, often face challenges with slow convergence rates when applied to
large-scale graphs. To address this issue, we propose a novel and powerful
approach that accelerates power iteration and push methods using Chebyshev
polynomials. Specifically, we first present a novel Chebyshev expansion formula
for general GP functions, offering a new perspective on GP computation and
achieving accelerated convergence. Building on these theoretical insights, we
develop a novel Chebyshev power iteration method (\ltwocheb) and a novel
Chebyshev push method (\chebpush). Our \ltwocheb method demonstrates an
approximate acceleration of $O(\sqrt{N})$ compared to existing power iteration
techniques for both personalized PageRank and heat kernel PageRank
computations, which are well-studied GP problems. For \chebpush, we propose an
innovative subset Chebyshev recurrence technique, enabling the design of a
push-style local algorithm with provable error guarantee and reduced time
complexity compared to existing push methods. We conduct extensive experiments
using 5 large real-world datasets to evaluate our proposed algorithms,
demonstrating their superior efficiency compared to state-of-the-art
approaches.",2024-12-14,"Yichun Yang, Rong-Hua Li, Meihao Liao, Longlong Lin, Guoren Wang"
"StyleDiT: A Unified Framework for Diverse Child and Partner Faces
  Synthesis with Style Latent Diffusion Transformer","Kinship face synthesis is a challenging problem due to the scarcity and low
quality of the available kinship data. Existing methods often struggle to
generate descendants with both high diversity and fidelity while precisely
controlling facial attributes such as age and gender. To address these issues,
we propose the Style Latent Diffusion Transformer (StyleDiT), a novel framework
that integrates the strengths of StyleGAN with the diffusion model to generate
high-quality and diverse kinship faces. In this framework, the rich facial
priors of StyleGAN enable fine-grained attribute control, while our conditional
diffusion model is used to sample a StyleGAN latent aligned with the kinship
relationship of conditioning images by utilizing the advantage of modeling
complex kinship relationship distribution. StyleGAN then handles latent
decoding for final face generation. Additionally, we introduce the Relational
Trait Guidance (RTG) mechanism, enabling independent control of influencing
conditions, such as each parent's facial image. RTG also enables a fine-grained
adjustment between the diversity and fidelity in synthesized faces.
Furthermore, we extend the application to an unexplored domain: predicting a
partner's facial images using a child's image and one parent's image within the
same framework. Extensive experiments demonstrate that our StyleDiT outperforms
existing methods by striking an excellent balance between generating diverse
and high-fidelity kinship faces.",2024-12-14,"Pin-Yen Chiu, Dai-Jie Wu, Po-Hsun Chu, Chia-Hsuan Hsu, Hsiang-Chen Chiu, Chih-Yu Wang, Jun-Cheng Chen"
Continual Learning for Behavior-based Driver Identification,"Behavior-based Driver Identification is an emerging technology that
recognizes drivers based on their unique driving behaviors, offering important
applications such as vehicle theft prevention and personalized driving
experiences. However, most studies fail to account for the real-world
challenges of deploying Deep Learning models within vehicles. These challenges
include operating under limited computational resources, adapting to new
drivers, and changes in driving behavior over time. The objective of this study
is to evaluate if Continual Learning (CL) is well-suited to address these
challenges, as it enables models to retain previously learned knowledge while
continually adapting with minimal computational overhead and resource
requirements. We tested several CL techniques across three scenarios of
increasing complexity based on the well-known OCSLab dataset. This work
provides an important step forward in scalable driver identification solutions,
demonstrating that CL approaches, such as DER, can obtain strong performance,
with only an 11% reduction in accuracy compared to the static scenario.
Furthermore, to enhance the performance, we propose two new methods, SmooER and
SmooDER, that leverage the temporal continuity of driver identity over time to
enhance classification accuracy. Our novel method, SmooDER, achieves optimal
results with only a 2% reduction compared to the 11\% of the DER approach. In
conclusion, this study proves the feasibility of CL approaches to address the
challenges of Driver Identification in dynamic environments, making them
suitable for deployment on cloud infrastructure or directly within vehicles.",2024-12-14,"Mattia Fanan, Davide Dalle Pezze, Emad Efatinasab, Ruggero Carli, Mirco Rampazzo, Gian Antonio Susto"
"Sample-efficient Unsupervised Policy Cloning from Ensemble
  Self-supervised Labeled Videos","Current advanced policy learning methodologies have demonstrated the ability
to develop expert-level strategies when provided enough information. However,
their requirements, including task-specific rewards, expert-labeled
trajectories, and huge environmental interactions, can be expensive or even
unavailable in many scenarios. In contrast, humans can efficiently acquire
skills within a few trials and errors by imitating easily accessible internet
video, in the absence of any other supervision. In this paper, we try to let
machines replicate this efficient watching-and-learning process through
Unsupervised Policy from Ensemble Self-supervised labeled Videos (UPESV), a
novel framework to efficiently learn policies from videos without any other
expert supervision. UPESV trains a video labeling model to infer the expert
actions in expert videos, through several organically combined self-supervised
tasks. Each task performs its own duties, and they together enable the model to
make full use of both expert videos and reward-free interactions for advanced
dynamics understanding and robust prediction. Simultaneously, UPESV clones a
policy from the labeled expert videos, in turn collecting environmental
interactions for self-supervised tasks. After a sample-efficient and
unsupervised (i.e., reward-free) training process, an advanced video-imitated
policy is obtained. Extensive experiments in sixteen challenging
procedurally-generated environments demonstrate that the proposed UPESV
achieves state-of-the-art few-shot policy learning (outperforming five current
advanced baselines on 12/16 tasks) without exposure to any other supervision
except videos. Detailed analysis is also provided, verifying the necessity of
each self-supervised task employed in UPESV.",2024-12-14,"Xin Liu, Yaran Chen"
"Boosting ViT-based MRI Reconstruction from the Perspectives of Frequency
  Modulation, Spatial Purification, and Scale Diversification","The accelerated MRI reconstruction process presents a challenging ill-posed
inverse problem due to the extensive under-sampling in k-space. Recently,
Vision Transformers (ViTs) have become the mainstream for this task,
demonstrating substantial performance improvements. However, there are still
three significant issues remain unaddressed: (1) ViTs struggle to capture
high-frequency components of images, limiting their ability to detect local
textures and edge information, thereby impeding MRI restoration; (2) Previous
methods calculate multi-head self-attention (MSA) among both related and
unrelated tokens in content, introducing noise and significantly increasing
computational burden; (3) The naive feed-forward network in ViTs cannot model
the multi-scale information that is important for image restoration. In this
paper, we propose FPS-Former, a powerful ViT-based framework, to address these
issues from the perspectives of frequency modulation, spatial purification, and
scale diversification. Specifically, for issue (1), we introduce a frequency
modulation attention module to enhance the self-attention map by adaptively
re-calibrating the frequency information in a Laplacian pyramid. For issue (2),
we customize a spatial purification attention module to capture interactions
among closely related tokens, thereby reducing redundant or irrelevant feature
representations. For issue (3), we propose an efficient feed-forward network
based on a hybrid-scale fusion strategy. Comprehensive experiments conducted on
three public datasets show that our FPS-Former outperforms state-of-the-art
methods while requiring lower computational costs.",2024-12-14,"Yucong Meng, Zhiwei Yang, Yonghong Shi, Zhijian Song"
VinTAGe: Joint Video and Text Conditioning for Holistic Audio Generation,"Recent advances in audio generation have focused on text-to-audio (T2A) and
video-to-audio (V2A) tasks. However, T2A or V2A methods cannot generate
holistic sounds (onscreen and off-screen). This is because T2A cannot generate
sounds aligning with onscreen objects, while V2A cannot generate semantically
complete (offscreen sounds missing). In this work, we address the task of
holistic audio generation: given a video and a text prompt, we aim to generate
both onscreen and offscreen sounds that are temporally synchronized with the
video and semantically aligned with text and video. Previous approaches for
joint text and video-to-audio generation often suffer from modality bias,
favoring one modality over the other. To overcome this limitation, we introduce
VinTAGe, a flow-based transformer model that jointly considers text and video
to guide audio generation. Our framework comprises two key components: a
Visual-Text Encoder and a Joint VT-SiT model. To reduce modality bias and
improve generation quality, we employ pretrained uni-modal text-to-audio and
video-to-audio generation models for additional guidance. Due to the lack of
appropriate benchmarks, we also introduce VinTAGe-Bench, a dataset of 636
video-text-audio pairs containing both onscreen and offscreen sounds. Our
comprehensive experiments on VinTAGe-Bench demonstrate that joint text and
visual interaction is necessary for holistic audio generation. Furthermore,
VinTAGe achieves state-of-the-art results on the VGGSound benchmark. Our source
code and pre-trained models will be released. Demo is available at:
https://www.youtube.com/watch?v=QmqWhUjPkJI.",2024-12-14,"Saksham Singh Kushwaha, Yapeng Tian"
"Neural Network Meta Classifier: Improving the Reliability of Anomaly
  Segmentation","Deep neural networks (DNNs) are a contemporary solution for semantic
segmentation and are usually trained to operate on a predefined closed set of
classes. In open-set environments, it is possible to encounter semantically
unknown objects or anomalies. Road driving is an example of such an environment
in which, from a safety standpoint, it is important to ensure that a DNN
indicates it is operating outside of its learned semantic domain. One possible
approach to anomaly segmentation is entropy maximization, which is paired with
a logistic regression based post-processing step called meta classification,
which is in turn used to improve the reliability of detection of anomalous
pixels. We propose to substitute the logistic regression meta classifier with a
more expressive lightweight fully connected neural network. We analyze
advantages and drawbacks of the proposed neural network meta classifier and
demonstrate its better performance over logistic regression. We also introduce
the concept of informative out-of-distribution examples which we show to
improve training results when using entropy maximization in practice. Finally,
we discuss the loss of interpretability and show that the behavior of logistic
regression and neural network is strongly correlated.",2024-12-14,"Jurica Runtas, Tomislav Petkovic"
"Rebalanced Vision-Language Retrieval Considering Structure-Aware
  Distillation","Vision-language retrieval aims to search for similar instances in one
modality based on queries from another modality. The primary objective is to
learn cross-modal matching representations in a latent common space. Actually,
the assumption underlying cross-modal matching is modal balance, where each
modality contains sufficient information to represent the others. However,
noise interference and modality insufficiency often lead to modal imbalance,
making it a common phenomenon in practice. The impact of imbalance on retrieval
performance remains an open question. In this paper, we first demonstrate that
ultimate cross-modal matching is generally sub-optimal for cross-modal
retrieval when imbalanced modalities exist. The structure of instances in the
common space is inherently influenced when facing imbalanced modalities, posing
a challenge to cross-modal similarity measurement. To address this issue, we
emphasize the importance of meaningful structure-preserved matching.
Accordingly, we propose a simple yet effective method to rebalance cross-modal
matching by learning structure-preserved matching representations.
Specifically, we design a novel multi-granularity cross-modal matching that
incorporates structure-aware distillation alongside the cross-modal matching
loss. While the cross-modal matching loss constraints instance-level matching,
the structure-aware distillation further regularizes the geometric consistency
between learned matching representations and intra-modal representations
through the developed relational matching. Extensive experiments on different
datasets affirm the superior cross-modal retrieval performance of our approach,
simultaneously enhancing single-modal retrieval capabilities compared to the
baseline models.",2024-12-14,"Yang Yang, Wenjuan Xi, Luping Zhou, Jinhui Tang"
p-Mean Regret for Stochastic Bandits,"In this work, we extend the concept of the $p$-mean welfare objective from
social choice theory (Moulin 2004) to study $p$-mean regret in stochastic
multi-armed bandit problems. The $p$-mean regret, defined as the difference
between the optimal mean among the arms and the $p$-mean of the expected
rewards, offers a flexible framework for evaluating bandit algorithms, enabling
algorithm designers to balance fairness and efficiency by adjusting the
parameter $p$. Our framework encompasses both average cumulative regret and
Nash regret as special cases.
  We introduce a simple, unified UCB-based algorithm (Explore-Then-UCB) that
achieves novel $p$-mean regret bounds. Our algorithm consists of two phases: a
carefully calibrated uniform exploration phase to initialize sample means,
followed by the UCB1 algorithm of Auer, Cesa-Bianchi, and Fischer (2002). Under
mild assumptions, we prove that our algorithm achieves a $p$-mean regret bound
of $\tilde{O}\left(\sqrt{\frac{k}{T^{\frac{1}{2|p|}}}}\right)$ for all $p \leq
-1$, where $k$ represents the number of arms and $T$ the time horizon. When
$-1<p<0$, we achieve a regret bound of
$\tilde{O}\left(\sqrt{\frac{k^{1.5}}{T^{\frac{1}{2}}}}\right)$. For the range
$0< p \leq 1$, we achieve a $p$-mean regret scaling as
$\tilde{O}\left(\sqrt{\frac{k}{T}}\right)$, which matches the previously
established lower bound up to logarithmic factors (Auer et al. 1995). This
result stems from the fact that the $p$-mean regret of any algorithm is at
least its average cumulative regret for $p \leq 1$.
  In the case of Nash regret (the limit as $p$ approaches zero), our unified
approach differs from prior work (Barman et al. 2023), which requires a new
Nash Confidence Bound algorithm. Notably, we achieve the same regret bound up
to constant factors using our more general method.",2024-12-14,"Anand Krishna, Philips George John, Adarsh Barik, Vincent Y. F. Tan"
Patch-level Sounding Object Tracking for Audio-Visual Question Answering,"Answering questions related to audio-visual scenes, i.e., the AVQA task, is
becoming increasingly popular. A critical challenge is accurately identifying
and tracking sounding objects related to the question along the timeline. In
this paper, we present a new Patch-level Sounding Object Tracking (PSOT)
method. It begins with a Motion-driven Key Patch Tracking (M-KPT) module, which
relies on visual motion information to identify salient visual patches with
significant movements that are more likely to relate to sounding objects and
questions. We measure the patch-wise motion intensity map between neighboring
video frames and utilize it to construct and guide a motion-driven graph
network. Meanwhile, we design a Sound-driven KPT (S-KPT) module to explicitly
track sounding patches. This module also involves a graph network, with the
adjacency matrix regularized by the audio-visual correspondence map. The M-KPT
and S-KPT modules are performed in parallel for each temporal segment, allowing
balanced tracking of salient and sounding objects. Based on the tracked
patches, we further propose a Question-driven KPT (Q-KPT) module to retain
patches highly relevant to the question, ensuring the model focuses on the most
informative clues. The audio-visual-question features are updated during the
processing of these modules, which are then aggregated for final answer
prediction. Extensive experiments on standard datasets demonstrate the
effectiveness of our method, achieving competitive performance even compared to
recent large-scale pretraining-based approaches.",2024-12-14,"Zhangbin Li, Jinxing Zhou, Jing Zhang, Shengeng Tang, Kun Li, Dan Guo"
"Enhancing Event Extraction from Short Stories through Contextualized
  Prompts","Event extraction is an important natural language processing (NLP) task of
identifying events in an unstructured text. Although a plethora of works deal
with event extraction from new articles, clinical text etc., only a few works
focus on event extraction from literary content. Detecting events in short
stories presents several challenges to current systems, encompassing a
different distribution of events as compared to other domains and the portrayal
of diverse emotional conditions. This paper presents \texttt{Vrittanta-EN}, a
collection of 1000 English short stories annotated for real events. Exploring
this field could result in the creation of techniques and resources that
support literary scholars in improving their effectiveness. This could
simultaneously influence the field of Natural Language Processing. Our
objective is to clarify the intricate idea of events in the context of short
stories. Towards the objective, we collected 1,000 short stories written mostly
for children in the Indian context. Further, we present fresh guidelines for
annotating event mentions and their categories, organized into \textit{seven
distinct classes}. The classes are {\tt{COGNITIVE-MENTAL-STATE(CMS),
COMMUNICATION(COM), CONFLICT(CON), GENERAL-ACTIVITY(GA), LIFE-EVENT(LE),
MOVEMENT(MOV), and OTHERS(OTH)}}. Subsequently, we apply these guidelines to
annotate the short story dataset. Later, we apply the baseline methods for
automatically detecting and categorizing events. We also propose a prompt-based
method for event detection and classification. The proposed method outperforms
the baselines, while having significant improvement of more than 4\% for the
class \texttt{CONFLICT} in event classification task.",2024-12-14,"Chaitanya Kirti, Ayon Chattopadhyay, Ashish Anand, Prithwijit Guha"
"DSRC: Learning Density-insensitive and Semantic-aware Collaborative
  Representation against Corruptions","As a potential application of Vehicle-to-Everything (V2X) communication,
multi-agent collaborative perception has achieved significant success in 3D
object detection. While these methods have demonstrated impressive results on
standard benchmarks, the robustness of such approaches in the face of complex
real-world environments requires additional verification. To bridge this gap,
we introduce the first comprehensive benchmark designed to evaluate the
robustness of collaborative perception methods in the presence of natural
corruptions typical of real-world environments. Furthermore, we propose DSRC, a
robustness-enhanced collaborative perception method aiming to learn
Density-insensitive and Semantic-aware collaborative Representation against
Corruptions. DSRC consists of two key designs: i) a semantic-guided
sparse-to-dense distillation framework, which constructs multi-view dense
objects painted by ground truth bounding boxes to effectively learn
density-insensitive and semantic-aware collaborative representation; ii) a
feature-to-point cloud reconstruction approach to better fuse critical
collaborative representation across agents. To thoroughly evaluate DSRC, we
conduct extensive experiments on real-world and simulated datasets. The results
demonstrate that our method outperforms SOTA collaborative perception methods
in both clean and corrupted conditions. Code is available at
https://github.com/Terry9a/DSRC.",2024-12-14,"Jingyu Zhang, Yilei Wang, Lang Qian, Peng Sun, Zengwen Li, Sudong Jiang, Maolin Liu, Liang Song"
Diagnosing Unknown Attacks in Smart Homes Using Abductive Reasoning,"Security attacks are rising, as evidenced by the number of reported
vulnerabilities. Among them, unknown attacks, including new variants of
existing attacks, technical blind spots or previously undiscovered attacks,
challenge enduring security. This is due to the limited number of techniques
that diagnose these attacks and enable the selection of adequate security
controls. In this paper, we propose an automated technique that detects and
diagnoses unknown attacks by identifying the class of attack and the violated
security requirements, enabling the selection of adequate security controls.
Our technique combines anomaly detection to detect unknown attacks with
abductive reasoning to diagnose them. We first model the behaviour of the smart
home and its requirements as a logic program in Answer Set Programming (ASP).
We then apply Z-Score thresholding to the anomaly scores of an Isolation Forest
trained using unlabeled data to simulate unknown attack scenarios. Finally, we
encode the network anomaly in the logic program and perform abduction by
refutation to identify the class of attack and the security requirements that
this anomaly may violate. We demonstrate our technique using a smart home
scenario, where we detect and diagnose anomalies in network traffic. We
evaluate the precision, recall and F1-score of the anomaly detector and the
diagnosis technique against 18 attacks from the ground truth labels provided by
two datasets, CICIoT2023 and IoT-23. Our experiments show that the anomaly
detector effectively identifies anomalies when the network traces are strong
indicators of an attack. When provided with sufficient contextual data, the
diagnosis logic effectively identifies true anomalies, and reduces the number
of false positives reported by anomaly detectors. Finally, we discuss how our
technique can support the selection of adequate security controls.",2024-12-14,"Kushal Ramkumar, Wanling Cai, John McCarthy, Gavin Doherty, Bashar Nuseibeh, Liliana Pasquale"
"Sentiment and Hashtag-aware Attentive Deep Neural Network for Multimodal
  Post Popularity Prediction","Social media users articulate their opinions on a broad spectrum of subjects
and share their experiences through posts comprising multiple modes of
expression, leading to a notable surge in such multimodal content on social
media platforms. Nonetheless, accurately forecasting the popularity of these
posts presents a considerable challenge. Prevailing methodologies primarily
center on the content itself, thereby overlooking the wealth of information
encapsulated within alternative modalities such as visual demographics,
sentiments conveyed through hashtags and adequately modeling the intricate
relationships among hashtags, texts, and accompanying images. This oversight
limits the ability to capture emotional connection and audience relevance,
significantly influencing post popularity. To address these limitations, we
propose a seNtiment and hAshtag-aware attentive deep neuRal netwoRk for
multimodAl posT pOpularity pRediction, herein referred to as NARRATOR that
extracts visual demographics from faces appearing in images and discerns
sentiment from hashtag usage, providing a more comprehensive understanding of
the factors influencing post popularity Moreover, we introduce a hashtag-guided
attention mechanism that leverages hashtags as navigational cues, guiding the
models focus toward the most pertinent features of textual and visual
modalities, thus aligning with target audience interests and broader social
media context. Experimental results demonstrate that NARRATOR outperforms
existing methods by a significant margin on two real-world datasets.
Furthermore, ablation studies underscore the efficacy of integrating visual
demographics, sentiment analysis of hashtags, and hashtag-guided attention
mechanisms in enhancing the performance of post popularity prediction, thereby
facilitating increased audience relevance, emotional engagement, and aesthetic
appeal.",2024-12-14,"Shubhi Bansal, Mohit Kumar, Chandravardhan Singh Raghaw, Nagendra Kumar"
"A technical solution for the rule of law, peace, security, and
  evolvability of global cyberspace -- solve the three genetic defects of IP
  network","Since its inception in the 1960s, the internet has profoundly transformed
human life. However, its original design now struggles to meet the evolving
demands of modern society. Three primary defects have emerged: First, the
concentration of power among a few dominant entities has intensified
international conflicts and widened the technological divide. Second, the
Internet Protocol (IP)-based system lacks inherent security, leading to
frequent global cybersecurity incidents. Third, the rigidity of the IP protocol
has hindered the sustainable development of cyberspace, as it resists necessary
adaptations and innovations. Addressing these issues is crucial for the future
resilience and security of the global digital landscape.
  To address these challenges, we propose the Co-governed Multi-Identifier
Network (CoG-MIN briefly as MIN), a novel network architecture that leverages
blockchain technology to ensure equal participation of countries worldwide in
cyberspace governance and the rule of law. As a next-generation network system,
CoG-MIN integrates mechanisms such as user authentication, data signatures, and
encryption to significantly enhance network security. In testing environments,
CoG-MIN has consistently withstood extensive attacks during various
international cybersecurity competitions. Additionally, CoG-MIN supports the
evolution and interoperability of different identifier systems, remains
IP-compatible, and facilitates a gradual transition away from IP, providing an
adaptable ecosystem for diverse network architectures. This adaptability
fosters the development and evolution of diverse network architectures within
CoG-MIN, making it a natural progression for the internet's future development.
  We further introduce a trilogy of cyberspace security theorems... (Due to
character limitations, the full abstract is available in the paper PDF.)",2024-12-14,"Hui Li, Kedan Li, Jiaqing Lv, Yuanshao Liang, Feng Han, Shuo-Yen Robert Li"
"Just a Few Glances: Open-Set Visual Perception with Image Prompt
  Paradigm","To break through the limitations of pre-training models on fixed categories,
Open-Set Object Detection (OSOD) and Open-Set Segmentation (OSS) have attracted
a surge of interest from researchers. Inspired by large language models,
mainstream OSOD and OSS methods generally utilize text as a prompt, achieving
remarkable performance. Following SAM paradigm, some researchers use visual
prompts, such as points, boxes, and masks that cover detection or segmentation
targets. Despite these two prompt paradigms exhibit excellent performance, they
also reveal inherent limitations. On the one hand, it is difficult to
accurately describe characteristics of specialized category using textual
description. On the other hand, existing visual prompt paradigms heavily rely
on multi-round human interaction, which hinders them being applied to fully
automated pipeline. To address the above issues, we propose a novel prompt
paradigm in OSOD and OSS, that is, \textbf{Image Prompt Paradigm}. This brand
new prompt paradigm enables to detect or segment specialized categories without
multi-round human intervention. To achieve this goal, the proposed image prompt
paradigm uses just a few image instances as prompts, and we propose a novel
framework named \textbf{MI Grounding} for this new paradigm. In this framework,
high-quality image prompts are automatically encoded, selected and fused,
achieving the single-stage and non-interactive inference. We conduct extensive
experiments on public datasets, showing that MI Grounding achieves competitive
performance on OSOD and OSS benchmarks compared to text prompt paradigm methods
and visual prompt paradigm methods. Moreover, MI Grounding can greatly
outperform existing method on our constructed specialized ADR50K dataset.",2024-12-14,"Jinrong Zhang, Penghui Wang, Chunxiao Liu, Wei Liu, Dian Jin, Qiong Zhang, Erli Meng, Zhengnan Hu"
BlockDoor: Blocking Backdoor Based Watermarks in Deep Neural Networks,"Adoption of machine learning models across industries have turned Neural
Networks (DNNs) into a prized Intellectual Property (IP), which needs to be
protected from being stolen or being used without authorization. This topic
gave rise to multiple watermarking schemes, through which, one can establish
the ownership of a model. Watermarking using backdooring is the most well
established method available in the literature, with specific works
demonstrating the difficulty in removing the watermarks, embedded as backdoors
within the weights of the network. However, in our work, we have identified a
critical flaw in the design of the watermark verification with backdoors,
pertaining to the behaviour of the samples of the Trigger Set, which acts as
the secret key. In this paper, we present BlockDoor, which is a comprehensive
package of techniques that is used as a wrapper to block all three different
kinds of Trigger samples, which are used in the literature as means to embed
watermarks within the trained neural networks as backdoors. The framework
implemented through BlockDoor is able to detect potential Trigger samples,
through separate functions for adversarial noise based triggers,
out-of-distribution triggers and random label based triggers. Apart from a
simple Denial-of-Service for a potential Trigger sample, our approach is also
able to modify the Trigger samples for correct machine learning functionality.
Extensive evaluation of BlockDoor establishes that it is able to significantly
reduce the watermark validation accuracy of the Trigger set by up to $98\%$
without compromising on functionality, delivering up to a less than $1\%$ drop
on the clean samples. BlockDoor has been tested on multiple datasets and neural
architectures.",2024-12-14,"Yi Hao Puah, Anh Tu Ngo, Nandish Chattopadhyay, Anupam Chattopadhyay"
"Cluster-Based Multi-Agent Task Scheduling for Space-Air-Ground
  Integrated Networks","The Space-Air-Ground Integrated Network (SAGIN) framework is a crucial
foundation for future networks, where satellites and aerial nodes assist in
computational task offloading. The low-altitude economy, leveraging the
flexibility and multifunctionality of Unmanned Aerial Vehicles (UAVs) in SAGIN,
holds significant potential for development in areas such as communication and
sensing. However, effective coordination is needed to streamline information
exchange and enable efficient system resource allocation. In this paper, we
propose a Clustering-based Multi-agent Deep Deterministic Policy Gradient
(CMADDPG) algorithm to address the multi-UAV cooperative task scheduling
challenges in SAGIN. The CMADDPG algorithm leverages dynamic UAV clustering to
partition UAVs into clusters, each managed by a Cluster Head (CH) UAV,
facilitating a distributed-centralized control approach. Within each cluster,
UAVs delegate offloading decisions to the CH UAV, reducing intra-cluster
communication costs and decision conflicts, thereby enhancing task scheduling
efficiency. Additionally, by employing a multi-agent reinforcement learning
framework, the algorithm leverages the extensive coverage of satellites to
achieve centralized training and distributed execution of multi-agent tasks,
while maximizing overall system profit through optimized task offloading
decision-making. Simulation results reveal that the CMADDPG algorithm
effectively optimizes resource allocation, minimizes queue delays, maintains
balanced load distribution, and surpasses existing methods by achieving at
least a 25\% improvement in system profit, showcasing its robustness and
adaptability across diverse scenarios.",2024-12-14,"Zhiying Wang, Gang Sun, Yuhui Wang, Hongfang Yu, Dusit Niyato"
"RMCSA Algorithm for Congestion-Aware and Service Latency Aware Dynamic
  Service Provisioning in Software-Defined SDM-EONs","The implementation of 5G and the future deployment of 6G necessitate the
utilization of optical networks that possess substantial capacity and exhibit
minimal latency. The dynamic arrival and departure of connection requests in
optical networks result in particular central links experiencing more traffic
and congestion than non-central links. The occurrence of congested links leads
to service blocking despite the availability of resources within the network,
restricting the efficient utilization of network resources. The available
algorithms in the literature that aim to balance load among network links offer
a trade-off between blocking performance and algorithmic complexity, thus
increasing service provisioning time. This work proposes a dynamic
routing-based congestion-aware routing, modulation, core, and spectrum
assignment (RMCSA) algorithm for space division multiplexing elastic optical
networks (SDM-EONs). The algorithm finds alternative candidate paths based on
real-time link occupancy metrics to minimize blocking due to link congestion
under dynamic traffic scenarios. As a result, the algorithm reduces the
formation of congestion hotspots in the network owing to link-betweenness
centrality. We have performed extensive simulations using two realistic network
topologies to compare the performance of the proposed algorithm with relevant
RMCSA algorithms available in the literature. The simulation results verify the
superior performance of our proposed algorithm compared to the benchmark Yen's
K-shortest paths and K-Disjoint shortest paths RMCSA algorithms in connection
blocking ratio and spectrum utilization efficiency. To expedite the
route-finding process, we present a novel caching strategy that allows the
proposed algorithm to demonstrate a much-reduced service delay time compared to
the recently developed adaptive link weight-based load-balancing RMCSA
algorithm.",2024-12-14,"Baljinder Singh Heera, Shrinivas Petale, Yatindra Nath Singh, Suresh Subramaniam"
"Chasing Progress, Not Perfection: Revisiting Strategies for End-to-End
  LLM Plan Generation","The capability of Large Language Models (LLMs) to plan remains a topic of
debate. Some critics argue that strategies to boost LLMs' reasoning skills are
ineffective in planning tasks, while others report strong outcomes merely from
training models on a planning corpus. This study reassesses recent strategies
by developing an end-to-end LLM planner and employing diverse metrics for a
thorough evaluation. We find that merely fine-tuning LLMs on a corpus of
planning instances does not lead to robust planning skills, as indicated by
poor performance on out-of-distribution test sets. At the same time, we find
that various strategies, including Chain-of-Thought, do enhance the probability
of a plan being executable. This indicates progress towards better plan
quality, despite not directly enhancing the final validity rate. Among the
strategies we evaluated, reinforcement learning with our novel `Longest
Contiguous Common Subsequence' reward emerged as the most effective,
contributing to both plan validity and executability. Overall, our research
addresses key misconceptions in the LLM-planning literature; we validate
incremental progress in plan executability, although plan validity remains a
challenge. Hence, future strategies should focus on both these aspects, drawing
insights from our findings.",2024-12-14,"Sukai Huang, Trevor Cohn, Nir Lipovetzky"
"USM: Unbiased Survey Modeling for Limiting Negative User Experiences in
  Recommendation Systems","Negative feedback signals are crucial to guardrail content recommendations
and improve user experience. When these signals are effectively integrated into
recommendation systems, they play a vital role in preventing the promotion of
harmful or undesirable content, thereby contributing to a healthier online
environment. However, the challenges associated with negative signals are
noteworthy. Due to the limited visibility of options for users to express
negative feedback, these signals are often sparse compared to positive signals.
This imbalance can lead to a skewed understanding of user preferences,
resulting in recommendations that prioritize short-term engagement over
long-term satisfaction. Moreover, an over-reliance on positive signals can
create a filter bubble, where users are continuously exposed to content that
aligns with their immediate preferences but may not be beneficial in the long
run. This scenario can ultimately lead to user attrition as audiences become
disillusioned with the quality of the content provided. Additionally, existing
user signals frequently fail to meet specific customized requirements, such as
understanding the underlying reasons for a user's likes or dislikes regarding a
video. This lack of granularity hinders our ability to tailor content
recommendations effectively, as we cannot identify the particular attributes of
content that resonate with individual users.",2024-12-14,"Chenghui Yu, Peiyi Li, Haoze Wu, Bingfeng Deng, Hongyu Xiong"
"User Personas Improve Social Sustainability by Encouraging Software
  Developers to Deprioritize Antisocial Features","Sustainable software development involves creating software in a manner that
meets present goals without undermining our ability to meet future goals. In a
software engineering context, sustainability has at least four dimensions:
ecological, economic, social, and technical. No interventions for improving
social sustainability in software engineering have been tested in rigorous
lab-based experiments, and little evidence-based guidance is available. The
purpose of this study is to evaluate the effectiveness of two
interventions-stakeholder maps and persona models-for improving social
sustainability through software feature prioritization. We conducted a
randomized controlled factorial experiment with 79 undergraduate computer
science students. Participants were randomly assigned to one of four groups and
asked to prioritize a backlog of prosocial, neutral, and antisocial user
stories for a shopping mall's digital screen display and facial recognition
software. Participants received either persona models, a stakeholder map, both,
or neither. We compared the differences in prioritization levels assigned to
prosocial and antisocial user stories using Cumulative Link Mixed Model
regression. Participants who received persona models gave significantly lower
priorities to antisocial user stories but no significant difference was evident
for prosocial user stories. The effects of the stakeholder map were not
significant. The interaction effects were not significant. Providing aspiring
software professionals with well-crafted persona models causes them to
de-prioritize antisocial software features. The impact of persona modelling on
sustainable software development therefore warrants further study with more
experience professionals. Moreover, the novel methodological strategy of
assessing social sustainability behavior through backlog prioritization appears
feasible in lab-based settings.",2024-12-14,"Bimpe Ayoola, Miikka Kuutila, Rina R. Wehbe, Paul Ralph"
Bi-Criteria Metric Distortion,"Selecting representatives based on voters' preferences is a fundamental
problem in social choice theory. While cardinal utility functions offer a
detailed representation of preferences, ordinal rankings are often the only
available information due to their simplicity and practical constraints. The
metric distortion framework addresses this issue by modeling voters and
candidates as points in a metric space, with distortion quantifying the
efficiency loss from relying solely on ordinal rankings. Existing works define
the cost of a voter with respect to a candidate as their distance and set the
overall cost as either the sum (utilitarian) or maximum (egalitarian) of these
costs across all voters. They show that deterministic algorithms achieve a
best-possible distortion of 3 for any metric when considering a single
candidate.
  This paper explores whether one can obtain a better approximation compared to
an optimal candidate by relying on a committee of $k$ candidates ($k \ge 1$),
where the cost of a voter is defined as its distance to the closest candidate
in the committee. We answer this affirmatively in the case of line metrics,
demonstrating that with $O(1)$ candidates, it is possible to achieve optimal
cost. Our results extend to both utilitarian and egalitarian objectives,
providing new upper bounds for the problem. We complement our results with
lower bounds for both the line and 2-D Euclidean metrics.",2024-12-14,"Kiarash Banihashem, Diptarka Chakraborty, Shayan Chashm Jahan, Iman Gholami, MohammadTaghi Hajiaghayi, Mohammad Mahdavi, Max Springer"
Pretrained Event Classification Model for High Energy Physics Analysis,"We introduce a foundation model for event classification in high-energy
physics, built on a Graph Neural Network architecture and trained on 120
million simulated proton-proton collision events spanning 12 distinct physics
processes. The model is pretrained to learn a general and robust representation
of collision data using challenging multiclass and multilabel classification
tasks. Its performance is evaluated across five event classification tasks,
which include both physics processes used during pretraining and new processes
not encountered during pretraining. Fine-tuning the pretrained model
significantly improves classification performance, particularly in scenarios
with limited training data, demonstrating gains in both accuracy and
computational efficiency. To investigate the underlying mechanisms behind these
performance improvements, we employ a representational similarity evaluation
framework based on Centered Kernel Alignment. This analysis reveals notable
differences in the learned representations of fine-tuned pretrained models
compared to baseline models trained from scratch.",2024-12-14,"Joshua Ho, Benjamin Ryan Roberts, Shuo Han, Haichen Wang"
"MEATRD: Multimodal Anomalous Tissue Region Detection Enhanced with
  Spatial Transcriptomics","The detection of anomalous tissue regions (ATRs) within affected tissues is
crucial in clinical diagnosis and pathological studies. Conventional automated
ATR detection methods, primarily based on histology images alone, falter in
cases where ATRs and normal tissues have subtle visual differences. The recent
spatial transcriptomics (ST) technology profiles gene expressions across tissue
regions, offering a molecular perspective for detecting ATRs. However, there is
a dearth of ATR detection methods that effectively harness complementary
information from both histology images and ST. To address this gap, we propose
MEATRD, a novel ATR detection method that integrates histology image and ST
data. MEATRD is trained to reconstruct image patches and gene expression
profiles of normal tissue spots (inliers) from their multimodal embeddings,
followed by learning a one-class classification AD model based on latent
multimodal reconstruction errors. This strategy harmonizes the strengths of
reconstruction-based and one-class classification approaches. At the heart of
MEATRD is an innovative masked graph dual-attention transformer (MGDAT)
network, which not only facilitates cross-modality and cross-node information
sharing but also addresses the model over-generalization issue commonly seen in
reconstruction-based AD methods. Additionally, we demonstrate that
modality-specific, task-relevant information is collated and condensed in
multimodal bottleneck encoding generated in MGDAT, marking the first
theoretical analysis of the informational properties of multimodal bottleneck
encoding. Extensive evaluations across eight real ST datasets reveal MEATRD's
superior performance in ATR detection, surpassing various state-of-the-art AD
methods. Remarkably, MEATRD also proves adept at discerning ATRs that only show
slight visual deviations from normal tissues.",2024-12-14,"Kaichen Xu, Qilong Wu, Yan Lu, Yinan Zheng, Wenlin Li, Xingjie Tang, Jun Wang, Xiaobo Sun"
"Combining Priors with Experience: Confidence Calibration Based on
  Binomial Process Modeling","Confidence calibration of classification models is a technique to estimate
the true posterior probability of the predicted class, which is critical for
ensuring reliable decision-making in practical applications. Existing
confidence calibration methods mostly use statistical techniques to estimate
the calibration curve from data or fit a user-defined calibration function, but
often overlook fully mining and utilizing the prior distribution behind the
calibration curve. However, a well-informed prior distribution can provide
valuable insights beyond the empirical data under the limited data or
low-density regions of confidence scores. To fill this gap, this paper proposes
a new method that integrates the prior distribution behind the calibration
curve with empirical data to estimate a continuous calibration curve, which is
realized by modeling the sampling process of calibration data as a binomial
process and maximizing the likelihood function of the binomial process. We
prove that the calibration curve estimating method is Lipschitz continuous with
respect to data distribution and requires a sample size of $3/B$ of that
required for histogram binning, where $B$ represents the number of bins. Also,
a new calibration metric ($TCE_{bpm}$), which leverages the estimated
calibration curve to estimate the true calibration error (TCE), is designed.
$TCE_{bpm}$ is proven to be a consistent calibration measure. Furthermore,
realistic calibration datasets can be generated by the binomial process
modeling from a preset true calibration curve and confidence score
distribution, which can serve as a benchmark to measure and compare the
discrepancy between existing calibration metrics and the true calibration
error. The effectiveness of our calibration method and metric are verified in
real-world and simulated data.",2024-12-14,"Jinzong Dong, Zhaohui Jiang, Dong Pan, Haoyang Yu"
"Global Estimation of Subsurface Eddy Kinetic Energy of Mesoscale Eddies
  Using a Multiple-input Residual Neural Network","Oceanic eddy kinetic energy (EKE) is a key quantity for measuring the
intensity of mesoscale eddies and for parameterizing eddy effects in ocean
climate models. Three decades of satellite altimetry observations allow a
global assessment of sea surface information. However, the subsurface EKE with
spatial filter has not been systematically studied due to the sparseness of
subsurface observational data. The subsurface EKE can be inferred both
theoretically and numerically from sea surface observations but is limited by
the issue of decreasing correlation with sea surface variables as depth
increases. In this work, inspired by the Taylor-series expansion of subsurface
EKE, a multiple-input neural network approach is proposed to reconstruct the
subsurface monthly mean EKE from sea surface variables and subsurface
climatological variables (e.g., horizontal filtered velocity gradients). Four
neural networks are trained on a high-resolution global ocean reanalysis
dataset, namely, surface-input fully connected neural network model (FCNN),
surface-input Residual neural network model (ResNet), multiple-input fully
connected neural network model (MI-FCNN), and multiple-input residual neural
network model (MI-ResNet). The proposed MI-FCNN and MI-ResNet models integrate
the surface input variables and the vertical profiles of subsurface variables.
The MI-ResNet model outperforms the FCNN, ResNet, and MI-FCNN models, and
traditional physics-based models in both regional and global reconstruction of
subsurface EKE in the upper 2000 m. In addition, the MI-ResNet model performs
well for both regional and global observational data based on transfer
learning. These findings reveal the potential of the MI-ResNet model for
efficient and accurate reconstruction of subsurface oceanic variables.",2024-12-14,"Chenyue Xie, An-Kang Gao, Xiyun Lu"
LAN: Learning to Adapt Noise for Image Denoising,"Removing noise from images, a.k.a image denoising, can be a very challenging
task since the type and amount of noise can greatly vary for each image due to
many factors including a camera model and capturing environments. While there
have been striking improvements in image denoising with the emergence of
advanced deep learning architectures and real-world datasets, recent denoising
networks struggle to maintain performance on images with noise that has not
been seen during training. One typical approach to address the challenge would
be to adapt a denoising network to new noise distribution. Instead, in this
work, we shift our focus to adapting the input noise itself, rather than
adapting a network. Thus, we keep a pretrained network frozen, and adapt an
input noise to capture the fine-grained deviations. As such, we propose a new
denoising algorithm, dubbed Learning-to-Adapt-Noise (LAN), where a learnable
noise offset is directly added to a given noisy image to bring a given input
noise closer towards the noise distribution a denoising network is trained to
handle. Consequently, the proposed framework exhibits performance improvement
on images with unseen noise, displaying the potential of the proposed research
direction. The code is available at https://github.com/chjinny/LAN",2024-12-14,"Changjin Kim, Tae Hyun Kim, Sungyong Baik"
"Enhancement of text recognition for hanja handwritten documents of
  Ancient Korea","We implemented a high-performance optical character recognition model for
classical handwritten documents using data augmentation with highly variable
cropping within the document region. Optical character recognition in
handwritten documents, especially classical documents, has been a challenging
topic in many countries and research organizations due to its difficulty.
Although many researchers have conducted research on this topic, the quality of
classical texts over time and the unique stylistic characteristics of various
authors have made it difficult, and it is clear that the recognition of hanja
handwritten documents is a meaningful and special challenge, especially since
hanja, which has been developed by reflecting the vocabulary, semantic, and
syntactic features of the Joseon Dynasty, is different from classical Chinese
characters. To study this challenge, we used 1100 cursive documents, which are
small in size, and augmented 100 documents per document by cropping a randomly
sized region within each document for training, and trained them using a
two-stage object detection model, High resolution neural network (HRNet), and
applied the resulting model to achieve a high inference recognition rate of 90%
for cursive documents. Through this study, we also confirmed that the
performance of OCR is affected by the simplified characters, variants, variant
characters, common characters, and alternators of Chinese characters that are
difficult to see in other studies, and we propose that the results of this
study can be applied to optical character recognition of modern documents in
multiple languages as well as other typefaces in classical documents.",2024-12-14,"Joonmo Ahna, Taehong Jang, Quan Fengnyu, Hyungil Lee, Jaehyuk Lee, Sojung Lucia Kim"
Scientific Realism vs. Anti-Realism: Toward a Common Ground,"The debate between scientific realism and anti-realism remains at a
stalemate, with reconciliation seeming hopeless. Yet, important work remains:
to seek a common ground, even if only to uncover deeper points of disagreement.
I develop the idea that everyone values some truths, and use it to benefit both
sides of the debate. More specifically, many anti-realists, such as
instrumentalists, have yet to seriously engage with Sober's call to justify
their preferred version of Ockham's razor through a positive epistemology.
Meanwhile, realists face a similar challenge: providing a non-circular
explanation of how their version of Ockham's razor connects to truth. Drawing
insights from fields that study scientific inference -- statistics and machine
learning -- I propose a common ground that addresses these challenges for both
sides. This common ground also isolates a distinctively epistemic root of the
irreconcilability in the realism debate.",2024-12-14,Hanti Lin
"Deviate or Not: Learning Coalition Structures with Multiple-bit
  Observations in Games","We consider the Coalition Structure Learning (CSL) problem in multi-agent
systems, motivated by the existence of coalitions in many real-world systems,
e.g., trading platforms and auction systems. In this problem, there is a hidden
coalition structure within a set of $n$ agents, which affects the behavior of
the agents in games. Our goal is to actively design a sequence of games for the
agents to play, such that observations in these games can be used to learn the
hidden coalition structure. In particular, we consider the setting where in
each round, we design and present a game together with a strategy profile to
the agents, and receive a multiple-bit observation -- for each agent, we
observe whether or not they would like to deviate from the specified strategy.
We show that we can learn the coalition structure in $O(\log n)$ rounds if we
are allowed to design any normal-form game, matching the
information-theoretical lower bound. For practicality, we extend the result to
settings where we can only choose games of a specific format, and design
algorithms to learn the coalition structure in these settings. For most
settings, our complexity matches the theoretical lower bound up to a constant
factor.",2024-12-14,"Yixuan Even Xu, Zhe Feng, Fei Fang"
"Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained
  Iterative Refinement","Abstract Purpose: High-quality 4D MRI requires an impractically long scanning
time for dense k-space signal acquisition covering all respiratory phases.
Accelerated sparse sampling followed by reconstruction enhancement is desired
but often results in degraded image quality and long reconstruction time. We
hereby propose the chained iterative reconstruction network (CIRNet) for
efficient sparse-sampling reconstruction while maintaining clinically
deployable quality. Methods: CIRNet adopts the denoising diffusion
probabilistic framework to condition the image reconstruction through a
stochastic iterative denoising process. During training, a forward Markovian
diffusion process is designed to gradually add Gaussian noise to the densely
sampled ground truth (GT), while CIRNet is optimized to iteratively reverse the
Markovian process from the forward outputs. At the inference stage, CIRNet
performs the reverse process solely to recover signals from noise, conditioned
upon the undersampled input. CIRNet processed the 4D data (3D+t) as temporal
slices (2D+t). The proposed framework is evaluated on a data cohort consisting
of 48 patients (12332 temporal slices) who underwent free-breathing liver 4D
MRI. 3-, 6-, 10-, 20- and 30-times acceleration were examined with a
retrospective random undersampling scheme. Compressed sensing (CS)
reconstruction with a spatiotemporal constraint and a recently proposed deep
network, Re-Con-GAN, are selected as baselines. Results: CIRNet consistently
achieved superior performance compared to CS and Re-Con-GAN. The inference time
of CIRNet, CS, and Re-Con-GAN are 11s, 120s, and 0.15s. Conclusion: A novel
framework, CIRNet, is presented. CIRNet maintains useable image quality for
acceleration up to 30 times, significantly reducing the burden of 4DMRI.",2024-12-14,"Di Xu, Xin Miao, Hengjie Liu, Jessica E. Scholey, Wensha Yang, Mary Feng, Michael Ohliger, Hui Lin, Yi Lao, Yang Yang, Ke Sheng"
Versatile Locomotion Skills for Hexapod Robots,"Hexapod robots are potentially suitable for carrying out tasks in cluttered
environments since they are stable, compact, and light weight. They also have
multi-joint legs and variable height bodies that make them good candidates for
tasks such as stairs climbing and squeezing under objects in a typical home
environment or an attic. Expanding on our previous work on joist climbing in
attics, we train a legged hexapod equipped with a depth camera and visual
inertial odometry (VIO) to perform three tasks: climbing stairs, avoiding
obstacles, and squeezing under obstacles such as a table. Our policies are
trained with simulation data only and can be deployed on lowcost hardware not
requiring real-time joint state feedback. We train our model in a
teacher-student model with 2 phases: In phase 1, we use reinforcement learning
with access to privileged information such as height maps and joint feedback.
In phase 2, we use supervised learning to distill the model into one with
access to only onboard observations, consisting of egocentric depth images and
robot pose captured by a tracking VIO camera. By manipulating available
privileged information, constructing simulation terrains, and refining reward
functions during phase 1 training, we are able to train the robots with skills
that are robust in non-ideal physical environments. We demonstrate successful
sim-to-real transfer and achieve high success rates across all three tasks in
physical experiments.",2024-12-14,"Tomson Qu, Dichen Li, Avideh Zakhor, Wenhao Yu, Tingnan Zhang"
"An Active Parameter Learning Approach to The Identification of Safe
  Regions","We consider the problem of identification of safe regions in the environment
of an autonomous system. The environment is divided into a finite collections
of Voronoi cells, with each cell having a representative, the Voronoi center.
The extent to which each region is considered to be safe by an oracle is
captured through a trust distribution. The trust placed by the oracle
conditioned on the region is modeled through a Bernoulli distribution whose the
parameter depends on the region. The parameters are unknown to the system.
However, if the agent were to visit a given region, it will receive a binary
valued random response from the oracle on whether the oracle trusts the region
or not. The objective is to design a path for the agent where, by traversing
through the centers of the cells, the agent is eventually able to label each
cell safe or unsafe. To this end, we formulate an active parameter learning
problem with the objective of minimizing visits or stays in potentially unsafe
regions. The active learning problem is formulated as a finite horizon
stochastic control problem where the cost function is derived utilizing the
large deviations principle (LDP). The challenges associated with a dynamic
programming approach to solve the problem are analyzed. Subsequently, the
optimization problem is relaxed to obtain single-step optimization problems for
which closed form solution is obtained. Using the solution, we propose an
algorithm for the active learning of the parameters. A relationship between the
trust distributions and the label of a cell is defined and subsequently a
classification algorithm is proposed to identify the safe regions. We prove
that the algorithm identifies the safe regions with finite number of visits to
unsafe regions. We demonstrate the algorithm through an example.",2024-12-14,"Aneesh Raghavan, Karl H Johansson"
"Certainty-Equivalence Model Predictive Control: Stability, Performance,
  and Beyond","Handling model mismatch is a common challenge in model-based controller
design, particularly in model predictive control (MPC). While robust MPC is
effective in managing uncertainties, its inherent conservatism often makes it
less desirable in practice. Certainty-equivalence MPC (CE-MPC), which relies on
a nominal model, offers an appealing alternative due to its design simplicity
and reduced online computational requirements. Contrary to the existing
analysis where MPC has access to the true model, this paper investigates
certainty-equivalence MPC for uncertain nonlinear systems with input
constraints; here the uncertainty stems from parametric discrepancies between
the true model and the nominal model. The primary contributions of the paper
are twofold. First, a novel perturbation analysis of the MPC value function is
provided, which avoids the common assumption of Lipschitz continuity for cost
functions and has broader applicability to topics such as value function
approximation, online model adaptation in MPC, and performance-driven MPC
design. Besides, a sufficient stability condition and performance analysis of
CE-MPC are derived, where the latter quantifies the suboptimality of CE-MPC
relative to the infinite-horizon optimal controller with perfect model
knowledge. The results provide valuable insights into how the prediction
horizon and model mismatch jointly affect stability and performance.
Furthermore, the general results are specialized to linear quadratic control,
and the competitive ratio is derived, serving as the first ratio-like
performance bound for predictive control of uncertain linear systems with
constraints.",2024-12-14,"Changrui Liu, Shengling Shi, Bart De Schutter"
Do Large Language Models Speak Scientific Workflows?,"With the advent of large language models (LLMs), there is a growing interest
in applying LLMs to scientific tasks. In this work, we conduct an experimental
study to explore applicability of LLMs for configuring, annotating,
translating, explaining, and generating scientific workflows. We use 5
different workflow specific experiments and evaluate several open- and
closed-source language models using state-of-the-art workflow systems. Our
studies reveal that LLMs often struggle with workflow related tasks due to
their lack of knowledge of scientific workflows. We further observe that the
performance of LLMs varies across experiments and workflow systems. Our
findings can help workflow developers and users in understanding LLMs
capabilities in scientific workflows, and motivate further research applying
LLMs to workflows.",2024-12-13,"Orcun Yildiz, Tom Peterka"
EvalGIM: A Library for Evaluating Generative Image Models,"As the use of text-to-image generative models increases, so does the adoption
of automatic benchmarking methods used in their evaluation. However, while
metrics and datasets abound, there are few unified benchmarking libraries that
provide a framework for performing evaluations across many datasets and
metrics. Furthermore, the rapid introduction of increasingly robust
benchmarking methods requires that evaluation libraries remain flexible to new
datasets and metrics. Finally, there remains a gap in synthesizing evaluations
in order to deliver actionable takeaways about model performance. To enable
unified, flexible, and actionable evaluations, we introduce EvalGIM (pronounced
''EvalGym''), a library for evaluating generative image models. EvalGIM
contains broad support for datasets and metrics used to measure quality,
diversity, and consistency of text-to-image generative models. In addition,
EvalGIM is designed with flexibility for user customization as a top priority
and contains a structure that allows plug-and-play additions of new datasets
and metrics. To enable actionable evaluation insights, we introduce
''Evaluation Exercises'' that highlight takeaways for specific evaluation
questions. The Evaluation Exercises contain easy-to-use and reproducible
implementations of two state-of-the-art evaluation methods of text-to-image
generative models: consistency-diversity-realism Pareto Fronts and
disaggregated measurements of performance disparities across groups. EvalGIM
also contains Evaluation Exercises that introduce two new analysis methods for
text-to-image generative models: robustness analyses of model rankings and
balanced evaluations across different prompt styles. We encourage text-to-image
model exploration with EvalGIM and invite contributions at
https://github.com/facebookresearch/EvalGIM/.",2024-12-13,"Melissa Hall, Oscar Mañas, Reyhane Askari-Hemmat, Mark Ibrahim, Candace Ross, Pietro Astolfi, Tariq Berrada Ifriqi, Marton Havasi, Yohann Benchetrit, Karen Ullrich, Carolina Braga, Abhishek Charnalia, Maeve Ryan, Mike Rabbat, Michal Drozdzal, Jakob Verbeek, Adriana Romero-Soriano"
iMoT: Inertial Motion Transformer for Inertial Navigation,"We propose iMoT, an innovative Transformer-based inertial odometry method
that retrieves cross-modal information from motion and rotation modalities for
accurate positional estimation. Unlike prior work, during the encoding of the
motion context, we introduce Progressive Series Decoupler at the beginning of
each encoder layer to stand out critical motion events inherent in acceleration
and angular velocity signals. To better aggregate cross-modal interactions, we
present Adaptive Positional Encoding, which dynamically modifies positional
embeddings for temporal discrepancies between different modalities. During
decoding, we introduce a small set of learnable query motion particles as
priors to model motion uncertainties within velocity segments. Each query
motion particle is intended to draw cross-modal features dedicated to a
specific motion mode, all taken together allowing the model to refine its
understanding of motion dynamics effectively. Lastly, we design a dynamic
scoring mechanism to stabilize iMoT's optimization by considering all aligned
motion particles at the final decoding step, ensuring robust and accurate
velocity segment estimation. Extensive evaluations on various inertial datasets
demonstrate that iMoT significantly outperforms state-of-the-art methods in
delivering superior robustness and accuracy in trajectory reconstruction.",2024-12-13,"Son Minh Nguyen, Linh Duy Tran, Duc Viet Le, Paul J. M Havinga"
Towards Unified Benchmark and Models for Multi-Modal Perceptual Metrics,"Human perception of similarity across uni- and multimodal inputs is highly
complex, making it challenging to develop automated metrics that accurately
mimic it. General purpose vision-language models, such as CLIP and large
multi-modal models (LMMs), can be applied as zero-shot perceptual metrics, and
several recent works have developed models specialized in narrow perceptual
tasks. However, the extent to which existing perceptual metrics align with
human perception remains unclear. To investigate this question, we introduce
UniSim-Bench, a benchmark encompassing 7 multi-modal perceptual similarity
tasks, with a total of 25 datasets. Our evaluation reveals that while
general-purpose models perform reasonably well on average, they often lag
behind specialized models on individual tasks. Conversely, metrics fine-tuned
for specific tasks fail to generalize well to unseen, though related, tasks. As
a first step towards a unified multi-task perceptual similarity metric, we
fine-tune both encoder-based and generative vision-language models on a subset
of the UniSim-Bench tasks. This approach yields the highest average
performance, and in some cases, even surpasses taskspecific models.
Nevertheless, these models still struggle with generalization to unseen tasks,
highlighting the ongoing challenge of learning a robust, unified perceptual
similarity metric capable of capturing the human notion of similarity. The code
and models are available at https://github.com/SaraGhazanfari/UniSim.",2024-12-13,"Sara Ghazanfari, Siddharth Garg, Nicolas Flammarion, Prashanth Krishnamurthy, Farshad Khorrami, Francesco Croce"
Integrating HW/SW Functionality for Flexible Wireless Radio,"Current methods of implementing wireless radio typically take one of two
forms; either dedicated fixed-function hardware, or pure Software Defined Radio
(SDR). Fixed function hardware is efficient, but being specific to each radio
standard it lacks flexibility, whereas Software Defined Radio is highly
flexible but requires powerful processors to meet real-time performance
constraints. This paper presents a hybrid hardware/software approach that aims
to combine the flexibility of SDR with the efficiency of dedicated hardware
solutions. We evaluate this approach by simulating five variants of the IEEE
802.15.4 protocol, commonly known as Zigbee, and demonstrate the range of
performance and power consumption characteristics for different accelerator and
software configurations. Across the spectrum of configurations we see power
consumption varies from 8% to 38% of a dedicated hardware implementation, and
show how the hybrid approach allows a new modulation standard to be retrofitted
to an existing design, with only a modest increase in power consumption.",2024-12-13,"Alexander Strachan, Nigel Topham"
PanSR: An Object-Centric Mask Transformer for Panoptic Segmentation,"Panoptic segmentation is a fundamental task in computer vision and a crucial
component for perception in autonomous vehicles. Recent mask-transformer-based
methods achieve impressive performance on standard benchmarks but face
significant challenges with small objects, crowded scenes and scenes exhibiting
a wide range of object scales. We identify several fundamental shortcomings of
the current approaches: (i) the query proposal generation process is biased
towards larger objects, resulting in missed smaller objects, (ii) initially
well-localized queries may drift to other objects, resulting in missed
detections, (iii) spatially well-separated instances may be merged into a
single mask causing inconsistent and false scene interpretations. To address
these issues, we rethink the individual components of the network and its
supervision, and propose a novel method for panoptic segmentation PanSR. PanSR
effectively mitigates instance merging, enhances small-object detection and
increases performance in crowded scenes, delivering a notable +3.4 PQ
improvement over state-of-the-art on the challenging LaRS benchmark, while
reaching state-of-the-art performance on Cityscapes. The code and models will
be publicly available at https://github.com/lojzezust/PanSR.",2024-12-13,"Lojze Žust, Matej Kristan"
"Agro-STAY : Collecte de données et analyse des informations en
  agriculture alternative issues de YouTube","To address the current crises (climatic, social, economic), the
self-sufficiency -- a set of practices that combine energy sobriety,
self-production of food and energy, and self-construction - arouses an
increasing interest. The CNRS STAY project (Savoirs Techniques pour
l'Auto-suffisance, sur YouTube) explores this topic by analyzing techniques
shared on YouTube. We present Agro-STAY, a platform designed for the
collection, processing, and visualization of data from YouTube videos and their
comments. We use Natural Language Processing (NLP) techniques and language
models, which enable a fine-grained analysis of alternative agricultural
practice described online.
  --
  Face aux crises actuelles (climatiques, sociales, \'economiques),
l'auto-suffisance -- ensemble de pratiques combinant sobri\'et\'e
\'energ\'etique, autoproduction alimentaire et \'energ\'etique et
autoconstruction - suscite un int\'er\^et croissant. Le projet CNRS STAY
(Savoirs Techniques pour l'Auto-suffisance, sur YouTube) s'inscrit dans ce
domaine en analysant les savoirs techniques diffus\'es sur YouTube. Nous
pr\'esentons Agro-STAY, une plateforme d\'edi\'ee \`a la collecte, au
traitement et \`a la visualisation de donn\'ees issues de vid\'eos YouTube et
de leurs commentaires. En mobilisant des techniques de traitement automatique
des langues (TAL) et des mod\`eles de langues, ce travail permet une analyse
fine des pratiques agricoles alternatives d\'ecrites en ligne.",2024-12-13,"Laura Maxim, Julien Rabatel, Jean-Marc Douguet, Natalia Grabar, Roberto Interdonato, Sébastien Loustau, Mathieu Roche, Maguelonne Teisseire"
ExeChecker: Where Did I Go Wrong?,"In this paper, we present a contrastive learning based framework, ExeChecker,
for the interpretation of rehabilitation exercises. Our work builds upon
state-of-the-art advances in the area of human pose estimation, graph-attention
neural networks, and transformer interpretablity. The downstream task is to
assist rehabilitation by providing informative feedback to users while they are
performing prescribed exercises. We utilize a contrastive learning strategy
during training. Given a tuple of correctly and incorrectly executed exercises,
our model is able to identify and highlight those joints that are involved in
an incorrect movement and thus require the user's attention. We collected an
in-house dataset, ExeCheck, with paired recordings of both correct and
incorrect execution of exercises. In our experiments, we tested our method on
this dataset as well as the UI-PRMD dataset and found ExeCheck outperformed the
baseline method using pairwise sequence alignment in identifying joints of
physical relevance in rehabilitation exercises.",2024-12-13,"Yiwen Gu, Mahir Patel, Margrit Betke"
"Evidence Contextualization and Counterfactual Attribution for
  Conversational QA over Heterogeneous Data with RAG Systems","Retrieval Augmented Generation (RAG) works as a backbone for interacting with
an enterprise's own data via Conversational Question Answering (ConvQA). In a
RAG system, a retriever fetches passages from a collection in response to a
question, which are then included in the prompt of a large language model (LLM)
for generating a natural language (NL) answer. However, several RAG systems
today suffer from two shortcomings: (i) retrieved passages usually contain
their raw text and lack appropriate document context, negatively impacting both
retrieval and answering quality; and (ii) attribution strategies that explain
answer generation usually rely only on similarity between the answer and the
retrieved passages, thereby only generating plausible but not causal
explanations. In this work, we demonstrate RAGONITE, a RAG system that remedies
the above concerns by: (i) contextualizing evidence with source metadata and
surrounding text; and (ii) computing counterfactual attribution, a causal
explanation approach where the contribution of an evidence to an answer is
determined by the similarity of the original response to the answer obtained by
removing that evidence. To evaluate our proposals, we release a new benchmark
ConfQuestions, with 300 hand-created conversational questions, each in English
and German, coupled with ground truth URLs, completed questions, and answers
from 215 public Confluence pages, that are typical of enterprise wiki spaces
with heterogeneous elements. Experiments with RAGONITE on ConfQuestions show
the viability of our ideas: contextualization improves RAG performance, and
counterfactual attribution is effective at explaining RAG answers.",2024-12-13,"Rishiraj Saha Roy, Joel Schlotthauer, Chris Hinze, Andreas Foltyn, Luzian Hahn, Fabian Kuech"
Compact Probe Request Fingerprinting with Asymmetric Pairwise Boosting,"Probe Requests are Wi-Fi management frames periodically sent by devices
during network discovery. Tracking Probe Requests over time offers insights
into movement patterns, traffic flows, and behavior trends, which are keys in
applications such as urban planning, human mobility analysis, and retail
analytics. To protect user privacy, techniques such as MAC address
randomization are employed, periodically altering device MAC addresses to limit
tracking. However, research has shown that these privacy measures can be
circumvented. By analyzing the Information Elements (IE) within the Probe
Request body, it is possible to fingerprint devices and track users over time.
This paper presents a machine learning-based approach for fingerprinting Wi-Fi
Probe Requests in a compact fashion. We utilize Asymmetric Pairwise Boosting to
learn discriminating filters which are then used to process specific bit
sequences in Probe Request frames, and quantize the results into a compact
binary format. Extensive evaluation on public datasets demonstrates a
two-order-of-magnitude storage reduction compared to existing methods while
maintaining robust fingerprinting performance.",2024-12-13,"Giovanni Baccichet, Fabio Palmese, Alessandro E. C. Redondi, Matteo Cesana"
"Identifying Predictions That Influence the Future: Detecting
  Performative Concept Drift in Data Streams","Concept Drift has been extensively studied within the context of Stream
Learning. However, it is often assumed that the deployed model's predictions
play no role in the concept drift the system experiences. Closer inspection
reveals that this is not always the case. Automated trading might be prone to
self-fulfilling feedback loops. Likewise, malicious entities might adapt to
evade detectors in the adversarial setting resulting in a self-negating
feedback loop that requires the deployed models to constantly retrain. Such
settings where a model may induce concept drift are called performative. In
this work, we investigate this phenomenon. Our contributions are as follows:
First, we define performative drift within a stream learning setting and
distinguish it from other causes of drift. We introduce a novel type of drift
detection task, aimed at identifying potential performative concept drift in
data streams. We propose a first such performative drift detection approach,
called CheckerBoard Performative Drift Detection (CB-PDD). We apply CB-PDD to
both synthetic and semi-synthetic datasets that exhibit varying degrees of
self-fulfilling feedback loops. Results are positive with CB-PDD showing high
efficacy, low false detection rates, resilience to intrinsic drift,
comparability to other drift detection techniques, and an ability to
effectively detect performative drift in semi-synthetic datasets. Secondly, we
highlight the role intrinsic (traditional) drift plays in obfuscating
performative drift and discuss the implications of these findings as well as
the limitations of CB-PDD.",2024-12-13,"Brandon Gower-Winter, Georg Krempl, Sergey Dragomiretskiy, Tineke Jelsma, Arno Siebes"
RAGServe: Fast Quality-Aware RAG Systems with Configuration Adaptation,"RAG (Retrieval Augmented Generation) allows LLMs (large language models) to
generate better responses with external knowledge, but using more external
knowledge often improves generation quality at the expense of response delay.
Prior work either reduces the response delay (through better scheduling of RAG
queries) or strives to maximize quality (which involves tuning the RAG
workflow), but they fall short in optimizing the tradeoff between the delay and
quality of RAG responses. This paper presents RAGServe, the first RAG system
that jointly schedules queries and adapts the key RAG configurations of each
query, such as the number of retrieved text chunks and synthesis methods, in
order to balance quality optimization and response delay reduction. Using 4
popular RAG-QA datasets, we show that compared with the state-of-the-art RAG
optimization schemes, RAGServe reduces the generation latency by
$1.64-2.54\times$ without sacrificing generation quality.",2024-12-13,"Siddhant Ray, Rui Pan, Zhuohan Gu, Kuntai Du, Ganesh Ananthanarayanan, Ravi Netravali, Junchen Jiang"
"Predicting Internet Connectivity in Schools: A Feasibility Study
  Leveraging Multi-modal Data and Location Encoders in Low-Resource Settings","Internet connectivity in schools is critical to provide students with the
digital literary skills necessary to compete in modern economies. In order for
governments to effectively implement digital infrastructure development in
schools, accurate internet connectivity information is required. However,
traditional survey-based methods can exceed the financial and capacity limits
of governments. Open-source Earth Observation (EO) datasets have unlocked our
ability to observe and understand socio-economic conditions on Earth from
space, and in combination with Machine Learning (ML), can provide the tools to
circumvent costly ground-based survey methods to support infrastructure
development. In this paper, we present our work on school internet connectivity
prediction using EO and ML. We detail the creation of our multi-modal,
freely-available satellite imagery and survey information dataset, leverage the
latest geographically-aware location encoders, and introduce the first results
of using the new European Space Agency phi-lab geographically-aware
foundational model to predict internet connectivity in Botswana and Rwanda. We
find that ML with EO and ground-based auxiliary data yields the best
performance in both countries, for accuracy, F1 score, and False Positive
rates, and highlight the challenges of internet connectivity prediction from
space with a case study in Kigali, Rwanda. Our work showcases a practical
approach to support data-driven digital infrastructure development in
low-resource settings, leveraging freely available information, and provide
cleaned and labelled datasets for future studies to the community through a
unique collaboration between UNICEF and the European Space Agency phi-lab.",2024-12-13,"Kelsey Doerksen, Casper Fibaek, Rochelle Schneider, Do-Hyung Kim, Isabelle Tingzon"
"Deep Reinforcement Learning for Scalable Multiagent Spacecraft
  Inspection","As the number of spacecraft in orbit continues to increase, it is becoming
more challenging for human operators to manage each mission. As a result,
autonomous control methods are needed to reduce this burden on operators. One
method of autonomous control is Reinforcement Learning (RL), which has proven
to have great success across a variety of complex tasks. For missions with
multiple controlled spacecraft, or agents, it is critical for the agents to
communicate and have knowledge of each other, where this information is
typically given to the Neural Network Controller (NNC) as an input observation.
As the number of spacecraft used for the mission increases or decreases, rather
than modifying the size of the observation, this paper develops a scalable
observation space that uses a constant observation size to give information on
all of the other agents. This approach is similar to a lidar sensor, where
determines ranges of other objects in the environment. This observation space
is applied to a spacecraft inspection task, where RL is used to train multiple
deputy spacecraft to cooperate and inspect a passive chief spacecraft. It is
expected that the scalable observation space will allow the agents to learn to
complete the task more efficiently compared to a baseline solution where no
information is communicated between agents.",2024-12-13,"Kyle Dunlap, Nathaniel Hamilton, Kerianne L. Hobbs"
"CRS Arena: Crowdsourced Benchmarking of Conversational Recommender
  Systems","We introduce CRS Arena, a research platform for scalable benchmarking of
Conversational Recommender Systems (CRS) based on human feedback. The platform
displays pairwise battles between anonymous conversational recommender systems,
where users interact with the systems one after the other before declaring
either a winner or a draw. CRS Arena collects conversations and user feedback,
providing a foundation for reliable evaluation and ranking of CRSs. We conduct
experiments with CRS Arena on both open and closed crowdsourcing platforms,
confirming that both setups produce highly correlated rankings of CRSs and
conversations with similar characteristics. We release CRSArena-Dial, a dataset
of 474 conversations and their corresponding user feedback, along with a
preliminary ranking of the systems based on the Elo rating system. The platform
is accessible at https://iai-group-crsarena.hf.space/.",2024-12-13,"Nolwenn Bernard, Hideaki Joko, Faegheh Hasibi, Krisztian Balog"
Differentially Private Multi-Sampling from Distributions,"Many algorithms have been developed to estimate probability distributions
subject to differential privacy (DP): such an algorithm takes as input
independent samples from a distribution and estimates the density function in a
way that is insensitive to any one sample. A recent line of work, initiated by
Raskhodnikova et al. (Neurips '21), explores a weaker objective: a
differentially private algorithm that approximates a single sample from the
distribution. Raskhodnikova et al. studied the sample complexity of DP
\emph{single-sampling} i.e., the minimum number of samples needed to perform
this task. They showed that the sample complexity of DP single-sampling is less
than the sample complexity of DP learning for certain distribution classes. We
define two variants of \emph{multi-sampling}, where the goal is to privately
approximate $m>1$ samples. This better models the realistic scenario where
synthetic data is needed for exploratory data analysis.
  A baseline solution to \emph{multi-sampling} is to invoke a single-sampling
algorithm $m$ times on independently drawn datasets of samples. When the data
comes from a finite domain, we improve over the baseline by a factor of $m$ in
the sample complexity. When the data comes from a Gaussian, Ghazi et al.
(Neurips '23) show that \emph{single-sampling} can be performed under
approximate differential privacy; we show it is possible to \emph{single- and
multi-sample Gaussians with known covariance subject to pure DP}. Our solution
uses a variant of the Laplace mechanism that is of independent interest.
  We also give sample complexity lower bounds, one for strong multi-sampling of
finite distributions and another for weak multi-sampling of bounded-covariance
Gaussians.",2024-12-13,"Albert Cheu, Debanuj Nayak"
Do Large Language Models Show Biases in Causal Learning?,"Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this
research, we investigate whether large language models (LLMs) develop causal
illusions, both in real-world and controlled laboratory contexts of causal
learning and inference. To this end, we built a dataset of over 2K samples
including purely correlational cases, situations with null contingency, and
cases where temporal information excludes the possibility of causality by
placing the potential effect before the cause. We then prompted the models to
make statements or answer causal questions to evaluate their tendencies to
infer causation erroneously in these structured settings. Our findings show a
strong presence of causal illusion bias in LLMs. Specifically, in open-ended
generation tasks involving spurious correlations, the models displayed bias at
levels comparable to, or even lower than, those observed in similar studies on
human subjects. However, when faced with null-contingency scenarios or temporal
cues that negate causal relationships, where it was required to respond on a
0-100 scale, the models exhibited significantly higher bias. These findings
suggest that the models have not uniformly, consistently, or reliably
internalized the normative principles essential for accurate causal learning.",2024-12-13,"Maria Victoria Carro, Francisca Gauna Selasco, Denise Alejandra Mester, Margarita Gonzales, Mario A. Leiva, Maria Vanina Martinez, Gerardo I. Simari"
Crosstalk-induced Side Channel Threats in Multi-Tenant NISQ Computers,"As quantum computing rapidly advances, its near-term applications are
becoming increasingly evident. However, the high cost and under-utilization of
quantum resources are prompting a shift from single-user to multi-user access
models. In a multi-tenant environment, where multiple users share one quantum
computer, protecting user confidentiality becomes crucial. The varied uses of
quantum computers increase the risk that sensitive data encoded by one user
could be compromised by others, rendering the protection of data integrity and
confidentiality essential. In the evolving quantum computing landscape, it is
imperative to study these security challenges within the scope of realistic
threat model assumptions, wherein an adversarial user can mount practical
attacks without relying on any heightened privileges afforded by physical
access to a quantum computer or rogue cloud services. In this paper, we
demonstrate the potential of crosstalk as an attack vector for the first time
on a Noisy Intermediate Scale Quantum (NISQ) machine, that an adversarial user
can exploit within a multi-tenant quantum computing model. The proposed
side-channel attack is conducted with minimal and realistic adversarial
privileges, with the overarching aim of uncovering the quantum algorithm being
executed by a victim. Crosstalk signatures are used to estimate the presence of
CNOT gates in the victim circuit, and subsequently, this information is encoded
and classified by a graph-based learning model to identify the victim quantum
algorithm. When evaluated on up to 336 benchmark circuits, our attack framework
is found to be able to unveil the victim's quantum algorithm with up to 85.7\%
accuracy.",2024-12-13,"Navnil Choudhury, Chaithanya Naik Mude, Sanjay Das, Preetham Chandra Tikkireddi, Swamit Tannu, Kanad Basu"
"SnapGen-V: Generating a Five-Second Video within Five Seconds on a
  Mobile Device","We have witnessed the unprecedented success of diffusion-based video
generation over the past year. Recently proposed models from the community have
wielded the power to generate cinematic and high-resolution videos with smooth
motions from arbitrary input prompts. However, as a supertask of image
generation, video generation models require more computation and are thus
hosted mostly on cloud servers, limiting broader adoption among content
creators. In this work, we propose a comprehensive acceleration framework to
bring the power of the large-scale video diffusion model to the hands of edge
users. From the network architecture scope, we initialize from a compact image
backbone and search out the design and arrangement of temporal layers to
maximize hardware efficiency. In addition, we propose a dedicated adversarial
fine-tuning algorithm for our efficient model and reduce the denoising steps to
4. Our model, with only 0.6B parameters, can generate a 5-second video on an
iPhone 16 PM within 5 seconds. Compared to server-side models that take minutes
on powerful GPUs to generate a single video, we accelerate the generation by
magnitudes while delivering on-par quality.",2024-12-13,"Yushu Wu, Zhixing Zhang, Yanyu Li, Yanwu Xu, Anil Kag, Yang Sui, Huseyin Coskun, Ke Ma, Aleksei Lebedev, Ju Hu, Dimitris Metaxas, Yanzhi Wang, Sergey Tulyakov, Jian Ren"
SafetyDPO: Scalable Safety Alignment for Text-to-Image Generation,"Text-to-image (T2I) models have become widespread, but their limited safety
guardrails expose end users to harmful content and potentially allow for model
misuse. Current safety measures are typically limited to text-based filtering
or concept removal strategies, able to remove just a few concepts from the
model's generative capabilities. In this work, we introduce SafetyDPO, a method
for safety alignment of T2I models through Direct Preference Optimization
(DPO). We enable the application of DPO for safety purposes in T2I models by
synthetically generating a dataset of harmful and safe image-text pairs, which
we call CoProV2. Using a custom DPO strategy and this dataset, we train safety
experts, in the form of low-rank adaptation (LoRA) matrices, able to guide the
generation process away from specific safety-related concepts. Then, we merge
the experts into a single LoRA using a novel merging strategy for optimal
scaling performance. This expert-based approach enables scalability, allowing
us to remove 7 times more harmful concepts from T2I models compared to
baselines. SafetyDPO consistently outperforms the state-of-the-art on many
benchmarks and establishes new practices for safety alignment in T2I networks.
Code and data will be shared at https://safetydpo.github.io/.",2024-12-13,"Runtao Liu, Chen I Chieh, Jindong Gu, Jipeng Zhang, Renjie Pi, Qifeng Chen, Philip Torr, Ashkan Khakzar, Fabio Pizzati"
OP-LoRA: The Blessing of Dimensionality,"Low-rank adapters enable fine-tuning of large models with only a small number
of parameters, thus reducing storage costs and minimizing the risk of
catastrophic forgetting. However, they often pose optimization challenges, with
poor convergence. To overcome these challenges, we introduce an
over-parameterized approach that accelerates training without increasing
inference costs. This method reparameterizes low-rank adaptation by employing a
separate MLP and learned embedding for each layer. The learned embedding is
input to the MLP, which generates the adapter parameters. Such
overparamaterization has been shown to implicitly function as an adaptive
learning rate and momentum, accelerating optimization. At inference time, the
MLP can be discarded, leaving behind a standard low-rank adapter. To study the
effect of MLP overparameterization on a small yet difficult proxy task, we
implement it for matrix factorization, and find it achieves faster convergence
and lower final loss. Extending this approach to larger-scale tasks, we observe
consistent performance gains across domains. We achieve improvements in
vision-language tasks and especially notable increases in image generation,
with CMMD scores improving by up to 15 points.",2024-12-13,"Piotr Teterwak, Kate Saenko, Bryan A. Plummer, Ser-Nam Lim"
Apollo: An Exploration of Video Understanding in Large Multimodal Models,"Despite the rapid integration of video perception capabilities into Large
Multimodal Models (LMMs), the underlying mechanisms driving their video
understanding remain poorly understood. Consequently, many design decisions in
this domain are made without proper justification or analysis. The high
computational cost of training and evaluating such models, coupled with limited
open research, hinders the development of video-LMMs. To address this, we
present a comprehensive study that helps uncover what effectively drives video
understanding in LMMs.
  We begin by critically examining the primary contributors to the high
computational requirements associated with video-LMM research and discover
Scaling Consistency, wherein design and training decisions made on smaller
models and datasets (up to a critical size) effectively transfer to larger
models. Leveraging these insights, we explored many video-specific aspects of
video-LMMs, including video sampling, architectures, data composition, training
schedules, and more. For example, we demonstrated that fps sampling during
training is vastly preferable to uniform frame sampling and which vision
encoders are the best for video representation.
  Guided by these findings, we introduce Apollo, a state-of-the-art family of
LMMs that achieve superior performance across different model sizes. Our models
can perceive hour-long videos efficiently, with Apollo-3B outperforming most
existing $7$B models with an impressive 55.1 on LongVideoBench. Apollo-7B is
state-of-the-art compared to 7B LMMs with a 70.9 on MLVU, and 63.3 on
Video-MME.",2024-12-13,"Orr Zohar, Xiaohan Wang, Yann Dubois, Nikhil Mehta, Tong Xiao, Philippe Hansen-Estruch, Licheng Yu, Xiaofang Wang, Felix Juefei-Xu, Ning Zhang, Serena Yeung-Levy, Xide Xia"
The Correlated Gaussian Sparse Histogram Mechanism,"We consider the problem of releasing a sparse histogram under $(\varepsilon,
\delta)$-differential privacy. The stability histogram independently adds noise
from a Laplace or Gaussian distribution to the non-zero entries and removes
those noisy counts below a threshold.
  Thereby, the introduction of new non-zero values between neighboring
histograms is only revealed with probability at most $\delta$, and typically,
the value of the threshold dominates the error of the mechanism. We consider
the variant of the stability histogram with Gaussian noise.
  Recent works ([Joseph and Yu, COLT '24] and [Lebeda, SOSA '25]) reduced the
error for private histograms using correlated Gaussian noise. However, these
techniques can not be directly applied in the very sparse setting. Instead, we
adopt Lebeda's technique and show that adding correlated noise to the non-zero
counts only allows us to reduce the magnitude of noise when we have a sparsity
bound. This, in turn, allows us to use a lower threshold by up to a factor of
$1/2$ compared to the non-correlated noise mechanism. We then extend our
mechanism to a setting without a known bound on sparsity. Additionally, we show
that correlated noise can give a similar improvement for the more practical
discrete Gaussian mechanism.",2024-12-13,"Christian Janos Lebeda, Lukas Retschmeier"
"COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation
  Tasks and Language Models","As key elements within the central dogma, DNA, RNA, and proteins play crucial
roles in maintaining life by guaranteeing accurate genetic expression and
implementation. Although research on these molecules has profoundly impacted
fields like medicine, agriculture, and industry, the diversity of machine
learning approaches-from traditional statistical methods to deep learning
models and large language models-poses challenges for researchers in choosing
the most suitable models for specific tasks, especially for cross-omics and
multi-omics tasks due to the lack of comprehensive benchmarks. To address this,
we introduce the first comprehensive multi-omics benchmark COMET (Benchmark for
Biological COmprehensive Multi-omics Evaluation Tasks and Language Models),
designed to evaluate models across single-omics, cross-omics, and multi-omics
tasks. First, we curate and develop a diverse collection of downstream tasks
and datasets covering key structural and functional aspects in DNA, RNA, and
proteins, including tasks that span multiple omics levels. Then, we evaluate
existing foundational language models for DNA, RNA, and proteins, as well as
the newly proposed multi-omics method, offering valuable insights into their
performance in integrating and analyzing data from different biological
modalities. This benchmark aims to define critical issues in multi-omics
research and guide future directions, ultimately promoting advancements in
understanding biological processes through integrated and different omics data
analysis.",2024-12-13,"Yuchen Ren, Wenwei Han, Qianyuan Zhang, Yining Tang, Weiqiang Bai, Yuchen Cai, Lifeng Qiao, Hao Jiang, Dong Yuan, Tao Chen, Siqi Sun, Pan Tan, Wanli Ouyang, Nanqing Dong, Xinzhu Ma, Peng Ye"
Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining,"Digital agents are increasingly employed to automate tasks in interactive
digital environments such as web pages, software applications, and operating
systems. While text-based agents built on Large Language Models (LLMs) often
require frequent updates due to platform-specific APIs, visual agents
leveraging Multimodal Large Language Models (MLLMs) offer enhanced adaptability
by interacting directly with Graphical User Interfaces (GUIs). However, these
agents face significant challenges in visual perception, particularly when
handling high-resolution, visually complex digital environments. This paper
introduces Iris, a foundational visual agent that addresses these challenges
through two key innovations: Information-Sensitive Cropping (ISC) and
Self-Refining Dual Learning (SRDL). ISC dynamically identifies and prioritizes
visually dense regions using a edge detection algorithm, enabling efficient
processing by allocating more computational resources to areas with higher
information density. SRDL enhances the agent's ability to handle complex tasks
by leveraging a dual-learning loop, where improvements in referring (describing
UI elements) reinforce grounding (locating elements) and vice versa, all
without requiring additional annotated data. Empirical evaluations demonstrate
that Iris achieves state-of-the-art performance across multiple benchmarks with
only 850K GUI annotations, outperforming methods using 10x more training data.
These improvements further translate to significant gains in both web and OS
agent downstream tasks.",2024-12-13,"Zhiqi Ge, Juncheng Li, Xinglei Pang, Minghe Gao, Kaihang Pan, Wang Lin, Hao Fei, Wenqiao Zhang, Siliang Tang, Yueting Zhuang"
"A Universal Degradation-based Bridging Technique for Domain Adaptive
  Semantic Segmentation","Semantic segmentation often suffers from significant performance degradation
when the trained network is applied to a different domain. To address this
issue, unsupervised domain adaptation (UDA) has been extensively studied.
Existing methods introduce the domain bridging techniques to mitigate
substantial domain gap, which construct intermediate domains to facilitate the
gradual transfer of knowledge across different domains. However, these
strategies often require dataset-specific designs and may generate unnatural
intermediate distributions that lead to semantic shift. In this paper, we
propose DiDA, a universal degradation-based bridging technique formalized as a
diffusion forward process. DiDA consists of two key modules: (1)
Degradation-based Intermediate Domain Construction, which creates continuous
intermediate domains through simple image degradation operations to encourage
learning domain-invariant features as domain differences gradually diminish;
(2) Semantic Shift Compensation, which leverages a diffusion encoder to encode
and compensate for semantic shift information with degraded time-steps,
preserving discriminative representations in the intermediate domains. As a
plug-and-play solution, DiDA supports various degradation operations and
seamlessly integrates with existing UDA methods. Extensive experiments on
prevalent synthetic-to-real semantic segmentation benchmarks demonstrate that
DiDA consistently improves performance across different settings and achieves
new state-of-the-art results when combined with existing methods.",2024-12-13,"Wangkai Li, Rui Sun, Tianzhu Zhang"
"Applied Statistics in the Era of Artificial Intelligence: A Review and
  Vision","The advent of artificial intelligence (AI) technologies has significantly
changed many domains, including applied statistics. This review and vision
paper explores the evolving role of applied statistics in the AI era, drawing
from our experiences in engineering statistics. We begin by outlining the
fundamental concepts and historical developments in applied statistics and
tracing the rise of AI technologies. Subsequently, we review traditional areas
of applied statistics, using examples from engineering statistics to illustrate
key points. We then explore emerging areas in applied statistics, driven by
recent technological advancements, highlighting examples from our recent
projects. The paper discusses the symbiotic relationship between AI and applied
statistics, focusing on how statistical principles can be employed to study the
properties of AI models and enhance AI systems. We also examine how AI can
advance applied statistics in terms of modeling and analysis. In conclusion, we
reflect on the future role of statisticians. Our paper aims to shed light on
the transformative impact of AI on applied statistics and inspire further
exploration in this dynamic field.",2024-12-13,"Jie Min, Xinyi Song, Simin Zheng, Caleb B. King, Xinwei Deng, Yili Hong"
"Sampling from exponential distributions in the time domain with
  superparamagnetic tunnel junctions","Though exponential distributions are ubiquitous in statistical physics and
related computational models, directly sampling them from device behavior is
rarely done. The superparamagnetic tunnel junction (SMTJ), a key device in
probabilistic computing, is known to naturally exhibit exponentially
distributed temporal switching dynamics. To sample an exponential distribution
with an SMTJ, we need to measure it in the time domain, which is challenging
with traditional techniques that focus on sampling the instantaneous state of
the device. In this work, we leverage a temporal encoding scheme, where
information is encoded in the time at which the device switches between its
resistance states. We then develop a circuit element known as a probabilistic
delay cell that applies an electrical current step to an SMTJ and a temporal
measurement circuit that measures the timing of the first switching event.
Repeated experiments confirm that these times are exponentially distributed.
Temporal processing methods then allow us to digitally compute with these
exponentially distributed probabilistic delay cells. We describe how to use
these circuits in a Metropolis-Hastings stepper and in a weighted random
sampler, both of which are computationally intensive applications that benefit
from the efficient generation of exponentially distributed random numbers.",2024-12-13,"Temitayo N. Adeyeye, Sidra Gibeault, Daniel P. Lathrop, Matthew W. Daniels, Mark D. Stiles, Jabez J. McClelland, William A. Borders, Jason T. Ryan, Philippe Talatchian, Ursula Ebels, Advait Madhavan"
"Interlocking-free Selective Rationalization Through Genetic-based
  Learning","A popular end-to-end architecture for selective rationalization is the
select-then-predict pipeline, comprising a generator to extract highlights fed
to a predictor. Such a cooperative system suffers from suboptimal equilibrium
minima due to the dominance of one of the two modules, a phenomenon known as
interlocking. While several contributions aimed at addressing interlocking,
they only mitigate its effect, often by introducing feature-based heuristics,
sampling, and ad-hoc regularizations. We present GenSPP, the first
interlocking-free architecture for selective rationalization that does not
require any learning overhead, as the above-mentioned. GenSPP avoids
interlocking by performing disjoint training of the generator and predictor via
genetic global search. Experiments on a synthetic and a real-world benchmark
show that our model outperforms several state-of-the-art competitors.",2024-12-13,"Federico Ruggeri, Gaetano Signorelli"
TrafficLoc: Localizing Traffic Surveillance Cameras in 3D Scenes,"We tackle the problem of localizing the traffic surveillance cameras in
cooperative perception. To overcome the lack of large-scale real-world
intersection datasets, we introduce Carla Intersection, a new simulated dataset
with 75 urban and rural intersections in Carla. Moreover, we introduce a novel
neural network, TrafficLoc, localizing traffic cameras within a 3D reference
map. TrafficLoc employs a coarse-to-fine matching pipeline. For image-point
cloud feature fusion, we propose a novel Geometry-guided Attention Loss to
address cross-modal viewpoint inconsistencies. During coarse matching, we
propose an Inter-Intra Contrastive Learning to achieve precise alignment while
preserving distinctiveness among local intra-features within image patch-point
group pairs. Besides, we introduce Dense Training Alignment with a soft-argmax
operator to consider additional features when regressing the final position.
Extensive experiments show that our TrafficLoc improves the localization
accuracy over the state-of-the-art Image-to-point cloud registration methods by
a large margin (up to 86%) on Carla Intersection and generalizes well to
real-world data. TrafficLoc also achieves new SOTA performance on KITTI and
NuScenes datasets, demonstrating strong localization ability across both
in-vehicle and traffic cameras. Our project page is publicly available at
https://tum-luk.github.io/projects/trafficloc/.",2024-12-13,"Yan Xia, Yunxiang Lu, Rui Song, Oussema Dhaouadi, João F. Henriques, Daniel Cremers"
A Note On Square-free Sequences and Anti-unification Type,"Anti-unification is a fundamental operation used for inductive inference. It
is abstractly defined as a process deriving from a set of symbolic expressions
a new symbolic expression possessing certain commonalities shared between its
members. We consider anti-unification over term algebras where some function
symbols are interpreted as associative-idempotent ($f(x,f(y,z)) = f(f(x,y),z)$
and $f(x,x)=x$, respectively) and show that there exists generalization
problems for which a minimal complete set of solutions does not exist
(Nullary), that is every complete set must contain comparable elements with
respect to the generality relation. In contrast to earlier techniques for
showing the nullarity of a generalization problem, we exploit combinatorial
properties of complete sets of solutions to show that comparable elements are
not avoidable. We show that every complete set of solutions contains an
infinite chain of comparable generalizations whose structure is isomorphic to a
subsequence of an infinite square-free sequence over three symbols.",2024-12-13,David M. Cerna
Prompt-Guided Mask Proposal for Two-Stage Open-Vocabulary Segmentation,"We tackle the challenge of open-vocabulary segmentation, where we need to
identify objects from a wide range of categories in different environments,
using text prompts as our input. To overcome this challenge, existing methods
often use multi-modal models like CLIP, which combine image and text features
in a shared embedding space to bridge the gap between limited and extensive
vocabulary recognition, resulting in a two-stage approach: In the first stage,
a mask generator takes an input image to generate mask proposals, and the in
the second stage the target mask is picked based on the query. However, the
expected target mask may not exist in the generated mask proposals, which leads
to an unexpected output mask. In our work, we propose a novel approach named
Prompt-guided Mask Proposal (PMP) where the mask generator takes the input text
prompts and generates masks guided by these prompts. Compared with mask
proposals generated without input prompts, masks generated by PMP are better
aligned with the input prompts. To realize PMP, we designed a cross-attention
mechanism between text tokens and query tokens which is capable of generating
prompt-guided mask proposals after each decoding. We combined our PMP with
several existing works employing a query-based segmentation backbone and the
experiments on five benchmark datasets demonstrate the effectiveness of this
approach, showcasing significant improvements over the current two-stage models
(1% ~ 3% absolute performance gain in terms of mIOU). The steady improvement in
performance across these benchmarks indicates the effective generalization of
our proposed lightweight prompt-aware method.",2024-12-13,"Yu-Jhe Li, Xinyang Zhang, Kun Wan, Lantao Yu, Ajinkya Kale, Xin Lu"
"Performance evaluation of predictive AI models to support medical
  decisions: Overview and guidance","A myriad of measures to illustrate performance of predictive artificial
intelligence (AI) models have been proposed in the literature. Selecting
appropriate performance measures is essential for predictive AI models that are
developed to be used in medical practice, because poorly performing models may
harm patients and lead to increased costs. We aim to assess the merits of
classic and contemporary performance measures when validating predictive AI
models for use in medical practice. We focus on models with a binary outcome.
We discuss 32 performance measures covering five performance domains
(discrimination, calibration, overall, classification, and clinical utility)
along with accompanying graphical assessments. The first four domains cover
statistical performance, the fifth domain covers decision-analytic performance.
We explain why two key characteristics are important when selecting which
performance measures to assess: (1) whether the measure's expected value is
optimized when it is calculated using the correct probabilities (i.e., a
""proper"" measure), and (2) whether they reflect either purely statistical
performance or decision-analytic performance by properly considering
misclassification costs. Seventeen measures exhibit both characteristics,
fourteen measures exhibited one characteristic, and one measure possessed
neither characteristic (the F1 measure). All classification measures (such as
classification accuracy and F1) are improper for clinically relevant decision
thresholds other than 0.5 or the prevalence. We recommend the following
measures and plots as essential to report: AUROC, calibration plot, a clinical
utility measure such as net benefit with decision curve analysis, and a plot
with probability distributions per outcome category.",2024-12-13,"Ben Van Calster, Gary S. Collins, Andrew J. Vickers, Laure Wynants, Kathleen F. Kerr, Lasai Barreñada, Gael Varoquaux, Karandeep Singh, Karel G. M. Moons, Tina Hernandez-boussard, Dirk Timmerman, David J. Mclernon, Maarten Van Smeden, Ewout W. Steyerberg"
Probabilistic Inverse Cameras: Image to 3D via Multiview Geometry,"We introduce a hierarchical probabilistic approach to go from a 2D image to
multiview 3D: a diffusion ""prior"" models the unseen 3D geometry, which then
conditions a diffusion ""decoder"" to generate novel views of the subject. We use
a pointmap-based geometric representation in a multiview image format to
coordinate the generation of multiple target views simultaneously. We
facilitate correspondence between views by assuming fixed target camera poses
relative to the source camera, and constructing a predictable distribution of
geometric features per target. Our modular, geometry-driven approach to
novel-view synthesis (called ""unPIC"") beats SoTA baselines such as CAT3D and
One-2-3-45 on held-out objects from ObjaverseXL, as well as real-world objects
ranging from Google Scanned Objects, Amazon Berkeley Objects, to the Digital
Twin Catalog.",2024-12-13,"Rishabh Kabra, Drew A. Hudson, Sjoerd van Steenkiste, Joao Carreira, Niloy J. Mitra"
Trustworthy and Explainable Decision-Making for Workforce allocation,"In industrial contexts, effective workforce allocation is crucial for
operational efficiency. This paper presents an ongoing project focused on
developing a decision-making tool designed for workforce allocation,
emphasising the explainability to enhance its trustworthiness. Our objective is
to create a system that not only optimises the allocation of teams to scheduled
tasks but also provides clear, understandable explanations for its decisions,
particularly in cases where the problem is infeasible. By incorporating
human-in-the-loop mechanisms, the tool aims to enhance user trust and
facilitate interactive conflict resolution. We implemented our approach on a
prototype tool/digital demonstrator intended to be evaluated on a real
industrial scenario both in terms of performance and user acceptability.",2024-12-13,"Guillaume Povéda, Ryma Boumazouza, Andreas Strahl, Mark Hall, Santiago Quintana-Amate, Nahum Alvarez, Ignace Bleukx, Dimos Tsouros, Hélène Verhaeghe, Tias Guns"
Cultural Evolution of Cooperation among LLM Agents,"Large language models (LLMs) provide a compelling foundation for building
generally-capable AI agents. These agents may soon be deployed at scale in the
real world, representing the interests of individual humans (e.g., AI
assistants) or groups of humans (e.g., AI-accelerated corporations). At
present, relatively little is known about the dynamics of multiple LLM agents
interacting over many generations of iterative deployment. In this paper, we
examine whether a ""society"" of LLM agents can learn mutually beneficial social
norms in the face of incentives to defect, a distinctive feature of human
sociality that is arguably crucial to the success of civilization. In
particular, we study the evolution of indirect reciprocity across generations
of LLM agents playing a classic iterated Donor Game in which agents can observe
the recent behavior of their peers. We find that the evolution of cooperation
differs markedly across base models, with societies of Claude 3.5 Sonnet agents
achieving significantly higher average scores than Gemini 1.5 Flash, which, in
turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an
additional mechanism for costly punishment to achieve yet higher scores, while
Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also
observe variation in emergent behavior across random seeds, suggesting an
understudied sensitive dependence on initial conditions. We suggest that our
evaluation regime could inspire an inexpensive and informative new class of LLM
benchmarks, focussed on the implications of LLM agent deployment for the
cooperative infrastructure of society.",2024-12-13,"Aron Vallinder, Edward Hughes"
"Does Multiple Choice Have a Future in the Age of Generative AI? A
  Posttest-only RCT","The role of multiple-choice questions (MCQs) as effective learning tools has
been debated in past research. While MCQs are widely used due to their ease in
grading, open response questions are increasingly used for instruction, given
advances in large language models (LLMs) for automated grading. This study
evaluates MCQs effectiveness relative to open-response questions, both
individually and in combination, on learning. These activities are embedded
within six tutor lessons on advocacy. Using a posttest-only randomized control
design, we compare the performance of 234 tutors (790 lesson completions)
across three conditions: MCQ only, open response only, and a combination of
both. We find no significant learning differences across conditions at
posttest, but tutors in the MCQ condition took significantly less time to
complete instruction. These findings suggest that MCQs are as effective, and
more efficient, than open response tasks for learning when practice time is
limited. To further enhance efficiency, we autograded open responses using
GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of
low-stakes assessment, though further research is needed for broader use. This
study contributes a dataset of lesson log data, human annotation rubrics, and
LLM prompts to promote transparency and reproducibility.",2024-12-13,"Danielle R. Thomas, Conrad Borchers, Sanjit Kakarla, Jionghao Lin, Shambhavi Bhushan, Boyuan Guo, Erin Gatz, Kenneth R. Koedinger"
"CognitionCapturer: Decoding Visual Stimuli From Human EEG Signal With
  Multimodal Information","Electroencephalogram (EEG) signals have attracted significant attention from
researchers due to their non-invasive nature and high temporal sensitivity in
decoding visual stimuli. However, most recent studies have focused solely on
the relationship between EEG and image data pairs, neglecting the valuable
``beyond-image-modality"" information embedded in EEG signals. This results in
the loss of critical multimodal information in EEG. To address this limitation,
we propose CognitionCapturer, a unified framework that fully leverages
multimodal data to represent EEG signals. Specifically, CognitionCapturer
trains Modality Expert Encoders for each modality to extract cross-modal
information from the EEG modality. Then, it introduces a diffusion prior to map
the EEG embedding space to the CLIP embedding space, followed by using a
pretrained generative model, the proposed framework can reconstruct visual
stimuli with high semantic and structural fidelity. Notably, the framework does
not require any fine-tuning of the generative models and can be extended to
incorporate more modalities. Through extensive experiments, we demonstrate that
CognitionCapturer outperforms state-of-the-art methods both qualitatively and
quantitatively. Code: https://github.com/XiaoZhangYES/CognitionCapturer.",2024-12-13,"Kaifan Zhang, Lihuo He, Xin Jiang, Wen Lu, Di Wang, Xinbo Gao"
"Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in
  Large Language Models","The sheer scale of data required to train modern large language models (LLMs)
poses significant risks, as models are likely to gain knowledge of sensitive
topics such as bio-security, as well the ability to replicate copyrighted
works. Methods designed to remove such knowledge must do so from all prompt
directions, in a multi-lingual capacity and without degrading general model
performance. To this end, we introduce the targeted angular reversal (TARS)
method of knowledge removal from LLMs. The TARS method firstly leverages the
LLM in combination with a detailed prompt to aggregate information about a
selected concept in the internal representation space of the LLM. It then
refines this approximate concept vector to trigger the concept token with high
probability, by perturbing the approximate concept vector with noise and
transforming it into token scores with the language model head. The feedforward
weight vectors in the LLM which operate directly on the internal representation
space, and have the highest cosine similarity with this targeting vector, are
then replaced by a reversed targeting vector, thus limiting the ability of the
concept to propagate through the model. The modularity of the TARS method
allows for a sequential removal of concepts from Llama 3.1 8B, such as the
famous literary detective Sherlock Holmes, and the planet Saturn. It is
demonstrated that the probability of triggering target concepts can be reduced
to 0.00 with as few as 1 TARS edit, whilst simultaneously removing the
knowledge bi-directionally. Moreover, knowledge is shown to be removed across
all languages despite only being targeted in English. Importantly, TARS has
minimal impact on the general model capabilities, as after removing 5 diverse
concepts in a modular fashion, there is minimal KL divergence in the next token
probabilities of the LLM on large corpora of Wikipedia text (median of 0.0015).",2024-12-13,"Harry J. Davies, Giorgos Iacovides, Danilo P. Mandic"
"AniSora: Exploring the Frontiers of Animation Video Generation in the
  Sora Era","Animation has gained significant interest in the recent film and TV industry.
Despite the success of advanced video generation models like Sora, Kling, and
CogVideoX in generating natural videos, they lack the same effectiveness in
handling animation videos. Evaluating animation video generation is also a
great challenge due to its unique artist styles, violating the laws of physics
and exaggerated motions. In this paper, we present a comprehensive system,
AniSora, designed for animation video generation, which includes a data
processing pipeline, a controllable generation model, and an evaluation
dataset. Supported by the data processing pipeline with over 10M high-quality
data, the generation model incorporates a spatiotemporal mask module to
facilitate key animation production functions such as image-to-video
generation, frame interpolation, and localized image-guided animation. We also
collect an evaluation benchmark of 948 various animation videos, the evaluation
on VBench and human double-blind test demonstrates consistency in character and
motion, achieving state-of-the-art results in animation video generation. Our
evaluation benchmark will be publicly available at
https://github.com/bilibili/Index-anisora.",2024-12-13,"Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Qi Sen, Xingyu Zheng, Jixuan Xu, Yue Zhang, Jinlong Hou, Huyang Sun"
Deep Gaussian Process Priors for Bayesian Image Reconstruction,"In image reconstruction, an accurate quantification of uncertainty is of
great importance for informed decision making. Here, the Bayesian approach to
inverse problems can be used: the image is represented through a random
function that incorporates prior information which is then updated through
Bayes' formula. However, finding a prior is difficult, as images often exhibit
non-stationary effects and multi-scale behaviour. Thus, usual Gaussian process
priors are not suitable. Deep Gaussian processes, on the other hand, encode
non-stationary behaviour in a natural way through their hierarchical structure.
To apply Bayes' formula, one commonly employs a Markov chain Monte Carlo (MCMC)
method. In the case of deep Gaussian processes, sampling is especially
challenging in high dimensions: the associated covariance matrices are large,
dense, and changing from sample to sample. A popular strategy towards
decreasing computational complexity is to view Gaussian processes as the
solutions to a fractional stochastic partial differential equation (SPDE). In
this work, we investigate efficient computational strategies to solve the
fractional SPDEs occurring in deep Gaussian process sampling, as well as MCMC
algorithms to sample from the posterior. Namely, we combine rational
approximation and a determinant-free sampling approach to achieve sampling via
the fractional SPDE. We test our techniques in standard Bayesian image
reconstruction problems: upsampling, edge detection, and computed tomography.
In these examples, we show that choosing a non-stationary prior such as the
deep GP over a stationary GP can improve the reconstruction. Moreover, our
approach enables us to compare results for a range of fractional and
non-fractional regularity parameter values.",2024-12-13,"Jonas Latz, Aretha L. Teckentrup, Simon Urbainczyk"
Efficient Continual Pre-training of LLMs for Low-resource Languages,"Open-source Large Language models (OsLLMs) propel the democratization of
natural language research by giving the flexibility to augment or update model
parameters for performance improvement. Nevertheless, like proprietary LLMs,
Os-LLMs offer poorer performance on low-resource languages (LRLs) than
high-resource languages (HRLs), owing to smaller amounts of training data and
underrepresented vocabulary. On the other hand, continual pre-training (CPT)
with large amounts of language-specific data is a costly proposition in terms
of data acquisition and computational resources. Our goal is to drastically
reduce CPT cost. To that end, we first develop a new algorithm to select a
subset of texts from a larger corpus. We show the effectiveness of our
technique using very little CPT data. In search of further improvement, we
design a new algorithm to select tokens to include in the LLM vocabulary. We
experiment with the recent Llama-3 model and nine Indian languages with diverse
scripts and extent of resource availability. For evaluation, we use
IndicGenBench, a generation task benchmark dataset for Indic languages. We
experiment with various CPT corpora and augmented vocabulary size and offer
insights across language families.",2024-12-13,"Arijit Nag, Soumen Chakrabarti, Animesh Mukherjee, Niloy Ganguly"
Learning Complex Non-Rigid Image Edits from Multimodal Conditioning,"In this paper we focus on inserting a given human (specifically, a single
image of a person) into a novel scene. Our method, which builds on top of
Stable Diffusion, yields natural looking images while being highly controllable
with text and pose. To accomplish this we need to train on pairs of images, the
first a reference image with the person, the second a ""target image"" showing
the same person (with a different pose and possibly in a different background).
Additionally we require a text caption describing the new pose relative to that
in the reference image. In this paper we present a novel dataset following this
criteria, which we create using pairs of frames from human-centric and
action-rich videos and employing a multimodal LLM to automatically summarize
the difference in human pose for the text captions. We demonstrate that
identity preservation is a more challenging task in scenes ""in-the-wild"", and
especially scenes where there is an interaction between persons and objects.
Combining the weak supervision from noisy captions, with robust 2D pose
improves the quality of person-object interactions.",2024-12-13,"Nikolai Warner, Jack Kolb, Meera Hahn, Vighnesh Birodkar, Jonathan Huang, Irfan Essa"
"GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view
  Diffusion","We propose a novel approach for reconstructing animatable 3D Gaussian avatars
from monocular videos captured by commodity devices like smartphones.
Photorealistic 3D head avatar reconstruction from such recordings is
challenging due to limited observations, which leaves unobserved regions
under-constrained and can lead to artifacts in novel views. To address this
problem, we introduce a multi-view head diffusion model, leveraging its priors
to fill in missing regions and ensure view consistency in Gaussian splatting
renderings. To enable precise viewpoint control, we use normal maps rendered
from FLAME-based head reconstruction, which provides pixel-aligned inductive
biases. We also condition the diffusion model on VAE features extracted from
the input image to preserve details of facial identity and appearance. For
Gaussian avatar reconstruction, we distill multi-view diffusion priors by using
iteratively denoised images as pseudo-ground truths, effectively mitigating
over-saturation issues. To further improve photorealism, we apply latent
upsampling to refine the denoised latent before decoding it into an image. We
evaluate our method on the NeRSemble dataset, showing that GAF outperforms the
previous state-of-the-art methods in novel view synthesis by a 5.34\% higher
SSIM score. Furthermore, we demonstrate higher-fidelity avatar reconstructions
from monocular videos captured on commodity devices.",2024-12-13,"Jiapeng Tang, Davide Davoli, Tobias Kirschstein, Liam Schoneveld, Matthias Niessner"
"HyperGraphOS: A Modern Meta-Operating System for the Scientific and
  Engineering Domains","This paper presents HyperGraphOS, a significant innovation in the domain of
operating systems, specifically designed to address the needs of scientific and
engineering domains. This platform aims to combine model-based engineering,
graph modeling, data containers, and documents, along with tools for handling
computational elements. HyperGraphOS functions as an Operating System offering
to users an infinite workspace for creating and managing complex models
represented as graphs with customizable semantics. By leveraging a web-based
architecture, it requires only a modern web browser for access, allowing
organization of knowledge, documents, and content into models represented in a
network of workspaces. Elements of the workspace are defined in terms of
domain-specific languages (DSLs). These DSLs are pivotal for navigating
workspaces, generating code, triggering AI components, and organizing
information and processes. The models' dual nature as both visual drawings and
data structures allows dynamic modifications and inspections both interactively
as well as programaticaly. We evaluated HyperGraphOS's efficiency and
applicability across a large set of diverse domains, including the design and
development of a virtual Avatar dialog system, a robotic task planner based on
large language models (LLMs), a new meta-model for feature-based code
development and many others. Our findings show that HyperGraphOS offers
substantial benefits in the interaction with a computer as information system,
as platoform for experiments and data analysis, as streamlined engineering
processes, demonstrating enhanced flexibility in managing data, computation and
documents, showing an innovative approaches to persistent desktop environments.",2024-12-13,"Antonello Ceravola, Frank Joublin"
"Solving Robust Markov Decision Processes: Generic, Reliable, Efficient","Markov decision processes (MDP) are a well-established model for sequential
decision-making in the presence of probabilities. In robust MDP (RMDP), every
action is associated with an uncertainty set of probability distributions,
modelling that transition probabilities are not known precisely. Based on the
known theoretical connection to stochastic games, we provide a framework for
solving RMDPs that is generic, reliable, and efficient. It is *generic* both
with respect to the model, allowing for a wide range of uncertainty sets,
including but not limited to intervals, $L^1$- or $L^2$-balls, and polytopes;
and with respect to the objective, including long-run average reward,
undiscounted total reward, and stochastic shortest path. It is *reliable*, as
our approach not only converges in the limit, but provides precision guarantees
at any time during the computation. It is *efficient* because -- in contrast to
state-of-the-art approaches -- it avoids explicitly constructing the underlying
stochastic game. Consequently, our prototype implementation outperforms
existing tools by several orders of magnitude and can solve RMDPs with a
million states in under a minute.",2024-12-13,"Tobias Meggendorfer, Maximilian Weininger, Patrick Wienhöft"
"A General Safety Framework for Autonomous Manipulation in Human
  Environments","Autonomous robots are projected to augment the manual workforce, especially
in repetitive and hazardous tasks. For a successful deployment of such robots
in human environments, it is crucial to guarantee human safety.
State-of-the-art approaches to ensure human safety are either too restrictive
to permit a natural human-robot collaboration or make strong assumptions that
do not hold when for autonomous robots, e.g., knowledge of a pre-defined
trajectory. Therefore, we propose SaRA-shield, a power and force limiting
framework for AI-based manipulation in human environments that gives formal
safety guarantees while allowing for fast robot speeds. As recent studies have
shown that unconstrained collisions allow for significantly higher contact
forces than constrained collisions (clamping), we propose to classify contacts
by their collision type using reachability analysis. We then verify that the
kinetic energy of the robot is below pain and injury thresholds for the
detected collision type of the respective human body part in contact. Our
real-world experiments show that SaRA-shield can effectively reduce the speed
of the robot to adhere to injury-preventing energy limits.",2024-12-13,"Jakob Thumm, Julian Balletshofer, Leonardo Maglanoc, Luis Muschal, Matthias Althoff"
SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models,"Given an input video of a person and a new garment, the objective of this
paper is to synthesize a new video where the person is wearing the specified
garment while maintaining spatiotemporal consistency. Although significant
advances have been made in image-based virtual try-on, extending these
successes to video often leads to frame-to-frame inconsistencies. Some
approaches have attempted to address this by increasing the overlap of frames
across multiple video chunks, but this comes at a steep computational cost due
to the repeated processing of the same frames, especially for long video
sequences. To tackle these challenges, we reconceptualize video virtual try-on
as a conditional video inpainting task, with garments serving as input
conditions. Specifically, our approach enhances image diffusion models by
incorporating temporal attention layers to improve temporal coherence. To
reduce computational overhead, we propose ShiftCaching, a novel technique that
maintains temporal consistency while minimizing redundant computations.
Furthermore, we introduce the TikTokDress dataset, a new video try-on dataset
featuring more complex backgrounds, challenging movements, and higher
resolution compared to existing public datasets. Extensive experiments
demonstrate that our approach outperforms current baselines, particularly in
terms of video consistency and inference speed. The project page is available
at https://swift-try.github.io/.",2024-12-13,"Hung Nguyen, Quang Qui-Vinh Nguyen, Khoi Nguyen, Rang Nguyen"
"Keep It Simple: Towards Accurate Vulnerability Detection for Large Code
  Graphs","Software vulnerability detection is crucial for high-quality software
development. Recently, some studies utilizing Graph Neural Networks (GNNs) to
learn the graph representation of code in vulnerability detection tasks have
achieved remarkable success. However, existing graph-based approaches mainly
face two limitations that prevent them from generalizing well to large code
graphs: (1) the interference of noise information in the code graph; (2) the
difficulty in capturing long-distance dependencies within the graph. To
mitigate these problems, we propose a novel vulnerability detection method,
ANGLE, whose novelty mainly embodies the hierarchical graph refinement and
context-aware graph representation learning. The former hierarchically filters
redundant information in the code graph, thereby reducing the size of the
graph, while the latter collaboratively employs the Graph Transformer and GNN
to learn code graph representations from both the global and local
perspectives, thus capturing long-distance dependencies. Extensive experiments
demonstrate promising results on three widely used benchmark datasets: our
method significantly outperforms several other baselines in terms of the
accuracy and F1 score. Particularly, in large code graphs, ANGLE achieves an
improvement in accuracy of 34.27%-161.93% compared to the state-of-the-art
method, AMPLE. Such results demonstrate the effectiveness of ANGLE in
vulnerability detection tasks.",2024-12-13,"Xin Peng, Shangwen Wang, Yihao Qin, Bo Lin, Liqian Chen, Xiaoguang Mao"
"Data Integration with Fusion Searchlight: Classifying Brain States from
  Resting-state fMRI","Spontaneous neural activity observed in resting-state fMRI is characterized
by complex spatio-temporal dynamics. Different measures related to local and
global brain connectivity and fluctuations in low-frequency amplitudes can
quantify individual aspects of these neural dynamics. Even though such measures
are derived from the same functional signals, they are often evaluated
separately, neglecting their interrelations and potentially reducing the
analysis sensitivity. In our study, we present a fusion searchlight (FuSL)
framework to combine the complementary information contained in different
resting-state fMRI metrics and demonstrate how this can improve the decoding of
brain states. Moreover, we show how explainable AI allows us to reconstruct the
differential impact of each metric on the decoding, which additionally
increases spatial specificity of searchlight analysis. In general, this
framework can be adapted to combine information derived from different imaging
modalities or experimental conditions, offering a versatile and interpretable
tool for data fusion in neuroimaging.",2024-12-13,"Simon Wein, Marco Riebel, Lisa-Marie Brunner, Caroline Nothdurfter, Rainer Rupprecht, Jens V. Schwarzbach"
Arbitrary Reading Order Scene Text Spotter with Local Semantics Guidance,"Scene text spotting has attracted the enthusiasm of relative researchers in
recent years. Most existing scene text spotters follow the
detection-then-recognition paradigm, where the vanilla detection module hardly
determines the reading order and leads to failure recognition. After rethinking
the auto-regressive scene text recognition method, we find that a well-trained
recognizer can implicitly perceive the local semantics of all characters in a
complete word or a sentence without a character-level detection module. Local
semantic knowledge not only includes text content but also spatial information
in the right reading order. Motivated by the above analysis, we propose the
Local Semantics Guided scene text Spotter (LSGSpotter), which auto-regressively
decodes the position and content of characters guided by the local semantics.
Specifically, two effective modules are proposed in LSGSpotter. On the one
hand, we design a Start Point Localization Module (SPLM) for locating text
start points to determine the right reading order. On the other hand, a
Multi-scale Adaptive Attention Module (MAAM) is proposed to adaptively
aggregate text features in a local area. In conclusion, LSGSpotter achieves the
arbitrary reading order spotting task without the limitation of sophisticated
detection, while alleviating the cost of computational resources with the grid
sampling strategy. Extensive experiment results show LSGSpotter achieves
state-of-the-art performance on the InverseText benchmark. Moreover, our
spotter demonstrates superior performance on English benchmarks for
arbitrary-shaped text, achieving improvements of 0.7\% and 2.5\% on Total-Text
and SCUT-CTW1500, respectively. These results validate our text spotter is
effective for scene texts in arbitrary reading order and shape.",2024-12-13,"Jiahao Lyu, Wei Wang, Dongbao Yang, Jinwen Zhong, Yu Zhou"
"A Clinical Tuning Framework for Continuous Kinematic and Impedance
  Control of a Powered Knee-Ankle Prosthesis","Objective: Configuring a prosthetic leg is an integral part of the fitting
process, but the personalization of a multi-modal powered knee-ankle prosthesis
is often too complex to realize in a clinical environment. This paper develops
both the technical means to individualize a hybrid kinematic-impedance
controller for variable-incline walking and sit-stand transitions, and an
intuitive Clinical Tuning Interface (CTI) that allows prosthetists to directly
modify the controller behavior.
  Methods: Utilizing an established method for predicting kinematic gait
individuality alongside a new parallel approach for kinetic individuality, we
applied tuned characteristics exclusively from level-ground walking to
personalize continuous-phase/task models of joint kinematics and impedance. To
take advantage of this method, we developed a CTI that translates common
clinical tuning parameters into model adjustments. We then conducted a case
study involving an above-knee amputee participant where a prosthetist
iteratively tuned the prosthesis in a simulated clinical session involving
walking and sit-stand transitions.
  Results: The prosthetist fully tuned the multi-activity prosthesis controller
in under 20 min. Each iteration of tuning (i.e., observation, parameter
adjustment, and model reprocessing) took 2 min on average for walking and 1 min
on average for sit-stand. The tuned behavior changes were appropriately
manifested in the commanded prosthesis torques, both at the tuned tasks and
across untuned tasks (inclines).
  Conclusion: The CTI leveraged able-bodied trends to efficiently personalize a
wide array of walking tasks and sit-stand transitions. A case-study validated
the CTI tuning method and demonstrated the efficiency necessary for powered
knee-ankle prostheses to become clinically viable.",2024-12-13,"Emma Reznick, T. Kevin Best, Robert Gregg"
"VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval
  Augmented Generation","We propose the VLR-Bench, a visual question answering (VQA) benchmark for
evaluating vision language models (VLMs) based on retrieval augmented
generation (RAG). Unlike existing evaluation datasets for external
knowledge-based VQA, the proposed VLR-Bench includes five input passages. This
allows testing of the ability to determine which passage is useful for
answering a given query, a capability lacking in previous research. In this
context, we constructed a dataset of 32,000 automatically generated
instruction-following examples, which we denote as VLR-IF. This dataset is
specifically designed to enhance the RAG capabilities of VLMs by enabling them
to learn how to generate appropriate answers based on input passages. We
evaluated the validity of the proposed benchmark and training data and verified
its performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3
model. The proposed VLR-Bench and VLR-IF datasets are publicly available
online.",2024-12-13,"Hyeonseok Lim, Dongjae Shin, Seohyun Song, Inho Won, Minjun Kim, Junghun Yuk, Haneol Jang, KyungTae Lim"
Can LLMs Convert Graphs to Text-Attributed Graphs?,"Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.",2024-12-13,"Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye"
"You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary
  Projects","The ability to execute the test suite of a project is essential in many
scenarios, e.g., to assess code quality and code coverage, to validate code
changes made by developers or automated tools, and to ensure compatibility with
dependencies. Despite its importance, executing the test suite of a project can
be challenging in practice because different projects use different programming
languages, software ecosystems, build systems, testing frameworks, and other
tools. These challenges make it difficult to create a reliable, universal test
execution method that works across different projects. This paper presents
ExecutionAgent, an automated technique that installs arbitrary projects,
configures them to run test cases, and produces project-specific scripts to
reproduce the setup. Inspired by the way a human developer would address this
task, our approach is a large language model-based agent that autonomously
executes commands and interacts with the host system. The agent uses
meta-prompting to gather guidelines on the latest technologies related to the
given project, and it iteratively refines its process based on feedback from
the previous steps. Our evaluation applies ExecutionAgent to 50 open-source
projects that use 14 different programming languages and many different build
and testing tools. The approach successfully executes the test suites of 33/55
projects, while matching the test results of ground truth test suite executions
with a deviation of only 7.5\%. These results improve over the best previously
available technique by 6.6x. The costs imposed by the approach are reasonable,
with an execution time of 74 minutes and LLM costs of 0.16 dollars, on average
per project. We envision ExecutionAgent to serve as a valuable tool for
developers, automated programming tools, and researchers that need to execute
tests across a wide variety of projects.",2024-12-13,"Islem Bouzenia, Michael Pradel"
Optimal Bounds for Private Minimum Spanning Trees via Input Perturbation,"We study the problem of privately releasing an approximate minimum spanning
tree (MST). Given a graph $G = (V, E, \vec{W})$ where $V$ is a set of $n$
vertices, $E$ is a set of $m$ undirected edges, and $ \vec{W} \in
\mathbb{R}^{|E|} $ is an edge-weight vector, our goal is to publish an
approximate MST under edge-weight differential privacy, as introduced by
Sealfon in PODS 2016, where $V$ and $E$ are considered public and the weight
vector is private. Our neighboring relation is $\ell_\infty$-distance on
weights: for a sensitivity parameter $\Delta_\infty$, graphs $ G = (V, E,
\vec{W}) $ and $ G' = (V, E, \vec{W}') $ are neighboring if
$\|\vec{W}-\vec{W}'\|_\infty \leq \Delta_\infty$.
  Existing private MST algorithms face a trade-off, sacrificing either
computational efficiency or accuracy. We show that it is possible to get the
best of both worlds: With a suitable random perturbation of the input that does
not suffice to make the weight vector private, the result of any non-private
MST algorithm will be private and achieves a state-of-the-art error guarantee.
  Furthermore, by establishing a connection to Private Top-k Selection [Steinke
and Ullman, FOCS '17], we give the first privacy-utility trade-off lower bound
for MST under approximate differential privacy, demonstrating that the error
magnitude, $\tilde{O}(n^{3/2})$, is optimal up to logarithmic factors. That is,
our approach matches the time complexity of any non-private MST algorithm and
at the same time achieves optimal error. We complement our theoretical
treatment with experiments that confirm the practicality of our approach.",2024-12-13,"Rasmus Pagh, Lukas Retschmeier, Hao Wu, Hanwen Zhang"
"CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language
  Models","In our previous work, we introduced CosyVoice, a multilingual speech
synthesis model based on supervised discrete speech tokens. By employing
progressive semantic decoding with two popular generative models, language
models (LMs) and Flow Matching, CosyVoice demonstrated high prosody
naturalness, content consistency, and speaker similarity in speech in-context
learning. Recently, significant progress has been made in multi-modal large
language models (LLMs), where the response latency and real-time factor of
speech synthesis play a crucial role in the interactive experience. Therefore,
in this report, we present an improved streaming speech synthesis model,
CosyVoice 2, which incorporates comprehensive and systematic optimizations.
Specifically, we introduce finite-scalar quantization to improve the codebook
utilization of speech tokens. For the text-speech LM, we streamline the model
architecture to allow direct use of a pre-trained LLM as the backbone. In
addition, we develop a chunk-aware causal flow matching model to support
various synthesis scenarios, enabling both streaming and non-streaming
synthesis within a single model. By training on a large-scale multilingual
dataset, CosyVoice 2 achieves human-parity naturalness, minimal response
latency, and virtually lossless synthesis quality in the streaming mode. We
invite readers to listen to the demos at
https://funaudiollm.github.io/cosyvoice2.",2024-12-13,"Zhihao Du, Yuxuan Wang, Qian Chen, Xian Shi, Xiang Lv, Tianyu Zhao, Zhifu Gao, Yexin Yang, Changfeng Gao, Hui Wang, Fan Yu, Huadai Liu, Zhengyan Sheng, Yue Gu, Chong Deng, Wen Wang, Shiliang Zhang, Zhijie Yan, Jingren Zhou"
Indirect Adaptive Control Using a Static Update Law,"The update law in the indirect adaptive control scheme can be extended to
include feedthrough of an error term. This reduces undesired oscillations of
the calculated weights. When the {\sigma}-modification is used for achieving
robustness against unstructured uncertainties, the gain of the feedthrough in
the update law cannot be chosen arbitrarily. Compared to our previous result,
we show stability of the closed loop for a larger parameter-range for the gain
of the feedthrough in the update law. This parameter-range includes a
configuration for which the influence of the integration in the update law
diminishes over time, i.e. for which the adaptation for large times is governed
solely by the feedthrough in the update law. By initializing at zero, this
allows for removing the integration from the update law, resulting in a static
update law. For the purely linear case, the adaptation acts like a disturbance
observer. Frequency-domain analysis of the closed loop with a second order
plant shows that removing the integration from the update law with
{\sigma}-modification and feedthrough affects how precisely disturbances in the
low-frequency band are observed. If the damping injected into the adaptation
process by the {\sigma}-modification exceeds certain bounds, then the precision
is increased by using the static update law.",2024-12-13,"Tom Kaufmann, Johann Reger"
"Unexpected but informative: What fixation-related potentials tell us
  about the processing of ambiguous program code","As software pervades more and more areas of our professional and personal
lives, there is an ever-increasing need to maintain software, and for
programmers to be able to efficiently write and understand program code. In the
first study of its kind, we analyze fixation-related potentials (FRPs) to
explore the online processing of program code patterns that are ambiguous to
programmers, but not the computer (so-called atoms of confusion), and their
underlying neurocognitive mechanisms in an ecologically valid setting. Relative
to unambiguous counterparts in program code, atoms of confusion elicit a late
frontal positivity with a duration of about 400 to 700 ms after first looking
at the atom of confusion. As the frontal positivity shows high resemblance with
an event-related potential (ERP) component found during natural language
processing that is elicited by unexpected but plausible words in sentence
context, we take these data to suggest that the brain engages similar
neurocognitive mechanisms in response to unexpected and informative inputs in
program code and in natural language. In both domains, these inputs lead to an
update of a comprehender's situation model that is essential for information
extraction from a quickly unfolding input.",2024-12-13,"Annabelle Bergum, Anna-Maria Maurer, Norman Peitek, Regine Bader, Axel Mecklinger, Vera Demberg, Janet Siegmund, Sven Apel"
"HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language
  Transfer and Automatic Data Annotation","In this paper we present our submission for the NorSID Shared Task as part of
the 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:
Intent Detection, Slot Filling and Dialect Identification, evaluated using data
in different dialects of the Norwegian language. For Intent Detection and Slot
Filling, we have fine-tuned a multitask model in a cross-lingual setting, to
leverage the xSID dataset available in 17 languages. In the case of Dialect
Identification, our final submission consists of a model fine-tuned on the
provided development set, which has obtained the highest scores within our
experiments. Our final results on the test set show that our models do not drop
in performance compared to the development set, likely due to the
domain-specificity of the dataset and the similar distribution of both subsets.
Finally, we also report an in-depth analysis of the provided datasets and their
artifacts, as well as other sets of experiments that have been carried out but
did not yield the best results. Additionally, we present an analysis on the
reasons why some methods have been more successful than others; mainly the
impact of the combination of languages and domain-specificity of the training
data on the results.",2024-12-13,"Jaione Bengoetxea, Mikel Zubillaga, Ekhi Azurmendi, Maite Heredia, Julen Etxaniz, Markel Ferro, Jeremy Barnes"
A Survey on Knowledge Graph Structure and Knowledge Graph Embeddings,"Knowledge Graphs (KGs) and their machine learning counterpart, Knowledge
Graph Embedding Models (KGEMs), have seen ever-increasing use in a wide variety
of academic and applied settings. In particular, KGEMs are typically applied to
KGs to solve the link prediction task; i.e. to predict new facts in the domain
of a KG based on existing, observed facts. While this approach has been shown
substantial power in many end-use cases, it remains incompletely characterised
in terms of how KGEMs react differently to KG structure. This is of particular
concern in light of recent studies showing that KG structure can be a
significant source of bias as well as partially determinant of overall KGEM
performance. This paper seeks to address this gap in the state-of-the-art. This
paper provides, to the authors' knowledge, the first comprehensive survey
exploring established relationships of Knowledge Graph Embedding Models and
Graph structure in the literature. It is the hope of the authors that this work
will inspire further studies in this area, and contribute to a more holistic
understanding of KGs, KGEMs, and the link prediction task.",2024-12-13,"Jeffrey Sardina, John D. Kelleher, Declan O'Sullivan"
"Social Recommendation through Heterogeneous Graph Modeling of the
  Long-term and Short-term Preference Defined by Dynamic Time Spans","Social recommendations have been widely adopted in substantial domains.
Recently, graph neural networks (GNN) have been employed in recommender systems
due to their success in graph representation learning. However, dealing with
the dynamic property of social network data is a challenge. This research
presents a novel method that provides social recommendations by incorporating
the dynamic property of social network data in a heterogeneous graph. The model
aims to capture user preference over time without going through the
complexities of a dynamic graph by adding period nodes to define users'
long-term and short-term preferences and aggregating assigned edge weights. The
model is applied to real-world data to argue its superior performance.
Promising results demonstrate the effectiveness of this model.",2023-12-21,"Behafarid Mohammad Jafari, Xiao Luo, Ali Jafari"
"HITSnDIFFs: From Truth Discovery to Ability Discovery by Recovering
  Matrices with the Consecutive Ones Property","We analyze a general problem in a crowd-sourced setting where one user asks a
question (also called item) and other users return answers (also called labels)
for this question. Different from existing crowd sourcing work which focuses on
finding the most appropriate label for the question (the ""truth""), our problem
is to determine a ranking of the users based on their ability to answer
questions. We call this problem ""ability discovery"" to emphasize the connection
to and duality with the more well-studied problem of ""truth discovery"".
  To model items and their labels in a principled way, we draw upon Item
Response Theory (IRT) which is the widely accepted theory behind standardized
tests such as SAT and GRE. We start from an idealized setting where the
relative performance of users is consistent across items and better users
choose better fitting labels for each item. We posit that a principled
algorithmic solution to our more general problem should solve this ideal
setting correctly and observe that the response matrices in this setting obey
the Consecutive Ones Property (C1P). While C1P is well understood
algorithmically with various discrete algorithms, we devise a novel variant of
the HITS algorithm which we call ""HITSNDIFFS"" (or HND), and prove that it can
recover the ideal C1P-permutation in case it exists. Unlike fast combinatorial
algorithms for finding the consecutive ones permutation (if it exists), HND
also returns an ordering when such a permutation does not exist. Thus it
provides a principled heuristic for our problem that is guaranteed to return
the correct answer in the ideal setting. Our experiments show that HND produces
user rankings with robustly high accuracy compared to state-of-the-art truth
discovery methods. We also show that our novel variant of HITS scales better in
the number of users than ABH, the only prior spectral C1P reconstruction
algorithm.",2023-12-21,"Zixuan Chen, Subhodeep Mitra, R Ravi, Wolfgang Gatterbauer"
"Designing Artificial Intelligence Equipped Social Decentralized
  Autonomous Organizations for Tackling Sextortion Cases Version 0.7","With the rapid diffusion of social networks in combination with mobile
phones, a new social threat of sextortion has emerged, in which vulnerable
young women are essentially blackmailed with their explicit shared multimedia
content. The phenomenon of sextortion is now widely studied by psychologists,
sociologists, criminologists, etc. The findings have been translated into
scattered help from NGOs, specialized law enforcement units, and therapists,
who usually do not coordinate their efforts among each other. This paper
addresses the gap of lacking coordination systems to effectively and
efficiently use modern information technologies that align the efforts of
scattered and non-aligned sextortion help organizations. Consequently, this
paper not only investigates the goals, incentives, and disincentives for a
system design and development that not only governs effectively and efficiently
diverse cases of sextortion victims, but also leverages artificial intelligence
in a targeted manner. It explores how AI and, in particular, autonomous
cognitive entities can improve victim profiles analysis, streamline support
mechanisms, and provide intelligent insight into sextortion cases. Furthermore,
the paper conceptually studies the extent to which such efforts can be
monetized in a sustainable way. Following a novel design methodology for the
design of trusted blockchain decentralized applications, the paper presents a
set of conceptual requirements and system models based on which it is possible
to deduce a best-practice technology stack for rapid implementation deployment.",2023-12-21,"Norta Alex, Makrygiannis Sotiris"
"Balancing Specialization and Adaptation in a Transforming Scientific
  Landscape","How do scientists navigate between the need to capitalize on their prior
knowledge through specialization, and the urge to adapt to evolving research
opportunities? Drawing from diverse perspectives on adaptation, including
cultural evolution, this paper proposes an unsupervised Bayesian approach
motivated by Optimal Transport of the evolution of scientists' research
portfolios in response to transformations in their field. The model relies on
$186,162$ scientific abstracts and authorship data to evaluate the influence of
intellectual, social, and institutional resources on scientists' trajectories
within a cohort of $2\,094$ high-energy physicists between 2000 and 2019. Using
Inverse Optimal Transport, the reallocation of research efforts is shown to be
shaped by learning costs, thus enhancing the utility of the scientific capital
disseminated among scientists. Two dimensions of social capital, namely
``diversity'' and ``power'', have opposite associations with the magnitude of
change in scientists' research interests: while ``diversity'' is associated
with greater change and expansion of research portfolios, ``power'' is
associated with more stable research agendas. Social capital plays a more
crucial role in shifts between cognitively distant research areas. More
generally, this work suggests new approaches for understanding, measuring and
modeling collective adaptation using Optimal Transport.",2023-12-21,Lucas Gautheron
"Benchmarking Evolutionary Community Detection Algorithms in Dynamic
  Networks","In dynamic complex networks, entities interact and form network communities
that evolve over time. Among the many static Community Detection (CD)
solutions, the modularity-based Louvain, or Greedy Modularity Algorithm (GMA),
is widely employed in real-world applications due to its intuitiveness and
scalability. Nevertheless, addressing CD in dynamic graphs remains an open
problem, since the evolution of the network connections may poison the
identification of communities, which may be evolving at a slower pace. Hence,
naively applying GMA to successive network snapshots may lead to temporal
inconsistencies in the communities. Two evolutionary adaptations of GMA, sGMA
and $\alpha$GMA, have been proposed to tackle this problem. Yet, evaluating the
performance of these methods and understanding to which scenarios each one is
better suited is challenging because of the lack of a comprehensive set of
metrics and a consistent ground truth. To address these challenges, we propose
(i) a benchmarking framework for evolutionary CD algorithms in dynamic networks
and (ii) a generalised modularity-based approach (NeGMA). Our framework allows
us to generate synthetic community-structured graphs and design evolving
scenarios with nine basic graph transformations occurring at different rates.
We evaluate performance through three metrics we define, i.e. Correctness,
Delay, and Stability. Our findings reveal that $\alpha$GMA is well-suited for
detecting intermittent transformations, but struggles with abrupt changes; sGMA
achieves superior stability, but fails to detect emerging communities; and
NeGMA appears a well-balanced solution, excelling in responsiveness and
instantaneous transformations detection.",2023-12-21,"Giordano Paoletti, Luca Gioacchini, Marco Mellia, Luca Vassio, Jussara M. Almeida"
Continuous-time Graph Representation with Sequential Survival Process,"Over the past two decades, there has been a tremendous increase in the growth
of representation learning methods for graphs, with numerous applications
across various fields, including bioinformatics, chemistry, and the social
sciences. However, current dynamic network approaches focus on discrete-time
networks or treat links in continuous-time networks as instantaneous events.
Therefore, these approaches have limitations in capturing the persistence or
absence of links that continuously emerge and disappear over time for
particular durations. To address this, we propose a novel stochastic process
relying on survival functions to model the durations of links and their
absences over time. This forms a generic new likelihood specification
explicitly accounting for intermittent edge-persistent networks, namely GraSSP:
Graph Representation with Sequential Survival Process. We apply the developed
framework to a recent continuous time dynamic latent distance model
characterizing network dynamics in terms of a sequence of piecewise linear
movements of nodes in latent space. We quantitatively assess the developed
framework in various downstream tasks, such as link prediction and network
completion, demonstrating that the developed modeling framework accounting for
link persistence and absence well tracks the intrinsic trajectories of nodes in
a latent space and captures the underlying characteristics of evolving network
structure.",2023-12-20,"Abdulkadir Celikkanat, Nikolaos Nakis, Morten Mørup"
"Big Tech influence over AI research revisited: memetic analysis of
  attribution of ideas to affiliation","There exists a growing discourse around the domination of Big Tech on the
landscape of artificial intelligence (AI) research, yet our comprehension of
this phenomenon remains cursory. This paper aims to broaden and deepen our
understanding of Big Tech's reach and power within AI research. It highlights
the dominance not merely in terms of sheer publication volume but rather in the
propagation of new ideas or memes. Current studies often oversimplify the
concept of influence to the share of affiliations in academic papers, typically
sourced from limited databases such as arXiv or specific academic conferences.
  The main goal of this paper is to unravel the specific nuances of such
influence, determining which AI ideas are predominantly driven by Big Tech
entities. By employing network and memetic analysis on AI-oriented paper
abstracts and their citation network, we are able to grasp a deeper insight
into this phenomenon. By utilizing two databases: OpenAlex and S2ORC, we are
able to perform such analysis on a much bigger scale than previous attempts.
  Our findings suggest that while Big Tech-affiliated papers are
disproportionately more cited in some areas, the most cited papers are those
affiliated with both Big Tech and Academia. Focusing on the most contagious
memes, their attribution to specific affiliation groups (Big Tech, Academia,
mixed affiliation) seems equally distributed between those three groups. This
suggests that the notion of Big Tech domination over AI research is
oversimplified in the discourse.",2023-12-20,"Stanisław Giziński, Paulina Kaczyńska, Hubert Ruczyński, Emilia Wiśnios, Bartosz Pieliński, Przemysław Biecek, Julian Sienkiewicz"
Towards Fair Graph Federated Learning via Incentive Mechanisms,"Graph federated learning (FL) has emerged as a pivotal paradigm enabling
multiple agents to collaboratively train a graph model while preserving local
data privacy. Yet, current efforts overlook a key issue: agents are
self-interested and would hesitant to share data without fair and satisfactory
incentives. This paper is the first endeavor to address this issue by studying
the incentive mechanism for graph federated learning. We identify a unique
phenomenon in graph federated learning: the presence of agents posing potential
harm to the federation and agents contributing with delays. This stands in
contrast to previous FL incentive mechanisms that assume all agents contribute
positively and in a timely manner. In view of this, this paper presents a novel
incentive mechanism tailored for fair graph federated learning, integrating
incentives derived from both model gradient and payoff. To achieve this, we
first introduce an agent valuation function aimed at quantifying agent
contributions through the introduction of two criteria: gradient alignment and
graph diversity. Moreover, due to the high heterogeneity in graph federated
learning, striking a balance between accuracy and fairness becomes particularly
crucial. We introduce motif prototypes to enhance accuracy, communicated
between the server and agents, enhancing global model aggregation and aiding
agents in local model optimization. Extensive experiments show that our model
achieves the best trade-off between accuracy and the fairness of model
gradient, as well as superior payoff fairness.",2023-12-20,"Chenglu Pan, Jiarong Xu, Yue Yu, Ziqi Yang, Qingbiao Wu, Chunping Wang, Lei Chen, Yang Yang"
A Stochastic Block Hypergraph model,"We propose a simple model for a hypergraph generalization of the stochastic
block model, using the clustering connection probability $P_{ij}$ between
communities $i$ and $j$, and integrating explicitly the hyperedge formation
process. Indeed, hyperedges are groups of nodes and we can expect that
different real-world networks correspond to different formation processes of
these groups and to different levels of homophily between nodes. We describe a
simple model where we can explicitly introduce the hyperedge formation process
and study its impact on the composition of hyperedges. We focus on the standard
case where $P_{ij}=p\delta_{ij}+q(1-\delta_{ij})$, and when $0\leq q\leq p$, we
show that the degree and hyperedge size distributions can be approximated by
binomials with effective parameters that depend on the number of communities
and on $q/p$. Also, the composition of hyperedges goes for $q=0$ from `pure'
hyperedges (comprising nodes belonging to the same community) to `mixed'
hyperedges that comprise nodes from different communities for $q=p$. We tested
various formation processes and our results suggest that when they depend on
the composition of the hyperedge, they tend to favor the dominant community and
lead to hyperedges with a smaller diversity. In contrast, for formation
processes that are independent from the hyperedge structure, we obtain
hyperedges comprising a larger diversity of communities. The advantages of the
model proposed here are its simplicity and flexibility that make it a good
candidate for testing community-related problems, from their detection to their
impact on various dynamics.",2023-12-19,"Alexis Pister, Marc Barthelemy"
Professional Network Matters: Connections Empower Person-Job Fit,"Online recruitment platforms typically employ Person-Job Fit models in the
core service that automatically match suitable job seekers with appropriate job
positions. While existing works leverage historical or contextual information,
they often disregard a crucial aspect: job seekers' social relationships in
professional networks. This paper emphasizes the importance of incorporating
professional networks into the Person-Job Fit model. Our innovative approach
consists of two stages: (1) defining a Workplace Heterogeneous Information
Network (WHIN) to capture heterogeneous knowledge, including professional
connections and pre-training representations of various entities using a
heterogeneous graph neural network; (2) designing a Contextual Social Attention
Graph Neural Network (CSAGNN) that supplements users' missing information with
professional connections' contextual information. We introduce a job-specific
attention mechanism in CSAGNN to handle noisy professional networks, leveraging
pre-trained entity representations from WHIN. We demonstrate the effectiveness
of our approach through experimental evaluations conducted across three
real-world recruitment datasets from LinkedIn, showing superior performance
compared to baseline models.",2023-12-19,"Hao Chen, Lun Du, Yuxuan Lu, Qiang Fu, Xu Chen, Shi Han, Yanbin Kang, Guangming Lu, Zi Li"
"Analyzing Public Reactions, Perceptions, and Attitudes during the MPox
  Outbreak: Findings from Topic Modeling of Tweets","The recent outbreak of the MPox virus has resulted in a tremendous increase
in the usage of Twitter. Prior works in this area of research have primarily
focused on the sentiment analysis and content analysis of these Tweets, and the
few works that have focused on topic modeling have multiple limitations. This
paper aims to address this research gap and makes two scientific contributions
to this field. First, it presents the results of performing Topic Modeling on
601,432 Tweets about the 2022 Mpox outbreak that were posted on Twitter between
7 May 2022 and 3 March 2023. The results indicate that the conversations on
Twitter related to Mpox during this time range may be broadly categorized into
four distinct themes - Views and Perspectives about Mpox, Updates on Cases and
Investigations about Mpox, Mpox and the LGBTQIA+ Community, and Mpox and
COVID-19. Second, the paper presents the findings from the analysis of these
Tweets. The results show that the theme that was most popular on Twitter (in
terms of the number of Tweets posted) during this time range was Views and
Perspectives about Mpox. This was followed by the theme of Mpox and the
LGBTQIA+ Community, which was followed by the themes of Mpox and COVID-19 and
Updates on Cases and Investigations about Mpox, respectively. Finally, a
comparison with related studies in this area of research is also presented to
highlight the novelty and significance of this research work.",2023-12-19,"Nirmalya Thakur, Yuvraj Nihal Duggal, Zihui Liu"
Topic Shifts as a Proxy for Assessing Politicization in Social Media,"Politicization is a social phenomenon studied by political science
characterized by the extent to which ideas and facts are given a political
tone. A range of topics, such as climate change, religion and vaccines has been
subject to increasing politicization in the media and social media platforms.
In this work, we propose a computational method for assessing politicization in
online conversations based on topic shifts, i.e., the degree to which people
switch topics in online conversations. The intuition is that topic shifts from
a non-political topic to politics are a direct measure of politicization --
making something political, and that the more people switch conversations to
politics, the more they perceive politics as playing a vital role in their
daily lives. A fundamental challenge that must be addressed when one studies
politicization in social media is that, a priori, any topic may be politicized.
Hence, any keyword-based method or even machine learning approaches that rely
on topic labels to classify topics are expensive to run and potentially
ineffective. Instead, we learn from a seed of political keywords and use
Positive-Unlabeled (PU) Learning to detect political comments in reaction to
non-political news articles posted on Twitter, YouTube, and TikTok during the
2022 Brazilian presidential elections. Our findings indicate that all platforms
show evidence of politicization as discussion around topics adjacent to
politics such as economy, crime and drugs tend to shift to politics. Even the
least politicized topics had the rate in which their topics shift to politics
increased in the lead up to the elections and after other political events in
Brazil -- an evidence of politicization.",2023-12-18,"Marcelo Sartori Locatelli, Pedro Calais, Matheus Prado Miranda, João Pedro Junho, Tomas Lacerda Muniz, Wagner Meira Jr., Virgilio Almeida"
"Graph Invariant Learning with Subgraph Co-mixup for Out-Of-Distribution
  Generalization","Graph neural networks (GNNs) have been demonstrated to perform well in graph
representation learning, but always lacking in generalization capability when
tackling out-of-distribution (OOD) data. Graph invariant learning methods,
backed by the invariance principle among defined multiple environments, have
shown effectiveness in dealing with this issue. However, existing methods
heavily rely on well-predefined or accurately generated environment partitions,
which are hard to be obtained in practice, leading to sub-optimal OOD
generalization performances. In this paper, we propose a novel graph invariant
learning method based on invariant and variant patterns co-mixup strategy,
which is capable of jointly generating mixed multiple environments and
capturing invariant patterns from the mixed graph data. Specifically, we first
adopt a subgraph extractor to identify invariant subgraphs. Subsequently, we
design one novel co-mixup strategy, i.e., jointly conducting environment Mixup
and invariant Mixup. For the environment Mixup, we mix the variant
environment-related subgraphs so as to generate sufficiently diverse multiple
environments, which is important to guarantee the quality of the graph
invariant learning. For the invariant Mixup, we mix the invariant subgraphs,
further encouraging to capture invariant patterns behind graphs while getting
rid of spurious correlations for OOD generalization. We demonstrate that the
proposed environment Mixup and invariant Mixup can mutually promote each other.
Extensive experiments on both synthetic and real-world datasets demonstrate
that our method significantly outperforms state-of-the-art under various
distribution shifts.",2023-12-18,"Tianrui Jia, Haoyang Li, Cheng Yang, Tao Tao, Chuan Shi"
"Sentiment Analysis and Text Analysis of the Public Discourse on Twitter
  about COVID-19 and MPox","Mining and analysis of the big data of Twitter conversations have been of
significant interest to the scientific community in the fields of healthcare,
epidemiology, big data, data science, computer science, and their related
areas, as can be seen from several works in the last few years that focused on
sentiment analysis and other forms of text analysis of tweets related to Ebola,
E-Coli, Dengue, Human Papillomavirus, Middle East Respiratory Syndrome,
Measles, Zika virus, H1N1, influenza like illness, swine flu, flu, Cholera,
Listeriosis, cancer, Liver Disease, Inflammatory Bowel Disease, kidney disease,
lupus, Parkinsons, Diphtheria, and West Nile virus. The recent outbreaks of
COVID-19 and MPox have served as catalysts for Twitter usage related to seeking
and sharing information, views, opinions, and sentiments involving both of
these viruses. None of the prior works in this field analyzed tweets focusing
on both COVID-19 and MPox simultaneously. To address this research gap, a total
of 61,862 tweets that focused on MPox and COVID-19 simultaneously, posted
between 7 May 2022 and 3 March 2023, were studied. The findings and
contributions of this study are manifold. First, the results of sentiment
analysis using the VADER approach show that nearly half the tweets had a
negative sentiment. It was followed by tweets that had a positive sentiment and
tweets that had a neutral sentiment, respectively. Second, this paper presents
the top 50 hashtags used in these tweets. Third, it presents the top 100 most
frequently used words in these tweets after performing tokenization, removal of
stopwords, and word frequency analysis. Finally, a comprehensive comparative
study that compares the contributions of this paper with 49 prior works in this
field is presented to further uphold the relevance and novelty of this work.",2023-12-17,Nirmalya Thakur
"Analysis of Nepotism in Bollywood using Personalized PageRank and
  Effective Influence","Bollywood is one of the largest film-producing industries with a large
worldwide audience. In this paper, we will try to find the most important stars
in the era of 1990 to 2014, as well as try to use social network analysis
methods and metrics to analyze the role of blood connections in getting
opportunities in the industry. We created the actor relationship data of around
1000 debutants using OpenAI API and used a novel approach ""Effective Influence""
to study the effect of having a blood-related established actor inside the
industry. We found that on an average every actor/director or actor/actor pair
is reachable by a path of length at most 4 and a correlation of 0.6 indicating
the advantage of having a blood connection inside the network in getting a good
co-cast in the debut film.",2023-12-16,Apoorv Jain
Introduction to graph theory and basic algorithms,"This book collects the lectures about graph theory and its applications which
were given to students of mathematical departments of Moscow State University
and Peking University. Graph theory is a very wide field with a lot of
applications in almost every scientific area: in many branches of mathematics,
computer science, physics, chemistry, biology and also in psychology, arts,
philosophy and many others. Nowadays, graph theory becomes especially more
important because of the rapid development of molecular biology, neural
networks and AI fields. One of the aims of writing this book was to give
students thorough knowledge about graphs to understand modern scientific fields
more deeply. Here we tried to give classical and modern theorems and algorithms
in more understandable and simple way. We spent many time to rewrite them and
close the gaps in several simplest well-known proofs to provide more precise
and accurate material for students.",2023-12-16,"Mikhail Tuzhilin, Dong Zhang"
"Capturing Dynamics in Online Public Discourse: A Case Study of Universal
  Basic Income Discussions on Reddit","Societal change is often driven by shifts in public opinion. As citizens
evolve in their norms, beliefs, and values, public policies change too. While
traditional opinion polling and surveys can outline the broad strokes of
whether public opinion on a particular topic is changing, they usually cannot
capture the full multi-dimensional richness and diversity of opinion present in
a large heterogeneous population. However, an increasing fraction of public
discourse about public policy issues is now occurring on online platforms,
which presents an opportunity to measure public opinion change at a
qualitatively different scale of resolution and context.
  In this paper, we present a conceptual model of observed opinion change on
online platforms and apply it to study public discourse on Universal Basic
Income (UBI) on Reddit throughout its history. UBI is a periodic,
no-strings-attached cash payment given to every citizen of a population. We
study UBI as it is a clearly-defined policy proposal that has recently
experienced a surge of interest through trends like automation and events like
the COVID-19 pandemic. We find that overall stance towards UBI on Reddit
significantly declined until mid-2019, when this historical trend suddenly
reversed and Reddit became substantially more supportive. Using our model, we
find the most significant drivers of this overall stance change were shifts
within different user cohorts, within communities that represented similar
affluence levels, and within communities that represented similar partisan
leanings. Our method identifies nuanced social drivers of opinion change in the
large-scale public discourse that now regularly occurs online, and could be
applied to a broad set of other important issues and policies.",2023-12-15,"Rachel Kim, Veniamin Veselovsky, Ashton Anderson"
"Combinatorial Complexes: Bridging the Gap Between Cell Complexes and
  Hypergraphs","Graph-based signal processing techniques have become essential for handling
data in non-Euclidean spaces. However, there is a growing awareness that these
graph models might need to be expanded into `higher-order' domains to
effectively represent the complex relations found in high-dimensional data.
Such higher-order domains are typically modeled either as hypergraphs, or as
simplicial, cubical or other cell complexes. In this context, cell complexes
are often seen as a subclass of hypergraphs with additional algebraic structure
that can be exploited, e.g., to develop a spectral theory. In this article, we
promote an alternative perspective. We argue that hypergraphs and cell
complexes emphasize \emph{different} types of relations, which may have
different utility depending on the application context. Whereas hypergraphs are
effective in modeling set-type, multi-body relations between entities, cell
complexes provide an effective means to model hierarchical,
interior-to-boundary type relations. We discuss the relative advantages of
these two choices and elaborate on the previously introduced concept of a
combinatorial complex that enables co-existing set-type and hierarchical
relations. Finally, we provide a brief numerical experiment to demonstrate that
this modelling flexibility can be advantageous in learning tasks.",2023-12-15,"Mustafa Hajij, Ghada Zamzmi, Theodore Papamarkou, Aldo Guzmán-Sáenz, Tolga Birdal, Michael T. Schaub"
"The irruption of cryptocurrencies into Twitter cashtags: a classifying
  solution","There is a consensus about the good sensing characteristics of Twitter to
mine and uncover knowledge in financial markets, being considered a relevant
feeder for taking decisions about buying or holding stock shares and even for
detecting stock manipulation. Although Twitter hashtags allow to aggregate
topic-related content, a specific mechanism for financial information also
exists: Cashtag. However, the irruption of cryptocurrencies has resulted in a
significant degradation on the cashtag-based aggregation of posts.
Unfortunately, Twitter' users may use homonym tickers to refer to
cryptocurrencies and to companies in stock markets, which means that filtering
by cashtag may result on both posts referring to stock companies and
cryptocurrencies. This research proposes automated classifiers to distinguish
conflicting cashtags and, so, their container tweets by analyzing the
distinctive features of tweets referring to stock companies and
cryptocurrencies. As experiment, this paper analyses the interference between
cryptocurrencies and company tickers in the London Stock Exchange (LSE),
specifically, companies in the main and alternative market indices FTSE-100 and
AIM-100. Heuristic-based as well as supervised classifiers are proposed and
their advantages and drawbacks, including their ability to self-adapt to
Twitter usage changes, are discussed. The experiment confirms a significant
distortion in collected data when colliding or homonym cashtags exist, i.e.,
the same \$ acronym to refer to company tickers and cryptocurrencies. According
to our results, the distinctive features of posts including cryptocurrencies or
company tickers support accurate classification of colliding tweets (homonym
cashtags) and Independent Models, as the most detached classifiers from
training data, have the potential to be trans-applicability (in different stock
markets) while retaining performance.",2023-12-14,"Ana Fernández Vilas, Rebeca Díaz Redondo, Antón Lorenzo García"
Echo chamber formation sharpened by priority users,"Priority users (e.g., verified profiles on Twitter) are social media users
whose content is promoted by recommendation algorithms. However, the impact of
this heterogeneous user influence on opinion dynamics, such as polarization
phenomena, is unknown. We conduct a computational mechanistic investigation of
such consequences in a stylized setting. First, we allow priority users, whose
content has greater reach (similar to algorithmic boosting), into an opinion
model on adaptive networks. Then, to exploit this gain in influence, we
incorporate stubborn user behavior, i.e., zealot users who remain committed to
opinions throughout the dynamics. Using a novel measure of echo chamber
formation, we find that prioritizing users can inadvertently reduce
polarization if they post according to the same rule but sharpen echo chamber
formation if they behave heterogeneously. Moreover, we show that a minority of
extremist ideologues (i.e., users who are both stubborn and priority) can push
the system into a transition from consensus to polarization with echo chambers.
Our findings imply that the implementation of the platform's prioritization
policy should be carefully monitored in order to ensure there is no abuse of
users with extra influence.",2023-12-14,"Henrique F. de Arruda, Kleber A. Oliveira, Yamir Moreno"
"Twitter Permeability to financial events: an experiment towards a model
  for sensing irregularities","There is a general consensus of the good sensing and novelty characteristics
of Twitter as an information media for the complex financial market. This paper
investigates the permeability of Twittersphere, the total universe of Twitter
users and their habits, towards relevant events in the financial market.
Analysis shows that a general purpose social media is permeable to
financial-specific events and establishes Twitter as a relevant feeder for
taking decisions regarding the financial market and event fraudulent activities
in that market. However, the provenance of contributions, their different
levels of credibility and quality and even the purpose or intention behind them
should to be considered and carefully contemplated if Twitter is used as a
single source for decision taking. With the overall aim of this research, to
deploy an architecture for real-time monitoring of irregularities in the
financial market, this paper conducts a series of experiments on the level of
permeability and the permeable features of Twitter in the event of one of these
irregularities. To be precise, Twitter data is collected concerning an event
comprising of a specific financial action on the 27th January 2017:{~ }the
announcement about the merge of two companies Tesco PLC and Booker Group PLC,
listed in the main market of the London Stock Exchange (LSE), to create the
UK's Leading Food Business. The experiment attempts to answer five key research
questions which aim to characterize the features of Twitter permeability to the
financial market. The experimental results confirm that a far-impacting
financial event, such as the merger considered, caused apparent disturbances in
all the features considered, that is, information volume, content and sentiment
as well as geographical provenance. Analysis shows that despite, Twitter not
being a specific financial forum, it is permeable to financial events.",2023-12-14,"Ana Fernández Vilas, Rebeca P. Díaz Redondo, Keeley Crockett, Majdi Owda, Lewis Evans"
"Weaving Pathways for Justice with GPT: LLM-driven automated drafting of
  interactive legal applications","Can generative AI help us speed up the authoring of tools to help
self-represented litigants?
  In this paper, we describe 3 approaches to automating the completion of court
forms: a generative AI approach that uses GPT-3 to iteratively prompt the user
to answer questions, a constrained template-driven approach that uses
GPT-4-turbo to generate a draft of questions that are subject to human review,
and a hybrid method. We use the open source Docassemble platform in all 3
experiments, together with a tool created at Suffolk University Law School
called the Assembly Line Weaver. We conclude that the hybrid model of
constrained automated drafting with human review is best suited to the task of
authoring guided interviews.",2023-12-14,"Quinten Steenhuis, David Colarusso, Bryce Willey"
"Uncertainty in GNN Learning Evaluations: A Comparison Between Measures
  for Quantifying Randomness in GNN Community Detection","(1) The enhanced capability of Graph Neural Networks (GNNs) in unsupervised
community detection of clustered nodes is attributed to their capacity to
encode both the connectivity and feature information spaces of graphs. The
identification of latent communities holds practical significance in various
domains, from social networks to genomics. Current real-world performance
benchmarks are perplexing due to the multitude of decisions influencing GNN
evaluations for this task. (2) Three metrics are compared to assess the
consistency of algorithm rankings in the presence of randomness. The
consistency and quality of performance between the results under a
hyperparameter optimisation with the default hyperparameters is evaluated. (3)
The results compare hyperparameter optimisation with default hyperparameters,
revealing a significant performance loss when neglecting hyperparameter
investigation. A comparison of metrics indicates that ties in ranks can
substantially alter the quantification of randomness. (4) Ensuring adherence to
the same evaluation criteria may result in notable differences in the reported
performance of methods for this task. The $W$ Randomness coefficient, based on
the Wasserstein distance, is identified as providing the most robust assessment
of randomness.",2023-12-14,"William Leeney, Ryan McConville"
"Efficient and Scalable Graph Generation through Iterative Local
  Expansion","In the realm of generative models for graphs, extensive research has been
conducted. However, most existing methods struggle with large graphs due to the
complexity of representing the entire joint distribution across all node pairs
and capturing both global and local graph structures simultaneously. To
overcome these issues, we introduce a method that generates a graph by
progressively expanding a single node to a target graph. In each step, nodes
and edges are added in a localized manner through denoising diffusion, building
first the global structure, and then refining the local details. The local
generation avoids modeling the entire joint distribution over all node pairs,
achieving substantial computational savings with subquadratic runtime relative
to node count while maintaining high expressivity through multiscale
generation. Our experiments show that our model achieves state-of-the-art
performance on well-established benchmark datasets while successfully scaling
to graphs with at least 5000 nodes. Our method is also the first to
successfully extrapolate to graphs outside of the training distribution,
showcasing a much better generalization capability over existing methods.",2023-12-14,"Andreas Bergmeister, Karolis Martinkus, Nathanaël Perraudin, Roger Wattenhofer"
"Heterogenous Network Analytics of Small Group Teamwork: Using Multimodal
  Data to Uncover Individual Behavioral Engagement Strategies","Individual behavioral engagement is an important indicator of active learning
in collaborative settings, encompassing multidimensional behaviors mediated
through various interaction modes. Little existing work has explored the use of
multimodal process data to understand individual behavioral engagement in
face-to-face collaborative learning settings. In this study we bridge this gap,
for the first time, introducing a heterogeneous tripartite network approach to
analyze the interconnections among multimodal process data in collaborative
learning. Students' behavioral engagement strategies are analyzed based on
their interaction patterns with various spatial locations and verbal
communication types using a heterogeneous tripartite network. The multimodal
collaborative learning process data were collected from 15 teams of four
students. We conducted stochastic blockmodeling on a projection of the
heterogeneous tripartite network to cluster students into groups that shared
similar spatial and oral engagement patterns. We found two distinct clusters of
students, whose characteristic behavioural engagement strategies were
identified by extracting interaction patterns that were statistically
significant relative to a multinomial null model. The two identified clusters
also exhibited a statistically significant difference regarding students'
perceived collaboration satisfaction and teacher-assessed team performance
level. This study advances collaboration analytics methodology and provides new
insights into personalized support in collaborative learning.",2023-12-14,"Shihui Feng, Lixiang Yan, Linxuan Zhao, Roberto Martinez Maldonado, Dragan Gašević"
CAT: A Causally Graph Attention Network for Trimming Heterophilic Graph,"Local Attention-guided Message Passing Mechanism (LAMP) adopted in Graph
Attention Networks (GATs) is designed to adaptively learn the importance of
neighboring nodes for better local aggregation on the graph, which can bring
the representations of similar neighbors closer effectively, thus showing
stronger discrimination ability. However, existing GATs suffer from a
significant discrimination ability decline in heterophilic graphs because the
high proportion of dissimilar neighbors can weaken the self-attention of the
central node, jointly resulting in the deviation of the central node from
similar nodes in the representation space. This kind of effect generated by
neighboring nodes is called the Distraction Effect (DE) in this paper. To
estimate and weaken the DE of neighboring nodes, we propose a Causally graph
Attention network for Trimming heterophilic graph (CAT). To estimate the DE,
since the DE are generated through two paths (grab the attention assigned to
neighbors and reduce the self-attention of the central node), we use Total
Effect to model DE, which is a kind of causal estimand and can be estimated
from intervened data; To weaken the DE, we identify the neighbors with the
highest DE (we call them Distraction Neighbors) and remove them. We adopt three
representative GATs as the base model within the proposed CAT framework and
conduct experiments on seven heterophilic datasets in three different sizes.
Comparative experiments show that CAT can improve the node classification
accuracy of all base GAT models. Ablation experiments and visualization further
validate the enhancement of discrimination ability brought by CAT. The source
code is available at https://github.com/GeoX-Lab/CAT.",2023-12-14,"Silu He, Qinyao Luo, Xinsha Fu, Ling Zhao, Ronghua Du, Haifeng Li"
A Generalized Neural Diffusion Framework on Graphs,"Recent studies reveal the connection between GNNs and the diffusion process,
which motivates many diffusion-based GNNs to be proposed. However, since these
two mechanisms are closely related, one fundamental question naturally arises:
Is there a general diffusion framework that can formally unify these GNNs? The
answer to this question can not only deepen our understanding of the learning
process of GNNs, but also may open a new door to design a broad new class of
GNNs. In this paper, we propose a general diffusion equation framework with the
fidelity term, which formally establishes the relationship between the
diffusion process with more GNNs. Meanwhile, with this framework, we identify
one characteristic of graph diffusion networks, i.e., the current neural
diffusion process only corresponds to the first-order diffusion equation.
However, by an experimental investigation, we show that the labels of
high-order neighbors actually exhibit monophily property, which induces the
similarity based on labels among high-order neighbors without requiring the
similarity among first-order neighbors. This discovery motives to design a new
high-order neighbor-aware diffusion equation, and derive a new type of graph
diffusion network (HiD-Net) based on the framework. With the high-order
diffusion equation, HiD-Net is more robust against attacks and works on both
homophily and heterophily graphs. We not only theoretically analyze the
relation between HiD-Net with high-order random walk, but also provide a
theoretical convergence guarantee. Extensive experimental results well
demonstrate the effectiveness of HiD-Net over state-of-the-art graph diffusion
networks.",2023-12-14,"Yibo Li, Xiao Wang, Hongrui Liu, Chuan Shi"
"Adversarial Socialbots Modeling Based on Structural Information
  Principles","The importance of effective detection is underscored by the fact that
socialbots imitate human behavior to propagate misinformation, leading to an
ongoing competition between socialbots and detectors. Despite the rapid
advancement of reactive detectors, the exploration of adversarial socialbot
modeling remains incomplete, significantly hindering the development of
proactive detectors. To address this issue, we propose a mathematical
Structural Information principles-based Adversarial Socialbots Modeling
framework, namely SIASM, to enable more accurate and effective modeling of
adversarial behaviors. First, a heterogeneous graph is presented to integrate
various users and rich activities in the original social network and measure
its dynamic uncertainty as structural entropy. By minimizing the
high-dimensional structural entropy, a hierarchical community structure of the
social network is generated and referred to as the optimal encoding tree.
Secondly, a novel method is designed to quantify influence by utilizing the
assigned structural entropy, which helps reduce the computational cost of SIASM
by filtering out uninfluential users. Besides, a new conditional structural
entropy is defined between the socialbot and other users to guide the follower
selection for network influence maximization. Extensive and comparative
experiments on both homogeneous and heterogeneous social networks demonstrate
that, compared with state-of-the-art baselines, the proposed SIASM framework
yields substantial performance improvements in terms of network influence (up
to 16.32%) and sustainable stealthiness (up to 16.29%) when evaluated against a
robust detector with 90% accuracy.",2023-12-13,"Xianghua Zeng, Hao Peng, Angsheng Li"
Computing approximate symmetries of complex networks,"The symmetry of complex networks is a global property that has recently
gained attention since MacArthur et al. 2008 showed that many real-world
networks contain a considerable number of symmetries. These authors work with a
very strict symmetry definition based on the network's automorphism. The
potential problem with this approach is that even a slight change in the
graph's structure can remove or create some symmetry. Recently, Liu 2020
proposed to use an approximate automorphism instead of strict automorphism.
This method can discover symmetries in the network while accepting some minor
imperfections in their structure. The proposed numerical method, however,
exhibits some performance problems and has some limitations while it assumes
the absence of fixed points. In this work, we exploit alternative approaches
recently developed for treating the Graph Matching Problem and propose a
method, which we will refer to as Quadratic Symmetry Approximator (QSA), to
address the aforementioned shortcomings. To test our method, we propose a set
of random graph models suitable for assessing a wide family of approximate
symmetry algorithms. The performance of our method is also demonstrated on
brain networks.",2023-12-13,"Anna Pidnebesna, David Hartman, Aneta Pokorná, Matěj Straka, Jaroslav Hlinka"
"On the Potential of an Independent Avatar to Augment Metaverse Social
  Networks","We present a computational modelling approach which targets capturing the
specifics on how to virtually augment a Metaverse user's available social time
capacity via using an independent and autonomous version of her digital
representation in the Metaverse. We motivate why this is a fundamental building
block to model large-scale social networks in the Metaverse, and emerging
properties herein. We envision a Metaverse-focused extension of the traditional
avatar concept: An avatar can be as well programmed to operate independently
when its user is not controlling it directly, thus turning it into an
agent-based digital human representation. This way, we highlight how such an
independent avatar could help its user to better navigate their social
relationships and optimize their socializing time in the Metaverse by (partly)
offloading some interactions to the avatar. We model the setting and identify
the characteristic variables by using selected concepts from social sciences:
ego networks, social presence, and social cues. Then, we formulate the problem
of maximizing the user's non-avatar-mediated spare time as a linear
optimization. Finally, we analyze the feasible region of the problem and we
present some initial insights on the spare time that can be achieved for
different parameter values of the avatar-mediated interactions.",2023-12-12,"Theofanis P. Raptis, Chiara Boldrini, Marco Conti, Andrea Passarella"
Multimodal Sentiment Analysis: Perceived vs Induced Sentiments,"Social media has created a global network where people can easily access and
exchange vast information. This information gives rise to a variety of
opinions, reflecting both positive and negative viewpoints. GIFs stand out as a
multimedia format offering a visually engaging way for users to communicate. In
this research, we propose a multimodal framework that integrates visual and
textual features to predict the GIF sentiment. It also incorporates attributes
including face emotion detection and OCR generated captions to capture the
semantic aspects of the GIF. The developed classifier achieves an accuracy of
82.7% on Twitter GIFs, which is an improvement over state-of-the-art models.
Moreover, we have based our research on the ReactionGIF dataset, analysing the
variance in sentiment perceived by the author and sentiment induced in the
reader",2023-12-12,"Aditi Aggarwal, Deepika Varshney, Saurabh Patel"
Efficient and Effective Similarity Search over Bipartite Graphs,"Similarity search over a bipartite graph aims to retrieve from the graph the
nodes that are similar to each other, which finds applications in various
fields such as online advertising, recommender systems etc. Existing similarity
measures either (i) overlook the unique properties of bipartite graphs, or (ii)
fail to capture high-order information between nodes accurately, leading to
suboptimal result quality. Recently, Hidden Personalized PageRank (HPP) is
applied to this problem and found to be more effective compared with prior
similarity measures. However, existing solutions for HPP computation incur
significant computational costs, rendering it inefficient especially on large
graphs.
  In this paper, we first identify an inherent drawback of HPP and overcome it
by proposing bidirectional HPP (BHPP). Then, we formulate similarity search
over bipartite graphs as the problem of approximate BHPP computation, and
present an efficient solution Approx-BHPP. Specifically, Approx-BHPP offers
rigorous theoretical accuracy guarantees with optimal computational complexity
by combining deterministic graph traversal with matrix operations in an
optimized and non-trivial way. Moreover, our solution achieves significant gain
in practical efficiency due to several carefully-designed optimizations.
Extensive experiments, comparing BHPP against 8 existing similarity measures
over 7 real bipartite graphs, demonstrate the effectiveness of BHPP on query
rewriting and item recommendation. Moreover, Approx-BHPP outperforms baseline
solutions often by up to orders of magnitude in terms of computational time on
both small and large datasets.",2023-12-11,Renchi Yang
"Transportation Transformed: A Comprehensive Review of Dynamic Rerouting
  in Multimodal Networks","The emergence of dynamic rerouting in multi-modal transportation networks has
emerged as a crucial area in operations research, revolutionizing routine
optimization. The review study analyzes multiple research publications on
algorithms and techniques related to dynamic rerouting to give a thorough
summary of the state of research in this field and provide future suggestions.
The research paper explains the importance of dynamic rerouting in modern
transportation systems and recognizes its critical role in tackling issues like
accidents, traffic congestion, and infrastructure constraints. In addition, the
review examines the development of dynamic rerouting techniques by examining
several studies to uncover the theoretical foundation, technological
developments, and effects of the practices on various forms of transportation.
The paper emphasizes the potential of technological advancements such as
artificial intelligence, the Internet of Things, and big data in transforming
routing efficiencies. Further, the review presents specific difficulties and
best practices for each mode of transportation, highlighting the many uses of
dynamic rerouting in air, sea, rail, and road transportation. The review also
digs deeper into the integration barriers common in multi-modal networks,
highlighting successful case studies that overcome these obstacles as well as
strategic approaches and regulatory modifications. Lastly, the research paper
assesses the impact of dynamic rerouting on urban development, sustainability,
and potential directions for future research such as the integration of large
language models. The comprehensive literature review incorporates multiple
research perspectives to offer significant insights into the efficacy,
challenges, and potential future pathways for dynamic rerouting within
multi-modal transportation networks.",2023-12-11,Suyash Pratap
The survival of scientific stylization,"This study elaborates a text-based metric to quantify the unique position of
stylized scientific research, characterized by its innovative integration of
diverse knowledge components and potential to pivot established scientific
paradigms. Our analysis reveals a concerning decline in stylized research,
highlighted by its comparative undervaluation in terms of citation counts and
protracted peer-review duration. Despite facing these challenges, the
disruptive potential of stylized research remains robust, consistently
introducing groundbreaking questions and theories. This paper posits that
substantive reforms are necessary to incentivize and recognize the value of
stylized research, including optimizations to the peer-review process and the
criteria for evaluating scientific impact. Embracing these changes may be
imperative to halt the downturn in stylized research and ensure enduring
scholarly exploration in endless frontiers.",2023-12-10,"Yuanyuan Shu, Tianxing Pan"
"Modeling Homophily in Exponential-Family Random Graph Models for
  Bipartite Networks","Homophily, the tendency of individuals who are alike to form ties with one
another, is an important concept in the study of social networks. Yet
accounting for homophily effects is complicated in the context of bipartite
networks where ties connect individuals not with one another but rather with a
separate set of nodes, which might also be individuals but which are often an
entirely different type of objects. As a result, much work on the effect of
homophily in a bipartite network proceeds by first eliminating the bipartite
structure, collapsing a two-mode network to a one-mode network and thereby
ignoring potentially meaningful structure in the data. We introduce a set of
methods to model homophily on bipartite networks without losing information in
this way, then we demonstrate that these methods allow for substantively
interesting findings in management science not possible using standard
techniques. These methods are implemented in the widely-used ergm package for
R.",2023-12-09,"Rashmi P. Bomiriya, Alina R. Kuvelkar, David R. Hunter, Steffen Triebel"
Polarization in Decentralized Online Social Networks,"Centralized social media platforms are currently experiencing a shift in user
engagement, drawing attention to alternative paradigms like Decentralized
Online Social Networks (DOSNs). The rising popularity of DOSNs finds its root
in the accessibility of open-source software, enabling anyone to create a new
instance (i.e., server) and participate in a decentralized network known as
Fediverse. Despite this growing momentum, there has been a lack of studies
addressing the effect of positive and negative interactions among instances
within DOSNs. This work aims to fill this gap by presenting a preliminary
examination of instances' polarization in DOSNs, focusing on Mastodon -- the
most widely recognized decentralized social media platform, boasting over 10M
users and nearly 20K instances to date. Our results suggest that polarization
in the Fediverse emerges in unique ways, influenced by the desire to foster a
federated environment between instances, also facilitating the isolation of
instances that may pose potential risks to the Fediverse.",2023-12-09,"Lucio La Cava, Domenico Mandaglio, Andrea Tagarelli"
"Do Socialization Restrictions Prevent Restaurants from Becoming Covid
  Hotspots?","Simulation models for infection spread can help understand what factors play
a major role in infection spread. Health agencies like the Center for Disease
Control (CDC) can accordingly mandate effective guidelines to curb the spread.
We built an infection spread model to simulate disease propagation through
airborne transmission to study the impact of restaurant operational policies on
the Covid-19 infections. We use the Wells-Riley model to measure the expected
value of new infections in a given time-frame in a particular location. For the
purpose of this study, we have restricted our analysis to bars and restaurants
in the Minneapolis-St. Paul region. Our model helps identify disease hotspots
within the Twin Cities and proves that stay-at-home orders were effective
during the recent lockdown, and the people typically followed the social
distancing guidelines. To arrive at this conclusion, we performed significance
testing by considering specific hypothetical scenarios. At the end of the
study, we discuss the reasoning behind the hotspots, and make suggestions that
could help avoid them.",2023-12-09,"Aviral Bhatnagar, Himanshu Kharkwal, Jaideep Srivastava"
"Unsupervised Social Event Detection via Hybrid Graph Contrastive
  Learning and Reinforced Incremental Clustering","Detecting events from social media data streams is gradually attracting
researchers. The innate challenge for detecting events is to extract
discriminative information from social media data thereby assigning the data
into different events. Due to the excessive diversity and high updating
frequency of social data, using supervised approaches to detect events from
social messages is hardly achieved. To this end, recent works explore learning
discriminative information from social messages by leveraging graph contrastive
learning (GCL) and embedding clustering in an unsupervised manner. However, two
intrinsic issues exist in benchmark methods: conventional GCL can only roughly
explore partial attributes, thereby insufficiently learning the discriminative
information of social messages; for benchmark methods, the learned embeddings
are clustered in the latent space by taking advantage of certain specific prior
knowledge, which conflicts with the principle of unsupervised learning
paradigm. In this paper, we propose a novel unsupervised social media event
detection method via hybrid graph contrastive learning and reinforced
incremental clustering (HCRC), which uses hybrid graph contrastive learning to
comprehensively learn semantic and structural discriminative information from
social messages and reinforced incremental clustering to perform efficient
clustering in a solidly unsupervised manner. We conduct comprehensive
experiments to evaluate HCRC on the Twitter and Maven datasets. The
experimental results demonstrate that our approach yields consistent
significant performance boosts. In traditional incremental setting,
semi-supervised incremental setting and solidly unsupervised setting, the model
performance has achieved maximum improvements of 53%, 45%, and 37%,
respectively.",2023-12-08,"Yuanyuan Guo, Zehua Zang, Hang Gao, Xiao Xu, Rui Wang, Lixiang Liu, Jiangmeng Li"
"The Graph Lottery Ticket Hypothesis: Finding Sparse, Informative Graph
  Structure","Graph learning methods help utilize implicit relationships among data items,
thereby reducing training label requirements and improving task performance.
However, determining the optimal graph structure for a particular learning task
remains a challenging research problem.
  In this work, we introduce the Graph Lottery Ticket (GLT) Hypothesis - that
there is an extremely sparse backbone for every graph, and that graph learning
algorithms attain comparable performance when trained on that subgraph as on
the full graph. We identify and systematically study 8 key metrics of interest
that directly influence the performance of graph learning algorithms.
Subsequently, we define the notion of a ""winning ticket"" for graph structure -
an extremely sparse subset of edges that can deliver a robust approximation of
the entire graph's performance. We propose a straightforward and efficient
algorithm for finding these GLTs in arbitrary graphs. Empirically, we observe
that performance of different graph learning algorithms can be matched or even
exceeded on graphs with the average degree as low as 5.",2023-12-08,"Anton Tsitsulin, Bryan Perozzi"
"Luck, skill, and depth of competition in games and social hierarchies","Patterns of wins and losses in pairwise contests, such as occur in sports and
games, consumer research and paired comparison studies, and human and animal
social hierarchies, are commonly analyzed using probabilistic models that allow
one to quantify the strength of competitors or predict the outcome of future
contests. Here we generalize this approach to incorporate two additional
features: an element of randomness or luck that leads to upset wins, and a
""depth of competition"" variable that measures the complexity of a game or
hierarchy. Fitting the resulting model to a large collection of data sets we
estimate depth and luck in a range of games, sports, and social situations. In
general, we find that social competition tends to be ""deep,"" meaning it has a
pronounced hierarchy with many distinct levels, but also that there is often a
nonzero chance of an upset victory, meaning that dominance challenges can be
won even by significant underdogs. Competition in sports and games, by
contrast, tends to be shallow and in most cases there is little evidence of
upset wins, beyond those already implied by the shallowness of the hierarchy.",2023-12-07,"Maximilian Jerdee, M. E. J. Newman"
"Content Moderation on Social Media in the EU: Insights From the DSA
  Transparency Database","The Digital Services Act (DSA) requires large social media platforms in the
EU to provide clear and specific information whenever they remove or restrict
access to certain content. These ""Statements of Reasons"" (SoRs) are collected
in the DSA Transparency Database to ensure transparency and scrutiny of content
moderation decisions of the providers of online platforms. In this work, we
empirically analyze 156 million SoRs within an observation period of two months
to provide an early look at content moderation decisions of social media
platforms in the EU. Our empirical analysis yields the following main findings:
(i) There are vast differences in the frequency of content moderation across
platforms. For instance, TikTok performs more than 350 times more content
moderation decisions per user than X/Twitter. (ii) Content moderation is most
commonly applied for text and videos, whereas images and other content formats
undergo moderation less frequently. (ii) The primary reasons for moderation
include content falling outside the platform's scope of service,
illegal/harmful speech, and pornography/sexualized content, with moderation of
misinformation being relatively uncommon. (iii) The majority of rule-breaking
content is detected and decided upon via automated means rather than manual
intervention. However, X/Twitter reports that it relies solely on non-automated
methods. (iv) There is significant variation in the content moderation actions
taken across platforms. Altogether, our study implies inconsistencies in how
social media platforms implement their obligations under the DSA -- resulting
in a fragmented outcome that the DSA is meant to avoid. Our findings have
important implications for regulators to clarify existing guidelines or lay out
more specific rules that ensure common standards on how social media providers
handle rule-breaking content on their platforms.",2023-12-07,"Chiara Drolsbach, Nicolas Pröllochs"
"Breaking the Entanglement of Homophily and Heterophily in
  Semi-supervised Node Classification","Recently, graph neural networks (GNNs) have shown prominent performance in
semi-supervised node classification by leveraging knowledge from the graph
database. However, most existing GNNs follow the homophily assumption, where
connected nodes are more likely to exhibit similar feature distributions and
the same labels, and such an assumption has proven to be vulnerable in a
growing number of practical applications. As a supplement, heterophily reflects
dissimilarity in connected nodes, which has gained significant attention in
graph learning. To this end, data engineers aim to develop a powerful GNN model
that can ensure performance under both homophily and heterophily. Despite
numerous attempts, most existing GNNs struggle to achieve optimal node
representations due to the constraints of undirected graphs. The neglect of
directed edges results in sub-optimal graph representations, thereby hindering
the capacity of GNNs. To address this issue, we introduce AMUD, which
quantifies the relationship between node profiles and topology from a
statistical perspective, offering valuable insights for Adaptively Modeling the
natural directed graphs as the Undirected or Directed graph to maximize the
benefits from subsequent graph learning. Furthermore, we propose Adaptive
Directed Pattern Aggregation (ADPA) as a new directed graph learning paradigm
for AMUD. Empirical studies have demonstrated that AMUD guides efficient graph
learning. Meanwhile, extensive experiments on 16 benchmark datasets
substantiate the impressive performance of ADPA, outperforming baselines by
significant margins of 3.96.",2023-12-07,"Henan Sun, Xunkai Li, Zhengyu Wu, Daohan Su, Rong-Hua Li, Guoren Wang"
Identifying hubs in directed networks,"Nodes in networks that exhibit high connectivity, also called ``hubs'', play
a critical role in determining the structural and functional properties of
networked systems. However, there is no clear definition of what constitutes a
hub node in a network, and the classification of network hubs in existing work
has either been purely qualitative or relies on ad hoc criteria for
thresholding continuous data that do not generalize well to networks with
certain degree sequences. Here we develop a set of efficient nonparametric
methods that classify hub nodes in directed networks using the Minimum
Description Length principle, effectively providing a clear and principled
definition for network hubs. We adapt our methods to both unweighted and
weighted networks and demonstrate them in a range of example applications using
real and synthetic network data.",2023-12-06,Alec Kirkley
"Public emotional dynamics toward AIGC content generation across social
  media platform","Given the widespread popularity of interactive AI models like ChatGPT, public
opinion on emerging artificial intelligence generated content(AIGC) has been
extensively debated. Pessimists believe that AIGC will replace humans in the
future, and optimists think that it will further liberate productivity. Public
emotions play a crucial role on social media platforms. They can provide
valuable insights into the public's opinions, attitudes, and behaviors. There
is a lack of research on the analysis of social group emotions triggered by
AIGC content, and even more on the cross-platform differences of group
emotions. This study fills the research gap by connecting the theory of group
dynamics with emotions in social media. Specifically, we develop a scientific
group emotion calculation and visualization system based on chains of
communication. The system is capable of crawling data in real time and
presenting the current state of group emotions in a fine-grained manner. We
then analyze which group dynamic factors drive different public emotions
towards nine AIGC products on the three most popular social media platforms in
China. Finally, we obtain four main findings. First, Douyin is the only
platform with negative group emotion on emerging AI technologies. Second, Weibo
users prefer extreme emotions more than others. Third, the group emotion varies
by education and age. It is negatively correlated with senior high school or
lower and 25 or younger, and positively correlated with bachelor's degree or
higher and 26-35. Fourth, the group emotion polarization increases with more
posts without comments and celebrity publishers. By analyzing the key dynamic
factors of group emotions to AIGC on various social media platforms, we can
improve our products and services, develop more effective marketing strategies,
and create more accurate and effective AI models to solve complex problems.",2023-12-06,"Qinglan Wei, Jiayi Li, Yuan Zhang"
"Using the SP!CE Framework to Code Influence Campaign Activity on Social
  Media: Case Study on the 2022 Brazilian Presidential Election","We describe a case study in the use of the Structured Process for Information
Campaign Enhancement (SP!CE, version 2.1) to evaluate influence campaigns
present in the 2nd round of the Brazilian presidential election in 2022
October. SP!CE is a US-military focused framework for describing both friendly
and adversary actions in influence campaigns, and is inter-operable with the
Disinformation Analysis and Risk Management (DISARM) framework. The purpose of
the case study is to demonstrate how SP!CE can be used to describe influence
campaign behaviors. We selected the Brazilian election as the target of the
case study as it is known that there were significant amounts of mis- and
disinformation present on social media during the campaigns. Our goal was to
demonstrate how SP!CE could be applied in such a context, showing how social
media content could be aligned with information campaign behaviors and how such
an alignment can be used to analyze which mis- and disinformation narratives
were in play. Additionally, we aim to provide insights on best practices
regarding how to apply the framework in further research. We release the coding
and screenshots of the relevant social media posts to support future research.",2023-12-05,"Alexander Gocso, Claudia Perez Brito, Bryan Ruesca, Allen Mendes, Mark A. Finlayson"
"A Low-cost, High-impact Node Injection Approach for Attacking Social
  Network Alignment","Social network alignment (SNA) holds significant importance for various
downstream applications, prompting numerous professionals to develop and share
SNA tools. Unfortunately, these tools can be exploited by malicious actors to
integrate sensitive user information, posing cybersecurity risks. While many
researchers have explored attacking SNA (ASNA) through a network modification
attack way, practical feasibility remains a challenge. This paper introduces a
novel approach, the node injection attack. To overcome the problem of modeling
and solving within a limited time and balancing costs and benefits, we propose
a low-cost, high-impact node injection attack via dynamic programming (DPNIA)
framework. DPNIA models ASNA as a problem of maximizing the number of confirmed
incorrect correspondent node pairs who have a greater similarity scores than
the pairs between existing nodes, making ASNA solvable. Meanwhile, it employs a
cross-network evaluation method to identify node vulnerability, facilitating a
progressive attack from easy to difficult. Additionally, it utilizes an optimal
injection strategy searching method, based on dynamic programming, to determine
which links should be added between injected nodes and existing nodes, thereby
achieving a high impact for attack effectiveness at a low cost. Experiments on
four real-world datasets consistently demonstrate that DPNIA consistently and
significantly outperforms various attack baselines.",2023-12-05,"Shuyu Jiang, Yunxiang Qiu, Xian Mo, Rui Tang, Wei Wang"
"Generalizing Political Leaning Inference to Multi-Party Systems:
  Insights from the UK Political Landscape","An ability to infer the political leaning of social media users can help in
gathering opinion polls thereby leading to a better understanding of public
opinion. While there has been a body of research attempting to infer the
political leaning of social media users, this has been typically simplified as
a binary classification problem (e.g. left vs right) and has been limited to a
single location, leading to a dearth of investigation into more complex,
multiclass classification and its generalizability to different locations,
particularly those with multi-party systems. Our work performs the first such
effort by studying political leaning inference in three of the UK's nations
(Scotland, Wales and Northern Ireland), each of which has a different political
landscape composed of multiple parties. To do so, we collect and release a
dataset comprising users labelled by their political leaning as well as
interactions with one another. We investigate the ability to predict the
political leaning of users by leveraging these interactions in challenging
scenarios such as few-shot learning, where training data is scarce, as well as
assessing the applicability to users with different levels of political
engagement. We show that interactions in the form of retweets between users can
be a very powerful feature to enable political leaning inference, leading to
consistent and robust results across different regions with multi-party
systems. However, we also see that there is room for improvement in predicting
the political leaning of users who are less engaged in politics.",2023-12-04,"Joseba Fernandez de Landa, Arkaitz Zubiaga, Rodrigo Agerri"
Finding mixed memberships in categorical data,"Latent class analysis, a fundamental problem in categorical data analysis,
often encounters overlapping latent classes that introduce further challenges.
This paper presents a solution to this problem by focusing on finding latent
mixed memberships of subjects in categorical data with polytomous responses. We
employ the Grade of Membership (GoM) model, which assigns each subject a
membership score in each latent class. To address this, we propose two
efficient spectral algorithms for estimating these mixed memberships and other
GoM parameters. Our algorithms are based on the singular value decomposition of
a regularized Laplacian matrix. We establish their convergence rates under a
mild condition on data sparsity. Additionally, we introduce a metric to
evaluate the quality of estimated mixed memberships for real-world categorical
data and determine the optimal number of latent classes based on this metric.
Finally, we demonstrate the practicality of our methods through experiments on
both computer-generated and real-world categorical datasets.",2023-12-04,Huan Qing
RaftGP: Random Fast Graph Partitioning,"Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides the node set of a graph into densely-connected blocks. Following
prior work on the IEEE HPEC Graph Challenge benchmark and recent advances in
graph machine learning, we propose a novel RAndom FasT Graph Partitioning
(RaftGP) method based on an efficient graph embedding scheme. It uses the
Gaussian random projection to extract community-preserving features from
classic GP objectives. These features are fed into a graph neural network (GNN)
to derive low-dimensional node embeddings. Surprisingly, our experiments
demonstrate that a randomly initialized GNN even without training is enough for
RaftGP to derive informative community-preserving embeddings and support
high-quality GP. To enable the derived embeddings to tackle GP, we introduce a
hierarchical model selection algorithm that simultaneously determines the
number of blocks and the corresponding GP result. We evaluate RaftGP on the
Graph Challenge benchmark and compare the performance with five baselines,
where our method can achieve a better trade-off between quality and efficiency.
In particular, compared to the baseline algorithm of the IEEE HPEC Graph
Challenge, our method is 6.68x -- 23.9x faster on graphs with 1E3 -- 5E4 nodes
and at least 64.5x faster on larger (1E5 node) graphs on which the baseline
takes more than 1E4 seconds. Our method achieves better accuracy on all test
cases. We also develop a new graph generator to address some limitations of the
original generator in the benchmark.",2023-12-04,"Yu Gao, Meng Qin, Yibin Ding, Li Zeng, Chaorui Zhang, Weixi Zhang, Wei Han, Rongqian Zhao, Bo Bai"
Understanding Opinions Towards Climate Change on Social Media,"Social media platforms such as Twitter (now known as X) have revolutionized
how the public engage with important societal and political topics. Recently,
climate change discussions on social media became a catalyst for political
polarization and the spreading of misinformation. In this work, we aim to
understand how real world events influence the opinions of individuals towards
climate change related topics on social media. To this end, we extracted and
analyzed a dataset of 13.6 millions tweets sent by 3.6 million users from 2006
to 2019. Then, we construct a temporal graph from the user-user mentions
network and utilize the Louvain community detection algorithm to analyze the
changes in community structure around Conference of the Parties on Climate
Change~(COP) events. Next, we also apply tools from the Natural Language
Processing literature to perform sentiment analysis and topic modeling on the
tweets. Our work acts as a first step towards understanding the evolution of
pro-climate change communities around COP events. Answering these questions
helps us understand how to raise people's awareness towards climate change thus
hopefully calling on more individuals to join the collaborative effort in
slowing down climate change.",2023-12-02,"Yashaswi Pupneja, Joseph Zou, Sacha Lévy, Shenyang Huang"
"Which linguistic cues make people fall for fake news? A comparison of
  cognitive and affective processing","Fake news on social media has large, negative implications for society.
However, little is known about what linguistic cues make people fall for fake
news and, hence, how to design effective countermeasures for social media. In
this study, we seek to understand which linguistic cues make people fall for
fake news. Linguistic cues (e.g., adverbs, personal pronouns, positive emotion
words, negative emotion words) are important characteristics of any text and
also affect how people process real vs. fake news. Specifically, we compare the
role of linguistic cues across both cognitive processing (related to careful
thinking) and affective processing (related to unconscious automatic
evaluations). To this end, we performed a within-subject experiment where we
collected neurophysiological measurements of 42 subjects while these read a
sample of 40 real and fake news articles. During our experiment, we measured
cognitive processing through eye fixations, and affective processing in situ
through heart rate variability. We find that users engage more in cognitive
processing for longer fake news articles, while affective processing is more
pronounced for fake news written in analytic words. To the best of our
knowledge, this is the first work studying the role of linguistic cues in fake
news processing. Altogether, our findings have important implications for
designing online platforms that encourage users to engage in careful thinking
and thus prevent them from falling for fake news.",2023-12-02,"Bernhard Lutz, Marc Adam, Stefan Feuerriegel, Nicolas Pröllochs, Dirk Neumann"
"Message-Passing on Hypergraphs: Detectability, Phase Transitions and
  Higher-Order Information","Hypergraphs are widely adopted tools to examine systems with higher-order
interactions. Despite recent advancements in methods for community detection in
these systems, we still lack a theoretical analysis of their detectability
limits. Here, we derive closed-form bounds for community detection in
hypergraphs. Using a Message-Passing formulation, we demonstrate that
detectability depends on hypergraphs' structural properties, such as the
distribution of hyperedge sizes or their assortativity. Our formulation enables
a characterization of the entropy of a hypergraph in relation to that of its
clique expansion, showing that community detection is enhanced when hyperedges
highly overlap on pairs of nodes. We develop an efficient Message-Passing
algorithm to learn communities and model parameters on large systems.
Additionally, we devise an exact sampling routine to generate synthetic data
from our probabilistic model. With these methods, we numerically investigate
the boundaries of community detection in synthetic datasets, and extract
communities from real systems. Our results extend the understanding of the
limits of community detection in hypergraphs and introduce flexible
mathematical tools to study systems with higher-order interactions.",2023-12-01,"Nicolò Ruggeri, Alessandro Lonardi, Caterina De Bacco"
"HOT: Higher-Order Dynamic Graph Representation Learning with Efficient
  Transformers","Many graph representation learning (GRL) problems are dynamic, with millions
of edges added or removed per second. A fundamental workload in this setting is
dynamic link prediction: using a history of graph updates to predict whether a
given pair of vertices will become connected. Recent schemes for link
prediction in such dynamic settings employ Transformers, modeling individual
graph updates as single tokens. In this work, we propose HOT: a model that
enhances this line of works by harnessing higher-order (HO) graph structures;
specifically, k-hop neighbors and more general subgraphs containing a given
pair of vertices. Harnessing such HO structures by encoding them into the
attention matrix of the underlying Transformer results in higher accuracy of
link prediction outcomes, but at the expense of increased memory pressure. To
alleviate this, we resort to a recent class of schemes that impose hierarchy on
the attention matrix, significantly reducing memory footprint. The final design
offers a sweetspot between high accuracy and low memory utilization. HOT
outperforms other dynamic GRL schemes, for example achieving 9%, 7%, and 15%
higher accuracy than - respectively - DyGFormer, TGN, and GraphMixer, for the
MOOC dataset. Our design can be seamlessly extended towards other dynamic GRL
workloads.",2023-11-30,"Maciej Besta, Afonso Claudino Catarino, Lukas Gianinazzi, Nils Blach, Piotr Nyczyk, Hubert Niewiadomski, Torsten Hoefler"
"Who can help me? Reconstructing users' psychological journeys in
  depression-related social media interactions","Social media are increasingly being used as self-help boards, where
individuals can disclose personal experiences and feelings and look for support
from peers or experts. Here we investigate several popular mental
health-related Reddit boards about depression while proposing a novel
psycho-social framework. We reconstruct users' psychological/linguistic
profiles together with their social interactions. We cover a total of 303,016
users, engaging in 378,483 posts and 1,475,044 comments from 01/05/2018 to
01/05/2020. After identifying a network of users' interactions, e.g., who
replied to whom, we open an unprecedented window over psycholinguistic,
cognitive, and affective digital traces with relevance for mental health
research. Through user-generated content, we identify four categories or
archetypes of users in agreement with the Patient Health Engagement model: the
emotionally turbulent/under blackout, the aroused, the adherent-yet-conflicted,
and the eudaimonically hopeful. Analyzing users' transitions over time through
conditional Markov processes, we show how these four archetypes are not
consecutive stages. We do not find a linear progression or sequential patient
journey, where users evolve from struggling to serenity through feelings of
conflict. Instead, we find online users to follow spirals towards both negative
and positive archetypal stages. Through psychological/linguistic and social
network modelling, we can provide compelling quantitative pieces of evidence on
how such a complex path unfolds through positive, negative, and conflicting
online contexts. Our approach opens the way to data-informed understandings of
psychological coping with mental health issues through social media.",2023-11-29,"Virginia Morini, Salvatore Citraro, Elena Sajno, Maria Sansoni, Giuseppe Riva, Massimo Stella, Giulio Rossetti"
"Invisible Women in Digital Diplomacy: A Multidimensional Framework for
  Online Gender Bias Against Women Ambassadors Worldwide","Despite mounting evidence that women in foreign policy often bear the brunt
of online hostility, the extent of online gender bias against diplomats remains
unexplored. This paper offers the first global analysis of the treatment of
women diplomats on social media. Introducing a multidimensional and
multilingual methodology for studying online gender bias, it focuses on three
critical elements: gendered language, negativity in tweets directed at
diplomats, and the visibility of women diplomats. Our unique dataset
encompasses ambassadors from 164 countries, their tweets, and the direct
responses to these tweets in 65 different languages. Using automated content
and sentiment analysis, our findings reveal a crucial gender bias. The language
in responses to diplomatic tweets is only mildly gendered and largely pertains
to international affairs and, generally, women ambassadors do not receive more
negative reactions to their tweets than men, yet the pronounced discrepancy in
online visibility stands out as a significant form of gender bias. Women
receive a staggering 66.4% fewer retweets than men. By unraveling the
invisibility that obscures women diplomats on social media, we hope to spark
further research on online bias in international politics.",2023-11-29,"Yevgeniy Golovchenko, Karolina Stańczak, Rebecca Adler-Nissen, Patrice Wangen, Isabelle Augenstein"
"Computational Hypergraph Discovery, a Gaussian Process framework for
  connecting the dots","Most scientific challenges can be framed into one of the following three
levels of complexity of function approximation. Type 1: Approximate an unknown
function given input/output data. Type 2: Consider a collection of variables
and functions, some of which are unknown, indexed by the nodes and hyperedges
of a hypergraph (a generalized graph where edges can connect more than two
vertices). Given partial observations of the variables of the hypergraph
(satisfying the functional dependencies imposed by its structure), approximate
all the unobserved variables and unknown functions. Type 3: Expanding on Type
2, if the hypergraph structure itself is unknown, use partial observations of
the variables of the hypergraph to discover its structure and approximate its
unknown functions. While most Computational Science and Engineering and
Scientific Machine Learning challenges can be framed as Type 1 and Type 2
problems, many scientific problems can only be categorized as Type 3. Despite
their prevalence, these Type 3 challenges have been largely overlooked due to
their inherent complexity. Although Gaussian Process (GP) methods are sometimes
perceived as well-founded but old technology limited to Type 1 curve fitting,
their scope has recently been expanded to Type 2 problems. In this paper, we
introduce an interpretable GP framework for Type 3 problems, targeting the
data-driven discovery and completion of computational hypergraphs. Our approach
is based on a kernel generalization of Row Echelon Form reduction from linear
systems to nonlinear ones and variance-based analysis. Here, variables are
linked via GPs and those contributing to the highest data variance unveil the
hypergraph's structure. We illustrate the scope and efficiency of the proposed
approach with applications to (algebraic) equation discovery, network discovery
(gene pathways, chemical, and mechanical) and raw data analysis.",2023-11-28,"Théo Bourdais, Pau Batlle, Xianjin Yang, Ricardo Baptista, Nicolas Rouquette, Houman Owhadi"
Compression-based inference of network motif sets,"Physical and functional constraints on biological networks lead to complex
topological patterns across multiple scales in their organization. A particular
type of higher-order network feature that has received considerable interest is
network motifs, defined as statistically regular subgraphs. These may implement
fundamental logical and computational circuits and are referred as ""building
blocks of complex networks"". Their well-defined structures and small sizes also
enables the testing of their functions in synthetic and natural biological
experiments. The statistical inference of network motifs is however fraught
with difficulties, from defining and sampling the right null model to
accounting for the large number of possible motifs and their potential
correlations in statistical testing. Here we develop a framework for motif
mining based on lossless network compression using subgraph contractions. The
minimum description length principle allows us to select the most significant
set of motifs as well as other prominent network features in terms of their
combined compression of the network. The approach inherently accounts for
multiple testing and correlations between subgraphs and does not rely on a
priori specification of an appropriate null model. This provides an alternative
definition of motif significance which guarantees more robust statistical
inference. Our approach overcomes the common problems in classic testing-based
motif analysis. We apply our methodology to perform comparative connectomics by
evaluating the compressibility and the circuit motifs of a range of
synaptic-resolution neural connectomes.",2023-11-27,"Alexis Bénichou, Jean-Baptiste Masson, Christian L. Vestergaard"
"Supply Chain Due Diligence Risk Assessment for the EU: A Network
  Approach to estimate expected effectiveness of the planned EU directive","Globalization has had undesirable effects on the labor standards embedded in
the products we consume. This paper proposes an ex-ante evaluation of supply
chain due diligence regulations, such as the EU Corporate Sustainable Due
Diligence Directive (CSDDD). We construct a full-scale network model derived
from structural business statistics of 30 million EU firms to quantify the
likelihood of links to firms potentially involved in human rights abuses in the
European supply chain. The 900 million supply links of these firms are modeled
in a way that is consistent with multiregional input-output data, EU import
data, and stylized facts of firm-level production networks. We find that this
network exhibits a small world effect with three degrees of separation, meaning
that most firms are no more than three steps away from each other in the
network. Consequently we find that about 8.5% of EU companies are at risk of
having child or forced labor in the first tier of their supply chains, about
82.4% are likely to have such offenders at the second tier and more than 99.1%
have such offenders at the third tier. We also profile companies by country,
sector, and size for the likelihood of having human rights violations or child
and forced labor violations at a given tier in their supply chain, revealing
considerable heterogeneity across EU companies. Our results show that supply
chain due diligence regulations that focus on monitoring individual
buyer-supplier links, as currently proposed in the CSDDD, are likely to be
ineffective due to a high degree of redundancy and the fact that individual
company value chains cannot be properly isolated from the global supply
network. Rather, to maximize cost-effectiveness without compromising due
diligence coverage, we suggest that regulations should focus on monitoring
individual suppliers.",2023-11-27,"Jan Hurt, Katharina Ledebur, Birgit Meyer, Klaus Friesenbichler, Markus Gerschberger, Stefan Thurner, Peter Klimek"
A Study of Partisan News Sharing in the Russian invasion of Ukraine,"Since the Russian invasion of Ukraine, a large volume of biased and partisan
news has been spread via social media platforms. As this may lead to wider
societal issues, we argue that understanding how partisan news sharing impacts
users' communication is crucial for better governance of online communities. In
this paper, we perform a measurement study of partisan news sharing. We aim to
characterize the role of such sharing in influencing users' communications. Our
analysis covers an eight-month dataset across six Reddit communities related to
the Russian invasion. We first perform an analysis of the temporal evolution of
partisan news sharing. We confirm that the invasion stimulates discussion in
the observed communities, accompanied by an increased volume of partisan news
sharing. Next, we characterize users' response to such sharing. We observe that
partisan bias plays a role in narrowing its propagation. More biased media is
less likely to be spread across multiple subreddits. However, we find that
partisan news sharing attracts more users to engage in the discussion, by
generating more comments. We then built a predictive model to identify users
likely to spread partisan news. The prediction is challenging though, with
61.57% accuracy on average. Our centrality analysis on the commenting network
further indicates that the users who disseminate partisan news possess lower
network influence in comparison to those who propagate neutral news.",2023-11-26,"Yiming Zhu, Ehsan-Ul Haq, Gareth Tyson, Lik-Hang Lee, Yuyang Wang, Pan Hui"
"Should I use metaverse or not? An investigation of university students
  behavioral intention to use MetaEducation technology","Metaverse, a burgeoning technological trend that combines virtual and
augmented reality, provides users with a fully digital environment where they
can assume a virtual identity through a digital avatar and interact with others
as they were in the real world. Its applications span diverse domains such as
economy (with its entry into the cryptocurrency field), finance, social life,
working environment, healthcare, real estate, and education. During the
COVID-19 and post-COVID-19 era, universities have rapidly adopted e-learning
technologies to provide students with online access to learning content and
platforms, rendering previous considerations on integrating such technologies
or preparing institutional infrastructures virtually obsolete. In light of this
context, the present study proposes a framework for analyzing university
students' acceptance and intention to use metaverse technologies in education,
drawing upon the Technology Acceptance Model (TAM). The study aims to
investigate the relationship between students' intention to use metaverse
technologies in education, hereafter referred to as MetaEducation, and selected
TAM constructs, including Attitude, Perceived Usefulness, Perceived Ease of
Use, Self-efficacy of metaverse technologies in education, and Subjective Norm.
Notably, Self-efficacy and Subjective Norm have a positive influence on
Attitude and Perceived Usefulness, whereas Perceived Ease of Use does not
exhibit a strong correlation with Attitude or Perceived Usefulness. The authors
postulate that the weak associations between the study's constructs may be
attributed to limited knowledge regarding MetaEducation and its potential
benefits. Further investigation and analysis of the study's proposed model are
warranted to comprehensively understand the complex dynamics involved in the
acceptance and utilization of MetaEducation technologies in the realm of higher
education",2023-11-26,"Nikolaos Misirlis, Yiannis Nikolaidis, Anna Sabidussi"
Anomaly detection in cross-country money transfer temporal networks,"This paper explores anomaly detection through temporal network analysis.
Unlike many conventional methods, relying on rule-based algorithms or general
machine learning approaches, our methodology leverages the evolving structure
and relationships within temporal networks, that can be used to model financial
transactions. Focusing on minimal changes in stable ecosystems, such as those
found in large international financial institutions, our approach utilizes
network centrality measures to gain insights into individual nodes. By
monitoring the temporal evolution of centrality-based node rankings, our method
effectively identifies abrupt shifts in the roles of specific nodes, prompting
further investigation by domain experts.
  To demonstrate its efficacy, our methodology is applied in the Anti-Financial
Crime (AFC) domain, analyzing a substantial financial dataset comprising over
80 million cross-country wire transfers. The goal is to pinpoint outliers
potentially involved in malicious activities, aligning with financial
regulations. This approach serves as an initial stride towards automating AFC
and Anti-Money Laundering (AML) processes, providing AFC officers with a
comprehensive top-down view to enhance their efforts. It overcomes many
limitations of current prevalent paradigms, offering a holistic interpretation
of the financial data landscape and addressing potential blindness to phenomena
that cannot be effectively estimated through single-node or narrowly focused
transactional approaches.",2023-11-24,"Salvatore Vilella, Arthur Thomas Edward Capozzi Lupi, Marco Fornasiero, Dario Moncalvo, Valeria Ricci, Silvia Ronchiadin, Giancarlo Ruffo"
Temporal link prediction methods based on behavioral synchrony,"Link prediction -- to identify potential missing or spurious links in
temporal network data -- has typically been based on local structures, ignoring
long-term temporal effects. In this chapter, we propose link-prediction methods
based on agents' behavioral synchrony. Since synchronous behavior signals
similarity and similar agents are known to have a tendency to connect in the
future, behavioral synchrony could function as a precursor of contacts and,
thus, as a basis for link prediction. We use four data sets of different sizes
to test the algorithm's accuracy. We compare the results with traditional link
prediction models involving both static and temporal networks. Among our
findings, we note that the proposed algorithm is superior to conventional
methods, with the average accuracy improved by approximately 2% - 5%. We
identify different evolution patterns of four network topologies -- a proximity
network, a communication network, transportation data, and a collaboration
network. We found that: (1) timescale similarity contributes more to the
evolution of the human contact network and the human communication network; (2)
such contribution is not observed through a transportation network whose
evolution pattern is more dependent on network structure than on the behavior
of regional agents; (3) both timescale similarity and local structural
similarity contribute to the collaboration network.",2023-11-24,"Yueran Duan, Qing Guan, Petter Holme, Yacheng Yang, Wei Guan"
"Fair Influence Maximization in Social Networks: A Community-Based
  Evolutionary Algorithm","Influence Maximization (IM) has been extensively studied in network science,
which attempts to find a subset of users to maximize the influence spread. A
new variant of IM, Fair Influence Maximization (FIM), which primarily enhances
the fair propagation of information, attracts increasing attention in academic.
However, existing algorithms for FIM suffer from a trade-off between fairness
and running time. Since it is a tough task to ensure that users are fairly
influenced in terms of sensitive attributes, such as race or gender, while
maintaining a high influence spread. To tackle this problem, in this paper, we
propose an effective and efficient Community-based Evolutionary Algorithm for
FIM (named CEA-FIM). In CEA-FIM, a community-based node selection strategy is
proposed to identify potential nodes, which not only considers the size of the
community but also the attributes of the nodes in the community. Subsequently,
we design an evolutionary algorithm based on the proposed node selection
strategy to hasten the search for the optimal solution, including the novel
initialization, crossover and mutation strategies. We validate the proposed
algorithm CEA-FIM by performing experiments on real-world and synthetic
networks. The experimental results show that the proposed CEA-FIM achieves a
better balance between effectiveness and efficiency, compared to the
state-of-the-art baseline algorithms.",2023-11-24,"Kaicong Ma, Xinxiang Xu, Haipeng Yang, Renzhi Cao, Lei Zhang"
"From Spin States to Social Consensus: Ising Approach to Dimer
  Configurations in Opinion Formation","The field of opinion dynamics has evolved steadily since the earliest studies
applying magnetic physics methods to better understand social opinion
formation. However, in the real world, complete agreement of opinions is rare,
and biaxial consensus, especially on social issues, is rare. To address this
challenge, Ishii and Kawabata (2018) proposed an extended version of the
Bounded Confidence Model that introduces new parameters indicating dissent and
distrust, as well as the influence of mass media. Their model aimed to capture
more realistic social opinion dynamics by introducing coefficients representing
the degree of trust and distrust, rather than assuming convergence of opinions.
In this paper, we propose a new approach to opinion dynamics based on this
Trust-Distrust Model (TDM), applying the dimer allocation and Ising model. Our
goal is to explore how the interaction between trust and distrust affects
social opinion formation. In particular, we analyze through mathematical models
how various external stimuli, such as mass media, third-party opinions, and
economic and political factors, affect people's opinions. Our approach is to
mathematically represent the dynamics of trust and distrust, which traditional
models have not addressed. This theoretical framework provides new insights
into the polarization of opinions, the process of consensus building, and how
these are reflected in social behavior. In addition to developing the
theoretical framework by applying the dimer configuration, the dimer model and
the Ising model, this paper uses numerical simulations to show how the proposed
model applies to actual social opinion formation. This research aims to
contribute to a deeper understanding of social opinion formation by providing
new perspectives in the fields of social science, physics, and computational
modeling.",2023-11-23,Yasuko Kawahata
"Temporal Network Analysis of Email Communication Patterns in a Long
  Standing Hierarchy","An important concept in organisational behaviour is how hierarchy affects the
voice of individuals, whereby members of a given organisation exhibit differing
power relations based on their hierarchical position. Although there have been
prior studies of the relationship between hierarchy and voice, they tend to
focus on more qualitative small-scale methods and do not account for structural
aspects of the organisation. This paper develops large-scale computational
techniques utilising temporal network analysis to measure the effect that
organisational hierarchy has on communication patterns within an organisation,
focusing on the structure of pairwise interactions between individuals. We
focus on one major organisation as a case study - the Internet Engineering Task
Force (IETF) - a major technical standards development organisation for the
Internet. A particularly useful feature of the IETF is a transparent hierarchy,
where participants take on explicit roles (e.g. Area Directors, Working Group
Chairs). Its processes are also open, so we have visibility into the
communication of people at different hierarchy levels over a long time period.
We utilise a temporal network dataset of 989,911 email interactions among
23,741 participants to study how hierarchy impacts communication patterns. We
show that the middle levels of the IETF are growing in terms of their dominance
in communications. Higher levels consistently experience a higher proportion of
incoming communication than lower levels, with higher levels initiating more
communications too. We find that communication tends to flow ""up"" the hierarchy
more than ""down"". Finally, we find that communication with higher-levels is
associated with future communication more than for lower-levels, which we
interpret as ""facilitation"". We conclude by discussing the implications this
has on patterns within the wider IETF and for other organisations.",2023-11-22,"Matthew Russell Barnes, Mladen Karan, Stephen McQuistin, Colin Perkins, Gareth Tyson, Matthew Purver, Ignacio Castro, Richard G. Clegg"
"Top-L Most Influential Community Detection Over Social Networks
  (Technical Report)","In many real-world applications such as social network analysis and online
marketing/advertising, the community detection is a fundamental task to
identify communities (subgraphs) in social networks with high structural
cohesiveness. While previous works focus on detecting communities alone, they
do not consider the collective influences of users in these communities on
other user nodes in social networks. Inspired by this, in this paper, we
investigate the influence propagation from some seed communities and their
influential effects that result in the influenced communities. We propose a
novel problem, named Top-L most Influential Community DEtection (TopL-ICDE)
over social networks, which aims to retrieve top-L seed communities with the
highest influences, having high structural cohesiveness, and containing
user-specified query keywords. In order to efficiently tackle the TopL-ICDE
problem, we design effective pruning strategies to filter out false alarms of
seed communities and propose an effective index mechanism to facilitate
efficient Top-L community retrieval. We develop an efficient TopL-ICDE
answering algorithm by traversing the index and applying our proposed pruning
strategies. We also formulate and tackle a variant of TopL-ICDE, named
diversified top-L most influential community detection (DTopL-ICDE), which
returns a set of L diversified communities with the highest diversity score
(i.e., collaborative influences by L communities). We prove that DTopL-ICDE is
NP-hard, and propose an efficient greedy algorithm with our designed diversity
score pruning. Through extensive experiments, we verify the efficiency and
effectiveness of our proposed TopL-ICDE and DTopL-ICDE approaches over
real/synthetic social networks under various parameter settings.",2023-11-22,"Nan Zhang, Yutong Ye, Xiang Lian, Mingsong Chen"
"Combatting Human Trafficking in the Cyberspace: A Natural Language
  Processing-Based Methodology to Analyze the Language in Online Advertisements","This project tackles the pressing issue of human trafficking in online C2C
marketplaces through advanced Natural Language Processing (NLP) techniques. We
introduce a novel methodology for generating pseudo-labeled datasets with
minimal supervision, serving as a rich resource for training state-of-the-art
NLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and
Organized Activity Detection (OAD), we employ cutting-edge Transformer models
for analysis. A key contribution is the implementation of an interpretability
framework using Integrated Gradients, providing explainable insights crucial
for law enforcement. This work not only fills a critical gap in the literature
but also offers a scalable, machine learning-driven approach to combat human
exploitation online. It serves as a foundation for future research and
practical applications, emphasizing the role of machine learning in addressing
complex social issues.",2023-11-22,"Alejandro Rodriguez Perez, Pablo Rivas"
Node Classification in Random Trees,"We propose a method for the classification of objects that are structured as
random trees. Our aim is to model a distribution over the node label
assignments in settings where the tree data structure is associated with node
attributes (typically high dimensional embeddings). The tree topology is not
predetermined and none of the label assignments are present during inference.
Other methods that produce a distribution over node label assignment in trees
(or more generally in graphs) either assume conditional independence of the
label assignment, operate on a fixed graph topology, or require part of the
node labels to be observed. Our method defines a Markov Network with the
corresponding topology of the random tree and an associated Gibbs distribution.
We parameterize the Gibbs distribution with a Graph Neural Network that
operates on the random tree and the node embeddings. This allows us to estimate
the likelihood of node assignments for a given random tree and use MCMC to
sample from the distribution of node assignments.
  We evaluate our method on the tasks of node classification in trees on the
Stanford Sentiment Treebank dataset. Our method outperforms the baselines on
this dataset, demonstrating its effectiveness for modeling joint distributions
of node labels in random trees.",2023-11-20,"Wouter W. L. Nuijten, Vlado Menkovski"
Multi-view Graph Convolution for Participant Recommendation,"Social networks have become essential for people's lives. The proliferation
of web services further expands social networks at an unprecedented scale,
leading to immeasurable commercial value for online platforms. Recently, the
group buying (GB) business mode is prevalent and also becoming more popular in
E-commerce. GB explicitly forms groups of users with similar interests to
secure better discounts from the merchants, often operating within social
networks. It is a novel way to further unlock the commercial value by
explicitly utilizing the online social network in E-commerce. Participant
recommendation, a fundamental problem emerging together with GB, aims to find
the participants for a launched group buying process with an initiator and a
target item to increase the GB success rate. This paper proposes Multi-View
Graph Convolution for Participant Recommendation (MVPRec) to tackle this
problem. To differentiate the roles of users (Initiator/Participant) within the
GB process, we explicitly reconstruct historical GB data into initiator-view
and participant-view graphs. Together with the social graph, we obtain a
multi-view user representation with graph encoders. Then MVPRec fuses the GB
and social representation with an attention module to obtain the user
representation and learns a matching score with the initiator's social friends
via a multi-head attention mechanism. Social friends with the Top-k matching
score are recommended for the corresponding GB process. Experiments on three
datasets justify the effectiveness of MVPRec in the emerging participant
recommendation problem.",2023-11-20,"Xiaolong Liu, Liangwei Yang, Chen Wang, Mingdai Yang, Zhiwei Liu, Philip S. Yu"
"A large-scale longitudinal structured dataset of the dark web
  cryptomarket Evolution (2014-2015)","Dark Web Marketplaces (DWM) facilitate the online trade of illicit goods. Due
to the illicit nature of these marketplaces, quality datasets are scarce and
difficult to produce. The Dark Net Market archives (2015) presented raw scraped
source files crawled from a selection of DWMs, including Evolution. Here, we
present, specifically for the Evolution DWM, a structured dataset extracted
from Dark Net Market archive data. Uniquely, many of the data quality issues
inherent to crawled data are resolved. The dataset covers over 500 thousand
forum posts and over 80 thousand listings, providing data on forums, topics,
posts, forum users, market vendors, listings, and more. Additionally, we
present temporal weighted communication networks extracted from this data. The
presented dataset provides easy access to a high quality DWM dataset to
facilitate the study of criminal behaviour and communication on such DWMs,
which may provide a relevant source of knowledge for researchers across
disciplines, from social science to law to network science.",2023-11-20,"Hanjo D. Boekhout, Arjan A. Blokland, Frank W. Takes"
"Multilayer Quantile Graph for Multivariate Time Series Analysis and
  Dimensionality Reduction","In recent years, there has been a surge in the prevalence of high- and
multi-dimensional temporal data across various scientific disciplines. These
datasets are characterized by their vast size and challenging potential for
analysis. Such data typically exhibit serial and cross-dependency and possess
high dimensionality, thereby introducing additional complexities to
conventional time series analysis methods. To address these challenges, a
recent and complementary approach has emerged, known as network-based analysis
methods for multivariate time series. In univariate settings, Quantile Graphs
have been employed to capture temporal transition properties and reduce data
dimensionality by mapping observations to a smaller set of sample quantiles.
  To confront the increasingly prominent issue of high dimensionality, we
propose an extension of Quantile Graphs into a multivariate variant, which we
term ""Multilayer Quantile Graphs"". In this innovative mapping, each time series
is transformed into a Quantile Graph, and inter-layer connections are
established to link contemporaneous quantiles of pairwise series. This enables
the analysis of dynamic transitions across multiple dimensions. In this study,
we demonstrate the effectiveness of this new mapping using a synthetic
multivariate time series dataset. We delve into the resulting network's
topological structures, extract network features, and employ these features for
original dataset analysis. Furthermore, we compare our results with a recent
method from the literature. The resulting multilayer network offers a
significant reduction in the dimensionality of the original data while
capturing serial and cross-dimensional transitions. This approach facilitates
the characterization and analysis of large multivariate time series datasets
through network analysis techniques.",2023-11-20,"Vanessa Freitas Silva, Maria Eduarda Silva, Pedro Ribeiro, Fernando Silva"
"A causal intervention framework for synthesizing mobility data and
  evaluating predictive neural networks","Deep neural networks are increasingly utilized in mobility prediction tasks,
yet their intricate internal workings pose challenges for interpretability,
especially in comprehending how various aspects of mobility behavior affect
predictions. This study introduces a causal intervention framework to assess
the impact of mobility-related factors on neural networks designed for next
location prediction -- a task focusing on predicting the immediate next
location of an individual. To achieve this, we employ individual mobility
models to synthesize location visit sequences and control behavior dynamics by
intervening in their data generation process. We evaluate the interventional
location sequences using mobility metrics and input them into well-trained
networks to analyze performance variations. The results demonstrate the
effectiveness in producing location sequences with distinct mobility behaviors,
thereby facilitating the simulation of diverse yet realistic spatial and
temporal changes. These changes result in performance fluctuations in next
location prediction networks, revealing impacts of critical mobility behavior
factors, including sequential patterns in location transitions, proclivity for
exploring new locations, and preferences in location choices at population and
individual levels. The gained insights hold value for the real-world
application of mobility prediction networks, and the framework is expected to
promote the use of causal inference to enhance the interpretability and
robustness of neural networks in mobility applications.",2023-11-20,"Ye Hong, Yanan Xin, Simon Dirmeier, Fernando Perez-Cruz, Martin Raubal"
Self-Supervised Pretraining for Heterogeneous Hypergraph Neural Networks,"Recently, pretraining methods for the Graph Neural Networks (GNNs) have been
successful at learning effective representations from unlabeled graph data.
However, most of these methods rely on pairwise relations in the graph and do
not capture the underling higher-order relations between entities. Hypergraphs
are versatile and expressive structures that can effectively model higher-order
relationships among entities in the data. Despite the efforts to adapt GNNs to
hypergraphs (HyperGNN), there are currently no fully self-supervised
pretraining methods for HyperGNN on heterogeneous hypergraphs. In this paper,
we present SPHH, a novel self-supervised pretraining framework for
heterogeneous HyperGNNs. Our method is able to effectively capture higher-order
relations among entities in the data in a self-supervised manner. SPHH is
consist of two self-supervised pretraining tasks that aim to simultaneously
learn both local and global representations of the entities in the hypergraph
by using informative representations derived from the hypergraph structure.
Overall, our work presents a significant advancement in the field of
self-supervised pretraining of HyperGNNs, and has the potential to improve the
performance of various graph-based downstream tasks such as node classification
and link prediction tasks which are mapped to hypergraph configuration. Our
experiments on two real-world benchmarks using four different HyperGNN models
show that our proposed SPHH framework consistently outperforms state-of-the-art
baselines in various downstream tasks. The results demonstrate that SPHH is
able to improve the performance of various HyperGNN models in various
downstream tasks, regardless of their architecture or complexity, which
highlights the robustness of our framework.",2023-11-19,"Abdalgader Abubaker, Takanori Maehara, Madhav Nimishakavi, Vassilis Plachouras"
"Individual misinformation tagging reinforces echo chambers; Collective
  tagging does not","Fears about the destabilizing impact of misinformation online have motivated
individuals and platforms to respond. Individuals have become empowered to
challenge others' online claims with fact-checks in pursuit of a healthier
information ecosystem and to break down echo chambers of self-reinforcing
opinion. Using Twitter data, here we show the consequences of individual
misinformation tagging: tagged posters had explored novel political information
and expanded topical interests immediately prior, but being tagged caused
posters to retreat into information bubbles. These unintended consequences were
softened by a collective verification system for misinformation moderation. In
Twitter's new platform, Community Notes, misinformation tagging was
peer-reviewed by other fact-checkers before exposure to the poster. With
collective misinformation tagging, posters were less likely to retreat from
diverse information engagement. Detailed comparison suggests differences in
toxicity, sentiment, readability, and delay in individual versus collective
misinformation tagging messages. These findings provide evidence for
differential impacts from individual versus collective moderation strategies on
the diversity of information engagement and mobility across the information
ecosystem.",2023-11-19,"Junsol Kim, Zhao Wang, Haohan Shi, Hsin-Keng Ling, James Evans"
Link Streams as a Generalization of Graphs and Time Series,"A link stream is a set of possibly weighted triplets (t, u, v) modeling that
u and v interacted at time t. Link streams offer an effective model for
datasets containing both temporal and relational information, making their
proper analysis crucial in many applications. They are commonly regarded as
sequences of graphs or collections of time series. Yet, a recent seminal work
demonstrated that link streams are more general objects of which graphs are
only particular cases. It therefore started the construction of a dedicated
formalism for link streams by extending graph theory. In this work, we
contribute to the development of this formalism by showing that link streams
also generalize time series. In particular, we show that a link stream
corresponds to a time-series extended to a relational dimension, which opens
the door to also extend the framework of signal processing to link streams. We
therefore develop extensions of numerous signal concepts to link streams: from
elementary ones like energy, correlation, and differentiation, to more advanced
ones like Fourier transform and filters.",2023-11-19,"Esteban Bautista, Matthieu Latapy"
Contextualizing Internet Memes Across Social Media Platforms,"Internet memes have emerged as a novel format for communication and
expressing ideas on the web. Their fluidity and creative nature are reflected
in their widespread use, often across platforms and occasionally for unethical
or harmful purposes. While computational work has already analyzed their
high-level virality over time and developed specialized classifiers for hate
speech detection, there have been no efforts to date that aim to holistically
track, identify, and map internet memes posted on social media. To bridge this
gap, we investigate whether internet memes across social media platforms can be
contextualized by using a semantic repository of knowledge, namely, a knowledge
graph. We collect thousands of potential internet meme posts from two social
media platforms, namely Reddit and Discord, and develop an
extract-transform-load procedure to create a data lake with candidate meme
posts. By using vision transformer-based similarity, we match these candidates
against the memes cataloged in IMKG -- a recently released knowledge graph of
internet memes. We leverage this grounding to highlight the potential of our
proposed framework to study the prevalence of memes on different platforms, map
them to IMKG, and provide context about memes on social media.",2023-11-18,"Saurav Joshi, Filip Ilievski, Luca Luceri"
Scalable Edge Clustering of Dynamic Graphs via Weighted Line Graphs,"Timestamped relational datasets consisting of records between pairs of
entities are ubiquitous in data and network science. For applications like
peer-to-peer communication, email, social network interactions, and computer
network security, it makes sense to organize these records into groups based on
how and when they are occurring. Weighted line graphs offer a natural way to
model how records are related in such datasets but for large real-world graph
topologies the complexity of building and utilizing the line graph is
prohibitive. We present an algorithm to cluster the edges of a dynamic graph
via the associated line graph without forming it explicitly.
  We outline a novel hierarchical dynamic graph edge clustering approach that
efficiently breaks massive relational datasets into small sets of edges
containing events at various timescales. This is in stark contrast to
traditional graph clustering algorithms that prioritize highly connected
community structures. Our approach relies on constructing a sufficient subgraph
of a weighted line graph and applying a hierarchical agglomerative clustering.
This work draws particular inspiration from HDBSCAN.
  We present a parallel algorithm and show that it is able to break
billion-scale dynamic graphs into small sets that correlate in topology and
time. The entire clustering process for a graph with $O(10 \text{ billion})$
edges takes just a few minutes of run time on 256 nodes of a distributed
compute environment. We argue how the output of the edge clustering is useful
for a multitude of data visualization and powerful machine learning tasks, both
involving the original massive dynamic graph data and/or the non-relational
metadata. Finally, we demonstrate its use on a real-world large-scale directed
dynamic graph and describe how it can be extended to dynamic hypergraphs and
graphs with unstructured data living on vertices and edges.",2023-11-17,"Michael Ostroski, Geoffrey Sanders, Trevor Steil, Roger Pearce"
Multiscale Hodge Scattering Networks for Data Analysis,"We propose new scattering networks for signals measured on simplicial
complexes, which we call \emph{Multiscale Hodge Scattering Networks} (MHSNs).
Our construction is based on multiscale basis dictionaries on simplicial
complexes, i.e., the $\kappa$-GHWT and $\kappa$-HGLET, which we recently
developed for simplices of dimension $\kappa \in \mathbb{N}$ in a given
simplicial complex by generalizing the node-based Generalized Haar-Walsh
Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The
$\kappa$-GHWT and the $\kappa$-HGLET both form redundant sets (i.e.,
dictionaries) of multiscale basis vectors and the corresponding expansion
coefficients of a given signal. Our MHSNs use a layered structure analogous to
a convolutional neural network (CNN) to cascade the moments of the modulus of
the dictionary coefficients. The resulting features are invariant to reordering
of the simplices (i.e., node permutation of the underlying graphs).
Importantly, the use of multiscale basis dictionaries in our MHSNs admits a
natural pooling operation that is akin to local pooling in CNNs, and which may
be performed either locally or per-scale. These pooling operations are harder
to define in both traditional scattering networks based on Morlet wavelets, and
geometric scattering networks based on Diffusion Wavelets. As a result, we are
able to extract a rich set of descriptive yet robust features that can be used
along with very simple machine learning methods (i.e., logistic regression or
support vector machines) to achieve high-accuracy classification systems with
far fewer parameters to train than most modern graph neural networks. Finally,
we demonstrate the usefulness of our MHSNs in three distinct types of problems:
signal classification, domain (i.e., graph/simplex) classification, and
molecular dynamics prediction.",2023-11-17,"Naoki Saito, Stefan C. Schonsheck, Eugene Shvarts"
"igraph enables fast and robust network analysis across programming
  languages","Networks or graphs are widely used across the sciences to represent
relationships of many kinds. igraph (https://igraph.org) is a general-purpose
software library for graph construction, analysis, and visualisation, combining
fast and robust performance with a low entry barrier. igraph pairs a fast core
written in C with beginner-friendly interfaces in Python, R, and Mathematica.
Over the last two decades, igraph has expanded substantially. It now scales to
billions of edges, supports Mathematica and interactive plotting, integrates
with Jupyter notebooks and other network libraries, includes new graph layouts
and community detection algorithms, and has streamlined the documentation with
examples and Spanish translations. Modern testing features such as continuous
integration, address sanitizers, stricter typing, and memory-managed vectors
have also increased robustness. Hundreds of bug reports have been fixed and a
community forum has been opened to connect users and developers. Specific
effort has been made to broaden use and community participation by women,
non-binary people, and other demographic groups typically underrepresented in
open source software.",2023-11-17,"Michael Antonov, Gábor Csárdi, Szabolcs Horvát, Kirill Müller, Tamás Nepusz, Daniel Noom, Maëlle Salmon, Vincent Traag, Brooke Foucault Welles, Fabio Zanini"
Measuring Moral Dimensions in Social Media with Mformer,"The ever-growing textual records of contemporary social issues, often
discussed online with moral rhetoric, present both an opportunity and a
challenge for studying how moral concerns are debated in real life. Moral
foundations theory is a taxonomy of intuitions widely used in data-driven
analyses of online content, but current computational tools to detect moral
foundations suffer from the incompleteness and fragility of their lexicons and
from poor generalization across data domains. In this paper, we fine-tune a
large language model to measure moral foundations in text based on datasets
covering news media and long- and short-form online discussions. The resulting
model, called Mformer, outperforms existing approaches on the same domains by
4--12% in AUC and further generalizes well to four commonly used moral text
datasets, improving by up to 17% in AUC. We present case studies using Mformer
to analyze everyday moral dilemmas on Reddit and controversies on Twitter,
showing that moral foundations can meaningfully describe people's stance on
social issues and such variations are topic-dependent. Pre-trained model and
datasets are released publicly. We posit that Mformer will help the research
community quantify moral dimensions for a range of tasks and data domains, and
eventually contribute to the understanding of moral situations faced by humans
and machines.",2023-11-16,"Tuan Dung Nguyen, Ziyu Chen, Nicholas George Carroll, Alasdair Tran, Colin Klein, Lexing Xie"
"Decoding Susceptibility: Modeling Misbelief to Misinformation Through a
  Computational Approach","Susceptibility to misinformation describes the degree of belief in
unverifiable claims, a latent aspect of individuals' mental processes that is
not observable. Existing susceptibility studies heavily rely on self-reported
beliefs, which can be subject to bias, expensive to collect, and challenging to
scale for downstream applications. To address these limitations, in this work,
we propose a computational approach to model users' latent susceptibility
levels. As shown in previous research, susceptibility is influenced by various
factors (e.g., demographic factors, political ideology), and directly
influences people's reposting behavior on social media. To represent the
underlying mental process, our susceptibility modeling incorporates these
factors as inputs, guided by the supervision of people's sharing behavior.
Using COVID-19 as a testbed domain, our experiments demonstrate a significant
alignment between the susceptibility scores estimated by our computational
modeling and human judgments, confirming the effectiveness of this latent
modeling approach. Furthermore, we apply our model to annotate susceptibility
scores on a large-scale dataset and analyze the relationships between
susceptibility with various factors. Our analysis reveals that political
leanings and psychological factors exhibit varying degrees of association with
susceptibility to COVID-19 misinformation.",2023-11-16,"Yanchen Liu, Mingyu Derek Ma, Wenna Qin, Azure Zhou, Jiaao Chen, Weiyan Shi, Wei Wang, Diyi Yang"
"Generating Drug Repurposing Hypotheses through the Combination of
  Disease-Specific Hypergraphs","The drug development pipeline for a new compound can last 10-20 years and
cost over 10 billion. Drug repurposing offers a more time- and cost-effective
alternative. Computational approaches based on biomedical knowledge graph
representations have recently yielded new drug repurposing hypotheses. In this
study, we present a novel, disease-specific hypergraph representation learning
technique to derive contextual embeddings of biological pathways of various
lengths but that all start at any given drug and all end at the disease of
interest. Further, we extend this method to multi-disease hypergraphs. To
determine the repurposing potential of each of the 1,522 drugs, we derive
drug-specific distributions of cosine similarity values and ultimately consider
the median for ranking. Cosine similarity values are computed between (1) all
biological pathways starting at the considered drug and ending at the disease
of interest and (2) all biological pathways starting at drugs currently
prescribed against that disease and ending at the disease of interest. We
illustrate our approach with Alzheimer's disease (AD) and two of its risk
factors: hypertension (HTN) and type 2 diabetes (T2D). We compare each drug's
rank across four hypergraph settings (single- or multi-disease): AD only, AD +
HTN, AD + T2D, and AD + HTN + T2D. Notably, our framework led to the
identification of two promising drugs whose repurposing potential was
significantly higher in hypergraphs combining two diseases: dapagliflozin
(antidiabetic; moved up, from top 32$\%$ to top 7$\%$, across all considered
drugs) and debrisoquine (antihypertensive; moved up, from top 76$\%$ to top
23$\%$). Our approach serves as a hypothesis generation tool, to be paired with
a validation pipeline relying on laboratory experiments and semi-automated
parsing of the biomedical literature.",2023-11-16,"Ayush Jain, Marie Laure-Charpignon, Irene Y. Chen, Anthony Philippakis, Ahmed Alaa"
"Finding polarised communities and tracking information diffusion on
  Twitter: The Irish Abortion Referendum","The analysis of social networks enables the understanding of social
interactions, polarisation of ideas, and the spread of information and
therefore plays an important role in society. We use Twitter data - as it is a
popular venue for the expression of opinion and dissemination of information -
to identify opposing sides of a debate and, importantly, to observe how
information spreads between these groups in our current polarised climate.
  To achieve this, we collected over 688,000 Tweets from the Irish Abortion
Referendum of 2018 to build a conversation network from users mentions with
sentiment-based homophily. From this network, community detection methods allow
us to isolate yes- or no-aligned supporters with high accuracy (90.9%). We
supplement this by tracking how information cascades spread via over 31,000
retweet-cascades. We found that very little information spread between
polarised communities. This provides a valuable methodology for extracting and
studying information diffusion on large networks by isolating ideologically
polarised groups and exploring the propagation of information within and
between these groups.",2023-11-15,"Caroline Pena, Pádraig MacCarron, David J. P. O'Sullivan"
"FCS-HGNN: Flexible Multi-type Community Search in Heterogeneous
  Information Networks","Community search is a personalized community discovery problem designed to
identify densely connected subgraphs containing the query node. Recently,
community search in heterogeneous information networks (HINs) has received
considerable attention. Existing methods typically focus on modeling
relationships in HINs through predefined meta-paths or user-specified
relational constraints. However, metapath-based methods are primarily designed
to identify single-type communities with nodes of the same type rather than
multi-type communities involving nodes of different types. Constraint-based
methods require users to have a good understanding of community patterns to
define a suitable set of relational constraints, which increases the burden on
users. In this paper, we propose FCS-HGNN, a novel method for flexibly
identifying both single-type and multi-type communities in HINs. Specifically,
FCS-HGNN extracts complementary information from different views and
dynamically considers the contribution of each relation instead of treating
them equally, thereby capturing more fine-grained heterogeneous information.
Furthermore, to improve efficiency on large-scale graphs, we further propose
LS-FCS-HGNN, which incorporates i) the neighbor sampling strategy to improve
training efficiency, and ii) the depth-based heuristic search strategy to
improve query efficiency. We conducted extensive experiments to demonstrate the
superiority of our proposed methods over state-of-the-art methods, achieving
average improvements of 14.3% and 11.1% on single-type and multi-type
communities, respectively.",2023-11-15,"Guoxin Chen, Fangda Guo, Yongqing Wang, Yanghao Liu, Peiying Yu, Huawei Shen, Xueqi Cheng"
"How international research teams respond to disruption in their mobility
  patterns","Combining social network analysis with personal interviews, the paper
examines how the social structure and internal composition of three
Africa-focused international research networks contributes to their resilience.
It shows that research networks are structured around a small number of highly
influential coordinators. This structure facilitates information exchange and
trust between countries and across fields. The study also suggests that the
surveyed teams tend to exchange information or trust each other irrespective of
their social and professional attributes, indicating that diversity is key to
understanding their responses to major shocks such as the COVID-19 pandemic. In
a second part, the paper analyzes how the spatial constraints imposed by
distance and borders affect their ability to function internationally. It shows
that the probability of exchanging information, trusting each other, and
co-publishing decreases considerably with distance and that research
communities are more likely formed inside the same country than
internationally. Interviews reveal that teams responded to travel bans and
border closure by emphasizing what they already did best, suggesting that
resilience should be considered as an evolutionary attribute of a system.",2023-11-14,"Olivier J. Walther, Rafael Prieto-Curiel, Erica Odera"
A Simple and Powerful Framework for Stable Dynamic Network Embedding,"In this paper, we address the problem of dynamic network embedding, that is,
representing the nodes of a dynamic network as evolving vectors within a
low-dimensional space. While the field of static network embedding is wide and
established, the field of dynamic network embedding is comparatively in its
infancy. We propose that a wide class of established static network embedding
methods can be used to produce interpretable and powerful dynamic network
embeddings when they are applied to the dilated unfolded adjacency matrix. We
provide a theoretical guarantee that, regardless of embedding dimension, these
unfolded methods will produce stable embeddings, meaning that nodes with
identical latent behaviour will be exchangeable, regardless of their position
in time or space. We additionally define a hypothesis testing framework which
can be used to evaluate the quality of a dynamic network embedding by testing
for planted structure in simulated networks. Using this, we demonstrate that,
even in trivial cases, unstable methods are often either conservative or encode
incorrect structure. In contrast, we demonstrate that our suite of stable
unfolded methods are not only more interpretable but also more powerful in
comparison to their unstable counterparts.",2023-11-14,"Ed Davis, Ian Gallagher, Daniel John Lawson, Patrick Rubin-Delanchy"
"Leveraging Large Language Models to Detect Influence Campaigns in Social
  Media","Social media influence campaigns pose significant challenges to public
discourse and democracy. Traditional detection methods fall short due to the
complexity and dynamic nature of social media. Addressing this, we propose a
novel detection method using Large Language Models (LLMs) that incorporates
both user metadata and network structures. By converting these elements into a
text format, our approach effectively processes multilingual content and adapts
to the shifting tactics of malicious campaign actors. We validate our model
through rigorous testing on multiple datasets, showcasing its superior
performance in identifying influence efforts. This research not only offers a
powerful tool for detecting campaigns, but also sets the stage for future
enhancements to keep up with the fast-paced evolution of social media-based
influence tactics.",2023-11-14,"Luca Luceri, Eric Boniardi, Emilio Ferrara"
Multi-agent Attacks for Black-box Social Recommendations,"The rise of online social networks has facilitated the evolution of social
recommender systems, which incorporate social relations to enhance users'
decision-making process. With the great success of Graph Neural Networks (GNNs)
in learning node representations, GNN-based social recommendations have been
widely studied to model user-item interactions and user-user social relations
simultaneously. Despite their great successes, recent studies have shown that
these advanced recommender systems are highly vulnerable to adversarial
attacks, in which attackers can inject well-designed fake user profiles to
disrupt recommendation performances. While most existing studies mainly focus
on argeted attacks to promote target items on vanilla recommender systems,
untargeted attacks to degrade the overall prediction performance are less
explored on social recommendations under a black-box scenario. To perform
untargeted attacks on social recommender systems, attackers can construct
malicious social relationships for fake users to enhance the attack
performance. However, the coordination of social relations and item profiles is
challenging for attacking black-box social recommendations. To address this
limitation, we first conduct several preliminary studies to demonstrate the
effectiveness of cross-community connections and cold-start items in degrading
recommendations performance. Specifically, we propose a novel framework
MultiAttack based on multi-agent reinforcement learning to coordinate the
generation of cold-start item profiles and cross-community social relations for
conducting untargeted attacks on black-box social recommendations.
Comprehensive experiments on various real-world datasets demonstrate the
effectiveness of our proposed attacking framework under the black-box setting.",2023-11-13,"Shijie Wang, Wenqi Fan, Xiao-yong Wei, Xiaowei Mei, Shanru Lin, Qing Li"
Open-Set Graph Anomaly Detection via Normal Structure Regularisation,"This paper considers an important Graph Anomaly Detection (GAD) task, namely
open-set GAD, which aims to train a detection model using a small number of
normal and anomaly nodes (referred to as seen anomalies) to detect both seen
anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the
training anomalies). Those labelled training data provide crucial prior
knowledge about abnormalities for GAD models, enabling substantially reduced
detection errors. However, current supervised GAD methods tend to
over-emphasise fitting the seen anomalies, leading to many errors of detecting
the unseen anomalies as normal nodes. Further, existing open-set AD models were
introduced to handle Euclidean data, failing to effectively capture
discriminative features from graph structure and node attributes for GAD. In
this work, we propose a novel open-set GAD approach, namely normal structure
regularisation (NSReg), to achieve generalised detection ability to unseen
anomalies, while maintaining its effectiveness on detecting seen anomalies. The
key idea in NSReg is to introduce a regularisation term that enforces the
learning of compact, semantically-rich representations of normal nodes based on
their structural relations to other nodes. When being optimised with supervised
anomaly detection losses, the regularisation term helps incorporate strong
normality into the modelling, and thus, it effectively avoids over-fitting the
seen anomalies and learns a better normality decision boundary, largely
reducing the false negatives of detecting unseen anomalies as normal. Extensive
empirical results on seven real-world datasets show that NSReg significantly
outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the
unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.",2023-11-12,"Qizhou Wang, Guansong Pang, Mahsa Salehi, Xiaokun Xia, Christopher Leckie"
"Privacy-Preserving Individual-Level COVID-19 Infection Prediction via
  Federated Graph Learning","Accurately predicting individual-level infection state is of great value
since its essential role in reducing the damage of the epidemic. However, there
exists an inescapable risk of privacy leakage in the fine-grained user mobility
trajectories required by individual-level infection prediction. In this paper,
we focus on developing a framework of privacy-preserving individual-level
infection prediction based on federated learning (FL) and graph neural networks
(GNN). We propose Falcon, a Federated grAph Learning method for
privacy-preserving individual-level infeCtion predictiON. It utilizes a novel
hypergraph structure with spatio-temporal hyperedges to describe the complex
interactions between individuals and locations in the contagion process. By
organically combining the FL framework with hypergraph neural networks, the
information propagation process of the graph machine learning is able to be
divided into two stages distributed on the server and the clients,
respectively, so as to effectively protect user privacy while transmitting
high-level information. Furthermore, it elaborately designs a differential
privacy perturbation mechanism as well as a plausible pseudo location
generation approach to preserve user privacy in the graph structure. Besides,
it introduces a cooperative coupling mechanism between the individual-level
prediction model and an additional region-level model to mitigate the
detrimental impacts caused by the injected obfuscation mechanisms. Extensive
experimental results show that our methodology outperforms state-of-the-art
algorithms and is able to protect user privacy against actual privacy attacks.
Our code and datasets are available at the link:
https://github.com/wjfu99/FL-epidemic.",2023-11-10,"Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang"
Recurrent Dynamic Message Passing with Loops for Epidemics on Networks,"Several theoretical methods have been developed to approximate prevalence and
threshold of epidemics on networks. Among them, the recurrent dynamic
message-passing (rDMP) theory offers a state-of-the-art performance by
preventing the echo chamber effect in network edges. However, the rDMP theory
was derived in an intuitive ad-hoc way, lacking a solid theoretical foundation
and resulting in a probabilistic inconsistency flaw. Furthermore, real-world
networks are clustered and full of local loops like triangles, whereas rDMP is
based on the assumption of a locally tree-like network structure, which makes
rDMP potentially inefficient on real applications. In this work, for the
recurrent-state epidemics, we first demonstrate that the echo chamber effect
exits not only in edges but also in local loops, which rDMP-like method can not
avoid. We then correct the deficiency of rDMP in a principled manner, leading
to the natural introduction of new higher-order dynamic messages, extending
rDMP to handle local loops. By linearizing the extended message-passing
equations, a new epidemic threshold estimation is given by the inverse of the
leading eigenvalue of a matrix named triangular non-backtracking matrix.
Numerical experiments conducted on synthetic and real-world networks to
evaluate our method, the efficacy of which is validated in epidemic prevalence
and threshold prediction tasks. In addition, our method has the potential to
speed up the solution of the immunization, influence maximization, and
robustness optimization problems in the networks.",2023-11-10,"Fei Gao, Jing Liu, Yaqian Zhao"
"HyperS2V: A Framework for Structural Representation of Nodes in Hyper
  Networks","In contrast to regular (simple) networks, hyper networks possess the ability
to depict more complex relationships among nodes and store extensive
information. Such networks are commonly found in real-world applications, such
as in social interactions. Learning embedded representations for nodes involves
a process that translates network structures into more simplified spaces,
thereby enabling the application of machine learning approaches designed for
vector data to be extended to network data. Nevertheless, there remains a need
to delve into methods for learning embedded representations that prioritize
structural aspects. This research introduces HyperS2V, a node embedding
approach that centers on the structural similarity within hyper networks.
Initially, we establish the concept of hyper-degrees to capture the structural
properties of nodes within hyper networks. Subsequently, a novel function is
formulated to measure the structural similarity between different hyper-degree
values. Lastly, we generate structural embeddings utilizing a multi-scale
random walk framework. Moreover, a series of experiments, both intrinsic and
extrinsic, are performed on both toy and real networks. The results underscore
the superior performance of HyperS2V in terms of both interpretability and
applicability to downstream tasks.",2023-11-07,"Shu Liu, Cameron Lai, Fujio Toriumi"
Simple Bundles of Complex Networks,"Complex networks can be used to represent and model an ample diversity of
abstract and real-world systems and structures. A good deal of the research on
these structures has focused on specific topological properties, including node
degree, shortest paths, and modularity. In the present work, we develop an
approach aimed at identifying and characterizing simple bundles of
interconnections between pairs of nodes (source and destination) in complex
networks. More specifically, simple bundles can be understood as corresponding
to the bundle of paths obtained while traveling through successive
neighborhoods after departing from a given source node. Because no node appears
more than once along a given bundle, these structures have been said to be
simple, in analogy to the concept of a simple path. In addition to describing
simple bundles and providing a possible methodology for their identification,
we also consider how their respective effective width can be estimated in terms
of diffusion flow and exponential entropy of transition probabilities. The
potential of the concepts and methods described in this work is then
illustrated respectively to the characterization and analysis of
model-theoretic networks, with several interesting results.",2023-11-07,"Alexandre Benatti, Luciano da F. Costa"
TempoGRAPHer: Aggregation Based Temporal Graph Exploration,"Graphs offer a generic abstraction for modeling entities, and the
interactions and relationships between them. Most real world graphs, such as
social and cooperation networks evolve over time, and exploring their evolution
may reveal important information. In this paper, we present TempoGRAPHer, a
system for visualizing and analyzing the evolution of a temporal attributed
graph. TempoGRAPHer supports both temporal and attribute aggregation. It also
allows graph exploration by identifying periods of significant growth,
shrinkage, or stability. Temporal exploration is supported by two complementary
strategies, namely skyline and interaction-based exploration. Skyline-based
exploration provides insights on the overall trends in the evolution, while
interaction-based exploration offers a closer look at specific parts of the
graph evolution history where significant changes appeared. We showcase the
usefulness of TempoGRAPHer in understanding graph evolution by presenting a
detailed scenario that explores the evolution of a contact network between
primary school students.",2023-11-07,"Evangelia Tsoukanara, Georgia Koloniari, Evaggelia Pitoura"
Incentive Design for Eco-driving in Urban Transportation Networks,"Eco-driving emerges as a cost-effective and efficient strategy to mitigate
greenhouse gas emissions in urban transportation networks. Acknowledging the
persuasive influence of incentives in shaping driver behavior, this paper
presents the `eco-planner,' a digital platform devised to promote eco-driving
practices in urban transportation. At the outset of their trips, users provide
the platform with their trip details and travel time preferences, enabling the
eco-planner to formulate personalized eco-driving recommendations and
corresponding incentives, while adhering to its budgetary constraints. Upon
trip completion, incentives are transferred to users who comply with the
recommendations and effectively reduce their emissions. By comparing our
proposed incentive mechanism with a baseline scheme that offers uniform
incentives to all users, we demonstrate that our approach achieves superior
emission reductions and increased user compliance with a smaller budget.",2023-11-07,"M. Umar B. Niazi, Jung-Hoon Cho, Munther A. Dahleh, Roy Dong, Cathy Wu"
"Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for
  Propaganda and Disinformation Detection","The spread of disinformation and propagandistic content poses a threat to
societal harmony, undermining informed decision-making and trust in reliable
sources. Online platforms often serve as breeding grounds for such content, and
malicious actors exploit the vulnerabilities of audiences to shape public
opinion. Although there have been research efforts aimed at the automatic
identification of disinformation and propaganda in social media content, there
remain challenges in terms of performance. The ArAIEval shared task aims to
further research on these particular issues within the context of the Arabic
language. In this paper, we discuss our participation in these shared tasks. We
competed in subtasks 1A and 2A, where our submitted system secured positions
9th and 10th, respectively. Our experiments consist of fine-tuning transformer
models and using zero- and few-shot learning with GPT-4.",2023-11-06,"Yunze Xiao, Firoj Alam"
"Detection Method for Social Subsets Consisting of Anti-Network
  Construction for Unilateral Preference Behavior on Directed Temporal Networks","In existing research, as an example of one-sided preference, a conversation
structure in which a person who is assumed to be an adult mainly sends
one-sided messages to a person who is assumed to be a minor was observed. If
subgraphs composed based on such unilateral preferences could be automatically
extracted from the network structure, it would be possible to automatically
detect communication conducted based on specific motivations from a vast amount
of conversation data. In this study, we construct a bottom-up method to detect
subgraphs composed of unilateral preferences in Greedy, and discuss the subset
of unilateral preferences detected in this simulation. (This paper is partially
an attempt to utilize ""Generative AI"" and was written with educational intent.
There are currently no plans for it to become a peer-reviewed paper.)",2023-11-05,Yasuko Kawahata
"Extracting Network Structures from Corporate Organization Charts Using
  Heuristic Image Processing","Organizational structure of corporations has potential to provide
implications for dynamics and performance of corporate operations. However,
this subject has remained unexplored because of the lack of readily available
organization network datasets. To overcome the this gap, we developed a new
heuristic image-processing method to extract and reconstruct organization
network data from published organization charts. Our method analyzes a PDF file
of a corporate organization chart and detects text labels, boxes, connecting
lines, and other objects through multiple steps of heuristically implemented
image processing. The detected components are reorganized together into a
Python's NetworkX Graph object for visualization, validation and further
network analysis. We applied the developed method to the organization charts of
all the listed firms in Japan shown in the ``Organization Chart/System Diagram
Handbook'' published by Diamond, Inc., from 2008 to 2011. Out of the 10,008
organization chart PDF files, our method was able to reconstruct 4,606
organization networks (data acquisition success rate: 46%). For each
reconstructed organization network, we measured several network diagnostics,
which will be used for further statistical analysis to investigate their
potential correlations with corporate behavior and performance.",2023-11-04,"Hiroki Sayama, Junichi Yamanoi"
"Sample Complexity of Opinion Formation on Networks with Linear
  Regression Models","Consider public health officials aiming to spread awareness about a new
vaccine in a community interconnected by a social network. How can they
distribute information with minimal resources, so as to avoid polarization and
ensure community-wide convergence of opinion? To tackle such challenges, we
initiate the study of sample complexity of opinion convergence in networks. Our
framework is built on the recognized opinion formation game, where we regard
the opinion of each agent as a data-derived model, unlike previous works that
treat opinions as data-independent scalars. The opinion model for every agent
is initially learned from its local samples and evolves game-theoretically as
all agents communicate with neighbors and revise their models towards an
equilibrium. Our focus is on the sample complexity needed to ensure that the
opinions converge to an equilibrium such that the final model of every agent
has low generalization error.
  Our paper has two main technical results. First, we present a novel
polynomial time optimization framework to quantify the total sample complexity
for arbitrary networks, when the underlying learning problem is (generalized)
linear regression. Second, we leverage this optimization to study the network
gain which measures the improvement of sample complexity when learning over a
network compared to that in isolation. Towards this end, we derive network gain
bounds for various network classes including cliques, star graphs, and random
regular graphs. Additionally, our framework provides a method to study sample
distribution within the network, suggesting that it is sufficient to allocate
samples inversely to the degree. Empirical results on both synthetic and
real-world networks strongly support our theoretical findings.",2023-11-04,"Haolin Liu, Rajmohan Rajaraman, Ravi Sundaram, Anil Vullikanti, Omer Wasim, Haifeng Xu"
Leveraging Large Language Models for Collective Decision-Making,"In various work contexts, such as meeting scheduling, collaborating, and
project planning, collective decision-making is essential but often challenging
due to diverse individual preferences, varying work focuses, and power dynamics
among members. To address this, we propose a system leveraging Large Language
Models (LLMs) to facilitate group decision-making by managing conversations and
balancing preferences among individuals. Our system aims to extract individual
preferences from conversations and suggest options that satisfy the preferences
of the members. We specifically apply this system to corporate meeting
scheduling. We create synthetic employee profiles and simulate conversations at
scale, leveraging LLMs to evaluate the system performance as a novel approach
to conducting a user study. Our results indicate efficient coordination with
reduced interactions between the members and the LLM-based system. The system
refines and improves its proposed options over time, ensuring that many of the
members' individual preferences are satisfied in an equitable way. Finally, we
conduct a survey study involving human participants to assess our system's
ability to aggregate preferences and reasoning about them. Our findings show
that the system exhibits strong performance in both dimensions.",2023-11-03,"Marios Papachristou, Longqi Yang, Chin-Chia Hsu"
Spectral Clustering of Attributed Multi-relational Graphs,"Graph clustering aims at discovering a natural grouping of the nodes such
that similar nodes are assigned to a common cluster. Many different algorithms
have been proposed in the literature: for simple graphs, for graphs with
attributes associated to nodes, and for graphs where edges represent different
types of relations among nodes. However, complex data in many domains can be
represented as both attributed and multi-relational networks.
  In this paper, we propose SpectralMix, a joint dimensionality reduction
technique for multi-relational graphs with categorical node attributes.
SpectralMix integrates all information available from the attributes, the
different types of relations, and the graph structure to enable a sound
interpretation of the clustering results. Moreover, it generalizes existing
techniques: it reduces to spectral embedding and clustering when only applied
to a single graph and to homogeneity analysis when applied to categorical data.
Experiments conducted on several real-world datasets enable us to detect
dependencies between graph structure and categorical attributes, moreover, they
exhibit the superiority of SpectralMix over existing methods.",2023-11-03,"Ylli Sadikaj, Yllka Velaj, Sahar Behzadi, Claudia Plant"
Similarity network aggregation for the analysis of glacier ecosystems,"The synthesis of information deriving from complex networks is a topic
receiving increasing relevance in ecology and environmental sciences. In
particular, the aggregation of multilayer networks, i.e. network structures
formed by multiple interacting networks (the layers), constitutes a
fast-growing field. In several environmental applications, the layers of a
multilayer network are modelled as a collection of similarity matrices
describing how similar pairs of biological entities are, based on different
types of features (e.g. biological traits). The present paper first discusses
two main techniques for combining the multi-layered information into a single
network (the so-called monoplex), i.e. Similarity Network Fusion (SNF) and
Similarity Matrix Average (SMA). Then, the effectiveness of the two methods is
tested on a real-world dataset of the relative abundance of microbial species
in the ecosystems of nine glaciers (four glaciers in the Alps and five in the
Andes). A preliminary clustering analysis on the monoplexes obtained with
different methods shows the emergence of a tightly connected community formed
by species that are typical of cryoconite holes worldwide. Moreover, the
weights assigned to different layers by the SMA algorithm suggest that two
large South American glaciers (Exploradores and Perito Moreno) are structurally
different from the smaller glaciers in both Europe and South America. Overall,
these results highlight the importance of integration methods in the discovery
of the underlying organizational structure of biological entities in multilayer
ecological networks.",2023-11-03,"Roberto Ambrosini, Federica Baccini, Lucio Barabesi"
CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model,"The social graphs synthesized by the generative models are increasingly in
demand due to data scarcity and concerns over user privacy. One of the key
performance criteria for generating social networks is the fidelity to
specified conditionals, such as users with certain membership and financial
status. While recent diffusion models have shown remarkable performance in
generating images, their effectiveness in synthesizing graphs has not yet been
explored in the context of conditional social graphs. In this paper, we propose
the first kind of conditional diffusion model for social networks, CDGraph,
which trains and synthesizes graphs based on two specified conditions. We
propose the co-evolution dependency in the denoising process of CDGraph to
capture the mutual dependencies between the dual conditions and further
incorporate social homophily and social contagion to preserve the connectivity
between nodes while satisfying the specified conditions. Moreover, we introduce
a novel classifier loss, which guides the training of the diffusion process
through the mutual dependency of dual conditions. We evaluate CDGraph against
four existing graph generative methods, i.e., SPECTRE, GSM, EDGE, and DiGress,
on four datasets. Our results show that the generated graphs from CDGraph
achieve much higher dual-conditional validity and lower discrepancy in various
social network metrics than the baselines, thus demonstrating its proficiency
in generating dual-conditional social graphs.",2023-11-03,"Jui-Yi Tsai, Ya-Wen Teng, Ho Chiok Yew, De-Nian Yang, Lydia Y. Chen"
Cooperative Network Learning for Large-Scale and Decentralized Graphs,"Graph research, the systematic study of interconnected data points
represented as graphs, plays a vital role in capturing intricate relationships
within networked systems. However, in the real world, as graphs scale up,
concerns about data security among different data-owning agencies arise,
hindering information sharing and, ultimately, the utilization of graph data.
Therefore, establishing a mutual trust mechanism among graph agencies is
crucial for unlocking the full potential of graphs. Here, we introduce a
Cooperative Network Learning (CNL) framework to ensure secure graph computing
for various graph tasks. Essentially, this CNL framework unifies the local and
global perspectives of GNN computing with distributed data for an agency by
virtually connecting all participating agencies as a global graph without a
fixed central coordinator. Inter-agency computing is protected by various
technologies inherent in our framework, including homomorphic encryption and
secure transmission. Moreover, each agency has a fair right to design or employ
various graph learning models from its local or global perspective. Thus, CNL
can collaboratively train GNN models based on decentralized graphs inferred
from local and global graphs. Experiments on contagion dynamics prediction and
traditional graph tasks (i.e., node classification and link prediction)
demonstrate that our CNL architecture outperforms state-of-the-art GNNs
developed at individual sites, revealing that CNL can provide a reliable, fair,
secure, privacy-preserving, and global perspective to build effective and
personalized models for network applications. We hope this framework will
address privacy concerns in graph-related research and integrate decentralized
graph data structures to benefit the network research community in cooperation
and innovation.",2023-11-03,"Qiang Wu, Yiming Huang, Yujie Zeng, Yijie Teng, Fang Zhou, Linyuan Lü"
"Better with Less: A Data-Active Perspective on Pre-Training Graph Neural
  Networks","Pre-training on graph neural networks (GNNs) aims to learn transferable
knowledge for downstream tasks with unlabeled data, and it has recently become
an active research area. The success of graph pre-training models is often
attributed to the massive amount of input data. In this paper, however, we
identify the curse of big data phenomenon in graph pre-training: more training
data do not necessarily lead to better downstream performance. Motivated by
this observation, we propose a better-with-less framework for graph
pre-training: fewer, but carefully chosen data are fed into a GNN model to
enhance pre-training. The proposed pre-training pipeline is called the
data-active graph pre-training (APT) framework, and is composed of a graph
selector and a pre-training model. The graph selector chooses the most
representative and instructive data points based on the inherent properties of
graphs as well as predictive uncertainty. The proposed predictive uncertainty,
as feedback from the pre-training model, measures the confidence level of the
model in the data. When fed with the chosen data, on the other hand, the
pre-training model grasps an initial understanding of the new, unseen data, and
at the same time attempts to remember the knowledge learned from previous data.
Therefore, the integration and interaction between these two components form a
unified framework (APT), in which graph pre-training is performed in a
progressive and iterative way. Experiment results show that the proposed APT is
able to obtain an efficient pre-training model with fewer training data and
better downstream performance.",2023-11-02,"Jiarong Xu, Renhong Huang, Xin Jiang, Yuxuan Cao, Carl Yang, Chunping Wang, Yang Yang"
"Non-Autoregressive Diffusion-based Temporal Point Processes for
  Continuous-Time Long-Term Event Prediction","Continuous-time long-term event prediction plays an important role in many
application scenarios. Most existing works rely on autoregressive frameworks to
predict event sequences, which suffer from error accumulation, thus
compromising prediction quality. Inspired by the success of denoising diffusion
probabilistic models, we propose a diffusion-based non-autoregressive temporal
point process model for long-term event prediction in continuous time. Instead
of generating events one at a time in an autoregressive way, our model predicts
the future event sequence entirely as a whole. In order to perform diffusion
processes on event sequences, we develop a bidirectional map between target
event sequences and the Euclidean vector space. Furthermore, we design a novel
denoising network to capture both sequential and contextual features for better
sample quality. Extensive experiments are conducted to prove the superiority of
our proposed model over state-of-the-art methods on long-term event prediction
in continuous time. To the best of our knowledge, this is the first work to
apply diffusion methods to long-term event prediction problems.",2023-11-02,"Wang-Tao Zhou, Zhao Kang, Ling Tian"
"An Innovative Tool for Uploading/Scraping Large Image Datasets on Social
  Networks","Nowadays, people can retrieve and share digital information in an
increasingly easy and fast fashion through the well-known digital platforms,
including sensitive data, inappropriate or illegal content, and, in general,
information that might serve as probative evidence in court. Consequently, to
assess forensics issues, we need to figure out how to trace back to the posting
chain of a digital evidence (e.g., a picture, an audio) throughout the involved
platforms -- this is what Digital (also Forensics) Ballistics basically deals
with. With the entry of Machine Learning as a tool of the trade in many
research areas, the need for vast amounts of data has been dramatically
increasing over the last few years. However, collecting or simply find the
""right"" datasets that properly enables data-driven research studies can turn
out to be not trivial in some cases, if not extremely challenging, especially
when it comes with highly specialized tasks, such as creating datasets analyzed
to detect the source media platform of a given digital media. In this paper we
propose an automated approach by means of a digital tool that we created on
purpose. The tool is capable of automatically uploading an entire image dataset
to the desired digital platform and then downloading all the uploaded pictures,
thus shortening the overall time required to output the final dataset to be
analyzed.",2023-11-01,"Nicolò Fabio Arceri, Oliver Giudice, Sebastiano Battiato"
"Bayes-enhanced Multi-view Attention Networks for Robust POI
  Recommendation","POI recommendation is practically important to facilitate various
Location-Based Social Network services, and has attracted rising research
attention recently. Existing works generally assume the available POI check-ins
reported by users are the ground-truth depiction of user behaviors. However, in
real application scenarios, the check-in data can be rather unreliable due to
both subjective and objective causes including positioning error and user
privacy concerns, leading to significant negative impacts on the performance of
the POI recommendation. To this end, we investigate a novel problem of robust
POI recommendation by considering the uncertainty factors of the user
check-ins, and proposes a Bayes-enhanced Multi-view Attention Network.
Specifically, we construct personal POI transition graph, the semantic-based
POI graph and distance-based POI graph to comprehensively model the
dependencies among the POIs. As the personal POI transition graph is usually
sparse and sensitive to noise, we design a Bayes-enhanced spatial dependency
learning module for data augmentation from the local view. A Bayesian posterior
guided graph augmentation approach is adopted to generate a new graph with
collaborative signals to increase the data diversity. Then both the original
and the augmented graphs are used for POI representation learning to counteract
the data uncertainty issue. Next, the POI representations of the three view
graphs are input into the proposed multi-view attention-based user preference
learning module. By incorporating the semantic and distance correlations of
POIs, the user preference can be effectively refined and finally robust
recommendation results are achieved. The results of extensive experiments show
that BayMAN significantly outperforms the state-of-the-art methods in POI
recommendation when the available check-ins are incomplete and noisy.",2023-11-01,"Jiangnan Xia, Yu Yang, Senzhang Wang, Hongzhi Yin, Jiannong Cao, Philip S. Yu"
BTRec: BERT-Based Trajectory Recommendation for Personalized Tours,"An essential task for tourists having a pleasant holiday is to have a
well-planned itinerary with relevant recommendations, especially when visiting
unfamiliar cities. Many tour recommendation tools only take into account a
limited number of factors, such as popular Points of Interest (POIs) and
routing constraints. Consequently, the solutions they provide may not always
align with the individual users of the system. We propose an iterative
algorithm in this paper, namely: BTREC (BERT-based Trajectory Recommendation),
that extends from the POIBERT embedding algorithm to recommend personalized
itineraries on POIs using the BERT framework. Our BTREC algorithm incorporates
users' demographic information alongside past POI visits into a modified BERT
language model to recommend a personalized POI itinerary prediction given a
pair of source and destination POIs. Our recommendation system can create a
travel itinerary that maximizes POIs visited, while also taking into account
user preferences for categories of POIs and time availability. Our
recommendation algorithm is largely inspired by the problem of sentence
completion in natural language processing (NLP). Using a dataset of eight
cities of different sizes, our experimental results demonstrate that our
proposed algorithm is stable and outperforms many other sequence prediction
algorithms, measured by recall, precision, and F1-scores.",2023-10-30,"Ngai Lam Ho, Roy Ka-Wei Lee, Kwan Hui Lim"
"A nonlinear spectral core-periphery detection method for multiplex
  networks","Core-periphery detection aims to separate the nodes of a complex network into
two subsets: a core that is densely connected to the entire network and a
periphery that is densely connected to the core but sparsely connected
internally. The definition of core-periphery structure in multiplex networks
that record different types of interactions between the same set of nodes on
different layers is nontrivial since a node may belong to the core in some
layers and to the periphery in others. We propose a nonlinear spectral method
for multiplex networks that simultaneously optimises a node and a layer
coreness vector by maximising a suitable nonconvex homogeneous objective
function by a provably convergent alternating fixed point iteration. We derive
a quantitative measure for the quality of a given multiplex core-periphery
structure that allows the determination of the optimal core size. Numerical
experiments on synthetic and real-world networks illustrate that our approach
is robust against noisy layers and significantly outperforms baseline methods
while improving the latter with our novel optimised layer coreness weights. As
the runtime of our method depends linearly on the number of edges of the
network it is scalable to large-scale multiplex networks.",2023-10-30,"Kai Bergermann, Martin Stoll, Francesco Tudisco"
"Backward and Forward Inference in Interacting Independent-Cascade
  Processes: A Scalable and Convergent Message-Passing Approach","We study the problems of estimating the past and future evolutions of two
diffusion processes that spread concurrently on a network. Specifically, given
a known network $G=(V, \overrightarrow{E})$ and a (possibly noisy) snapshot
$\mathcal{O}_n$ of its state taken at (a possibly unknown) time $W$, we wish to
determine the posterior distributions of the initial state of the network and
the infection times of its nodes. These distributions are useful in finding
source nodes of epidemics and rumors -- $\textit{backward inference}$ -- , and
estimating the spread of a fixed set of source nodes -- $\textit{forward
inference}$.
  To model the interaction between the two processes, we study an extension of
the independent-cascade (IC) model where, when a node gets infected with either
process, its susceptibility to the other one changes. First, we derive the
exact joint probability of the initial state of the network and the
observation-snapshot $\mathcal{O}_n$. Then, using the machinery of
factor-graphs, factor-graph transformations, and the generalized
distributive-law, we derive a Belief-Propagation (BP) based algorithm that is
scalable to large networks and can converge on graphs of arbitrary topology (at
a likely expense in approximation accuracy).",2023-10-29,"Nouman Khan, Kangle Mu, Mehrdad Moharrami, Vijay Subramanian"
Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach,"The progress in hyperbolic neural networks (HNNs) research is hindered by
their absence of inductive bias mechanisms, which are essential for
generalizing to new tasks and facilitating scalable learning over large
datasets. In this paper, we aim to alleviate these issues by learning
generalizable inductive biases from the nodes' local subgraph and transfer them
for faster learning over new subgraphs with a disjoint set of nodes, edges, and
labels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph
Meta Learner (H-GRAM), that, for the tasks of node classification and link
prediction, learns transferable information from a set of support local
subgraphs in the form of hyperbolic meta gradients and label hyperbolic
protonets to enable faster learning over a query set of new tasks dealing with
disjoint subgraphs. Furthermore, we show that an extension of our meta-learning
framework also mitigates the scalability challenges seen in HNNs faced by
existing approaches. Our comparative analysis shows that H-GRAM effectively
learns and transfers information in multiple challenging few-shot settings
compared to other state-of-the-art baselines. Additionally, we demonstrate
that, unlike standard HNNs, our approach is able to scale over large graph
datasets and improve performance over its Euclidean counterparts.",2023-10-29,"Nurendra Choudhary, Nikhil Rao, Chandan K. Reddy"
"Uncovering Gender Bias within Journalist-Politician Interaction in
  Indian Twitter","Gender bias in political discourse is a significant problem on today's social
media. Previous studies found that the gender of politicians indeed influences
the content directed towards them by the general public. However, these works
are particularly focused on the global north, which represents individualistic
culture. Furthermore, they did not address whether there is gender bias even
within the interaction between popular journalists and politicians in the
global south. These understudied journalist-politician interactions are
important (more so in collectivistic cultures like the global south) as they
can significantly affect public sentiment and help set gender-biased social
norms. In this work, using large-scale data from Indian Twitter we address this
research gap.
  We curated a gender-balanced set of 100 most-followed Indian journalists on
Twitter and 100 most-followed politicians. Then we collected 21,188 unique
tweets posted by these journalists that mentioned these politicians. Our
analysis revealed that there is a significant gender bias -- the frequency with
which journalists mention male politicians vs. how frequently they mention
female politicians is statistically significantly different ($p<<0.05$). In
fact, median tweets from female journalists mentioning female politicians
received ten times fewer likes than median tweets from female journalists
mentioning male politicians. However, when we analyzed tweet content, our
emotion score analysis and topic modeling analysis did not reveal any
significant gender-based difference within the journalists' tweets towards
politicians. Finally, we found a potential reason for the significant gender
bias: the number of popular male Indian politicians is almost twice as large as
the number of popular female Indian politicians, which might have resulted in
the observed bias. We conclude by discussing the implications of this work.",2023-10-29,"Brisha Jain, Mainack Mondal"
"How Hard is Takeover in DPoS Blockchains? Understanding the Security of
  Coin-based Voting Governance","Delegated-Proof-of-Stake (DPoS) blockchains, such as EOSIO, Steem and TRON,
are governed by a committee of block producers elected via a coin-based voting
system. We recently witnessed the first de facto blockchain takeover that
happened between Steem and TRON. Within one hour of this incident, TRON founder
took over the entire Steem committee, forcing the original Steem community to
leave the blockchain that they maintained for years. This is a historical event
in the evolution of blockchains and Web 3.0. Despite its significant disruptive
impact, little is known about how vulnerable DPoS blockchains are in general to
takeovers and the ways in which we can improve their resistance to takeovers.
  In this paper, we demonstrate that the resistance of a DPoS blockchain to
takeovers is governed by both the theoretical design and the actual use of its
underlying coin-based voting governance system. When voters actively cooperate
to resist potential takeovers, our theoretical analysis reveals that the
current active resistance of DPoS blockchains is far below the theoretical
upper bound. However in practice, voter preferences could be significantly
different. This paper presents the first large-scale empirical study of the
passive takeover resistance of EOSIO, Steem and TRON. Our study identifies the
diversity in voter preferences and characterizes the impact of this diversity
on takeover resistance. Through both theoretical and empirical analyses, our
study provides novel insights into the security of coin-based voting governance
and suggests potential ways to improve the takeover resistance of any
blockchain that implements this governance model.",2023-10-28,"Chao Li, Balaji Palanisamy, Runhua Xu, Li Duan, Jiqiang Liu, Wei Wang"
RDBench: ML Benchmark for Relational Databases,"Benefiting from high-quality datasets and standardized evaluation metrics,
machine learning (ML) has achieved sustained progress and widespread
applications. However, while applying machine learning to relational databases
(RDBs), the absence of a well-established benchmark remains a significant
obstacle to the development of ML. To address this issue, we introduce ML
Benchmark For Relational Databases (RDBench), a standardized benchmark that
aims to promote reproducible ML research on RDBs that include multiple tables.
RDBench offers diverse RDB datasets of varying scales, domains, and relational
structures, organized into 4 levels. Notably, to simplify the adoption of
RDBench for diverse ML domains, for any given database, RDBench exposes three
types of interfaces including tabular data, homogeneous graphs, and
heterogeneous graphs, sharing the same underlying task definition. For the
first time, RDBench enables meaningful comparisons between ML methods from
diverse domains, ranging from XGBoost to Graph Neural Networks, under RDB
prediction tasks. We design multiple classification and regression tasks for
each RDB dataset and report averaged results over the same dataset, further
enhancing the robustness of the experimental findings. RDBench is implemented
with DBGym, a user-friendly platform for ML research and application on
databases, enabling benchmarking new ML methods with RDBench at ease.",2023-10-25,"Zizhao Zhang, Yi Yang, Lutong Zou, He Wen, Tao Feng, Jiaxuan You"
"Complexity of Government response to Covid-19 pandemic: A perspective of
  coupled dynamics on information heterogeneity and epidemic outbreak","This study aims at modeling the universal failure in preventing the outbreak
of COVID-19 via real-world data from the perspective of complexity and network
science. Through formalizing information heterogeneity and government
intervention in the coupled dynamics of epidemic and infodemic spreading;
first, we find that information heterogeneity and its induced variation in
human responses significantly increase the complexity of the government
intervention decision. The complexity results in a dilemma between the socially
optimal intervention that is risky for the government and the privately optimal
intervention that is safer for the government but harmful to the social
welfare. Second, via counterfactual analysis against the COVID-19 crisis in
Wuhan, 2020, we find that the intervention dilemma becomes even worse if the
initial decision time and the decision horizon vary. In the short horizon, both
socially and privately optimal interventions agree with each other and require
blocking the spread of all COVID-19-related information, leading to a
negligible infection ratio 30 days after the initial reporting time. However,
if the time horizon is prolonged to 180 days, only the privately optimal
intervention requires information blocking, which would induce a
catastrophically higher infection ratio than that in the counter-factual world
where the socially optimal intervention encourages early-stage information
spread. These findings contribute to the literature by revealing the complexity
incurred by the coupled infodemic-epidemic dynamics and information
heterogeneity to the governmental intervention decision, which also sheds
insight into the design of an effective early warning system against the
epidemic crisis in the future.",2023-10-25,"Xiaoqi Zhang, Jie Fu, Sheng Hua, Han Liang, Zi-Ke Zhang"
Analyzing User Characteristics of Hate Speech Spreaders on Social Media,"Hate speech on social media threatens the mental and physical well-being of
individuals and contributes to real-world violence. Resharing is an important
driver behind the spread of hate speech on social media. Yet, little is known
about who reshares hate speech and what their characteristics are. In this
paper, we analyze the role of user characteristics in hate speech resharing
across different types of hate speech (e.g., political hate). For this, we
proceed as follows: First, we cluster hate speech posts using large language
models to identify different types of hate speech. Then we model the effects of
user attributes on users' probability to reshare hate speech using an
explainable machine learning model. To do so, we apply debiasing to control for
selection bias in our observational social media data and further control for
the latent vulnerability of users to hate speech. We find that, all else equal,
users with fewer followers, fewer friends, fewer posts, and older accounts
share more hate speech. This shows that users with little social influence tend
to share more hate speech. Further, we find substantial heterogeneity across
different types of hate speech. For example, racist and misogynistic hate is
spread mostly by users with little social influence. In contrast, political
anti-Trump and anti-right-wing hate is reshared by users with larger social
influence. Overall, understanding the factors that drive users to share hate
speech is crucial for detecting individuals at risk of engaging in harmful
behavior and for designing effective mitigation strategies.",2023-10-24,"Dominique Geissler, Abdurahman Maarouf, Stefan Feuerriegel"
Hypergraph Motifs and Their Extensions Beyond Binary,"Hypergraphs naturally represent group interactions, which are omnipresent in
many domains: collaborations of researchers, co-purchases of items, and joint
interactions of proteins, to name a few. In this work, we propose tools for
answering the following questions: (Q1) what are the structural design
principles of real-world hypergraphs? (Q2) how can we compare local structures
of hypergraphs of different sizes? (Q3) how can we identify domains from which
hypergraphs are? We first define hypergraph motifs (h-motifs), which describe
the overlapping patterns of three connected hyperedges. Then, we define the
significance of each h-motif in a hypergraph as its occurrences relative to
those in properly randomized hypergraphs. Lastly, we define the characteristic
profile (CP) as the vector of the normalized significance of every h-motif.
Regarding Q1, we find that h-motifs' occurrences in 11 real-world hypergraphs
from 5 domains are clearly distinguished from those of randomized hypergraphs.
Then, we demonstrate that CPs capture local structural patterns unique to each
domain, and thus comparing CPs of hypergraphs addresses Q2 and Q3. The concept
of CP is extended to represent the connectivity pattern of each node or
hyperedge as a vector, which proves useful in node classification and hyperedge
prediction. Our algorithmic contribution is to propose MoCHy, a family of
parallel algorithms for counting h-motifs' occurrences in a hypergraph. We
theoretically analyze their speed and accuracy and show empirically that the
advanced approximate version MoCHy-A+ is more accurate and faster than the
basic approximate and exact versions, respectively. Furthermore, we explore
ternary hypergraph motifs that extends h-motifs by taking into account not only
the presence but also the cardinality of intersections among hyperedges. This
extension proves beneficial for all previously mentioned applications.",2023-10-24,"Geon Lee, Seokbum Yoon, Jihoon Ko, Hyunju Kim, Kijung Shin"
"A universal meta-heuristic framework for influence maximization in
  hypergraphs","Influence maximization (IM) aims to select a small number of nodes that are
able to maximize their influence in a network and covers a wide range of
applications. Despite numerous attempts to provide effective solutions in
ordinary networks, higher-order interactions between entities in various
real-world systems are not usually taken into account. In this paper, we
propose a versatile meta-heuristic approach, hyper genetic algorithm (HGA), to
tackle the IM problem in hypergraphs, which is based on the concept of genetic
evolution. Systematic validations in synthetic and empirical hypergraphs under
both simple and complex contagion models indicate that HGA achieves universal
and plausible performance compared to baseline methods. We explore the cause of
the excellent performance of HGA through ablation studies and correlation
analysis. The findings show that the solution of HGA is distinct from that of
other prior methods. Moreover, a closer look at the local topological features
of the seed nodes acquired by different algorithms reveals that the selection
of seed nodes cannot be based on a single topological characteristic, but
should involve a combination of multiple topological features to address the IM
problem.",2023-10-24,"Ming Xie, Xiu-Xiu Zhan, Chuang Liu, Zi-Ke Zhang"
"K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific
  Ratings","Numerous datasets have been proposed to combat the spread of online hate.
Despite these efforts, a majority of these resources are English-centric,
primarily focusing on overt forms of hate. This research gap calls for
developing high-quality corpora in diverse languages that also encapsulate more
subtle hate expressions. This study introduces K-HATERS, a new corpus for hate
speech detection in Korean, comprising approximately 192K news comments with
target-specific offensiveness ratings. This resource is the largest offensive
language corpus in Korean and is the first to offer target-specific ratings on
a three-point Likert scale, enabling the detection of hate expressions in
Korean across varying degrees of offensiveness. We conduct experiments showing
the effectiveness of the proposed corpus, including a comparison with existing
datasets. Additionally, to address potential noise and bias in human
annotations, we explore a novel idea of adopting the Cognitive Reflection Test,
which is widely used in social science for assessing an individual's cognitive
ability, as a proxy of labeling quality. Findings indicate that annotations
from individuals with the lowest test scores tend to yield detection models
that make biased predictions toward specific target groups and are less
accurate. This study contributes to the NLP research on hate speech detection
and resource construction. The code and dataset can be accessed at
https://github.com/ssu-humane/K-HATERS.",2023-10-24,"Chaewon Park, Soohwan Kim, Kyubyong Park, Kunwoo Park"
"Visual Elements and Cognitive Biases Influence Interpretations of Trends
  in Scatter Plots","Visualizations are common methods to convey information but also increasingly
used to spread misinformation. It is therefore important to understand the
factors people use to interpret visualizations. In this paper, we focus on
factors that influence interpretations of scatter plots, investigating the
extent to which common visual aspects of scatter plots (outliers and trend
lines) and cognitive biases (people's beliefs) influence perception of
correlation trends. We highlight three main findings: outliers skew trend
perception but exert less influence than other points; trend lines make trends
seem stronger but also mitigate the influence of some outliers; and people's
beliefs have a small influence on perceptions of weak, but not strong
correlations. From these results we derive guidelines for adjusting visual
elements to mitigate the influence of factors that distort interpretations of
scatter plots. We explore how these guidelines may generalize to other
visualization types and make recommendations for future studies.",2023-10-23,"Alexandre Filipowicz, Scott Carter, Nayeli Bravo, Rumen Iliev, Shabnam Hakimi, David Ayman Shamma, Kent Lyons, Candice Hogan, Charlene Wu"
Detecting Changes in Crowdsourced Social Media Images,"We propose a novel service framework to detect changes in crowdsourced
images. We use a service-oriented approach to model and represent crowdsourced
images as image services. Non-functional attributes of an image service are
leveraged to detect changes in an image. The changes are reported in form of a
version tree. The version tree is constructed in a way that it reflects the
extent of changes introduced in different versions. Afterwards, we find
semantic differences in between different versions to determine the extent of
changes introduced in a specific version. Preliminary experimental results
demonstrate the effectiveness of the proposed approach.",2023-10-23,"Muhammad Umair, Athman Bouguettaya, Abdallah Lakhdari"
Context-Aware Prediction of User Engagement on Online Social Platforms,"The success of online social platforms hinges on their ability to predict and
understand user behavior at scale. Here, we present data suggesting that
context-aware modeling approaches may offer a holistic yet lightweight and
potentially privacy-preserving representation of user engagement on online
social platforms. Leveraging deep LSTM neural networks to analyze more than 100
million Snapchat sessions from almost 80.000 users, we demonstrate that
patterns of active and passive use are predictable from past behavior
(R2=0.345) and that the integration of context features substantially improves
predictive performance compared to the behavioral baseline model (R2=0.522).
Features related to smartphone connectivity status, location, temporal context,
and weather were found to capture non-redundant variance in user engagement
relative to features derived from histories of in-app behaviors. Further, we
show that a large proportion of variance can be accounted for with minimal
behavioral histories if momentary context is considered (R2=0.442). These
results indicate the potential of context-aware approaches for making models
more efficient and privacy-preserving by reducing the need for long data
histories. Finally, we employ model explainability techniques to glean
preliminary insights into the underlying behavioral mechanisms. Our findings
are consistent with the notion of context-contingent, habit-driven patterns of
active and passive use, underscoring the value of contextualized
representations of user behavior for predicting user engagement on social
platforms.",2023-10-23,"Heinrich Peters, Yozen Liu, Francesco Barbieri, Raiyan Abdul Baten, Sandra C. Matz, Maarten W. Bos"
Efficient Heterogeneous Graph Learning via Random Projection,"Heterogeneous Graph Neural Networks (HGNNs) are powerful tools for deep
learning on heterogeneous graphs. Typical HGNNs require repetitive message
passing during training, limiting efficiency for large-scale real-world graphs.
Recent pre-computation-based HGNNs use one-time message passing to transform a
heterogeneous graph into regular-shaped tensors, enabling efficient mini-batch
training. Existing pre-computation-based HGNNs can be mainly categorized into
two styles, which differ in how much information loss is allowed and
efficiency. We propose a hybrid pre-computation-based HGNN, named Random
Projection Heterogeneous Graph Neural Network (RpHGNN), which combines the
benefits of one style's efficiency with the low information loss of the other
style. To achieve efficiency, the main framework of RpHGNN consists of
propagate-then-update iterations, where we introduce a Random Projection
Squashing step to ensure that complexity increases only linearly. To achieve
low information loss, we introduce a Relation-wise Neighbor Collection
component with an Even-odd Propagation Scheme, which aims to collect
information from neighbors in a finer-grained way. Experimental results
indicate that our approach achieves state-of-the-art results on seven small and
large benchmark datasets while also being 230% faster compared to the most
effective baseline. Surprisingly, our approach not only surpasses
pre-processing-based baselines but also outperforms end-to-end methods.",2023-10-23,"Jun Hu, Bryan Hooi, Bingsheng He"
"On the Relationship Between Relevance and Conflict in Online Social Link
  Recommendations","In an online social network, link recommendations are a way for users to
discover relevant links to people they may know, thereby potentially increasing
their engagement on the platform. However, the addition of links to a social
network can also have an effect on the level of conflict in the network --
expressed in terms of polarization and disagreement. To this date, however, we
have very little understanding of how these two implications of link formation
relate to each other: are the goals of high relevance and conflict reduction
aligned, or are the links that users are most likely to accept fundamentally
different from the ones with the greatest potential for reducing conflict? Here
we provide the first analysis of this question, using the recently popular
Friedkin-Johnsen model of opinion dynamics. We first present a surprising
result on how link additions shift the level of opinion conflict, followed by
explanation work that relates the amount of shift to structural features of the
added links. We then characterize the gap in conflict reduction between the set
of links achieving the largest reduction and the set of links achieving the
highest relevance. The gap is measured on real-world data, based on
instantiations of relevance defined by 13 link recommendation algorithms. We
find that some, but not all, of the more accurate algorithms actually lead to
better reduction of conflict. Our work suggests that social links recommended
for increasing user engagement may not be as conflict-provoking as people might
have thought.",2023-10-21,"Yanbang Wang, Jon Kleinberg"
"An Offer you Cannot Refuse? Trends in the Coerciveness of Amazon Book
  Recommendations","Recommender systems can be a helpful tool for recommending content but they
can also influence users' preferences. One sociological theory for this
influence is that companies are incentivised to influence preferences to make
users easier to predict and thus more profitable by making it harder to change
preferences. This paper seeks to test that theory empirically. We use
\textit{Barrier-to-Exit}, a metric for how difficult it is for users to change
preferences, to analyse a large dataset of Amazon Book Ratings from 1998 to
2018. We focus the analysis on users who have changed preferences according to
Barrier-to-Exit. To assess the growth of Barrier-to-Exit over time, we
developed a linear mixed-effects model with crossed random effects for users
and categories. Our findings indicate a highly significant growth of
Barrier-to-Exit over time, suggesting that it has become more difficult for the
analysed subset of users to change their preferences. However, it should be
noted that these findings come with several statistical and methodological
caveats including sample bias and construct validity issues related to
Barrier-to-Exit. We discuss the strengths and limitations of our approach and
its implications. Additionally, we highlight the challenges of creating
context-sensitive and generalisable measures for complex socio-technical
concepts such as ""difficulty to change preferences."" We conclude with a call
for further research: to curb the potential threats of preference manipulation,
we need more measures that allow us to compare commercial as well as
non-commercial systems.",2023-10-21,Jonathan H. Rystrøm
"COVIDFakeExplainer: An Explainable Machine Learning based Web
  Application for Detecting COVID-19 Fake News","Fake news has emerged as a critical global issue, magnified by the COVID-19
pandemic, underscoring the need for effective preventive tools. Leveraging
machine learning, including deep learning techniques, offers promise in
combatting fake news. This paper goes beyond by establishing BERT as the
superior model for fake news detection and demonstrates its utility as a tool
to empower the general populace. We have implemented a browser extension,
enhanced with explainability features, enabling real-time identification of
fake news and delivering easily interpretable explanations. To achieve this, we
have employed two publicly available datasets and created seven distinct data
configurations to evaluate three prominent machine learning architectures. Our
comprehensive experiments affirm BERT's exceptional accuracy in detecting
COVID-19-related fake news. Furthermore, we have integrated an explainability
component into the BERT model and deployed it as a service through Amazon's
cloud API hosting (AWS). We have developed a browser extension that interfaces
with the API, allowing users to select and transmit data from web pages,
receiving an intelligible classification in return. This paper presents a
practical end-to-end solution, highlighting the feasibility of constructing a
holistic system for fake news detection, which can significantly benefit
society.",2023-10-21,"Dylan Warman, Muhammad Ashad Kabir"
"Densest Subhypergraph: Negative Supermodular Functions and Strongly
  Localized Methods","Dense subgraph discovery is a fundamental primitive in graph and hypergraph
analysis which among other applications has been used for real-time story
detection on social media and improving access to data stores of social
networking systems. We present several contributions for localized densest
subgraph discovery, which seeks dense subgraphs located nearby given seed sets
of nodes. We first introduce a generalization of a recent $\textit{anchored
densest subgraph}$ problem, extending this previous objective to hypergraphs
and also adding a tunable locality parameter that controls the extent to which
the output set overlaps with seed nodes. Our primary technical contribution is
to prove when it is possible to obtain a strongly-local algorithm for solving
this problem, meaning that the runtime depends only on the size of the input
set. We provide a strongly-local algorithm that applies whenever the locality
parameter is not too small, and show via counterexample why strongly-local
algorithms are impossible below a certain threshold. Along the way to proving
our results for localized densest subgraph discovery, we also provide several
advances in solving global dense subgraph discovery objectives. This includes
the first strongly polynomial time algorithm for the densest supermodular set
problem and a flow-based exact algorithm for a heavy and dense subgraph
discovery problem in graphs with arbitrary node weights. We demonstrate our
algorithms on several web-based data analysis tasks.",2023-10-20,"Yufan Huang, David F. Gleich, Nate Veldt"
Infection Curve Flattening via Targeted Interventions and Self-Isolation,"Understanding the impact of network clustering and small-world properties on
epidemic spread can be crucial in developing effective strategies for managing
and controlling infectious diseases. Particularly in this work, we study the
impact of these network features on targeted intervention (e.g., self-isolation
and quarantine). The targeted individuals for self-isolation are based on
centrality measures and node influence metrics. Compared to our previous works
on scale-free networks, small-world networks are considered in this paper.
Small-world networks resemble real-world social and human networks. In this
type of network, most nodes are not directly connected but can be reached
through a few intermediaries (known as the small-worldness property). Real
social networks, such as friendship networks, also exhibit this small-worldness
property, where most people are connected through a relatively small number of
intermediaries. We particularly study the epidemic curve flattening by
centrality-based interventions/isolation over small-world networks. Our results
show that high clustering while having low small-worldness (higher shortest
path characteristics) implies flatter infection curves. In reality, a flatter
infection curve implies that the number of new cases of a disease is spread out
over a longer period of time, rather than a sharp and sudden increase in cases
(a peak in epidemic). In turn, this reduces the strain on healthcare resources
and helps to relieve the healthcare services.",2023-10-19,"Mohammadreza Doostmohammadian, Houman Zarrabi, Azam Doustmohammadian, Hamid R. Rabiee"
Soccer on Social Media,"In the era of digitalization, social media has become an integral part of our
lives, serving as a significant hub for individuals and businesses to share
information, communicate, and engage. This is also the case for professional
sports, where leagues, clubs and players are using social media to reach out to
their fans. In this respect, a huge amount of time is spent curating multimedia
content for various social media platforms and their target users. With the
emergence of Artificial Intelligence (AI), AI-based tools for automating
content generation and enhancing user experiences on social media have become
widely popular. However, to effectively utilize such tools, it is imperative to
comprehend the demographics and preferences of users on different platforms,
understand how content providers post information in these channels, and how
different types of multimedia are consumed by audiences. This report presents
an analysis of social media platforms, in terms of demographics, supported
multimedia modalities, and distinct features and specifications for different
modalities, followed by a comparative case study of select European soccer
leagues and teams, in terms of their social media practices. Through this
analysis, we demonstrate that social media, while being very important for and
widely used by supporters from all ages, also requires a fine-tuned effort on
the part of soccer professionals, in order to elevate fan experiences and
foster engagement.",2023-10-18,"Mehdi Houshmand Sarkhoosh, Sayed Mohammad Majidi Dorcheh, Sushant Gautam, Cise Midoglu, Saeed Shafiee Sabet, Pål Halvorsen"
"Towards Understanding and Characterizing the Arbitrage Bot Scam In the
  Wild","This paper presents the first comprehensive analysis of an emerging
cryptocurrency scam named ""arbitrage bot"" disseminated on online social
networks. The scam revolves around Decentralized Exchanges (DEX) arbitrage and
aims to lure victims into executing a so-called ""bot contract"" to steal funds
from them.
  To collect the scam at a large scale, we developed a fully automated scam
detection system named CryptoScamHunter, which continuously collects YouTube
videos and automatically detects scams. Meanwhile, CryptoScamHunter can
download the source code of the bot contract from the provided links and
extract the associated scam cryptocurrency address. Through deploying
CryptoScamHunter from Jun. 2022 to Jun. 2023, we have detected 10,442 arbitrage
bot scam videos published from thousands of YouTube accounts. Our analysis
reveals that different strategies have been utilized in spreading the scam,
including crafting popular accounts, registering spam accounts, and using
obfuscation tricks to hide the real scam address in the bot contracts.
Moreover, from the scam videos we have collected over 800 malicious bot
contracts with source code and extracted 354 scam addresses. By further
expanding the scam addresses with a similar contract matching technique, we
have obtained a total of 1,697 scam addresses. Through tracing the transactions
of all scam addresses on the Ethereum mainnet and Binance Smart Chain, we
reveal that over 25,000 victims have fallen prey to this scam, resulting in a
financial loss of up to 15 million USD.
  Overall, our work sheds light on the dissemination tactics and censorship
evasion strategies adopted in the arbitrage bot scam, as well as on the scale
and impact of such a scam on online social networks and blockchain platforms,
emphasizing the urgent need for effective detection and prevention mechanisms
against such fraudulent activity.",2023-10-18,"Kai Li, Shixuan Guan, Darren Lee"
"Stranger Danger! Cross-Community Interactions with Fringe Users Increase
  the Growth of Fringe Communities on Reddit","Fringe communities promoting conspiracy theories and extremist ideologies
have thrived on mainstream platforms, raising questions about the mechanisms
driving their growth. Here, we hypothesize and study a possible mechanism: new
members may be recruited through fringe-interactions: the exchange of comments
between members and non-members of fringe communities. We apply text-based
causal inference techniques to study the impact of fringe-interactions on the
growth of three prominent fringe communities on Reddit: r/Incel,
r/GenderCritical, and r/The_Donald. Our results indicate that
fringe-interactions attract new members to fringe communities. Users who
receive these interactions are up to 4.2 percentage points (pp) more likely to
join fringe communities than similar, matched users who do not.
  This effect is influenced by 1) the characteristics of communities where the
interaction happens (e.g., left vs. right-leaning communities) and 2) the
language used in the interactions. Interactions using toxic language have a 5pp
higher chance of attracting newcomers to fringe communities than non-toxic
interactions. We find no effect when repeating this analysis by replacing
fringe (r/Incel, r/GenderCritical, and r/The_Donald) with non-fringe
communities (r/climatechange, r/NBA, r/leagueoflegends), suggesting this growth
mechanism is specific to fringe communities. Overall, our findings suggest that
curtailing fringe-interactions may reduce the growth of fringe communities on
mainstream platforms.",2023-10-18,"Giuseppe Russo, Manoel Horta Ribeiro, Robert West"
"Unveiling Local Patterns of Child Pornography Consumption in France
  using Tor","Child pornography represents a severe form of exploitation and victimization
of children, leaving the victims with emotional and physical trauma. In this
study, we aim to analyze local patterns of child pornography consumption across
1341 French communes in 20 metropolitan regions of France using fine-grained
mobile traffic data of Tor network-related web services. We estimate that
approx. 0.08 % of Tor mobile download traffic observed in France is linked to
the consumption of child sexual abuse materials by correlating it with
local-level temporal porn consumption patterns. This compares to 0.19 % of what
we conservatively estimate to be the share of child pornographic content in
global Tor traffic. In line with existing literature on the link between sexual
child abuse and the consumption of image-based content thereof, we observe a
positive and statistically significant effect of our child pornography
consumption estimates on the reported number of victims of sexual violence and
vice versa, which validates our findings, after controlling for a set of
spatial and non-spatial features including socio-demographic characteristics,
voting behaviour, nearby points of interest and Google Trends queries. While
this is a first, exploratory attempt to look at child pornography from a
spatial epidemiological angle, we believe this research provides public health
officials with valuable information to prioritize target areas for public
awareness campaigns as another step to fulfil the global community's pledge to
target 16.2 of the Sustainable Development Goals: ""End abuse, exploitation,
trafficking and all forms of violence and torture against children"".",2023-10-17,"Till Koebe, Zinnya del Villar, Brahmani Nutakki, Nursulu Sagimbayeva, Ingmar Weber"
"SignGT: Signed Attention-based Graph Transformer for Graph
  Representation Learning","The emerging graph Transformers have achieved impressive performance for
graph representation learning over graph neural networks (GNNs). In this work,
we regard the self-attention mechanism, the core module of graph Transformers,
as a two-step aggregation operation on a fully connected graph. Due to the
property of generating positive attention values, the self-attention mechanism
is equal to conducting a smooth operation on all nodes, preserving the
low-frequency information. However, only capturing the low-frequency
information is inefficient in learning complex relations of nodes on diverse
graphs, such as heterophily graphs where the high-frequency information is
crucial. To this end, we propose a Signed Attention-based Graph Transformer
(SignGT) to adaptively capture various frequency information from the graphs.
Specifically, SignGT develops a new signed self-attention mechanism (SignSA)
that produces signed attention values according to the semantic relevance of
node pairs. Hence, the diverse frequency information between different node
pairs could be carefully preserved. Besides, SignGT proposes a structure-aware
feed-forward network (SFFN) that introduces the neighborhood bias to preserve
the local topology information. In this way, SignGT could learn informative
node representations from both long-range dependencies and local topology
information. Extensive empirical results on both node-level and graph-level
tasks indicate the superiority of SignGT against state-of-the-art graph
Transformers as well as advanced GNNs.",2023-10-17,"Jinsong Chen, Gaichao Li, John E. Hopcroft, Kun He"
WGoM: A novel model for categorical data with weighted responses,"The Graded of Membership (GoM) model is a powerful tool for inferring latent
classes in categorical data, which enables subjects to belong to multiple
latent classes. However, its application is limited to categorical data with
nonnegative integer responses, making it inappropriate for datasets with
continuous or negative responses. To address this limitation, this paper
proposes a novel model named the Weighted Grade of Membership (WGoM) model.
Compared with GoM, our WGoM relaxes GoM's distribution constraint on the
generation of a response matrix and it is more general than GoM. We then
propose an algorithm to estimate the latent mixed memberships and the other
WGoM parameters. We derive the error bounds of the estimated parameters and
show that the algorithm is statistically consistent. The algorithmic
performance is validated in both synthetic and real-world datasets. The results
demonstrate that our algorithm is accurate and efficient, indicating its high
potential for practical applications. This paper makes a valuable contribution
to the literature by introducing a novel model that extends the applicability
of the GoM model and provides a more flexible framework for analyzing
categorical data with weighted responses.",2023-10-17,Huan Qing
"Analyzing Modularity Maximization in Approximation, Heuristic, and Graph
  Neural Network Algorithms for Community Detection","Community detection, which involves partitioning nodes within a network, has
widespread applications across computational sciences. Modularity-based
algorithms identify communities by attempting to maximize the modularity
function across network node partitions. Our study assesses the performance of
various modularity-based algorithms in obtaining optimal partitions. Our
analysis utilizes 104 networks, including both real-world instances from
diverse contexts and modular graphs from two families of synthetic benchmarks.
We analyze ten inexact modularity-based algorithms against the exact integer
programming baseline that globally optimizes modularity. Our comparative
analysis includes eight heuristics, two variants of a graph neural network
algorithm, and nine variations of the Bayan approximation algorithm.
  Our findings reveal that the average modularity-based heuristic yields
optimal partitions in only 43.9% of the 104 networks analyzed. Graph neural
networks and approximate Bayan, on average, achieve optimality on 68.7% and
82.3% of the networks respectively. Additionally, our analysis of three
partition similarity metrics exposes substantial dissimilarities between
high-modularity sub-optimal partitions and any optimal partition of the
networks. We observe that near-optimal partitions are often disproportionately
dissimilar to any optimal partition. Taken together, our analysis points to a
crucial limitation of the commonly used modularity-based methods: they rarely
produce an optimal partition or a partition resembling an optimal partition
even on networks with modular structures. If modularity is to be used for
detecting communities, we recommend approximate optimization algorithms for a
more methodologically sound usage of modularity within its applicability
limits.",2023-10-17,"Samin Aref, Mahdi Mostajabdaveh"
Tracking China's cross-strait bot networks against Taiwan,"The cross-strait relationship between China and Taiwan is marked by
increasing hostility around potential reunification. We analyze an unattributed
bot network and how repeater bots engaged in an influence campaign against
Taiwan following US House Speaker Nancy Pelosi's visit to Taiwan in 2022. We
examine the message amplification tactics employed by four key bot
sub-communities, the widespread dissemination of information across multiple
platforms through URLs, and the potential targeted audiences of this bot
network. We find that URL link sharing reveals circumvention around YouTube
suspensions, in addition to the potential effectiveness of algorithmic bot
connectivity to appear less bot-like, and detail a sequence of coordination
within a sub-community for message amplification. We additionally find the
narratives and targeted audience potentially shifting after account activity
discrepancies, demonstrating how dynamic these bot networks can operate.",2023-10-16,"Charity S. Jacobs, Lynnette Hui Xian Ng, Kathleen M. Carley"
"Content Moderation and the Formation of Online Communities: A
  Theoretical Framework","We study the impact of content moderation policies in online communities. In
our theoretical model, a platform chooses a content moderation policy and
individuals choose whether or not to participate in the community according to
the fraction of user content that aligns with their preferences. The effects of
content moderation, at first blush, might seem obvious: it restricts speech on
a platform. However, when user participation decisions are taken into account,
its effects can be more subtle $\unicode{x2013}$ and counter-intuitive. For
example, our model can straightforwardly demonstrate how moderation policies
may increase participation and diversify content available on the platform. In
our analysis, we explore a rich set of interconnected phenomena related to
content moderation in online communities. We first characterize the
effectiveness of a natural class of moderation policies for creating and
sustaining stable communities. Building on this, we explore how
resource-limited or ideological platforms might set policies, how communities
are affected by differing levels of personalization, and competition between
platforms. Our model provides a vocabulary and mathematically tractable
framework for analyzing platform decisions about content moderation.",2023-10-16,"Cynthia Dwork, Chris Hays, Jon Kleinberg, Manish Raghavan"
"Exploiting User Comments for Early Detection of Fake News Prior to
  Users' Commenting","Both accuracy and timeliness are key factors in detecting fake news on social
media. However, most existing methods encounter an accuracy-timeliness dilemma:
Content-only methods guarantee timeliness but perform moderately because of
limited available information, while social con-text-based ones generally
perform better but inevitably lead to latency because of social context
accumulation needs. To break such a dilemma, a feasible but not well-studied
solution is to leverage social contexts (e.g., comments) from historical news
for training a detection model and apply it to newly emerging news without
social contexts. This requires the model to (1) sufficiently learn helpful
knowledge from social contexts, and (2) be well compatible with situations that
social contexts are available or not. To achieve this goal, we propose to
absorb and parameterize useful knowledge from comments in historical news and
then inject it into a content-only detection model. Specifically, we design the
Comments ASsisted FakE News Detection method (CAS-FEND), which transfers useful
knowledge from a comment-aware teacher model to a content-only student model
and detects newly emerging news with the student model. Experiments show that
the CAS-FEND student model outperforms all content-only methods and even
comment-aware ones with 1/4 comments as inputs, demonstrating its superiority
for early detection.",2023-10-16,"Qiong Nan, Qiang Sheng, Juan Cao, Yongchun Zhu, Danding Wang, Guang Yang, Jintao Li"
"Analysis and implementation of nanotargeting on LinkedIn based on
  publicly available non-PII","The literature has shown that combining a few non-Personal Identifiable
Information (non-PII) is enough to make a user unique in a dataset including
millions of users. This work demonstrates that a combination of a few non-PII
items can be activated to nanotarget users. We demonstrate that the combination
of the location and {5} rare ({13} random) skills in a LinkedIn profile is
enough to become unique in a user base of {$\sim$970M} users with a probability
of 75\%. The novelty is that these attributes are publicly accessible to anyone
registered on LinkedIn and can be activated through advertising campaigns. We
ran an experiment configuring ad campaigns using the location and skills of
three of the paper's authors, demonstrating how all the ads using $\geq13$
skills were delivered exclusively to the targeted user. We reported this
vulnerability to LinkedIn, which initially ignored the problem, but fixed it as
of November 2023.%This nanotargeting may expose LinkedIn users to privacy and
security risks such as malvertising or manipulation.",2023-10-16,"Ángel Merino, José González-Cabañas, Ángel Cuevas, Rubén Cuevas"
Node classification in networks via simplicial interactions,"In the node classification task, it is natural to presume that densely
connected nodes tend to exhibit similar attributes. Given this, it is crucial
to first define what constitutes a dense connection and to develop a reliable
mathematical tool for assessing node cohesiveness. In this paper, we propose a
probability-based objective function for semi-supervised node classification
that takes advantage of higher-order networks' capabilities. The proposed
function reflects the philosophy aligned with the intuition behind classifying
within higher order networks, as it is designed to reduce the likelihood of
nodes interconnected through higher-order networks bearing different labels.
Additionally, we propose the Stochastic Block Tensor Model (SBTM) as a graph
generation model designed specifically to address a significant limitation of
the traditional stochastic block model, which does not adequately represent the
distribution of higher-order structures in real networks. We evaluate the
objective function using networks generated by the SBTM, which include both
balanced and imbalanced scenarios. Furthermore, we present an approach that
integrates the objective function with graph neural network (GNN)-based
semi-supervised node classification methodologies, aiming for additional
performance gains. Our results demonstrate that in challenging classification
scenarios-characterized by a low probability of homo-connections, a high
probability of hetero-connections, and limited prior node information-models
based on the higher-order network outperform pairwise interaction-based models.
Furthermore, experimental results suggest that integrating our proposed
objective function with existing GNN-based node classification approaches
enhances classification performance by efficiently learning higher-order
structures distributed in the network.",2023-10-16,"Eunho Koo, Tongseok Lim"
Network Analysis of the iNaturalist Citizen Science Community,"In recent years, citizen science has become a larger and larger part of the
scientific community. Its ability to crowd source data and expertise from
thousands of citizen scientists makes it invaluable. Despite the field's
growing popularity, the interactions and structure of citizen science projects
are still poorly understood and under analyzed. We use the iNaturalist citizen
science platform as a case study to analyze the structure of citizen science
projects. We frame the data from iNaturalist as a bipartite network and use
visualizations as well as established network science techniques to gain
insights into the structure and interactions between users in citizen science
projects. Finally, we propose a novel unique benchmark for network science
research by using the iNaturalist data to create a network which has an unusual
structure relative to other common benchmark networks. We demonstrate using a
link prediction task that this network can be used to gain novel insights into
a variety of network science methods.",2023-10-16,"Yu Lu Liu, Thomas Jiralerspong"
"Effects of Same-Race Mentorship Preferences on Academic Performance and
  Survival","Same-race mentorship preference refers to mentors or mentees forming
connections significantly influenced by a shared race. Although racial
diversity in science has been well-studied and linked to favorable outcomes,
the extent and effects of same-race mentorship preferences remain largely
underexplored. Here, we analyze 465,355 mentor-mentee pairs from more than 60
research areas over the last 70 years to investigate the effect of same-race
mentorship preferences on mentees' academic performance and survival. We use
causal inference and statistical matching to measure same-race mentorship
preferences while accounting for racial demographic variations across
institutions, time periods, and research fields. Our findings reveal a
pervasive same-race mentorship propensity across races, fields, and
universities of varying research intensity. We observe an increase in same-race
mentorship propensity over the years, further reinforced inter-generationally
within a mentorship lineage. This propensity is more pronounced for minorities
(Asians, Blacks, and Hispanics). Our results reveal that mentees under the
supervision of mentors with high same-race propensity experience significantly
lower productivity, impact, and collaboration reach during and after training,
ultimately leading to a 27.6% reduced likelihood of remaining in academia. In
contrast, a mentorship approach devoid of racial propensity appears to offer
the best prospects for academic performance and persistence. These findings
underscore the importance of mentorship diversity for academic success and shed
light on factors contributing to minority underrepresentation in science.",2023-10-14,"Meijun Liu, Yi Bu, Daifeng Li, Ying Ding, Daniel E. Acuna"
"An Intrinsic Integrity-Driven Rating Model for a Sustainable Reputation
  System","In the era of digital markets, the challenge for consumers is discerning
quality amidst information asymmetry. While traditional markets use brand
mechanisms to address this issue, transferring such systems to internet-based
P2P markets, where misleading practices like fake ratings are rampant, remains
challenging. Current internet platforms strive to counter this through
verification algorithms, but these efforts find themselves in a continuous
tug-of-war with counterfeit actions.
  Exploiting the transparency, immutability, and traceability of blockchain
technology, this paper introduces a robust reputation voting system grounded in
it. Unlike existing blockchain-based reputation systems, our model harnesses an
intrinsically economically incentivized approach to bolster agent integrity. We
optimize this model to mirror real-world user behavior, preserving the
reputation system's foundational sustainability. Through Monte-Carlo
simulations, using both uniform and power-law distributions enabled by an
innovative inverse transform method, we traverse a broad parameter landscape,
replicating real-world complexity. The findings underscore the promise of a
sustainable, transparent, and formidable reputation mechanism. Given its
structure, our framework can potentially function as a universal, sustainable
oracle for offchain-onchain bridging, aiding entities in perpetually
cultivating their reputation. Future integration with technologies like Ring
Signature and Zero Knowledge Proof could amplify the system's privacy facets,
rendering it particularly influential in the ever-evolving digital domain.",2023-10-13,"H. Wen, T. Huang, D. Xiao"
"Bots, Elections, and Controversies: Twitter Insights from Brazil's
  Polarised Elections","From 2018 to 2023, Brazil experienced its most fiercely contested elections
in history, resulting in the election of far-right candidate Jair Bolsonaro
followed by the left-wing, Lula da Silva. This period was marked by a murder
attempt, a coup attempt, the pandemic, and a plethora of conspiracy theories
and controversies. This paper analyses 437 million tweets originating from 13
million accounts associated with Brazilian politics during these two
presidential election cycles. We focus on accounts' behavioural patterns. We
noted a quasi-monotonic escalation in bot engagement, marked by notable surges
both during COVID-19 and in the aftermath of the 2022 election. The data
revealed a strong correlation between bot engagement and the number of replies
during a single day ($r=0.66$, $p<0.01$). Furthermore, we identified a range of
suspicious activities, including an unusually high number of accounts being
created on the same day, with some days witnessing over 20,000 new accounts and
super-prolific accounts generating close to 100,000 tweets. Lastly, we
uncovered a sprawling network of accounts sharing Twitter handles, with a
select few managing to utilise more than 100 distinct handles. This work can be
instrumental in dismantling coordinated campaigns and offer valuable insights
for the enhancement of bot detection algorithms.",2023-10-13,Diogo Pacheco
Impact of Stricter Content Moderation on Parler's Users' Discourse,"Social media platforms employ various content moderation techniques to remove
harmful, offensive, and hate speech content. The moderation level varies across
platforms; even over time, it can evolve in a platform. For example, Parler, a
fringe social media platform popular among conservative users, was known to
have the least restrictive moderation policies, claiming to have open
discussion spaces for their users. However, after linking the 2021 US Capitol
Riots and the activity of some groups on Parler, such as QAnon and Proud Boys,
on January 12, 2021, Parler was removed from the Apple and Google App Store and
suspended from Amazon Cloud hosting service. Parler would have to modify their
moderation policies to return to these online stores. After a month of
downtime, Parler was back online with a new set of user guidelines, which
reflected stricter content moderation, especially regarding the \emph{hate
speech} policy.
  In this paper, we studied the moderation changes performed by Parler and
their effect on the toxicity of its content. We collected a large longitudinal
Parler dataset with 17M parleys from 432K active users from February 2021 to
January 2022, after its return to the Internet and App Store. To the best of
our knowledge, this is the first study investigating the effectiveness of
content moderation techniques using data-driven approaches and also the first
Parler dataset after its brief hiatus. Our quasi-experimental time series
analysis indicates that after the change in Parler's moderation, the severe
forms of toxicity (above a threshold of 0.5) immediately decreased and
sustained. In contrast, the trend did not change for less severe threats and
insults (a threshold between 0.5 - 0.7). Finally, we found an increase in the
factuality of the news sites being shared, as well as a decrease in the number
of conspiracy or pseudoscience sources being shared.",2023-10-13,"Nihal Kumarswamy, Mohit Singhal, Shirin Nilizadeh"
"Is Fact-Checking Politically Neutral? Asymmetries in How U.S.
  Fact-Checking Organizations Pick Up False Statements Mentioning Political
  Elites","Political elites play an important role in the proliferation of online
misinformation. However, an understanding of how fact-checking platforms pick
up politicized misinformation for fact-checking is still in its infancy. Here,
we conduct an empirical analysis of mentions of U.S. political elites within
fact-checked statements. For this purpose, we collect a comprehensive dataset
consisting of 35,014 true and false statements that have been fact-checked by
two major fact-checking organizations (Snopes, PolitiFact) in the U.S. between
2008 and 2023, i.e., within an observation period of 15 years. Subsequently, we
perform content analysis and explanatory regression modeling to analyze how
veracity is linked to mentions of U.S. political elites in fact-checked
statements. Our analysis yields the following main findings: (i) Fact-checked
false statements are, on average, 20% more likely to mention political elites
than true fact-checked statements. (ii) There is a partisan asymmetry such that
fact-checked false statements are 88.1% more likely to mention Democrats, but
26.5% less likely to mention Republicans, compared to fact-checked true
statements. (iii) Mentions of political elites in fact-checked false statements
reach the highest level during the months preceding elections. (iv)
Fact-checked false statements that mention political elites carry stronger
other-condemning emotions and are more likely to be pro-Republican, compared to
fact-checked true statements. In sum, our study offers new insights into
understanding mentions of political elites in false statements on U.S.
fact-checking platforms, and bridges important findings at the intersection
between misinformation and politicization.",2023-10-13,"Yuwei Chuai, Jichang Zhao, Nicolas Pröllochs, Gabriele Lenzini"
"Understanding the Humans Behind Online Misinformation: An Observational
  Study Through the Lens of the COVID-19 Pandemic","The proliferation of online misinformation has emerged as one of the biggest
threats to society. Considerable efforts have focused on building
misinformation detection models, still the perils of misinformation remain
abound. Mitigating online misinformation and its ramifications requires a
holistic approach that encompasses not only an understanding of its intricate
landscape in relation to the complex issue and topic-rich information ecosystem
online, but also the psychological drivers of individuals behind it. Adopting a
time series analytic technique and robust causal inference-based design, we
conduct a large-scale observational study analyzing over 32 million COVID-19
tweets and 16 million historical timeline tweets. We focus on understanding the
behavior and psychology of users disseminating misinformation during COVID-19
and its relationship with the historical inclinations towards sharing
misinformation on Non-COVID domains before the pandemic. Our analysis
underscores the intricacies inherent to cross-domain misinformation, and
highlights that users' historical inclination toward sharing misinformation is
positively associated with their present behavior pertaining to misinformation
sharing on emergent topics and beyond. This work may serve as a valuable
foundation for designing user-centric inoculation strategies and
ecologically-grounded agile interventions for effectively tackling online
misinformation.",2023-10-12,"Mohit Chandra, Anush Mattapalli, Munmun De Choudhury"
"CODY: A graph-based framework for the analysis of COnversation DYnamics
  in online social networks","Conversations are an integral part of online social media, and gaining
insights into these conversations is of significant value for many commercial
as well as academic use cases. From a computational perspective, however,
analyzing conversation data is complex, and numerous aspects must be
considered. Next to the structure of conversations, the discussed content - as
well as their dynamics - have to be taken into account. Still, most existing
modelling and analysis approaches focus only on one of these aspects and, in
particular, lack the capability to investigate the temporal evolution of a
conversation. To address these shortcomings, in this work, we present CODY, a
content-aware, graph-based framework to study the dynamics of online
conversations along multiple dimensions. Its capabilities are extensively
demonstrated by conducting three experiments based on a large conversation
dataset from the German political Twittersphere. First, the posting activity
across the lifetime of conversations is examined. We find that posting activity
follows an exponential saturation pattern. Based on this activity model, we
develop a volume-based sampling method to study conversation dynamics using
temporal network snapshots. In a second experiment, we focus on the evolution
of a conversation's structure and leverage a novel metric, the temporal Wiener
index, for that. Results indicate that as conversations progress, a
conversation's structure tends to be less sprawling and more centered around
the original seed post. Furthermore, focusing on the dynamics of content in
conversations, the evolution of hashtag usage within conversations is studied.
Initially used hashtags do not necessarily keep their dominant prevalence
throughout the lifetime of a conversation. Instead, various ""hashtag hijacking""
scenarios are found.",2023-10-12,"John Ziegler, Fabian Kneissl, Michael Gertz"
Local Graph Clustering with Noisy Labels,"The growing interest in machine learning problems over graphs with additional
node information such as texts, images, or labels has popularized methods that
require the costly operation of processing the entire graph. Yet, little effort
has been made to the development of fast local methods (i.e. without accessing
the entire graph) that extract useful information from such data. To that end,
we propose a study of local graph clustering using noisy node labels as a proxy
for additional node information. In this setting, nodes receive initial binary
labels based on cluster affiliation: 1 if they belong to the target cluster and
0 otherwise. Subsequently, a fraction of these labels is flipped. We
investigate the benefits of incorporating noisy labels for local graph
clustering. By constructing a weighted graph with such labels, we study the
performance of graph diffusion-based local clustering method on both the
original and the weighted graphs. From a theoretical perspective, we consider
recovering an unknown target cluster with a single seed node in a random graph
with independent noisy node labels. We provide sufficient conditions on the
label noise under which, with high probability, using diffusion in the weighted
graph yields a more accurate recovery of the target cluster. This approach
proves more effective than using the given labels alone or using diffusion in
the label-free original graph. Empirically, we show that reliable node labels
can be obtained with just a few samples from an attributed graph. Moreover,
utilizing these labels via diffusion in the weighted graph leads to
significantly better local clustering performance across several real-world
datasets, improving F1 scores by up to 13%.",2023-10-12,"Artur Back de Luca, Kimon Fountoulakis, Shenghao Yang"
Social Approval and Network Homophily as Motivators of Online Toxicity,"Online hate messaging is a pervasive issue plaguing the well-being of social
media users. This research empirically investigates a novel theory positing
that online hate may be driven primarily by the pursuit of social approval
rather than a direct desire to harm the targets. Results show that toxicity is
homophilous in users' social networks and that a user's propensity for
hostility can be predicted by their social networks. We also illustrate how
receiving greater or fewer social engagements in the form of likes, retweets,
quotes, and replies affects a user's subsequent toxicity. We establish a clear
connection between receiving social approval signals and increases in
subsequent toxicity. Being retweeted plays a particularly prominent role in
escalating toxicity. Results also show that not receiving expected levels of
social approval leads to decreased toxicity. We discuss the important
implications of our research and opportunities to combat online hate.",2023-10-11,"Julie Jiang, Luca Luceri, Joseph B. Walther, Emilio Ferrara"
"ClausewitzGPT Framework: A New Frontier in Theoretical Large Language
  Model Enhanced Information Operations","In a digital epoch where cyberspace is the emerging nexus of geopolitical
contention, the melding of information operations and Large Language Models
(LLMs) heralds a paradigm shift, replete with immense opportunities and
intricate challenges. As tools like the Mistral 7B LLM (Mistral, 2023)
democratise access to LLM capabilities (Jin et al., 2023), a vast spectrum of
actors, from sovereign nations to rogue entities (Howard et al., 2023), find
themselves equipped with potent narrative-shaping instruments (Goldstein et
al., 2023). This paper puts forth a framework for navigating this brave new
world in the ""ClausewitzGPT"" equation. This novel formulation not only seeks to
quantify the risks inherent in machine-speed LLM-augmented operations but also
underscores the vital role of autonomous AI agents (Wang, Xie, et al., 2023).
These agents, embodying ethical considerations (Hendrycks et al., 2021), emerge
as indispensable components (Wang, Ma, et al., 2023), ensuring that as we race
forward, we do not lose sight of moral compasses and societal imperatives.
  Mathematically underpinned and inspired by the timeless tenets of
Clausewitz's military strategy (Clausewitz, 1832), this thesis delves into the
intricate dynamics of AI-augmented information operations. With references to
recent findings and research (Department of State, 2023), it highlights the
staggering year-on-year growth of AI information campaigns (Evgeny Pashentsev,
2023), stressing the urgency of our current juncture. The synthesis of
Enlightenment thinking, and Clausewitz's principles provides a foundational
lens, emphasising the imperative of clear strategic vision, ethical
considerations, and holistic understanding in the face of rapid technological
advancement.",2023-10-11,Benjamin Kereopa-Yorke
"Leveraging Twitter Data for Sentiment Analysis of Transit User Feedback:
  An NLP Framework","Traditional methods of collecting user feedback through transit surveys are
often time-consuming, resource intensive, and costly. In this paper, we propose
a novel NLP-based framework that harnesses the vast, abundant, and inexpensive
data available on social media platforms like Twitter to understand users'
perceptions of various service issues. Twitter, being a microblogging platform,
hosts a wealth of real-time user-generated content that often includes valuable
feedback and opinions on various products, services, and experiences. The
proposed framework streamlines the process of gathering and analyzing user
feedback without the need for costly and time-consuming user feedback surveys
using two techniques. First, it utilizes few-shot learning for tweet
classification within predefined categories, allowing effective identification
of the issues described in tweets. It then employs a lexicon-based sentiment
analysis model to assess the intensity and polarity of the tweet sentiments,
distinguishing between positive, negative, and neutral tweets. The
effectiveness of the framework was validated on a subset of manually labeled
Twitter data and was applied to the NYC subway system as a case study. The
framework accurately classifies tweets into predefined categories related to
safety, reliability, and maintenance of the subway system and effectively
measured sentiment intensities within each category. The general findings were
corroborated through a comparison with an agency-run customer survey conducted
in the same year. The findings highlight the effectiveness of the proposed
framework in gauging user feedback through inexpensive social media data to
understand the pain points of the transit system and plan for targeted
improvements.",2023-10-11,"Adway Das, Abhishek Kumar Prajapati, Pengxiang Zhang, Mukund Srinath, Andisheh Ranjbari"
"Enhanced Graph Neural Networks with Ego-Centric Spectral Subgraph
  Embeddings Augmentation","Graph Neural Networks (GNNs) have shown remarkable merit in performing
various learning-based tasks in complex networks. The superior performance of
GNNs often correlates with the availability and quality of node-level features
in the input networks. However, for many network applications, such node-level
information may be missing or unreliable, thereby limiting the applicability
and efficacy of GNNs. To address this limitation, we present a novel approach
denoted as Ego-centric Spectral subGraph Embedding Augmentation (ESGEA), which
aims to enhance and design node features, particularly in scenarios where
information is lacking. Our method leverages the topological structure of the
local subgraph to create topology-aware node features. The subgraph features
are generated using an efficient spectral graph embedding technique, and they
serve as node features that capture the local topological organization of the
network. The explicit node features, if present, are then enhanced with the
subgraph embeddings in order to improve the overall performance. ESGEA is
compatible with any GNN-based architecture and is effective even in the absence
of node features. We evaluate the proposed method in a social network graph
classification task where node attributes are unavailable, as well as in a node
classification task where node features are corrupted or even absent. The
evaluation results on seven datasets and eight baseline models indicate up to a
10% improvement in AUC and a 7% improvement in accuracy for graph and node
classification tasks, respectively.",2023-10-10,"Anwar Said, Mudassir Shabbir, Tyler Derr, Waseem Abbas, Xenofon Koutsoukos"
"Deep Learning for Automatic Detection and Facial Recognition in Japanese
  Macaques: Illuminating Social Networks","Individual identification plays a pivotal role in ecology and ethology,
notably as a tool for complex social structures understanding. However,
traditional identification methods often involve invasive physical tags and can
prove both disruptive for animals and time-intensive for researchers. In recent
years, the integration of deep learning in research offered new methodological
perspectives through automatization of complex tasks. Harnessing object
detection and recognition technologies is increasingly used by researchers to
achieve identification on video footage. This study represents a preliminary
exploration into the development of a non-invasive tool for face detection and
individual identification of Japanese macaques (Macaca fuscata) through deep
learning. The ultimate goal of this research is, using identifications done on
the dataset, to automatically generate a social network representation of the
studied population. The current main results are promising: (i) the creation of
a Japanese macaques' face detector (Faster-RCNN model), reaching a 82.2%
accuracy and (ii) the creation of an individual recognizer for K{\=o}jima
island macaques population (YOLOv8n model), reaching a 83% accuracy. We also
created a K{\=o}jima population social network by traditional methods, based on
co-occurrences on videos. Thus, we provide a benchmark against which the
automatically generated network will be assessed for reliability. These
preliminary results are a testament to the potential of this innovative
approach to provide the scientific community with a tool for tracking
individuals and social network studies in Japanese macaques.",2023-10-10,"Julien Paulet, Axel Molina, Benjamin Beltzung, Takafumi Suzumura, Shinya Yamamoto, Cédric Sueur"
"Harmful Conspiracies in Temporal Interaction Networks: Understanding the
  Dynamics of Digital Wildfires through Phase Transitions","Shortly after the first COVID-19 cases became apparent in December 2020,
rumors spread on social media suggesting a connection between the virus and the
5G radiation emanating from the recently deployed telecommunications network.
In the course of the following weeks, this idea gained increasing popularity,
and various alleged explanations for how such a connection manifests emerged.
Ultimately, after being amplified by prominent conspiracy theorists, a series
of arson attacks on telecommunication equipment follows, concluding with the
kidnapping of telecommunication technicians in Peru. In this paper, we study
the spread of content related to a conspiracy theory with harmful consequences,
a so-called digital wildfire. In particular, we investigate the 5G and COVID-19
misinformation event on Twitter before, during, and after its peak in April and
May 2020. For this purpose, we examine the community dynamics in complex
temporal interaction networks underlying Twitter user activity. We assess the
evolution of such digital wildfires by appropriately defining the temporal
dynamics of communication in communities within social networks. We show that,
for this specific misinformation event, the number of interactions of the users
participating in a digital wildfire, as well as the size of the engaged
communities, both follow a power-law distribution. Moreover, our research
elucidates the possibility of quantifying the phases of a digital wildfire, as
per established literature. We identify one such phase as a critical
transition, marked by a shift from sporadic tweets to a global spread event,
highlighting the dramatic scaling of misinformation propagation.",2023-10-09,"Kaspara Skovli Gåsvær, Pedro G. Lind, Johannes Langguth, Morten Hjorth-Jensen, Michael Kreil, Daniel Thilo Schroeder"
A One-Size-Fits-All Approach to Improving Randomness in Paper Assignment,"The assignment of papers to reviewers is a crucial part of the peer review
processes of large publication venues, where organizers (e.g., conference
program chairs) rely on algorithms to perform automated paper assignment. As
such, a major challenge for the organizers of these processes is to specify
paper assignment algorithms that find appropriate assignments with respect to
various desiderata. Although the main objective when choosing a good paper
assignment is to maximize the expertise of each reviewer for their assigned
papers, several other considerations make introducing randomization into the
paper assignment desirable: robustness to malicious behavior, the ability to
evaluate alternative paper assignments, reviewer diversity, and reviewer
anonymity. However, it is unclear in what way one should randomize the paper
assignment in order to best satisfy all of these considerations simultaneously.
In this work, we present a practical, one-size-fits-all method for randomized
paper assignment intended to perform well across different motivations for
randomness. We show theoretically and experimentally that our method
outperforms currently-deployed methods for randomized paper assignment on
several intuitive randomness metrics, demonstrating that the randomized
assignments produced by our method are general-purpose.",2023-10-09,"Yixuan Even Xu, Steven Jecmen, Zimeng Song, Fei Fang"
Semiotics Networks Representing Perceptual Inference,"Every day, humans perceive objects and communicate these perceptions through
various channels. In this paper, we present a computational model designed to
track and simulate the perception of objects, as well as their representations
as conveyed in communication.
  We delineate two fundamental components of our internal representation,
termed ""observed"" and ""seen"", which we correlate with established concepts in
computer vision, namely encoding and decoding. These components are integrated
into semiotic networks, which simulate perceptual inference of object
perception and human communication.
  Our model of object perception by a person allows us to define object
perception by {\em a network}. We demonstrate this with an example of an image
baseline classifier by constructing a new network that includes the baseline
classifier and an additional layer. This layer produces the images ""perceived""
by the entire network, transforming it into a perceptualized image classifier.
This facilitates visualization of the acquired network.
  Within our network, the image representations become more efficient for
classification tasks when they are assembled and randomized. In our
experiments, the perceptualized network outperformed the baseline classifier on
MNIST training databases consisting of a restricted number of images.
  Our model is not limited to persons and can be applied to any system
featuring a loop involving the processing from ""internal"" to ""external""
representations.",2023-10-08,"David Kupeev, Eyal Nitzany"
Data-centric Graph Learning: A Survey,"The history of artificial intelligence (AI) has witnessed the significant
impact of high-quality data on various deep learning models, such as ImageNet
for AlexNet and ResNet. Recently, instead of designing more complex neural
architectures as model-centric approaches, the attention of AI community has
shifted to data-centric ones, which focuses on better processing data to
strengthen the ability of neural models. Graph learning, which operates on
ubiquitous topological data, also plays an important role in the era of deep
learning. In this survey, we comprehensively review graph learning approaches
from the data-centric perspective, and aim to answer three crucial questions:
(1) when to modify graph data, (2) what part of the graph data needs
modification to unlock the potential of various graph models, and (3) how to
safeguard graph models from problematic data influence. Accordingly, we propose
a novel taxonomy based on the stages in the graph learning pipeline, and
highlight the processing methods for different data structures in the graph
data, i.e., topology, feature and label. Furthermore, we analyze some potential
problems embedded in graph data and discuss how to solve them in a data-centric
manner. Finally, we provide some promising future directions for data-centric
graph learning.",2023-10-08,"Yuxin Guo, Deyu Bo, Cheng Yang, Zhiyuan Lu, Zhongjian Zhang, Jixi Liu, Yufei Peng, Chuan Shi"
"Deconstructing Cooperation and Ostracism via Multi-Agent Reinforcement
  Learning","Cooperation is challenging in biological systems, human societies, and
multi-agent systems in general. While a group can benefit when everyone
cooperates, it is tempting for each agent to act selfishly instead. Prior human
studies show that people can overcome such social dilemmas while choosing
interaction partners, i.e., strategic network rewiring. However, little is
known about how agents, including humans, can learn about cooperation from
strategic rewiring and vice versa. Here, we perform multi-agent reinforcement
learning simulations in which two agents play the Prisoner's Dilemma game
iteratively. Each agent has two policies: one controls whether to cooperate or
defect; the other controls whether to rewire connections with another agent.
This setting enables us to disentangle complex causal dynamics between
cooperation and network rewiring. We find that network rewiring facilitates
mutual cooperation even when one agent always offers cooperation, which is
vulnerable to free-riding. We then confirm that the network-rewiring effect is
exerted through agents' learning of ostracism, that is, connecting to
cooperators and disconnecting from defectors. However, we also find that
ostracism alone is not sufficient to make cooperation emerge. Instead,
ostracism emerges from the learning of cooperation, and existing cooperation is
subsequently reinforced due to the presence of ostracism. Our findings provide
insights into the conditions and mechanisms necessary for the emergence of
cooperation with network rewiring.",2023-10-06,"Atsushi Ueshima, Shayegan Omidshafiei, Hirokazu Shirado"
"Marketing to Children Through Online Targeted Advertising: Targeting
  Mechanisms and Legal Aspects","Many researchers and organizations, such as WHO and UNICEF, have raised
awareness of the dangers of advertisements targeted at children. While most
existing laws only regulate ads on television that may reach children,
lawmakers have been working on extending regulations to online advertising and,
for example, forbid (e.g., the DSA) or restrict (e.g., the COPPA) advertising
based on profiling to children. At first sight, ad platforms such as Google
seem to protect children by not allowing advertisers to target their ads to
users who are less than 18 years old. However, this paper shows that other
targeting features can be exploited to reach children. For example, on YouTube,
advertisers can target their ads to users watching a particular video through
placement-based targeting, a form of contextual targeting. Hence, advertisers
can target children by placing their ads in children-focused videos. Through a
series of ad experiments, we show that placement-based targeting is possible on
children-focused videos and enables marketing to children. In addition, our ad
experiments show that advertisers can use targeting based on profiling (e.g.,
interest, location, behavior) in combination with placement-based advertising
on children-focused videos. We discuss the lawfulness of these two practices
concerning DSA and COPPA. Finally, we investigate to which extent real-world
advertisers are employing placement-based targeting to reach children with ads
on YouTube. We propose a measurement methodology consisting of building a
Chrome extension to capture ads and instrument six browser profiles to watch
children-focused videos. Our results show that 7% of ads that appear in the
children-focused videos we test use placement-based targeting. Hence, targeting
children with ads on YouTube is not only hypothetically possible but also
occurs in practice...",2023-10-06,"Tinhinane Medjkoune, Oana Goga, Juliette Senechal"
"Mobility Segregation Dynamics and Residual Isolation During Pandemic
  Interventions","External shocks embody an unexpected and disruptive impact on the regular
life of people. This was the case during the COVID-19 outbreak that rapidly led
to changes in the typical mobility patterns in urban areas. In response, people
reorganised their daily errands throughout space. However, these changes might
not have been the same across socioeconomic classes leading to possibile
additional detrimental effects on inequality due to the pandemic. In this paper
we study the reorganisation of mobility segregation networks due to external
shocks and show that the diversity of visited places in terms of locations and
socioeconomic status is affected by the enforcement of mobility restriction
during pandemic. We use the case of COVID-19 as a natural experiment in several
cities to observe not only the effect of external shocks but also its mid-term
consequences and residual effects. We build on anonymised and privacy-preserved
mobility data in four cities: Bogota, Jakarta, London, and New York. We couple
mobility data with socioeconomic information to capture inequalities in
mobility among different socioeconomic groups and see how it changes
dynamically before, during, and after different lockdown periods. We find that
the first lockdowns induced considerable increases in mobility segregation in
each city, while loosening mobility restrictions did not necessarily diminished
isolation between different socioeconomic groups, as mobility mixing has not
recovered fully to its pre-pandemic level even weeks after the interruption of
interventions. Our results suggest that a one fits-all policy does not equally
affect the way people adjust their mobility, which calls for socioeconomically
informed intervention policies in the future.",2023-10-05,"Rafiazka Millanida Hilman, Manuel García-Herranz, Vedran Sekara, Márton Karsai"
IoTScent: Enhancing Forensic Capabilities in Internet of Things Gateways,"The widespread deployment of Consumer Internet of Things devices in proximity
to human activities makes them digital observers of our daily actions. This has
led to a new field of digital forensics, known as IoT Forensics, where digital
traces generated by IoT devices can serve as key evidence for forensic
investigations. Thus, there is a need to develop tools that can efficiently
acquire and store network traces from IoT ecosystems. This paper presents
IoTScent, an open-source IoT forensic tool that enables IoT gateways and Home
Automation platforms to perform IoT traffic capture and analysis. Unlike other
works focusing on IP-based protocols, IoTScent is specifically designed to
operate over IEEE 802.15.4-based traffic, which is the basis for many
IoT-specific protocols such as Zigbee, 6LoWPAN and Thread. IoTScent offers live
traffic capture and feature extraction capabilities, providing a framework for
forensic data collection that simplifies the task of setting up a data
collection pipeline, automating the data collection process, and providing
ready-made features that can be used for forensic evidence extraction. This
work provides a comprehensive description of the IoTScent tool, including a
practical use case that demonstrates the use of the tool to perform device
identification from Zigbee traffic. The study presented here significantly
contributes to the ongoing research in IoT Forensics by addressing the
challenges faced in the field and publicly releasing the IoTScent tool.",2023-10-05,"Antonio Boiano, Alessandro Enrico Cesare Redondi, Matteo Cesana"
"Differential Game Strategies for Social Networks with Self-Interested
  Individuals","A social network population engages in collective actions as a direct result
of forming a particular opinion. The strategic interactions among the
individuals acting independently and selfishly naturally portray a
noncooperative game. Nash equilibrium allows for self-enforcing strategic
interactions between selfish and self-interested individuals. This paper
presents a differential game approach to the opinion formation problem in
social networks to investigate the evolution of opinions as a result of a Nash
equilibrium. The opinion of each individual is described by a differential
equation, which is the continuous-time Hegselmann-Krause model for opinion
dynamics with a time delay in input. The objective of each individual is to
seek optimal strategies for her own opinion evolution by minimizing an
individual cost function. Two differential game problems emerge, one for a
population that is not stubborn and another for a population that is stubborn.
The open-loop Nash equilibrium actions and their associated opinion
trajectories are derived for both differential games using Pontryagin's
principle. Additionally, the receding horizon control scheme is used to
practice feedback strategies where the information flow is restricted by fixed
and complete social graphs as well as the second neighborhood concept. The game
strategies were executed on the well-known Zachary's Karate Club social
network. The resulting opinion trajectories associated with the game strategies
showed consensus, polarization, and disagreement in final opinions.",2023-10-05,Hossein B. Jond
"Non-coresident family as a driver of migration change in a crisis: The
  case of the COVID-19 pandemic","Changes in U.S. migration during the COVID-19 pandemic show that many moved
to less populated cities from larger cities, deviating from previous trends. In
this study, building on prior work in the literature showing that the abundance
of family ties is inversely related to population size, we analyze these
migration changes with a focus on the crucial, yet overlooked factor of
extended family. Employing two large-scale data sets, census microdata and
mobile phone GPS relocation data, we show a collection of empirical results
that paints a picture of migration change affected by kin. Namely, we find that
people migrated closer to family at higher rates after the COVID-19 pandemic
started. Moreover, even controlling for factors such as population density and
cost of living, we find that changes in net in-migration tended to be larger
and positive in cities with larger proportions of people who can be parents to
adult children (our proxy for parental family availability, which is also
inversely related to population size). Our study advances the
demography-disaster nexus and amplifies ongoing literature highlighting the
role of broader kinship systems in large-scale socioeconomic phenomena.",2023-10-05,"Unchitta Kan, Jericho McLeod, Eduardo López"
Finding coherent node groups in directed graphs,"Summarizing a large graph by grouping the nodes into clusters is a standard
technique for studying the given network. Traditionally, the order of the
discovered groups does not matter. However, there are applications where, for
example, given a directed graph, we would like to find coherent groups while
minimizing the backward cross edges. More formally, in this paper, we study a
problem where we are given a directed network and are asked to partition the
graph into a sequence of coherent groups while attempting to conform to the
cross edges. We assume that nodes in the network have features, and we measure
the group coherence by comparing these features. Furthermore, we incorporate
the cross edges by penalizing the forward cross edges and backward cross edges
with different weights. If the weights are set to 0, then the problem is
equivalent to clustering. However, if we penalize the backward edges
significantly more, then the order of discovered groups matters, and we can
view our problem as a generalization of a classic segmentation problem. To
solve the algorithm we consider a common iterative approach where we solve the
groups given the centroids, and then find the centroids given the groups. We
show that - unlike in clustering - the first subproblem is NP-hard. However, we
show that if the underlying graph is a tree we can solve the subproblem with
dynamic programming. In addition, if the number of groups is 2, we can solve
the subproblem with a minimum cut. For the more general case, we propose a
heuristic where we optimize each pair of groups separately while keeping the
remaining groups intact. We also propose a greedy search where nodes are moved
between the groups while optimizing the overall loss. We demonstrate with our
experiments that the algorithms are practical and yield interpretable results.",2023-10-04,"Iiro Kumpulainen, Nikolaj Tatti"
"Exploring the Impact of Disrupted Peer-to-Peer Communications on Fully
  Decentralized Learning in Disaster Scenarios","Fully decentralized learning enables the distribution of learning resources
and decision-making capabilities across multiple user devices or nodes, and is
rapidly gaining popularity due to its privacy-preserving and decentralized
nature. Importantly, this crowdsourcing of the learning process allows the
system to continue functioning even if some nodes are affected or disconnected.
In a disaster scenario, communication infrastructure and centralized systems
may be disrupted or completely unavailable, hindering the possibility of
carrying out standard centralized learning tasks in these settings. Thus, fully
decentralized learning can help in this case. However, transitioning from
centralized to peer-to-peer communications introduces a dependency between the
learning process and the topology of the communication graph among nodes. In a
disaster scenario, even peer-to-peer communications are susceptible to abrupt
changes, such as devices running out of battery or getting disconnected from
others due to their position. In this study, we investigate the effects of
various disruptions to peer-to-peer communications on decentralized learning in
a disaster setting. We examine the resilience of a decentralized learning
process when a subset of devices drop from the process abruptly. To this end,
we analyze the difference between losing devices holding data, i.e., potential
knowledge, vs. devices contributing only to the graph connectivity, i.e., with
no data. Our findings on a Barabasi-Albert graph topology, where training data
is distributed across nodes in an IID fashion, indicate that the accuracy of
the learning process is more affected by a loss of connectivity than by a loss
of data. Nevertheless, the network remains relatively robust, and the learning
process can achieve a good level of accuracy.",2023-10-04,"Luigi Palmieri, Chiara Boldrini, Lorenzo Valerio, Andrea Passarella, Marco Conti"
Analyzing Key Users' behavior trends in Volunteer-Based Networks,"Online social networks usage has increased significantly in the last decade
and continues to grow in popularity. Multiple social platforms use volunteers
as a central component. The behavior of volunteers in volunteer-based networks
has been studied extensively in recent years. Here, we explore the development
of volunteer-based social networks, primarily focusing on their key users'
behaviors and activities. We developed two novel algorithms: the first reveals
key user behavior patterns over time; the second utilizes machine learning
methods to generate a forecasting model that can predict the future behavior of
key users, including whether they will remain active donors or change their
behavior to become mainly recipients, and vice-versa. These algorithms allowed
us to analyze the factors that significantly influence behavior predictions.
  To evaluate our algorithms, we utilized data from over 2.4 million users on a
peer-to-peer food-sharing online platform. Using our algorithm, we identified
four main types of key user behavior patterns that occur over time. Moreover,
we succeeded in forecasting future active donor key users and predicting the
key users that would change their behavior to donors, with an accuracy of up to
89.6%. These findings provide valuable insights into the behavior of key users
in volunteer-based social networks and pave the way for more effective
communities-building in the future, while using the potential of machine
learning for this goal.",2023-10-04,"Nofar Piterman, Tamar Makov, Michael Fire"
"Community Archetypes: An Empirical Framework for Guiding Research
  Methodologies to Reflect User Experiences of Sense of Virtual Community","Humans need a sense of community (SOC), and social media platforms afford
opportunities to address this need by providing users with a sense of virtual
community (SOVC). This paper explores SOVC on Reddit and is motivated by two
goals: (1) providing researchers with an excellent resource for methodological
decisions in studies of Reddit communities; and (2) creating the foundation for
a new class of research methods and community support tools that reflect users'
experiences of SOVC. To ensure that methods are respectfully and ethically
designed in service and accountability to impacted communities, our work takes
a qualitative, community-centered approach by engaging with two key stakeholder
groups. First, we interviewed 21 researchers to understand how they study
""community"" on Reddit. Second, we surveyed 12 subreddits to gain insight into
user experiences of SOVC. Results show that some research methods can broadly
reflect users' SOVC regardless of the topic or type of subreddit. However, user
responses also evidenced the existence of five distinct Community Archetypes:
Topical Q&A, Learning & Perspective Broadening, Social Support, Content
Generation, and Affiliation with an Entity. We offer the Community Archetypes
framework to support future work in designing methods that align more closely
with user experiences of SOVC and to create community support tools that can
meaningfully nourish the human need for SOC/SOVC in our modern world.",2023-10-04,"Gale H. Prinster, C. Estelle Smith, Chenhao Tan, Brian C. Keegan"
"RouteKG: A knowledge graph-based framework for route prediction on road
  networks","Short-term route prediction on road networks allows us to anticipate the
future trajectories of road users, enabling a plethora of intelligent
transportation applications such as dynamic traffic control or personalized
route recommendation. Despite recent advances in this area, existing methods
focus primarily on learning sequential transition patterns, neglecting the
inherent spatial structural relations in road networks that can affect human
routing decisions. To fill this gap, this paper introduces RouteKG, a novel
Knowledge Graph-based framework for route prediction. Specifically, we
construct a Knowledge Graph on the road network, thereby learning and
leveraging spatial relations, especially moving directions, which are crucial
for human navigation. Moreover, an n-ary tree-based algorithm is introduced to
efficiently generate top-K routes in a batch mode, enhancing scalability and
computational efficiency. To further optimize the prediction performance, a
rank refinement module is incorporated to fine-tune the candidate route
rankings. The model performance is evaluated using two real-world vehicle
trajectory datasets from two Chinese cities, Chengdu and Shanghai, under
various practical scenarios. The results demonstrate a significant improvement
in accuracy over baseline methods.We further validate our model through a case
study that utilizes the pre-trained model as a simulator for real-time traffic
flow estimation at the link level. The proposed RouteKG promises wide-ranging
applications in vehicle navigation, traffic management, and other intelligent
transportation tasks.",2023-10-03,"Yihong Tang, Zhan Zhao, Weipeng Deng, Shuyu Lei, Yuebing Liang, Zhenliang Ma"
"HyperGraphDis: Leveraging Hypergraphs for Contextual and Social-Based
  Disinformation Detection","In light of the growing impact of disinformation on social, economic, and
political landscapes, accurate and efficient identification methods are
increasingly critical. This paper introduces HyperGraphDis, a novel approach
for detecting disinformation on Twitter that employs a hypergraph-based
representation to capture (i) the intricate social structures arising from
retweet cascades, (ii) relational features among users, and (iii) semantic and
topical nuances. Evaluated on four Twitter datasets -- focusing on the 2016
U.S. Presidential election and the COVID-19 pandemic -- HyperGraphDis
outperforms existing methods in both accuracy and computational efficiency,
underscoring its effectiveness and scalability for tackling the challenges
posed by disinformation dissemination. HyperGraphDis displays exceptional
performance on a COVID-19-related dataset, achieving an impressive F1 score
(weighted) of approximately 89.5%. This result represents a notable improvement
of around 4% compared to the other state-of-the-art methods. Additionally,
significant enhancements in computation time are observed for both model
training and inference. In terms of model training, completion times are
accelerated by a factor ranging from 2.3 to 7.6 compared to the second-best
method across the four datasets. Similarly, during inference, computation times
are 1.3 to 6.8 times faster than the state-of-the-art.",2023-10-02,"Nikos Salamanos, Pantelitsa Leonidou, Nikolaos Laoutaris, Michael Sirivianos, Maria Aspri, Marius Paraschiv"
Epistemic integration and social segregation of AI in neuroscience,"In recent years, Artificial Intelligence (AI) shows a spectacular ability of
insertion inside a variety of disciplines which use it for scientific
advancements and which sometimes improve it for their conceptual and
methodological needs. According to the transverse science framework originally
conceived by Shinn and Joerges, AI can be seen as an instrument which is
progressively acquiring a universal character through its diffusion across
science. In this paper we address empirically one aspect of this diffusion,
namely the penetration of AI into a specific field of research. Taking
neuroscience as a case study, we conduct a scientometric analysis of the
development of AI in this field. We especially study the temporal egocentric
citation network around the articles included in this literature, their
represented journals and their authors linked together by a temporal
collaboration network. We find that AI is driving the constitution of a
particular disciplinary ecosystem in neuroscience which is distinct from other
subfields, and which is gathering atypical scientific profiles who are coming
from neuroscience or outside it. Moreover we observe that this AI community in
neuroscience is socially confined in a specific subspace of the neuroscience
collaboration network, which also publishes in a small set of dedicated
journals that are mostly active in AI research. According to these results, the
diffusion of AI in a discipline such as neuroscience didn't really challenge
its disciplinary orientations but rather induced the constitution of a
dedicated socio-cognitive environment inside this field.",2023-10-02,"Sylvain Fontaine, Floriana Gargiulo, Michel Dubois, Paola Tubaro"
"Visual Political Communication in a Polarized Society: A Longitudinal
  Study of Brazilian Presidential Elections on Instagram","In today's digital age, images have emerged as powerful tools for politicians
to engage with their voters on social media platforms. Visual content possesses
a unique emotional appeal that often leads to increased user engagement.
However, research on visual communication remains relatively limited,
particularly in the Global South. This study aims to bridge this gap by
employing a combination of computational methods and qualitative approach to
investigate the visual communication strategies employed in a dataset of 11,263
Instagram posts by 19 Brazilian presidential candidates in 2018 and 2022
national elections. Through two studies, we observed consistent patterns across
these candidates on their use of visual political communication. Notably, we
identify a prevalence of celebratory and positively toned images. They also
exhibit a strong sense of personalization, portraying candidates connected with
their voters on a more emotional level. Our research also uncovers unique
contextual nuances specific to the Brazilian political landscape. We note a
substantial presence of screenshots from news websites and other social media
platforms. Furthermore, text-edited images with portrayals emerge as a
prominent feature. In light of these results, we engage in a discussion
regarding the implications for the broader field of visual political
communication. This article serves as a testament to the pivotal role that
Instagram has played in shaping the narrative of two fiercely polarized
Brazilian elections, casting a revealing light on the ever-evolving dynamics of
visual political communication in the digital age. Finally, we propose avenues
for future research in the realm of visual political communication.",2023-09-30,"Mathias-Felipe de-Lima-Santos, Isabella Gonçalves, Marcos G. Quiles, Lucia Mesquita, Wilson Ceron, Maria Clara Couto Lorena"
Degree Distribution Identifiability of Stochastic Kronecker Graphs,"Large-scale analysis of the distributions of the network graphs observed in
naturally-occurring phenomena has revealed that the degrees of such graphs
follow a power-law or lognormal distribution. Seshadhri, Pinar, and Kolda (J.
ACM, 2013) proved that stochastic Kronecker graph (SKG) models cannot generate
graphs with degree distribution that follows a power-law or lognormal
distribution. As a result, variants of the SKG model have been proposed to
generate graphs which approximately follow degree distributions, without any
significant oscillations. However, all existing solutions either require
significant additional parameterization or have no provable guarantees on the
degree distribution.
  -- In this work, we present statistical and computational identifiability
notions which imply the separation of SKG models. Specifically, we prove that
SKG models in different identifiability classes can be separated by the
existence of isolated vertices and connected components in their corresponding
generated graphs. This could explain the large (i.e., $>50\%$) fraction of
isolated vertices in some popular graph generation benchmarks.
  -- We present and analyze an efficient algorithm that can get rid of
oscillations in the degree distribution by mixing seeds of relative prime
dimensions. For an initial $2\times 1$ and $2\times 2$ seed, a crucial
subroutine of this algorithm solves a degree-2 and degree-4 optimization
problem in the variables of the initial seed, respectively. We generalize this
approach to solving optimization problems for $m\times n$ seeds, for any $m,
n\in\mathbb{N}$.
  -- The use of $3\times 3$ seeds alone cannot get rid of significant
oscillations. We prove that such seeds result in degree distribution that is
bounded above by an exponential tail and thus cannot result in a power-law or
lognormal.",2023-09-29,"Daniel Alabi, Dimitris Kalimeris"
"Differentially Private Computation of Basic Reproduction Numbers in
  Networked Epidemic Models","The basic reproduction number of a networked epidemic model, denoted $R_0$,
can be computed from a network's topology to quantify epidemic spread. However,
disclosure of $R_0$ risks revealing sensitive information about the underlying
network, such as an individual's relationships within a social network.
Therefore, we propose a framework to compute and release $R_0$ in a
differentially private way. First, we provide a new result that shows how $R_0$
can be used to bound the level of penetration of an epidemic within a single
community as a motivation for the need of privacy, which may also be of
independent interest. We next develop a privacy mechanism to formally safeguard
the edge weights in the underlying network when computing $R_0$. Then we
formalize tradeoffs between the level of privacy and the accuracy of values of
the privatized $R_0$. To show the utility of the private $R_0$ in practice, we
use it to bound this level of penetration under privacy, and concentration
bounds on these analyses show they remain accurate with privacy implemented. We
apply our results to real travel data gathered during the spread of COVID-19,
and we show that, under real-world conditions, we can compute $R_0$ in a
differentially private way while incurring errors as low as $7.6\%$ on average.",2023-09-29,"Bo Chen, Baike She, Calvin Hawkins, Alex Benvenuti, Brandon Fallin, Philip E. Paré, Matthew Hale"
"Rationality and connectivity in stochastic learning for networked
  coordination games","Coordination is a desirable feature in many multi-agent systems such as
robotic and socioeconomic networks. We consider a task allocation problem as a
binary networked coordination game over an undirected regular graph. Each agent
in the graph has bounded rationality, and uses a distributed stochastic
learning algorithm to update its action choice conditioned on the actions
currently played by its neighbors. After establishing that our framework leads
to a potential game, we analyze the regime of bounded rationality, where the
agents are allowed to make sub-optimal decisions with some probability. Our
analysis shows that there is a relationship between the connectivity of the
network, and the rationality of the agents. In particular, we show that in some
scenarios, an agent can afford to be less rational and still converge to a near
optimal collective strategy, provided that its connectivity degree increases.
Such phenomenon is akin to the wisdom of crowds.",2023-09-29,"Yifei Zhang, Marcos M. Vasconcelos"
"A Small World of Bad Guys: Investigating the Behavior of Hacker Groups
  in Cyber-Attacks","This paper explores the behaviour of malicious hacker groups operating in
cyberspace and how they organize themselves in structured networks. To better
understand these groups, the paper uses Social Network Analysis (SNA) to
analyse the interactions and relationships among several malicious hacker
groups. The study uses a tested dataset as its primary source, providing an
empirical analysis of the cooperative behaviours exhibited by these groups. The
study found that malicious hacker groups tend to form close-knit networks where
they consult, coordinate with, and assist each other in carrying out their
attacks. The study also identified a ""small world"" phenomenon within the
population of malicious actors, which suggests that these groups establish
interconnected relationships to facilitate their malicious operations. The
small world phenomenon indicates that the actor-groups are densely connected,
but they also have a small number of connections to other groups, allowing for
efficient communication and coordination of their activities.",2023-09-28,"Giampiero Giacomello, Antonio Iovanella, Luigi Martino"
"Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News
  Detection","Despite considerable advances in automated fake news detection, due to the
timely nature of news, it remains a critical open question how to effectively
predict the veracity of news articles based on limited fact-checks. Existing
approaches typically follow a ""Train-from-Scratch"" paradigm, which is
fundamentally bounded by the availability of large-scale annotated data. While
expressive pre-trained language models (PLMs) have been adapted in a
""Pre-Train-and-Fine-Tune"" manner, the inconsistency between pre-training and
downstream objectives also requires costly task-specific supervision. In this
paper, we propose ""Prompt-and-Align"" (P&A), a novel prompt-based paradigm for
few-shot fake news detection that jointly leverages the pre-trained knowledge
in PLMs and the social context topology. Our approach mitigates label scarcity
by wrapping the news article in a task-related textual prompt, which is then
processed by the PLM to directly elicit task-specific knowledge. To supplement
the PLM with social context without inducing additional training overheads,
motivated by empirical observation on user veracity consistency (i.e., social
users tend to consume news of the same veracity type), we further construct a
news proximity graph among news articles to capture the veracity-consistent
signals in shared readerships, and align the prompting predictions along the
graph edges in a confidence-informed manner. Extensive experiments on three
real-world benchmarks demonstrate that P&A sets new states-of-the-art for
few-shot fake news detection performance by significant margins.",2023-09-28,"Jiaying Wu, Shen Li, Ailin Deng, Miao Xiong, Bryan Hooi"
Context-Based Tweet Engagement Prediction,"Twitter is currently one of the biggest social media platforms. Its users may
share, read, and engage with short posts called tweets. For the ACM Recommender
Systems Conference 2020, Twitter published a dataset around 70 GB in size for
the annual RecSys Challenge. In 2020, the RecSys Challenge invited
participating teams to create models that would predict engagement likelihoods
for given user-tweet combinations. The submitted models predicting like, reply,
retweet, and quote engagements were evaluated based on two metrics: area under
the precision-recall curve (PRAUC) and relative cross-entropy (RCE).
  In this diploma thesis, we used the RecSys 2020 Challenge dataset and
evaluation procedure to investigate how well context alone may be used to
predict tweet engagement likelihood. In doing so, we employed the Spark engine
on TU Wien's Little Big Data Cluster to create scalable data preprocessing,
feature engineering, feature selection, and machine learning pipelines. We
manually created just under 200 additional features to describe tweet context.
  The results indicate that features describing users' prior engagement history
and the popularity of hashtags and links in the tweet were the most
informative. We also found that factors such as the prediction algorithm,
training dataset size, training dataset sampling method, and feature selection
significantly affect the results. After comparing the best results of our
context-only prediction models with content-only models and with models
developed by the Challenge winners, we identified that the context-based models
underperformed in terms of the RCE score. This work thus concludes by situating
this discrepancy and proposing potential improvements to our implementation,
which is shared in a public git repository.",2023-09-28,Jovan Jeromela
Brand Network Booster: A new system for improving brand connectivity,"This paper presents a new decision support system offered for an in-depth
analysis of semantic networks, which can provide insights for a better
exploration of a brand's image and the improvement of its connectivity. In
terms of network analysis, we show that this goal is achieved by solving an
extended version of the Maximum Betweenness Improvement problem, which includes
the possibility of considering adversarial nodes, constrained budgets, and
weighted networks - where connectivity improvement can be obtained by adding
links or increasing the weight of existing connections. Our contribution
includes a new algorithmic framework and the integration of this framework into
a software system called Brand Network Booster (BNB), which supports brand
connectivity evaluation and improvement. We present this new system together
with three case studies, and we also discuss its performance. Our tool and
approach are valuable to both network scholars and in facilitating strategic
decision-making processes for marketing and communication managers across
various sectors, be it public or private.",2023-09-28,"J. Cancellieri, W. Didimo, A. Fronzetti Colladon, F. Montecchiani, R. Vestrelli"
Influence Pathway Discovery on Social Media,"This paper addresses influence pathway discovery, a key emerging problem in
today's online media. We propose a discovery algorithm that leverages recently
published work on unsupervised interpretable ideological embedding, a mapping
of ideological beliefs (done in a self-supervised fashion) into interpretable
low-dimensional spaces. Computing the ideological embedding at scale allows one
to analyze correlations between the ideological positions of leaders,
influencers, news portals, or population segments, deriving potential influence
pathways. The work is motivated by the importance of social media as the
preeminent means for global interactions and collaborations on today's
Internet, as well as their frequent (mis-)use to wield influence that targets
social beliefs and attitudes of selected populations. Tools that enable the
understanding and mapping of influence propagation through population segments
on social media are therefore increasingly important. In this paper, influence
is measured by the perceived ideological shift over time that is correlated
with influencers' activity. Correlated shifts in ideological embeddings
indicate changes, such as swings/switching (among competing ideologies),
polarization (depletion of neutral ideological positions),
escalation/radicalization (shifts to more extreme versions of the ideology), or
unification/cooldown (shifts towards more neutral stances). Case-studies are
presented to explore selected influence pathways (i) in a recent French
election, (ii) during political discussions in the Philippines, and (iii) for
some Russian messaging during the Russia/Ukraine conflict.",2023-09-27,"Xinyi Liu, Ruijie Wang, Dachun Sun, Jinning Li, Christina Youn, You Lyu, Jianyuan Zhan, Dayou Wu, Xinhe Xu, Mingjun Liu, Xinshuo Lei, Zhihao Xu, Yutong Zhang, Zehao Li, Qikai Yang, Tarek Abdelzaher"
Dynamics of Ideological Biases of Social Media Users,"Humanity for centuries has perfected skills of interpersonal interactions and
evolved patterns that enable people to detect lies and deceiving behavior of
others in face-to-face settings. Unprecedented growth of people's access to
mobile phones and social media raises an important question: How does this new
technology influence people's interactions and support the use of traditional
patterns? In this article, we answer this question for homophily-driven
patterns in social media. In our previous studies, we found that, on a
university campus, changes in student opinions were driven by the desire to
hold popular opinions. Here, we demonstrate that the evolution of online
platform-wide opinion groups is driven by the same desire. We focus on two
social media: Twitter and Parler, on which we tracked the political biases of
their users. On Parler, an initially stable group of Right-biased users evolved
into a permanent Right-leaning echo chamber dominating weaker, transient groups
of members with opposing political biases. In contrast, on Twitter, the initial
presence of two large opposing bias groups led to the evolution of a bimodal
bias distribution, with a high degree of polarization. We capture the movement
of users from the initial to final bias groups during the tracking period. We
also show that user choices are influenced by side-effects of homophily. Users
entering the platform attempt to find a sufficiently large group whose members
hold political biases within the range sufficiently close to their own. If
successful, they stabilize their biases and become permanent members of the
group. Otherwise, they leave the platform. We believe that the dynamics of
users' behavior uncovered in this article create a foundation for technical
solutions supporting social groups on social media and socially aware networks.",2023-09-27,"Mohammed Shahid Modi, James Flamino, Boleslaw K. Szymanski"
"A Tale of Two Cultures: Comparing Interpersonal Information Disclosure
  Norms on Twitter","We present an exploration of cultural norms surrounding online disclosure of
information about one's interpersonal relationships (such as information about
family members, colleagues, friends, or lovers) on Twitter. The literature
identifies the cultural dimension of individualism versus collectivism as being
a major determinant of offline communication differences in terms of emotion,
topic, and content disclosed. We decided to study whether such differences also
occur online in context of Twitter when comparing tweets posted in an
individualistic (U.S.) versus a collectivist (India) society. We collected more
than 2 million tweets posted in the U.S. and India over a 3 month period which
contain interpersonal relationship keywords. A card-sort study was used to
develop this culturally-sensitive saturated taxonomy of keywords that represent
interpersonal relationships (e.g., ma, mom, mother). Then we developed a
high-accuracy interpersonal disclosure detector based on dependency-parsing
(F1-score: 86%) to identify when the words refer to a personal relationship of
the poster (e.g., ""my mom"" as opposed to ""a mom""). This allowed us to identify
the 400K+ tweets in our data set which actually disclose information about the
poster's interpersonal relationships. We used a mixed methods approach to
analyze these tweets (e.g., comparing the amount of joy expressed about one's
family) and found differences in emotion, topic, and content disclosed between
tweets from the U.S. versus India. Our analysis also reveals how a combination
of qualitative and quantitative methods are needed to uncover these
differences; Using just one or the other can be misleading. This study extends
the prior literature on Multi-Party Privacy and provides guidance for
researchers and designers of culturally-sensitive systems.",2023-09-26,"Mainack Mondal, Anju Punuru, Tyng-Wen Scott Cheng, Kenneth Vargas, Chaz Gundry, Nathan S Driggs, Noah Schill, Nathaniel Carlson, Josh Bedwell, Jaden Q Lorenc, Isha Ghosh, Yao Li, Nancy Fulda, Xinru Page"
"Robust Stance Detection: Understanding Public Perceptions in Social
  Media","The abundance of social media data has presented opportunities for accurately
determining public and group-specific stances around policy proposals or
controversial topics. In contrast with sentiment analysis which focuses on
identifying prevailing emotions, stance detection identifies precise positions
(i.e., supportive, opposing, neutral) relative to a well-defined topic, such as
perceptions toward specific global health interventions during the COVID-19
pandemic. Traditional stance detection models, while effective within their
specific domain (e.g., attitudes towards masking protocols during COVID-19),
often lag in performance when applied to new domains and topics due to changes
in data distribution. This limitation is compounded by the scarcity of
domain-specific, labeled datasets, which are expensive and labor-intensive to
create. A solution we present in this paper combines counterfactual data
augmentation with contrastive learning to enhance the robustness of stance
detection across domains and topics of interest. We evaluate the performance of
current state-of-the-art stance detection models, including a prompt-optimized
large language model, relative to our proposed framework succinctly called
STANCE-C3 (domain-adaptive Cross-target STANCE detection via Contrastive
learning and Counterfactual generation). Empirical evaluations demonstrate
STANCE-C3's consistent improvements over the baseline models with respect to
accuracy across domains and varying focal topics. Despite the increasing
prevalence of general-purpose models such as generative AI, specialized models
such as STANCE-C3 provide utility in safety-critical domains wherein precision
is highly valued, especially when a nuanced understanding of the concerns of
different population segments could result in crafting more impactful public
policies.",2023-09-26,"Nayoung Kim, David Mosallanezhad, Lu Cheng, Michelle V. Mancenido, Huan Liu"
Methods of quantifying specialized knowledge and network rewiring,"Technological innovations are a major driver of economic development that
depend on the exchange of knowledge and ideas among those with unique but
complementary specialized knowledge and knowhow. However, measurement of
specialized knowledge embedded in technologists, scientists and entrepreneurs
in the knowledge economy presents an empirical challenge as both the exchange
of knowledge and knowledge itself remain difficult to observe. We develop novel
measures of specialized knowledge using a unique dataset of longitudinal
records of participation at technology-focused meetup events in two regional
knowledge economics. Our measures of specialized knowledge can be further used
to quantify the extend of knowledge spillover and network rewiring and uncover
underlying social mechanisms that contribute to the development of increasingly
complex and differentiated networks in maturing knowledge economies. We apply
these methods in the context of the rapid morphogenesis of emerging regional
technology economies in New York City and Los Angeles.",2023-09-25,"Sirui Wang, Michael Macy, Victor Nee"
Here Be Livestreams: Trade-offs in Creating Temporal Maps of Reddit,"We present a method for mapping Reddit communities that accounts for temporal
shifts, using quantitative and qualitative analyses of clustering techniques to
produce high-quality, stable, and meaningful maps for researchers, journalists
and casual Reddit users. Building on previous work using community embeddings,
we find that only a month of Reddit comments suffices to create snapshot
embeddings that maintain quality while supporting insight into changes in
Reddit communities over time. Comparing different clusterings of community
embeddings with quantitative measures of quality and temporal stability, we
describe properties of the models and what they tell us about the underlying
Reddit data. Moreover, qualitative analysis of the resulting clusters
illuminate which properties of clusterings are useful for analysis of Reddit
communities. Although clusterings of subreddits have been used in many earlier
works, we believe this is the first study to qualitatively analyze how these
clusterings are perceived by social media researchers at a Reddit-wide scale.
  Finally, we demonstrate how the temporal snapshots might be used in
exploratory study. We are able to identify particularly stable communities
during 2021-2022, such as the Reddit Public Access Network, as well as emerging
communities, like one focused on NFT trading. This work informed the
development of a webtool for exploring Reddit now available to the public at
RedditMap.social.",2023-09-25,"Virginia Partridge, Jasmine Mangat, Rebecca Curran, Ryan McGrady, Ethan Zuckerman"
"TouchUp-G: Improving Feature Representation through Graph-Centric
  Finetuning","How can we enhance the node features acquired from Pretrained Models (PMs) to
better suit downstream graph learning tasks? Graph Neural Networks (GNNs) have
become the state-of-the-art approach for many high-impact, real-world graph
applications. For feature-rich graphs, a prevalent practice involves utilizing
a PM directly to generate features, without incorporating any domain adaptation
techniques. Nevertheless, this practice is suboptimal because the node features
extracted from PM are graph-agnostic and prevent GNNs from fully utilizing the
potential correlations between the graph structure and node features, leading
to a decline in GNNs performance. In this work, we seek to improve the node
features obtained from a PM for downstream graph tasks and introduce TOUCHUP-G,
which has several advantages. It is (a) General: applicable to any downstream
graph task, including link prediction which is often employed in recommender
systems; (b) Multi-modal: able to improve raw features of any modality (e.g.
images, texts, audio); (c) Principled: it is closely related to a novel metric,
feature homophily, which we propose to quantify the potential correlations
between the graph structure and node features and we show that TOUCHUP-G can
effectively shrink the discrepancy between the graph structure and node
features; (d) Effective: achieving state-of-the-art results on four real-world
datasets spanning different tasks and modalities.",2023-09-25,"Jing Zhu, Xiang Song, Vassilis N. Ioannidis, Danai Koutra, Christos Faloutsos"
"Bringing Spatial Interaction Measures into Multi-Criteria Assessment of
  Redistricting Plans Using Interactive Web Mapping","Redistricting is the process by which electoral district boundaries are
drawn, and a common normative assumption in this process is that districts
should be drawn so as to capture coherent communities of interest (COIs). While
states rely on various proxies for community illustration, such as compactness
metrics and municipal split counts, to guide redistricting, recent legal
challenges and scholarly works have shown the failings of such proxy measures
and the difficulty of balancing multiple criteria in district plan creation. To
address these issues, we propose the use of spatial interaction communities to
directly quantify the degree to which districts capture the underlying COIs.
Using large-scale human mobility flow data, we condense spatial interaction
community capture for a set of districts into a single number, the interaction
ratio (IR), which can be used for redistricting plan evaluation. To compare the
IR to traditional redistricting criteria (compactness and fairness), and to
explore the range of IR values found in valid districting plans, we employ a
Markov chain-based regionalization algorithm (ReCom) to produce ensembles of
valid plans, and calculate the degree to which they capture spatial interaction
communities. Furthermore, we propose two methods for biasing the ReCom
algorithm towards different IR values. We perform a multi-criteria assessment
of the space of valid maps, and present the results in an interactive web map.
The experiments on Wisconsin congressional districting plans demonstrate the
effectiveness of our methods for biasing sampling towards higher or lower IR
values. Furthermore, the analysis of the districts produced with these methods
suggests that districts with higher IR and compactness values tend to produce
district plans that are more proportional with regards to seats allocated to
each of the two major parties.",2023-09-23,"Jacob Kruse, Song Gao, Yuhan Ji, Daniel P. Szabo, Kenneth Mayer"
Multilevel User Credibility Assessment in Social Networks,"Online social networks are one of the largest platforms for disseminating
both real and fake news. Many users on these networks, intentionally or
unintentionally, spread harmful content, fake news, and rumors in fields such
as politics and business. As a result, numerous studies have been conducted in
recent years to assess the credibility of users. A shortcoming of most of
existing methods is that they assess users by placing them in one of two
categories, real or fake. However, in real-world applications it is usually
more desirable to consider several levels of user credibility. Another
shortcoming is that existing approaches only use a portion of important
features, which downgrades their performance. In this paper, due to the lack of
an appropriate dataset for multilevel user credibility assessment, first we
design a method to collect data suitable to assess credibility at multiple
levels. Then, we develop the MultiCred model that places users at one of
several levels of credibility, based on a rich and diverse set of features
extracted from users' profile, tweets and comments. MultiCred exploits deep
language models to analyze textual data and deep neural models to process
non-textual features. Our extensive experiments reveal that MultiCred
considerably outperforms existing approaches, in terms of several accuracy
measures.",2023-09-23,"Mohammad Moradi, Mostafa Haghir Chehreghani"
"Higher-order Graph Convolutional Network with Flower-Petals Laplacians
  on Simplicial Complexes","Despite the recent successes of vanilla Graph Neural Networks (GNNs) on
various tasks, their foundation on pairwise networks inherently limits their
capacity to discern latent higher-order interactions in complex systems. To
bridge this capability gap, we propose a novel approach exploiting the rich
mathematical theory of simplicial complexes (SCs) - a robust tool for modeling
higher-order interactions. Current SC-based GNNs are burdened by high
complexity and rigidity, and quantifying higher-order interaction strengths
remains challenging. Innovatively, we present a higher-order Flower-Petals (FP)
model, incorporating FP Laplacians into SCs. Further, we introduce a
Higher-order Graph Convolutional Network (HiGCN) grounded in FP Laplacians,
capable of discerning intrinsic features across varying topological scales. By
employing learnable graph filters, a parameter group within each FP Laplacian
domain, we can identify diverse patterns where the filters' weights serve as a
quantifiable measure of higher-order interaction strengths. The theoretical
underpinnings of HiGCN's advanced expressiveness are rigorously demonstrated.
Additionally, our empirical investigations reveal that the proposed model
accomplishes state-of-the-art performance on a range of graph tasks and
provides a scalable and flexible solution to explore higher-order interactions
in graphs. Codes and datasets are available at
https://github.com/Yiminghh/HiGCN.",2023-09-22,"Yiming Huang, Yujie Zeng, Qiang Wu, Linyuan Lü"
"Multi-Modal Embeddings for Isolating Cross-Platform Coordinated
  Information Campaigns on Social Media","Coordinated multi-platform information operations are implemented in a
variety of contexts on social media, including state-run disinformation
campaigns, marketing strategies, and social activism. Characterized by the
promotion of messages via multi-platform coordination, in which multiple user
accounts, within a short time, post content advancing a shared informational
agenda on multiple platforms, they contribute to an already confusing and
manipulated information ecosystem. To make things worse, reliable datasets that
contain ground truth information about such operations are virtually
nonexistent. This paper presents a multi-modal approach that identifies the
social media messages potentially engaged in a coordinated information campaign
across multiple platforms. Our approach incorporates textual content, temporal
information and the underlying network of user and messages posted to identify
groups of messages with unusual coordination patterns across multiple social
media platforms. We apply our approach to content posted on four platforms
related to the Syrian Civil Defence organization known as the White Helmets:
Twitter, Facebook, Reddit, and YouTube. Results show that our approach
identifies social media posts that link to news YouTube channels with similar
factuality score, which is often an indication of coordinated operations.",2023-09-22,"Fabio Barbero, Sander op den Camp, Kristian van Kuijk, Carlos Soto García-Delgado, Gerasimos Spanakis, Adriana Iamnitchi"
Recurrent Temporal Revision Graph Networks,"Temporal graphs offer more accurate modeling of many real-world scenarios
than static graphs. However, neighbor aggregation, a critical building block of
graph networks, for temporal graphs, is currently straightforwardly extended
from that of static graphs. It can be computationally expensive when involving
all historical neighbors during such aggregation. In practice, typically only a
subset of the most recent neighbors are involved. However, such subsampling
leads to incomplete and biased neighbor information. To address this
limitation, we propose a novel framework for temporal neighbor aggregation that
uses the recurrent neural network with node-wise hidden states to integrate
information from all historical neighbors for each node to acquire the complete
neighbor information. We demonstrate the superior theoretical expressiveness of
the proposed framework as well as its state-of-the-art performance in
real-world applications. Notably, it achieves a significant +9.6% improvement
on averaged precision in a real-world Ecommerce dataset over existing methods
on 2-layer models.",2023-09-22,"Yizhou Chen, Anxiang Zeng, Guangda Huzhang, Qingtao Yu, Kerui Zhang, Cao Yuanpeng, Kangle Wu, Han Yu, Zhiming Zhou"
"Before Blue Birds Became X-tinct: Understanding the Effect of Regime
  Change on Twitter's Advertising and Compliance of Advertising Policies","Social media platforms, including Twitter (now X), have policies in place to
maintain a safe and trustworthy advertising environment. However, the extent to
which these policies are adhered to and enforced remains a subject of interest
and concern. We present the first large-scale audit of advertising on Twitter
focusing on compliance with the platform's advertising policies, particularly
those related to political and adult content. We investigate the compliance of
advertisements on Twitter with the platform's stated policies and the impact of
recent acquisition on the advertising activity of the platform. By analyzing
34K advertisements from ~6M tweets, collected over six months, we find evidence
of widespread noncompliance with Twitter's political and adult content
advertising policies suggesting a lack of effective ad content moderation. We
also find that Elon Musk's acquisition of Twitter had a noticeable impact on
the advertising landscape, with most existing advertisers either completely
stopping their advertising activity or reducing it. Major brands decreased
their advertising on Twitter, suggesting a negative immediate effect on the
platform's advertising revenue. Our findings underscore the importance of
external audits to monitor compliance and improve transparency in online
advertising.",2023-09-22,"Yash Vekaria, Zubair Shafiq, Savvas Zannettou"
"Transitioning To The Digital Generation Case Studies (Previous Digital
  Point Studies In Japan Cases:1993-2023)","In this paper, we discuss at The 8th International Workshop on Application of
Big Data for Computational Social Science, October 26-29, 2023, Venice, Italy.
To achieve the realization of the Global and Innovation Gateway for All (GIGA)
initiative (2019), proposed in December 2019 by the Primary and Secondary
Education Planning Division of the Elementary and Secondary Education Bureau of
the Ministry of Education, Culture, Sports, Science and Technology, a movement
has emerged to utilize information and communication technology (ICT) in the
field of education. The history of ICT education in Japan dates back to the 100
Schools Project (1994), which aimed to provide network access environments, and
the New 100 Schools Project (1997), which marked the beginning of full-scale
ICT education in Japan. In this paper, we discuss the usage dynamics of
smartphone-based learning applications among young people (analyzing data from
January to September 2020) and their current status. Further, the results are
summarized and future research topics and issues are discussed. The results
show that there are situations in which ICT learning environments can be
effectively utilized and others in which they cannot, depending on the
differences between digital students and analog students who utilize ICT in
their studies; this indicates that we are currently in a transition to a
generation of digital natives. ICT education has both advantages and
disadvantages, and it is expected that it will be used in combination with
conventional educational methods while assessing the characteristics of ICT
education in the future. Of course, there are many challenges. We plan to
discuss how to appeal in this regard at the Workshop.",2023-09-21,Yasuko Kawahata
Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting,"This paper studies the problem of traffic flow forecasting, which aims to
predict future traffic conditions on the basis of road networks and traffic
conditions in the past. The problem is typically solved by modeling complex
spatio-temporal correlations in traffic data using spatio-temporal graph neural
networks (GNNs). However, the performance of these methods is still far from
satisfactory since GNNs usually have limited representation capacity when it
comes to complex traffic networks. Graphs, by nature, fall short in capturing
non-pairwise relations. Even worse, existing methods follow the paradigm of
message passing that aggregates neighborhood information linearly, which fails
to capture complicated spatio-temporal high-order interactions. To tackle these
issues, in this paper, we propose a novel model named Dynamic Hypergraph
Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise
relationships, our DyHSL extracts hypergraph structural information to model
dynamics in the traffic networks, and updates each node representation by
aggregating messages from its associated hyperedges. Additionally, to capture
high-order spatio-temporal relations in the road network, we introduce an
interactive graph convolution block, which further models the neighborhood
interaction for each node. Finally, we integrate these two views into a
holistic multi-scale correlation extraction module, which conducts temporal
pooling with different scales to model different temporal patterns. Extensive
experiments on four popular traffic benchmark datasets demonstrate the
effectiveness of our proposed DyHSL compared with a broad range of competing
baselines.",2023-09-21,"Yusheng Zhao, Xiao Luo, Wei Ju, Chong Chen, Xian-Sheng Hua, Ming Zhang"
"Four universal growth regimes in degree-dependent first passage
  percolation on spatial random graphs I","One-dependent first passage percolation is a spreading process on a graph
where the transmission time through each edge depends on the direct
surroundings of the edge. In particular, the classical iid transmission time
$L_{xy}$ is multiplied by $(W_xW_y)^\mu$, a polynomial of the expected degrees
$W_x, W_y$ of the endpoints of the edge $xy$, which we call the penalty
function. Beyond the Markov case, we also allow any distribution for $L_{xy}$
with regularly varying distribution near $0$. We then run this process on three
spatial scale-free random graph models: finite and infinite Geometric
Inhomogeneous Random Graphs, and Scale-Free Percolation. In these spatial
models, the connection probability between two vertices depends on their
spatial distance and on their expected degrees.
  We show that as the penalty-function, i.e., $\mu$ increases, the transmission
time between two far away vertices sweeps through four universal phases:
explosive (with tight transmission times), polylogarithmic, polynomial but
strictly sublinear, and linear in the Euclidean distance. The strictly
polynomial growth phase here is a new phenomenon that so far was extremely rare
in spatial graph models. The four growth phases are highly robust in the model
parameters and are not restricted to phase boundaries. Further, the transition
points between the phases depend non-trivially on the main model parameters:
the tail of the degree distribution, a long-range parameter governing the
presence of long edges, and the behaviour of the distribution $L$ near $0$. In
this paper we develop new methods to prove the upper bounds in all
sub-explosive phases. Our companion paper complements these results by
providing matching lower bounds in the polynomial and linear regimes.",2023-09-21,"Júlia Komjáthy, John Lapinskas, Johannes Lengler, Ulysse Schaller"
A Comprehensive Review of Community Detection in Graphs,"The study of complex networks has significantly advanced our understanding of
community structures which serves as a crucial feature of real-world graphs.
Detecting communities in graphs is a challenging problem with applications in
sociology, biology, and computer science. Despite the efforts of an
interdisciplinary community of scientists, a satisfactory solution to this
problem has not yet been achieved. This review article delves into the topic of
community detection in graphs, which serves as a thorough exposition of various
community detection methods from perspectives of modularity-based method,
spectral clustering, probabilistic modelling, and deep learning. Along with the
methods, a new community detection method designed by us is also presented.
Additionally, the performance of these methods on the datasets with and without
ground truth is compared. In conclusion, this comprehensive review provides a
deep understanding of community detection in graphs.",2023-09-21,"Jiakang Li, Songning Lai, Zhihao Shuai, Yuan Tan, Yifan Jia, Mianyang Yu, Zichen Song, Xiaokang Peng, Ziyang Xu, Yongxin Ni, Haifeng Qiu, Jiayu Yang, Yutong Liu, Yonggang Lu"
The latent cognitive structures of social networks,"When people are asked to recall their social networks, theoretical and
empirical work tells us that they rely on shortcuts, or heuristics. Cognitive
Social Structures (CSS) are multilayer social networks where each layer
corresponds to an individual's perception of the network. With multiple
perceptions of the same network, CSSs contain rich information about how these
heuristics manifest, motivating the question, Can we identify people who share
the same heuristics? In this work, we propose a method for identifying
cognitive structure across multiple network perceptions, analogous to how
community detection aims to identify social structure in a network. To
simultaneously model the joint latent social and cognitive structure, we study
CSSs as three-dimensional tensors, employing low-rank nonnegative Tucker
decompositions (NNTuck) to approximate the CSS--a procedure closely related to
estimating a multilayer stochastic block model (SBM) from such data. We propose
the resulting latent cognitive space as an operationalization of the
sociological theory of social cognition by identifying individuals who share
relational schema. In addition to modeling cognitively independent, dependent,
and redundant networks, we propose a specific model instance and related
statistical test for testing when there is social-cognitive agreement in a
network: when the social and cognitive structures are equivalent. We use our
approach to analyze four different CSSs and give insights into the latent
cognitive structures of those networks.",2023-09-20,"Izabel Aguiar, Johan Ugander"
"Decentralized Online Learning in Task Assignment Games for Mobile
  Crowdsensing","The problem of coordinated data collection is studied for a mobile
crowdsensing (MCS) system. A mobile crowdsensing platform (MCSP) sequentially
publishes sensing tasks to the available mobile units (MUs) that signal their
willingness to participate in a task by sending sensing offers back to the
MCSP. From the received offers, the MCSP decides the task assignment. A stable
task assignment must address two challenges: the MCSP's and MUs' conflicting
goals, and the uncertainty about the MUs' required efforts and preferences. To
overcome these challenges a novel decentralized approach combining matching
theory and online learning, called collision-avoidance multi-armed bandit with
strategic free sensing (CA-MAB-SFS), is proposed. The task assignment problem
is modeled as a matching game considering the MCSP's and MUs' individual goals
while the MUs learn their efforts online. Our innovative ""free-sensing""
mechanism significantly improves the MU's learning process while reducing
collisions during task allocation. The stable regret of CA-MAB-SFS, i.e., the
loss of learning, is analytically shown to be bounded by a sublinear function,
ensuring the convergence to a stable optimal solution. Simulation results show
that CA-MAB-SFS increases the MUs' and the MCSP's satisfaction compared to
state-of-the-art methods while reducing the average task completion time by at
least 16%.",2023-09-19,"Bernd Simon, Andrea Ortiz, Walid Saad, Anja Klein"
"Towards Generative Modeling of Urban Flow through Knowledge-enhanced
  Denoising Diffusion","Although generative AI has been successful in many areas, its ability to
model geospatial data is still underexplored. Urban flow, a typical kind of
geospatial data, is critical for a wide range of urban applications. Existing
studies mostly focus on predictive modeling of urban flow that predicts the
future flow based on historical flow data, which may be unavailable in
data-sparse areas or newly planned regions. Some other studies aim to predict
OD flow among regions but they fail to model dynamic changes of urban flow over
time. In this work, we study a new problem of urban flow generation that
generates dynamic urban flow for regions without historical flow data. To
capture the effect of multiple factors on urban flow, such as region features
and urban environment, we employ diffusion model to generate urban flow for
regions under different conditions. We first construct an urban knowledge graph
(UKG) to model the urban environment and relationships between regions, based
on which we design a knowledge-enhanced spatio-temporal diffusion model
(KSTDiff) to generate urban flow for each region. Specifically, to accurately
generate urban flow for regions with different flow volumes, we design a novel
diffusion process guided by a volume estimator, which is learnable and
customized for each region. Moreover, we propose a knowledge-enhanced denoising
network to capture the spatio-temporal dependencies of urban flow as well as
the impact of urban environment in the denoising process. Extensive experiments
on four real-world datasets validate the superiority of our model over
state-of-the-art baselines in urban flow generation. Further in-depth studies
demonstrate the utility of generated urban flow data and the ability of our
model for long-term flow generation and urban flow prediction. Our code is
released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.",2023-09-19,"Zhilun Zhou, Jingtao Ding, Yu Liu, Depeng Jin, Yong Li"
"Analysis and Extraction of Tempo-Spatial Events in an Efficient Archival
  CDN with Emphasis on Telegram","This paper presents an efficient archival framework for exploring and
tracking cyberspace large-scale data called Tempo-Spatial Content Delivery
Network (TS-CDN). Social media data streams are renewing in time and spatial
dimensions. Various types of websites and social networks (i.e., channels,
groups, pages, etc.) are considered spatial in cyberspace. Accurate analysis
entails encompassing the bulk of data. In TS-CDN by applying the hash function
on big data an efficient content delivery network is created. Using hash
function rebuffs data redundancy and leads to conclude unique data archive in
large-scale. This framework based on entered query allows for apparent
monitoring and exploring data in tempo-spatial dimension based on TF-IDF score.
Also by conformance from i18n standard, the Unicode problem has been dissolved.
For evaluation of TS-CDN framework, a dataset from Telegram news channels from
March 23, 2020 (1399-01-01), to September 21, 2020 (1399-06-31) on topics
including Coronavirus (COVID-19), vaccine, school reopening, flood, earthquake,
justice shares, petroleum, and quarantine exploited. By applying hash on
Telegram dataset in the mentioned time interval, a significant reduction in
media files such as 39.8% for videos (from 79.5 GB to 47.8 GB), and 10% for
images (from 4 GB to 3.6 GB) occurred. TS-CDN infrastructure in a web-based
approach has been presented as a service-oriented system. Experiments conducted
on enormous time series data, including different spatial dimensions (i.e.,
Khabare Fouri, Khabarhaye Fouri, Akhbare Rouze Iran, and Akhbare Rasmi Telegram
news channels), demonstrate the efficiency and applicability of the implemented
TS-CDN framework.",2023-09-16,"Melika Bahman-Abadi, M. B. Ghaznavi-Ghoushchi"
Narratives of War: Ukrainian Memetic Warfare on Twitter,"The 2022 Russian invasion of Ukraine has seen an intensification in the use
of social media by governmental actors in cyber warfare. Wartime communication
via memes has been a successful strategy used not only by independent accounts
such as @uamemesforces, but also-for the first time in a full-scale interstate
war-by official Ukrainian government accounts such as @Ukraine and @DefenceU.
We study this prominent example of memetic warfare through the lens of its
narratives, and find them to be a key component of success: tweets with a
'victim' narrative garner twice as many retweets. However, malevolent
narratives focusing on the enemy resonate more than those about heroism or
victims with countries providing more assistance to Ukraine. Our findings
present a nuanced examination of Ukraine's influence operations and of the
worldwide response to it, thus contributing new insights into the evolution of
socio-technical systems in times of war.",2023-09-15,"Yelena Mejova, Arthur Capozzi, Corrado Monti, Gianmarco De Francisci Morales"
"Social media polarization reflects shifting political alliances in
  Pakistan","The rise of ideological divides in public discourse has received considerable
attention in recent years. However, much of this research has been concentrated
on Western democratic nations, leaving other regions largely unexplored. Here,
we delve into the political landscape of Pakistan, a nation marked by intricate
political dynamics and persistent turbulence. Spanning from 2018 to 2022, our
analysis of Twitter data allows us to capture pivotal shifts and developments
in Pakistan's political arena. By examining interactions and content generated
by politicians affiliated with major political parties, we reveal a consistent
and active presence of politicians on Twitter, with opposition parties
exhibiting particularly robust engagement. We explore the alignment of party
audiences, highlighting a notable convergence among opposition factions over
time. Our analysis also uncovers significant shifts in political affiliations,
including the transition of politicians to the opposition alliance.
Quantitatively, we assess evolving interaction patterns, showcasing the
prevalence of homophilic connections while identifying a growing
interconnection among audiences of opposition parties. Our study, by accurately
reflecting shifts in the political landscape, underscores the reliability of
our methodology and social media data as a valuable tool for monitoring
political polarization and providing a nuanced understanding of macro-level
trends and individual-level transformations.",2023-09-15,"Anees Baqir, Alessandro Galeazzi, Andrea Drocco, Fabiana Zollo"
"Locating Community Smells in Software Development Processes Using
  Higher-Order Network Centralities","Community smells are negative patterns in software development teams'
interactions that impede their ability to successfully create software.
Examples are team members working in isolation, lack of communication and
collaboration across departments or sub-teams, or areas of the codebase where
only a few team members can work on. Current approaches aim to detect community
smells by analysing static network representations of software teams'
interaction structures. In doing so, they are insufficient to locate community
smells within development processes. Extending beyond the capabilities of
traditional social network analysis, we show that higher-order network models
provide a robust means of revealing such hidden patterns and complex
relationships. To this end, we develop a set of centrality measures based on
the MOGen higher-order network model and show their effectiveness in predicting
influential nodes using five empirical datasets. We then employ these measures
for a comprehensive analysis of a product team at the German IT security
company genua GmbH, showcasing our method's success in identifying and locating
community smells. Specifically, we uncover critical community smells in two
areas of the team's development process. Semi-structured interviews with five
team members validate our findings: while the team was aware of one community
smell and employed measures to address it, it was not aware of the second. This
highlights the potential of our approach as a robust tool for identifying and
addressing community smells in software development teams. More generally, our
work contributes to the social network analysis field with a powerful set of
higher-order network centralities that effectively capture community dynamics
and indirect relationships.",2023-09-14,"Christoph Gote, Vincenzo Perri, Christian Zingg, Giona Casiraghi, Carsten Arzig, Alexander von Gernler, Frank Schweitzer, Ingo Scholtes"
"Domain-adaptive Graph Attention-supervised Network for Cross-network
  Edge Classification","Graph neural networks (GNNs) have shown great ability in modeling graphs,
however, their performance would significantly degrade when there are noisy
edges connecting nodes from different classes. To alleviate negative effect of
noisy edges on neighborhood aggregation, some recent GNNs propose to predict
the label agreement between node pairs within a single network. However,
predicting the label agreement of edges across different networks has not been
investigated yet. Our work makes the pioneering attempt to study a novel
problem of cross-network homophilous and heterophilous edge classification
(CNHHEC), and proposes a novel domain-adaptive graph attention-supervised
network (DGASN) to effectively tackle the CNHHEC problem. Firstly, DGASN adopts
multi-head GAT as the GNN encoder, which jointly trains node embeddings and
edge embeddings via the node classification and edge classification losses. As
a result, label-discriminative embeddings can be obtained to distinguish
homophilous edges from heterophilous edges. In addition, DGASN applies direct
supervision on graph attention learning based on the observed edge labels from
the source network, thus lowering the negative effects of heterophilous edges
while enlarging the positive effects of homophilous edges during neighborhood
aggregation. To facilitate knowledge transfer across networks, DGASN employs
adversarial domain adaptation to mitigate domain divergence. Extensive
experiments on real-world benchmark datasets demonstrate that the proposed
DGASN achieves the state-of-the-art performance in CNHHEC.",2023-09-14,"Xiao Shen, Mengqiu Shao, Shirui Pan, Laurence T. Yang, Xi Zhou"
Defensive Alliances in Signed Networks,"The analysis of (social) networks and multi-agent systems is a central theme
in Artificial Intelligence. Some line of research deals with finding groups of
agents that could work together to achieve a certain goal. To this end,
different notions of so-called clusters or communities have been introduced in
the literature of graphs and networks. Among these, defensive alliance is a
kind of quantitative group structure. However, all studies on the alliance so
for have ignored one aspect that is central to the formation of alliances on a
very intuitive level, assuming that the agents are preconditioned concerning
their attitude towards other agents: they prefer to be in some group (alliance)
together with the agents they like, so that they are happy to help each other
towards their common aim, possibly then working against the agents outside of
their group that they dislike. Signed networks were introduced in the
psychology literature to model liking and disliking between agents,
generalizing graphs in a natural way. Hence, we propose the novel notion of a
defensive alliance in the context of signed networks. We then investigate
several natural algorithmic questions related to this notion. These, and also
combinatorial findings, connect our notion to that of correlation clustering,
which is a well-established idea of finding groups of agents within a signed
network. Also, we introduce a new structural parameter for signed graphs,
signed neighborhood diversity snd, and exhibit a parameterized algorithm that
finds a smallest defensive alliance in a signed graph.",2023-09-13,"Emmanuel Arrighi, Zhidan Feng, Henning Fernau, Kevin Mann, Xingqin Qi, Petra Wolf"
"Large Language Models Can Infer Psychological Dispositions of Social
  Media Users","Large Language Models (LLMs) demonstrate increasingly human-like abilities
across a wide variety of tasks. In this paper, we investigate whether LLMs like
ChatGPT can accurately infer the psychological dispositions of social media
users and whether their ability to do so varies across socio-demographic
groups. Specifically, we test whether GPT-3.5 and GPT-4 can derive the Big Five
personality traits from users' Facebook status updates in a zero-shot learning
scenario. Our results show an average correlation of r = .29 (range = [.22,
.33]) between LLM-inferred and self-reported trait scores - a level of accuracy
that is similar to that of supervised machine learning models specifically
trained to infer personality. Our findings also highlight heterogeneity in the
accuracy of personality inferences across different age groups and gender
categories: predictions were found to be more accurate for women and younger
individuals on several traits, suggesting a potential bias stemming from the
underlying training data or differences in online self-expression. The ability
of LLMs to infer psychological dispositions from user-generated text has the
potential to democratize access to cheap and scalable psychometric assessments
for both researchers and practitioners. On the one hand, this democratization
might facilitate large-scale research of high ecological validity and spark
innovation in personalized services. On the other hand, it also raises ethical
concerns regarding user privacy and self-determination, highlighting the need
for stringent ethical frameworks and regulation.",2023-09-13,"Heinrich Peters, Sandra Matz"
"Enhancing Hyperedge Prediction with Context-Aware Self-Supervised
  Learning","Hypergraphs can naturally model group-wise relations (e.g., a group of users
who co-purchase an item) as hyperedges. Hyperedge prediction is to predict
future or unobserved hyperedges, which is a fundamental task in many real-world
applications (e.g., group recommendation). Despite the recent breakthrough of
hyperedge prediction methods, the following challenges have been rarely
studied: (C1) How to aggregate the nodes in each hyperedge candidate for
accurate hyperedge prediction? and (C2) How to mitigate the inherent data
sparsity problem in hyperedge prediction? To tackle both challenges together,
in this paper, we propose a novel hyperedge prediction framework (CASH) that
employs (1) context-aware node aggregation to precisely capture complex
relations among nodes in each hyperedge for (C1) and (2) self-supervised
contrastive learning in the context of hyperedge prediction to enhance
hypergraph representations for (C2). Furthermore, as for (C2), we propose a
hyperedge-aware augmentation method to fully exploit the latent semantics
behind the original hypergraph and consider both node-level and group-level
contrasts (i.e., dual contrasts) for better node and hyperedge representations.
Extensive experiments on six real-world hypergraphs reveal that CASH
consistently outperforms all competing methods in terms of the accuracy in
hyperedge prediction and each of the proposed strategies is effective in
improving the model accuracy of CASH. For the detailed information of CASH, we
provide the code and datasets at: https://github.com/yy-ko/cash.",2023-09-11,"Yunyong Ko, Hanghang Tong, Sang-Wook Kim"
Errors are Robustly Tamed in Cumulative Knowledge Processes,"We study processes of societal knowledge accumulation, where the validity of
a new unit of knowledge depends both on the correctness of its derivation and
on the validity of the units it depends on. A fundamental question in this
setting is: If a constant fraction of the new derivations is wrong, can
investing a constant fraction, bounded away from one, of effort ensure that a
constant fraction of knowledge in society is valid? Ben-Eliezer, Mikulincer,
Mossel, and Sudan (ITCS 2023) introduced a concrete probabilistic model to
analyze such questions and showed an affirmative answer to this question. Their
study, however, focuses on the simple case where each new unit depends on just
one existing unit, and units attach according to a $\textit{preferential
attachment rule}$.
  In this work, we consider much more general families of cumulative knowledge
processes, where new units may attach according to varied attachment mechanisms
and depend on multiple existing units. We also allow a (random) fraction of
insertions of adversarial nodes.
  We give a robust affirmative answer to the above question by showing that for
$\textit{all}$ of these models, as long as many of the units follow simple
heuristics for checking a bounded number of units they depend on, all errors
will be eventually eliminated. Our results indicate that preserving the quality
of large interdependent collections of units of knowledge is feasible, as long
as careful but not too costly checks are performed when new units are
derived/deposited.",2023-09-11,"Anna Brandenberger, Cassandra Marcussen, Elchanan Mossel, Madhu Sudan"
"Quantitative Analysis of Forecasting Models:In the Aspect of Online
  Political Bias","Understanding and mitigating political bias in online social media platforms
are crucial tasks to combat misinformation and echo chamber effects. However,
characterizing political bias temporally using computational methods presents
challenges due to the high frequency of noise in social media datasets. While
existing research has explored various approaches to political bias
characterization, the ability to forecast political bias and anticipate how
political conversations might evolve in the near future has not been
extensively studied. In this paper, we propose a heuristic approach to classify
social media posts into five distinct political leaning categories. Since there
is a lack of prior work on forecasting political bias, we conduct an in-depth
analysis of existing baseline models to identify which model best fits to
forecast political leaning time series. Our approach involves utilizing
existing time series forecasting models on two social media datasets with
different political ideologies, specifically Twitter and Gab. Through our
experiments and analyses, we seek to shed light on the challenges and
opportunities in forecasting political bias in social media platforms.
Ultimately, our work aims to pave the way for developing more effective
strategies to mitigate the negative impact of political bias in the digital
realm.",2023-09-11,"Srinath Sai Tripuraneni, Sadia Kamal, Arunkumar Bagavathi"
"Duplicate Question Retrieval and Confirmation Time Prediction in
  Software Communities","Community Question Answering (CQA) in different domains is growing at a large
scale because of the availability of several platforms and huge shareable
information among users. With the rapid growth of such online platforms, a
massive amount of archived data makes it difficult for moderators to retrieve
possible duplicates for a new question and identify and confirm existing
question pairs as duplicates at the right time. This problem is even more
critical in CQAs corresponding to large software systems like askubuntu where
moderators need to be experts to comprehend something as a duplicate. Note that
the prime challenge in such CQA platforms is that the moderators are themselves
experts and are therefore usually extremely busy with their time being
extraordinarily expensive. To facilitate the task of the moderators, in this
work, we have tackled two significant issues for the askubuntu CQA platform:
(1) retrieval of duplicate questions given a new question and (2) duplicate
question confirmation time prediction. In the first task, we focus on
retrieving duplicate questions from a question pool for a particular newly
posted question. In the second task, we solve a regression problem to rank a
pair of questions that could potentially take a long time to get confirmed as
duplicates. For duplicate question retrieval, we propose a Siamese neural
network based approach by exploiting both text and network-based features,
which outperforms several state-of-the-art baseline techniques. Our method
outperforms DupPredictor and DUPE by 5% and 7% respectively. For duplicate
confirmation time prediction, we have used both the standard machine learning
models and neural network along with the text and graph-based features. We
obtain Spearman's rank correlation of 0.20 and 0.213 (statistically
significant) for text and graph based features respectively.",2023-09-10,"Rima Hazra, Debanjan Saha, Amruit Sahoo, Somnath Banerjee, Animesh Mukherjee"
Influence Maximization in Social Networks: A Survey,"Online social networks have become an important platform for people to
communicate, share knowledge and disseminate information. Given the widespread
usage of social media, individuals' ideas, preferences and behavior are often
influenced by their peers or friends in the social networks that they
participate in. Since the last decade, influence maximization (IM) problem has
been extensively adopted to model the diffusion of innovations and ideas. The
purpose of IM is to select a set of k seed nodes who can influence the most
individuals in the network.
  In this survey, we present a systematical study over the researches and
future directions with respect to IM problem. We review the information
diffusion models and analyze a variety of algorithms for the classic IM
algorithms. We propose a taxonomy for potential readers to understand the key
techniques and challenges. We also organize the milestone works in time order
such that the readers of this survey can experience the research roadmap in
this field. Moreover, we also categorize other application-oriented IM studies
and correspondingly study each of them. What's more, we list a series of open
questions as the future directions for IM-related researches, where a potential
reader of this survey can easily observe what should be done next in this
field.",2023-09-09,"Hui Li, Susu Yang, Mengting Xu, Sourav S Bhowmick, Jiangtao Cui"
"Creating a Systematic ESG (Environmental Social Governance) Scoring
  System Using Social Network Analysis and Machine Learning for More
  Sustainable Company Practices","Environmental Social Governance (ESG) is a widely used metric that measures
the sustainability of a company practices. Currently, ESG is determined using
self-reported corporate filings, which allows companies to portray themselves
in an artificially positive light. As a result, ESG evaluation is subjective
and inconsistent across raters, giving executives mixed signals on what to
improve. This project aims to create a data-driven ESG evaluation system that
can provide better guidance and more systemized scores by incorporating social
sentiment. Social sentiment allows for more balanced perspectives which
directly highlight public opinion, helping companies create more focused and
impactful initiatives. To build this, Python web scrapers were developed to
collect data from Wikipedia, Twitter, LinkedIn, and Google News for the S&P 500
companies. Data was then cleaned and passed through NLP algorithms to obtain
sentiment scores for ESG subcategories. Using these features, machine-learning
algorithms were trained and calibrated to S&P Global ESG Ratings to test their
predictive capabilities. The Random-Forest model was the strongest model with a
mean absolute error of 13.4% and a correlation of 26.1% (p-value 0.0372),
showing encouraging results. Overall, measuring ESG social sentiment across
sub-categories can help executives focus efforts on areas people care about
most. Furthermore, this data-driven methodology can provide ratings for
companies without coverage, allowing more socially responsible firms to thrive.",2023-09-07,"Aarav Patel, Peter Gloor"
Social Media Influence Operations,"Social media platforms enable largely unrestricted many-to-many
communication. In times of crisis, they offer a space for collective
sense-making and gave rise to new social phenomena (e.g. open-source
investigations). However, they also serve as a tool for threat actors to
conduct cyber-enabled social influence operations (CeSIOs) in order to shape
public opinion and interfere in decision-making processes. CeSIOs rely on the
employment of sock puppet accounts to engage authentic users in online
communication, exert influence, and subvert online discourse. Large Language
Models (LLMs) may further enhance the deceptive properties of sock puppet
accounts. Recent LLMs are able to generate targeted and persuasive text which
is for the most part indistinguishable from human-written content -- ideal
features for covert influence. This article reviews recent developments at the
intersection of LLMs and influence operations, summarizes LLMs' salience, and
explores the potential impact of LLM-instrumented sock puppet accounts for
CeSIOs. Finally, mitigation measures for the near future are highlighted.",2023-09-07,Raphael Meier
"Machine Learning for Tangible Effects: Natural Language Processing for
  Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing","I explore two questions in this thesis: how can computer science be used to
fight human trafficking? And how can computer vision create a sense of touch?
  I use natural language processing (NLP) to monitor the United States illicit
massage industry (IMI), a multi-billion dollar industry that offers not just
therapeutic massages but also commercial sexual services. Employees of this
industry are often immigrant women with few job opportunities, leaving them
vulnerable to fraud, coercion, and other facets of human trafficking.
Monitoring spatiotemporal trends helps prevent trafficking in the IMI. By
creating datasets with three publicly-accessible websites: Google Places,
Rubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and
Word2Vec, I show how to derive insights into the labor pressures and language
barriers that employees face, as well as the income, demographics, and societal
pressures affecting sex buyers. I include a call-to-action to other researchers
given these datasets. I also consider how to creating synthetic financial data,
which can aid with counter-trafficking in the banking sector. I use an
agent-based model to create both tabular and payee-recipient graph data.
  I then consider the role of computer vision in making tactile sensors. I
report on a novel sensor, the Digger Finger, that adapts the Gelsight sensor to
finding objects in granular media. Changes include using a wedge shape to
facilitate digging, replacing the internal lighting LEDs with fluorescent
paint, and adding a vibrator motor to counteract jamming. Finally, I also show
how to use a webcam and a printed reference marker, or fiducial, to create a
low-cost six-axis force-torque sensor. This sensor is up to a hundred times
less expensive than commercial sensors, allowing for a wider range of
applications. For this and earlier chapters I release design files and code as
open source.",2023-09-07,Rui Ouyang
"Navigating the IoT landscape: Unraveling forensics, security issues,
  applications, research challenges, and future","Given the exponential expansion of the internet, the possibilities of
security attacks and cybercrimes have increased accordingly. However, poorly
implemented security mechanisms in the Internet of Things (IoT) devices make
them susceptible to cyberattacks, which can directly affect users. IoT
forensics is thus needed for investigating and mitigating such attacks. While
many works have examined IoT applications and challenges, only a few have
focused on both the forensic and security issues in IoT. Therefore, this paper
reviews forensic and security issues associated with IoT in different fields.
Future prospects and challenges in IoT research and development are also
highlighted. As demonstrated in the literature, most IoT devices are vulnerable
to attacks due to a lack of standardized security measures. Unauthorized users
could get access, compromise data, and even benefit from control of critical
infrastructure. To fulfil the security-conscious needs of consumers, IoT can be
used to develop a smart home system by designing a FLIP-based system that is
highly scalable and adaptable. Utilizing a blockchain-based authentication
mechanism with a multi-chain structure can provide additional security
protection between different trust domains. Deep learning can be utilized to
develop a network forensics framework with a high-performing system for
detecting and tracking cyberattack incidents. Moreover, researchers should
consider limiting the amount of data created and delivered when using big data
to develop IoT-based smart systems. The findings of this review will stimulate
academics to seek potential solutions for the identified issues, thereby
advancing the IoT field.",2023-09-06,"Shams Forruque Ahmed, Shanjana Shuravi, Afsana Bhuyian, Shaila Afrin, Aanushka Mehjabin, Sweety Angela Kuldeep, Md. Sakib Bin Alam, Amir H. Gandomi"
"Experience Capture in Shipbuilding through Computer Applications and
  Neural Networks","It has always been a severe loss for any establishment when an experienced
hand retires or moves to another firm. The specific details of what his
job/position entails will always make the work more efficient. To curtail such
losses, it is possible to implement a system that takes input from a new
employee regarding the challenges he/she is facing and match it to a previous
occurrence where someone else held his/her chair. This system could be made
possible with input through the ages from the array of individuals who managed
that particular job and processing this data through a neural network that
recognizes the pattern. The paper is based on data collected from traditional
wooden dhow builders and some of the modern day unconventional shipyards. Since
the requirements for successful implementation in such scenarios seems too
steep at the moment, an alternate approach has been suggested by implementation
through the design processes across multiple shipyards. The process entails the
traditional value passed down through generations regarding a particular
profession and analysis has been done regarding how this knowledge/experience
can be captured and preserved for future generations to work upon. A series of
tools including SharePoint, MATLAB, and some similar software working in tandem
can be used for the design of the same. This research will provide valuable
insight as to how information sharing can be applied through generations for
effective application of production capabilities.",2023-09-05,"Sankaramangalam Ulhas Sangeet, Sivaprasad K, Yashwant R. Kamath"
Black-Box Attacks against Signed Graph Analysis via Balance Poisoning,"Signed graphs are well-suited for modeling social networks as they capture
both positive and negative relationships. Signed graph neural networks (SGNNs)
are commonly employed to predict link signs (i.e., positive and negative) in
such graphs due to their ability to handle the unique structure of signed
graphs. However, real-world signed graphs are vulnerable to malicious attacks
by manipulating edge relationships, and existing adversarial graph attack
methods do not consider the specific structure of signed graphs. SGNNs often
incorporate balance theory to effectively model the positive and negative
links. Surprisingly, we find that the balance theory that they rely on can
ironically be exploited as a black-box attack. In this paper, we propose a
novel black-box attack called balance-attack that aims to decrease the balance
degree of the signed graphs. We present an efficient heuristic algorithm to
solve this NP-hard optimization problem. We conduct extensive experiments on
five popular SGNN models and four real-world datasets to demonstrate the
effectiveness and wide applicability of our proposed attack method. By
addressing these challenges, our research contributes to a better understanding
of the limitations and resilience of robust models when facing attacks on
SGNNs. This work contributes to enhancing the security and reliability of
signed graph analysis in social network modeling. Our PyTorch implementation of
the attack is publicly available on GitHub:
https://github.com/JialongZhou666/Balance-Attack.git.",2023-09-05,"Jialong Zhou, Yuni Lai, Jian Ren, Kai Zhou"
"Incorporating Dictionaries into a Neural Network Architecture to Extract
  COVID-19 Medical Concepts From Social Media","We investigate the potential benefit of incorporating dictionary information
into a neural network architecture for natural language processing. In
particular, we make use of this architecture to extract several concepts
related to COVID-19 from an on-line medical forum. We use a sample from the
forum to manually curate one dictionary for each concept. In addition, we use
MetaMap, which is a tool for extracting biomedical concepts, to identify a
small number of semantic concepts. For a supervised concept extraction task on
the forum data, our best model achieved a macro $F_1$ score of 90\%. A major
difficulty in medical concept extraction is obtaining labelled data from which
to build supervised models. We investigate the utility of our models to
transfer to data derived from a different source in two ways. First for
producing labels via weak learning and second to perform concept extraction.
The dataset we use in this case comprises COVID-19 related tweets and we
achieve an $F_1$ score 81\% for symptom concept extraction trained on weakly
labelled data. The utility of our dictionaries is compared with a COVID-19
symptom dictionary that was constructed directly from Twitter. Further
experiments that incorporate BERT and a COVID-19 version of BERTweet
demonstrate that the dictionaries provide a commensurate result. Our results
show that incorporating small domain dictionaries to deep learning models can
improve concept extraction tasks. Moreover, models built using dictionaries
generalize well and are transferable to different datasets on a similar task.",2023-09-05,"Abul Hasan, Mark Levene, David Weston"
"iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and
  Re-occurrence Preservation","Continuous-time dynamic graph modeling is a crucial task for many real-world
applications, such as financial risk management and fraud detection. Though
existing dynamic graph modeling methods have achieved satisfactory results,
they still suffer from three key limitations, hindering their scalability and
further applicability. i) Indiscriminate updating. For incoming edges, existing
methods would indiscriminately deal with them, which may lead to more time
consumption and unexpected noisy information. ii) Ineffective node-wise
long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a
backbone, which has been demonstrated to be incapable of fully capturing
node-wise long-term dependencies in event sequences. iii) Neglect of
re-occurrence patterns. Dynamic graphs involve the repeated occurrence of
neighbors that indicates their importance, which is disappointedly neglected by
existing methods. In this paper, we present iLoRE, a novel dynamic graph
modeling method with instant node-wise Long-term modeling and Re-occurrence
preservation. To overcome the indiscriminate updating issue, we introduce the
Adaptive Short-term Updater module that will automatically discard the useless
or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further
propose the Long-term Updater to realize more effective node-wise long-term
modeling, where we innovatively propose the Identity Attention mechanism to
empower a Transformer-based updater, bypassing the limited effectiveness of
typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are
also encoded into a graph module for informative representation learning, which
will further improve the expressiveness of our method. Our experimental results
on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic
graph modeling.",2023-09-05,"Siwei Zhang, Yun Xiong, Yao Zhang, Xixi Wu, Yiheng Sun, Jiawei Zhang"
Evolving linguistic divergence on polarizing social media,"Language change is influenced by many factors, but often starts from
synchronic variation, where multiple linguistic patterns or forms coexist, or
where different speech communities use language in increasingly different ways.
Besides regional or economic reasons, communities may form and segregate based
on political alignment. The latter, referred to as political polarization, is
of growing societal concern across the world. Here we map and quantify
linguistic divergence across the partisan left-right divide in the United
States, using social media data. We develop a general methodology to delineate
(social) media users by their political preference, based on which (potentially
biased) news media accounts they do and do not follow on a given platform. Our
data consists of 1.5M short posts by 10k users (about 20M words) from the
social media platform Twitter (now ""X""). Delineating this sample involved
mining the platform for the lists of followers (n=422M) of 72 large news media
accounts. We quantify divergence in topics of conversation and word
frequencies, messaging sentiment, and lexical semantics of words and emoji. We
find signs of linguistic divergence across all these aspects, especially in
topics and themes of conversation, in line with previous research. While US
American English remains largely intelligible within its large speech
community, our findings point at areas where miscommunication may eventually
arise given ongoing polarization and therefore potential linguistic divergence.
Our methodology - combining data mining, lexicostatistics, machine learning,
large language models and a systematic human annotation approach - is largely
language and platform agnostic. In other words, while we focus here on US
political divides and US English, the same approach is applicable to other
countries, languages, and social media platforms.",2023-09-04,"Andres Karjus, Christine Cuskley"
An Accurate Graph Generative Model with Tunable Features,"A graph is a very common and powerful data structure used for modeling
communication and social networks. Models that generate graphs with arbitrary
features are important basic technologies in repeated simulations of networks
and prediction of topology changes. Although existing generative models for
graphs are useful for providing graphs similar to real-world graphs, graph
generation models with tunable features have been less explored in the field.
Previously, we have proposed GraphTune, a generative model for graphs that
continuously tune specific graph features of generated graphs while maintaining
most of the features of a given graph dataset. However, the tuning accuracy of
graph features in GraphTune has not been sufficient for practical applications.
In this paper, we propose a method to improve the accuracy of GraphTune by
adding a new mechanism to feed back errors of graph features of generated
graphs and by training them alternately and independently. Experiments on a
real-world graph dataset showed that the features in the generated graphs are
accurately tuned compared with conventional models.",2023-09-03,"Takahiro Yokoyama, Yoshiki Sato, Sho Tsugawa, Kohei Watabe"
"The Power of Patents: Leveraging Text Mining and Social Network Analysis
  to Forecast IoT Trends","Technology has become an indispensable competitive tool as science and
technology have progressed throughout history. Organizations can compete on an
equal footing by implementing technology appropriately. Technology trends or
technology lifecycles begin during the initiation phase. Finally, it reaches
saturation after entering the maturity phase. As technology reaches saturation,
it will be removed or replaced by another. This makes investing in technologies
during this phase unjustifiable. Technology forecasting is a critical tool for
research and development to determine the future direction of technology. Based
on registered patents, this study examined the trends of IOT technologies. A
total of 3697 patents related to the Internet of Things from the last six years
of patenting have been gathered using lens.org for this purpose. The main
people and companies were identified through the creation of the IOT patent
registration cooperation network, and the main groups active in patent
registration were identified by the community detection technique. The patents
were then divided into six technology categories: Safety and Security,
Information Services, Public Safety and Environment Monitoring, Collaborative
Aware Systems, Smart Homes/Buildings, and Smart Grid. And their technical
maturity was identified and examined using the Sigma Plot program. Based on the
findings, information services technologies are in the saturation stage, while
both smart homes/buildings, and smart grid technologies are in the saturation
stage. Three technologies, Safety and Security, Public Safety and Environment
Monitoring, and Collaborative Aware Systems are in the maturity stage.",2023-09-01,"Mehrdad Maghsoudi, Reza Nourbakhsh, Mehrdad Agha Mohammadali Kermani, Rahim Khanizad"
A normative approach to radicalization in social networks,"In recent decades, the massification of online social connections has made
information globally accessible in a matter of seconds. Unfortunately, this has
been accompanied by a dramatic surge in extreme opinions, without a clear
solution in sight. Using a model performing probabilistic inference in
large-scale loopy graphs through exchange of messages between nodes, we show
how circularity in the social graph directly leads to radicalization and the
polarization of opinions. We demonstrate that these detrimental effects could
be avoided if the correlations between incoming messages could be decreased.
This approach is based on an extension of Belief Propagation (BP) named
Circular Belief Propagation (CBP) that can be trained to drastically improve
inference within a cyclic graph. CBP was benchmarked using data from Facebook
and Twitter. This approach could inspire new methods for preventing the viral
spreading and amplification of misinformation online, improving the capacity of
social networks to share knowledge globally without resorting to censorship.",2023-09-01,"Vincent Bouttier, Salomé Leclercq, Renaud Jardri, Sophie Deneve"
"A Task-Interdependency Model of Complex Collaboration Towards
  Human-Centered Crowd Work","Models of crowdsourcing and human computation often assume that individuals
independently carry out small, modular tasks. However, while these models have
successfully shown how crowds can accomplish significant objectives, they can
inadvertently advance a less than human view of crowd workers and fail to
capture the unique human capacity for complex collaborative work. We present a
model centered on interdependencies -- a phenomenon well understood to be at
the core of collaboration -- that allows one to formally reason about diverse
challenges to complex collaboration. Our model represents tasks as an
interdependent collection of subtasks, formalized as a task graph. We use it to
explain challenges to scaling complex collaborative work, underscore the
importance of expert workers, reveal critical factors for learning on the job,
and explore the relationship between coordination intensity and occupational
wages. Using data from O*NET and the Bureau of Labor Statistics, we introduce
an index of occupational coordination intensity to validate our theoretical
predictions. We present preliminary evidence that occupations with greater
coordination intensity are less exposed to displacement by AI, and discuss
opportunities for models that emphasize the collaborative capacities of human
workers, bridge models of crowd work and traditional work, and promote AI in
roles augmenting human collaboration.",2023-08-31,"David T. Lee, Christos A. Makridis"
"Inference of dynamic hypergraph representations in temporal interaction
  data","A range of systems across the social and natural sciences generate datasets
consisting of interactions between two distinct categories of items at various
instances in time. Online shopping, for example, generates purchasing events of
the form (user, product, time of purchase), and mutualistic interactions in
plant-pollinator systems generate pollination events of the form (insect,
plant, time of pollination). These data sets can be meaningfully modeled as
temporal hypergraph snapshots in which multiple items within one category (i.e.
online shoppers) share a hyperedge if they interacted with a common item in the
other category (i.e. purchased the same product) within a given time window,
allowing for the application of hypergraph analysis techniques. However, it is
often unclear how to choose the number and duration of these temporal
snapshots, which have a strong influence on the final hypergraph
representations. Here we propose a principled nonparametric solution to this
problem by extracting temporal hypergraph snapshots that optimally capture
structural regularities in temporal event data according to the minimum
description length principle. We demonstrate our methods on real and synthetic
datasets, finding that they can recover planted artificial hypergraph structure
in the presence of considerable noise and reveal meaningful activity
fluctuations in human mobility data.",2023-08-31,Alec Kirkley
"In-class Data Analysis Replications: Teaching Students while Testing
  Science","Science is facing a reproducibility crisis. Previous work has proposed
incorporating data analysis replications into classrooms as a potential
solution. However, despite the potential benefits, it is unclear whether this
approach is feasible, and if so, what the involved stakeholders-students,
educators, and scientists-should expect from it. Can students perform a data
analysis replication over the course of a class? What are the costs and
benefits for educators? And how can this solution help benchmark and improve
the state of science?
  In the present study, we incorporated data analysis replications in the
project component of the Applied Data Analysis course (CS-401) taught at EPFL
(N=354 students). Here we report pre-registered findings based on surveys
administered throughout the course. First, we demonstrate that students can
replicate previously published scientific papers, most of them qualitatively
and some exactly. We find discrepancies between what students expect of data
analysis replications and what they experience by doing them along with changes
in expectations about reproducibility, which together serve as evidence of
attitude shifts to foster students' critical thinking. Second, we provide
information for educators about how much overhead is needed to incorporate
replications into the classroom and identify concerns that replications bring
as compared to more traditional assignments. Third, we identify tangible
benefits of the in-class data analysis replications for scientific communities,
such as a collection of replication reports and insights about replication
barriers in scientific work that should be avoided going forward.
  Overall, we demonstrate that incorporating replication tasks into a large
data science class can increase the reproducibility of scientific work as a
by-product of data science instruction, thus benefiting both science and
students.",2023-08-31,"Kristina Gligoric, Tiziano Piccardi, Jake Hofman, Robert West"
A stochastic block model for community detection in attributed networks,"Community detection is an important content in complex network analysis. The
existing community detection methods in attributed networks mostly focus on
only using network structure, while the methods of integrating node attributes
is mainly for the traditional community structures, and cannot detect
multipartite structures and mixture structures in network. In addition, the
model-based community detection methods currently proposed for attributed
networks do not fully consider unique topology information of nodes, such as
betweenness centrality and clustering coefficient. Therefore, a stochastic
block model that integrates betweenness centrality and clustering coefficient
of nodes for community detection in attributed networks, named BCSBM, is
proposed in this paper. Different from other generative models for attributed
networks, the generation process of links and attributes in BCSBM model follows
the Poisson distribution, and the probability between community is considered
based on the stochastic block model. Moreover, the betweenness centrality and
clustering coefficient of nodes are introduced into the process of links and
attributes generation. Finally, the expectation maximization algorithm is
employed to estimate the parameters of the BCSBM model, and the node-community
memberships is obtained through the hard division process, so the community
detection is completed. By experimenting on six real-work networks containing
different network structures, and comparing with the community detection
results of five algorithms, the experimental results show that the BCSBM model
not only inherits the advantages of the stochastic block model and can detect
various network structures, but also has good data fitting ability due to
introducing the betweenness centrality and clustering coefficient of nodes.
Overall, the performance of this model is superior to other five compared
algorithms.",2023-08-31,"Xiao Wang, Fang Dai, Wenyan Guo, Junfeng Wang"
A Mathematical Framework for Citation Disruption,"Many theories of scientific and technological progress imagine science as an
iterative, developmental process periodically interrupted by innovations which
disrupt and restructure the status quo. Due to the immense societal value
created by these disruptive scientific and technological innovations,
accurately operationalizing this perspective into quantifiable terms represents
a key challenge for researchers seeking to understand the history and
mechanisms underlying scientific and technological progress. Researchers have
recently proposed a number of quantitative measures that seek to quantify the
extent to which works in science and technology are disruptive with respect to
their scientific context. While these disruption measures show promise in their
ability to quantify potentially disruptive works of science and technology,
their definitions are bespoke to the science of science and lack a broader
theoretical framework, obscuring their interrelationships and limiting their
adoption within broader network science paradigms. We propose a mathematical
framework for conceptualizing and measuring disruptive scientific contributions
within citation networks through the lens of network centrality, and formally
relate the CD Index disruption measure and its variants to betweenness
centrality. By reinterpreting disruption through the lens of centrality, we
unify a number of existing citation-based disruption measures while
simultaneously providing natural generalizations which enjoy empirical and
computational efficiencies. We validate these theoretical observations by
computing a variety of disruption measures on real citation data and find that
computing these centrality-based disruption measures over ego networks of
increasing radius results in better discernment of award-winning scientific
innovations relative to conventional disruption metrics which rely on local
citation context alone.",2023-08-30,"Thomas Gebhart, Russell Funk"
Food Choice Mimicry on a Large University Campus,"Social influence is a strong determinant of food consumption, which in turn
influences health. Although consistent observations have been made on the role
of social factors in driving similarities in food consumption, much less is
known about the precise governing mechanisms. We study social influence on food
choice through carefully designed causal analyses, leveraging the sequential
nature of shop queues on a major university campus. In particular, we consider
a large number of adjacent purchases where a focal user immediately follows
another user (""partner"") in the checkout queue and both make a purchase.
Identifying the partner's impact on the focal user, we find strong evidence of
a specific behavioral mechanism for how dietary similarities between
individuals arise: purchasing mimicry, a phenomenon where the focal user copies
the partner's purchases. For instance, across food additions purchased during
lunchtime together with a meal, we find that the focal user is significantly
more likely to purchase the food item when the partner buys the item, v.s. when
the partner does not, increasing the purchasing probability by 14% in absolute
terms, or by 83% in relative terms. The effect is observed across all food
types, but largest for condiments, and smallest for soft drinks. We find that
no such effect is observed when a focal user is compared to a random (rather
than directly preceding) partner. Furthermore, purchasing mimicry is present
across age, gender, and status subpopulations, but strongest for students and
the youngest persons. Finally, we find a dose-response relationship whereby
mimicry decreases as proximity in the purchasing queue decreases. The results
of this study elucidate the behavioral mechanism of purchasing mimicry and have
further implications for understanding and improving dietary behaviors on
campus.",2023-08-30,"Kristina Gligoric, Arnaud Chiolero, Emre Kıcıman, Ryen W. White, Eric Horvitz, Robert West"
Jaccard-constrained dense subgraph discovery,"Finding dense subgraphs is a core problem in graph mining with many
applications in diverse domains. At the same time many real-world networks vary
over time, that is, the dataset can be represented as a sequence of graph
snapshots. Hence, it is natural to consider the question of finding dense
subgraphs in a temporal network that are allowed to vary over time to a certain
degree. In this paper, we search for dense subgraphs that have large pairwise
Jaccard similarity coefficients. More formally, given a set of graph snapshots
and a weight $\lambda$, we find a collection of dense subgraphs such that the
sum of densities of the induced subgraphs plus the sum of Jaccard indices,
weighted by $\lambda$, is maximized. We prove that this problem is NP-hard. To
discover dense subgraphs with good objective value, we present an iterative
algorithm which runs in $\mathcal{O}(n^2k^2 + m \log n + k^3 n)$ time per
single iteration, and a greedy algorithm which runs in $\mathcal{O}(n^2k^2 + m
\log n + k^3 n)$ time, where $k$ is the length of the graph sequence and $n$
and $m$ denote number of nodes and total number of edges respectively. We show
experimentally that our algorithms are efficient, they can find ground truth in
synthetic datasets and provide interpretable results from real-world datasets.
Finally, we present a case study that shows the usefulness of our problem.",2023-08-30,"Chamalee Wickrama Arachchi, Nikolaj Tatti"
"A Hybrid Membership Latent Distance Model for Unsigned and Signed
  Integer Weighted Networks","Graph representation learning (GRL) has become a prominent tool for
furthering the understanding of complex networks providing tools for network
embedding, link prediction, and node classification. In this paper, we propose
the Hybrid Membership-Latent Distance Model (HM-LDM) by exploring how a Latent
Distance Model (LDM) can be constrained to a latent simplex. By controlling the
edge lengths of the corners of the simplex, the volume of the latent space can
be systematically controlled. Thereby communities are revealed as the space
becomes more constrained, with hard memberships being recovered as the simplex
volume goes to zero. We further explore a recent likelihood formulation for
signed networks utilizing the Skellam distribution to account for signed
weighted networks and extend the HM-LDM to the signed Hybrid Membership-Latent
Distance Model (sHM-LDM). Importantly, the induced likelihood function
explicitly attracts nodes with positive links and deters nodes from having
negative interactions. We demonstrate the utility of HM-LDM and sHM-LDM on
several real networks. We find that the procedures successfully identify
prominent distinct structures, as well as how nodes relate to the extracted
aspects providing favorable performances in terms of link prediction when
compared to prominent baselines. Furthermore, the learned soft memberships
enable easily interpretable network visualizations highlighting distinct
patterns.",2023-08-29,"Nikolaos Nakis, Abdulkadir Çelikkanat, Morten Mørup"
"The Anatomy of Conspirators: Unveiling Traits using a Comprehensive
  Twitter Dataset","The discourse around conspiracy theories is currently thriving amidst the
rampant misinformation in online environments. Research in this field has been
focused on detecting conspiracy theories on social media, often relying on
limited datasets. In this study, we present a novel methodology for
constructing a Twitter dataset that encompasses accounts engaged in
conspiracy-related activities throughout the year 2022. Our approach centers on
data collection that is independent of specific conspiracy theories and
information operations. Additionally, our dataset includes a control group
comprising randomly selected users who can be fairly compared to the
individuals involved in conspiracy activities. This comprehensive collection
effort yielded a total of 15K accounts and 37M tweets extracted from their
timelines. We conduct a comparative analysis of the two groups across three
dimensions: topics, profiles, and behavioral characteristics. The results
indicate that conspiracy and control users exhibit similarity in terms of their
profile metadata characteristics. However, they diverge significantly in terms
of behavior and activity, particularly regarding the discussed topics, the
terminology used, and their stance on trending subjects. In addition, we find
no significant disparity in the presence of bot users between the two groups.
Finally, we develop a classifier to identify conspiracy users using features
borrowed from bot, troll and linguistic literature. The results demonstrate a
high accuracy level (with an F1 score of 0.94), enabling us to uncover the most
discriminating features associated with conspiracy-related accounts.",2023-08-29,"Margherita Gambini, Serena Tardelli, Maurizio Tesconi"
"CommunityFish: A Poisson-based Document Scaling With Hierarchical
  Clustering","Document scaling has been a key component in text-as-data applications for
social scientists and a major field of interest for political researchers, who
aim at uncovering differences between speakers or parties with the help of
different probabilistic and non-probabilistic approaches. Yet, most of these
techniques are either built upon the agnostically bag-of-word hypothesis or use
prior information borrowed from external sources that might embed the results
with a significant bias. If the corpus has long been considered as a collection
of documents, it can also be seen as a dense network of connected words whose
structure could be clustered to differentiate independent groups of words,
based on their co-occurrences in documents, known as communities. This paper
introduces CommunityFish as an augmented version of Wordfish based on a
hierarchical clustering, namely the Louvain algorithm, on the word space to
yield communities as semantic and independent n-grams emerging from the corpus
and use them as an input to Wordfish method, instead of considering the word
space. This strategy emphasizes the interpretability of the results, since
communities have a non-overlapping structure, hence a crucial informative power
in discriminating parties or speakers, in addition to allowing a faster
execution of the Poisson scaling model. Aside from yielding communities,
assumed to be subtopic proxies, the application of this technique outperforms
the classic Wordfish model by highlighting historical developments in the U.S.
State of the Union addresses and was found to replicate the prevailing
political stance in Germany when using the corpus of parties' legislative
manifestos.",2023-08-28,Sami Diaf
"AI in the Gray: Exploring Moderation Policies in Dialogic Large Language
  Models vs. Human Answers in Controversial Topics","The introduction of ChatGPT and the subsequent improvement of Large Language
Models (LLMs) have prompted more and more individuals to turn to the use of
ChatBots, both for information and assistance with decision-making. However,
the information the user is after is often not formulated by these ChatBots
objectively enough to be provided with a definite, globally accepted answer.
  Controversial topics, such as ""religion"", ""gender identity"", ""freedom of
speech"", and ""equality"", among others, can be a source of conflict as partisan
or biased answers can reinforce preconceived notions or promote disinformation.
By exposing ChatGPT to such debatable questions, we aim to understand its level
of awareness and if existing models are subject to socio-political and/or
economic biases. We also aim to explore how AI-generated answers compare to
human ones. For exploring this, we use a dataset of a social media platform
created for the purpose of debating human-generated claims on polemic subjects
among users, dubbed Kialo.
  Our results show that while previous versions of ChatGPT have had important
issues with controversial topics, more recent versions of ChatGPT
(gpt-3.5-turbo) are no longer manifesting significant explicit biases in
several knowledge areas. In particular, it is well-moderated regarding economic
aspects. However, it still maintains degrees of implicit libertarian leaning
toward right-winged ideals which suggest the need for increased moderation from
the socio-political point of view. In terms of domain knowledge on
controversial topics, with the exception of the ""Philosophical"" category,
ChatGPT is performing well in keeping up with the collective human level of
knowledge. Finally, we see that sources of Bing AI have slightly more tendency
to the center when compared to human answers. All the analyses we make are
generalizable to other types of biases and domains.",2023-08-28,"Vahid Ghafouri, Vibhor Agarwal, Yong Zhang, Nishanth Sastry, Jose Such, Guillermo Suarez-Tangil"
Graph Meets LLMs: Towards Large Graph Models,"Large models have emerged as the most recent groundbreaking achievements in
artificial intelligence, and particularly machine learning. However, when it
comes to graphs, large models have not achieved the same level of success as in
other fields, such as natural language processing and computer vision. In order
to promote applying large models for graphs forward, we present a perspective
paper to discuss the challenges and opportunities associated with developing
large graph models. First, we discuss the desired characteristics of large
graph models. Then, we present detailed discussions from three key
perspectives: representation basis, graph data, and graph models. In each
category, we provide a brief overview of recent advances and highlight the
remaining challenges together with our visions. Finally, we discuss valuable
applications of large graph models. We believe this perspective can encourage
further investigations into large graph models, ultimately pushing us one step
closer towards artificial general intelligence (AGI). We are the first to
comprehensively study large graph models, to the best of our knowledge.",2023-08-28,"Ziwei Zhang, Haoyang Li, Zeyang Zhang, Yijian Qin, Xin Wang, Wenwu Zhu"
Topology and dynamics of higher-order multiplex networks,"Higher-order networks are gaining significant scientific attention due to
their ability to encode the many-body interactions present in complex systems.
However, higher-order networks have the limitation that they only capture
many-body interactions of the same type. To address this limitation, we present
a mathematical framework that determines the topology of higher-order multiplex
networks and illustrates the interplay between their topology and dynamics.
Specifically, we examine the diffusion of topological signals associated not
only to the nodes but also to the links and to the higher-dimensional simplices
of multiplex simplicial complexes. We leverage on the ubiquitous presence of
the overlap of the simplices to couple the dynamics among multiplex layers,
introducing a definition of multiplex Hodge Laplacians and Dirac operators. We
show that the spectral properties of these operators determine higher-order
diffusion on higher-order multiplex networks and encode their multiplex Betti
numbers. Our numerical investigation of the spectral properties of synthetic
and real (connectome, microbiome) multiplex simplicial complexes indicates that
the coupling between the layers can either speed up or slow down the
higher-order diffusion of topological signals. This mathematical framework is
very general and can be applied to study generic higher-order systems with
interactions of multiple types. In particular, these results might find
applications in brain networks which are understood to be both multilayer and
higher-order.",2023-08-27,"Sanjukta Krishnagopal, Ginestra Bianconi"
"SPEED: Streaming Partition and Parallel Acceleration for Temporal
  Interaction Graph Embedding","Temporal Interaction Graphs (TIGs) are widely employed to model intricate
real-world systems such as financial systems and social networks. To capture
the dynamism and interdependencies of nodes, existing TIG embedding models need
to process edges sequentially and chronologically. However, this requirement
prevents it from being processed in parallel and struggle to accommodate
burgeoning data volumes to GPU. Consequently, many large-scale temporal
interaction graphs are confined to CPU processing. Furthermore, a generalized
GPU scaling and acceleration approach remains unavailable. To facilitate
large-scale TIGs' implementation on GPUs for acceleration, we introduce a novel
training approach namely Streaming Edge Partitioning and Parallel Acceleration
for Temporal Interaction Graph Embedding (SPEED). The SPEED is comprised of a
Streaming Edge Partitioning Component (SEP) which addresses space overhead
issue by assigning fewer nodes to each GPU, and a Parallel Acceleration
Component (PAC) which enables simultaneous training of different sub-graphs,
addressing time overhead issue. Our method can achieve a good balance in
computing resources, computing time, and downstream task performance. Empirical
validation across 7 real-world datasets demonstrates the potential to expedite
training speeds by a factor of up to 19.29x. Simultaneously, resource
consumption of a single-GPU can be diminished by up to 69%, thus enabling the
multiple GPU-based training and acceleration encompassing millions of nodes and
billions of edges. Furthermore, our approach also maintains its competitiveness
in downstream tasks.",2023-08-27,"Xi Chen, Yongxiang Liao, Yun Xiong, Yao Zhang, Siwei Zhang, Jiawei Zhang, Yiheng Sun"
"Neural Influence Estimator: Towards Real-time Solutions to Influence
  Blocking Maximization","Real-time solutions to the influence blocking maximization (IBM) problems are
crucial for promptly containing the spread of misinformation. However,
achieving this goal is non-trivial, mainly because assessing the blocked
influence of an IBM problem solution typically requires plenty of expensive
Monte Carlo simulations (MCSs). Although several approaches have been proposed
to enhance efficiency, they still fail to achieve real-time solutions to IBM
problems of practical scales. This work presents a novel approach that enables
solving IBM problems with hundreds of thousands of nodes and edges in seconds.
The key idea is to construct a fast-to-evaluate surrogate model, called neural
influence estimator (NIE), as a substitute for the time-intensive MCSs. To this
end, a learning problem is formulated to build the NIE that takes the
false-and-true information instance as input, extracts features describing the
topology and inter-relationship between two seed sets, and predicts the blocked
influence. A well-trained NIE can generalize across different IBM problems
defined on a social network, and can be readily combined with existing IBM
optimization algorithms such as the greedy algorithm. The experiments on 25 IBM
problems with up to millions of edges show that the NIE-based optimization
method can be up to four orders of magnitude faster than MCSs-based
optimization method to achieve the same solution quality. Moreover, given a
real-time constraint of one minute, the NIE-based method can solve IBM problems
with up to hundreds of thousands of nodes, which is at least one order of
magnitude larger than what can be solved by existing methods.",2023-08-27,"Wenjie Chen, Shengcai Liu, Yew-Soon Ong, Ke Tang"
"Quantifying the Influence of User Behaviors on the Dissemination of Fake
  News on Twitter with Multivariate Hawkes Processes","Fake news has emerged as a pervasive problem within Online Social Networks,
leading to a surge of research interest in this area. Understanding the
dissemination mechanisms of fake news is crucial in comprehending the
propagation of disinformation/misinformation and its impact on users in Online
Social Networks. This knowledge can facilitate the development of interventions
to curtail the spread of false information and inform affected users to remain
vigilant against fraudulent/malicious content. In this paper, we specifically
target the Twitter platform and propose a Multivariate Hawkes Point Processes
model that incorporates essential factors such as user networks, response tweet
types, and user stances as model parameters. Our objective is to investigate
and quantify their influence on the dissemination process of fake news. We
derive parameter estimation expressions using an Expectation Maximization
algorithm and validate them on a simulated dataset. Furthermore, we conduct a
case study using a real dataset of fake news collected from Twitter to explore
the impact of user stances and tweet types on dissemination patterns. This
analysis provides valuable insights into how users are influenced by or
influence the dissemination process of disinformation/misinformation, and
demonstrates how our model can aid in intervening in this process.",2023-08-26,"Yichen Jiang, Michael D. Porter"
Network science Ising states of matter,"Network science provides very powerful tools for extracting information from
interacting data. Although recently the unsupervised detection of phases of
matter using machine learning has raised significant interest, the full
prediction power of network science has not yet been systematically explored in
this context. Here we fill this gap by providing an in-depth statistical,
combinatorial, geometrical and topological characterization of 2D Ising
snapshot networks (IsingNets) extracted from Monte Carlo simulations of the
$2$D Ising model at different temperatures, going across the phase transition.
Our analysis reveals the complex organization properties of IsingNets in both
the ferromagnetic and paramagnetic phases and demonstrates the significant
deviations of the IsingNets with respect to randomized null models. In
particular percolation properties of the IsingNets reflect the existence of the
symmetry between configurations with opposite magnetization below the critical
temperature and the very compact nature of the two emerging giant clusters
revealed by our persistent homology analysis of the IsingNets. Moreover, the
IsingNets display a very broad degree distribution and significant
degree-degree correlations and weight-degree correlations demonstrating that
they encode relevant information present in the configuration space of the $2$D
Ising model. The geometrical organization of the critical IsingNets is
reflected in their spectral properties deviating from the one of the null
model. This work reveals the important insights that network science can bring
to the characterization of phases of matter. The set of tools described hereby
can be applied as well to numerical and experimental data.",2023-08-25,"Hanlin Sun, Rajat Kumar Panda, Roberto Verdel, Alex Rodriguez, Marcello Dalmonte, Ginestra Bianconi"
"TpuGraphs: A Performance Prediction Dataset on Large Tensor
  Computational Graphs","Precise hardware performance models play a crucial role in code
optimizations. They can assist compilers in making heuristic decisions or aid
autotuners in identifying the optimal configuration for a given program. For
example, the autotuner for XLA, a machine learning compiler, discovered 10-20%
speedup on state-of-the-art models serving substantial production traffic at
Google. Although there exist a few datasets for program performance prediction,
they target small sub-programs such as basic blocks or kernels. This paper
introduces TpuGraphs, a performance prediction dataset on full tensor programs,
represented as computational graphs, running on Tensor Processing Units (TPUs).
Each graph in the dataset represents the main computation of a machine learning
workload, e.g., a training epoch or an inference step. Each data sample
contains a computational graph, a compilation configuration, and the execution
time of the graph when compiled with the configuration. The graphs in the
dataset are collected from open-source machine learning programs, featuring
popular model architectures, e.g., ResNet, EfficientNet, Mask R-CNN, and
Transformer. TpuGraphs provides 25x more graphs than the largest graph property
prediction dataset (with comparable graph sizes), and 770x larger graphs on
average compared to existing performance prediction datasets on machine
learning programs. This graph-level prediction task on large graphs introduces
new challenges in learning, ranging from scalability, training efficiency, to
model quality.",2023-08-25,"Phitchaya Mangpo Phothilimthana, Sami Abu-El-Haija, Kaidi Cao, Bahare Fatemi, Mike Burrows, Charith Mendis, Bryan Perozzi"
Age of Information Diffusion on Social Networks,"To promote viral marketing, major social platforms (e.g., Facebook
Marketplace and Pinduoduo) repeatedly select and invite different users (as
seeds) in online social networks to share fresh information about a product or
service with their friends. Thereby, we are motivated to optimize a multi-stage
seeding process of viral marketing in social networks, and adopt the recent
notions of the peak and the average age of information (AoI) to measure the
timeliness of promotion information received by network users. Our problem is
different from the literature on information diffusion in social networks,
which limits to one-time seeding and overlooks AoI dynamics or information
replacement over time. As a critical step, we manage to develop closed-form
expressions that characterize and trace AoI dynamics over any social network.
For the peak AoI problem, we first prove the NP-hardness of our multi-stage
seeding problem by a highly non-straightforward reduction from the dominating
set problem, and then present a new polynomial-time algorithm that achieves
good approximation guarantees (e.g., less than 2 for linear network topology).
To minimize the average AoI, we also prove that our problem is NP-hard by
properly reducing it from the set cover problem. Benefiting from our two-sided
bound analysis on the average AoI objective, we build up a new framework for
approximation analysis and link our problem to a much simplified sum-distance
minimization problem. This intriguing connection inspires us to develop another
polynomial-time algorithm that achieves a good approximation guarantee.
Additionally, our theoretical results are well corroborated by experiments on a
real social network.",2023-08-25,"Songhua Li, Lingjie Duan"
"Estimating Treatment Effects Using Costly Simulation Samples from a
  Population-Scale Model of Opioid Use Disorder","Large-scale models require substantial computational resources for analysis
and studying treatment conditions. Specifically, estimating treatment effects
using simulations may require a lot of infeasible resources to allocate at
every treatment condition. Therefore, it is essential to develop efficient
methods to allocate computational resources for estimating treatment effects.
Agent-based simulation allows us to generate highly realistic simulation
samples. FRED (A Framework for Reconstructing Epidemiological Dynamics) is an
agent-based modeling system with a geospatial perspective using a synthetic
population constructed based on the U.S. census data. Given its synthetic
population, FRED simulations present a baseline for comparable results from
different treatment conditions and treatment conditions. In this paper, we show
three other methods for estimating treatment effects. In the first method, we
resort to brute-force allocation, where all treatment conditions have an equal
number of samples with a relatively large number of simulation runs. In the
second method, we try to reduce the number of simulation runs by customizing
individual samples required for each treatment effect based on the width of
confidence intervals around the mean estimates. In the third method, we use a
regression model, which allows us to learn across the treatment conditions such
that simulation samples allocated for a treatment condition will help better
estimate treatment effects in other conditions. We show that the
regression-based methods result in a comparable estimate of treatment effects
with less computational resources. The reduced variability and faster
convergence of model-based estimates come at the cost of increased bias, and
the bias-variance trade-off can be controlled by adjusting the number of model
parameters (e.g., including higher-order interaction terms in the regression
model).",2023-08-24,"Abdulrahman A. Ahmed, M. Amin Rahimian, Mark S. Roberts"
"Tracking the Structure and Sentiment of Vaccination Discussions on
  Mumsnet","Vaccination is one of the most impactful healthcare interventions in terms of
lives saved at a given cost, leading the anti-vaccination movement to be
identified as one of the top 10 threats to global health in 2019 by the World
Health Organization. This issue increased in importance during the COVID-19
pandemic where, despite good overall adherence to vaccination, specific
communities still showed high rates of refusal. Online social media has been
identified as a breeding ground for anti-vaccination discussions. In this work,
we study how vaccination discussions are conducted in the discussion forum of
Mumsnet, a United Kingdom based website aimed at parents. By representing
vaccination discussions as networks of social interactions, we can apply
techniques from network analysis to characterize these discussions, namely
network comparison, a task aimed at quantifying similarities and differences
between networks. Using network comparison based on graphlets -- small
connected network subgraphs -- we show how the topological structure
vaccination discussions on Mumsnet differs over time, in particular before and
after COVID-19. We also perform sentiment analysis on the content of the
discussions and show how the sentiment towards vaccinations changes over time.
Our results highlight an association between differences in network structure
and changes to sentiment, demonstrating how network comparison can be used as a
tool to guide and enhance the conclusions from sentiment analysis.",2023-08-24,"Miguel E. P. Silva, Rigina Skeva, Thomas House, Caroline Jay"
"Does society show differential attention to researchers based on gender
  and field?","While not all researchers prioritize social impact, it is undeniably a
crucial aspect that adds significance to their work. The objective of this
paper is to explore potential gender differences in the social attention paid
to researchers and to examine their association with specific fields of study.
To achieve this goal, the paper analyzes four dimensions of social influence
and examines three measures of social attention to researchers. The dimensions
are media influence (mentions in mainstream news), political influence
(mentions in public policy reports), social media influence (mentions in
Twitter), and educational influence (mentions in Wikipedia). The measures of
social attention to researchers are: proportion of publications with social
mentions (social attention orientation), mentions per publication (level of
social attention), and mentions per mentioned publication (intensity of social
attention). By analyzing the rankings of authors -- for the four dimensions
with the three measures in the 22 research fields of the Web of Science
database -- and by using Spearman correlation coefficients, we conclude that:
1) significant differences are observed between fields; 2) the dimensions
capture different and independent aspects of the social impact. Finally, we use
non-parametric means comparison tests to detect gender bias in social
attention. We conclude that for most fields and dimensions with enough non-zero
altmetrics data, gender differences in social attention are not predominant,
but are still present and vary across fields.",2023-08-22,"Sara M. González-Betancor, Pablo Dorta-González"
"Enhancing Graph Transformers with Hierarchical Distance Structural
  Encoding","Graph transformers need strong inductive biases to derive meaningful
attention scores. Yet, current methods often fall short in capturing longer
ranges, hierarchical structures, or community structures, which are common in
various graphs such as molecules, social networks, and citation networks. This
paper presents a Hierarchical Distance Structural Encoding (HDSE) method to
model node distances in a graph, focusing on its multi-level, hierarchical
nature. We introduce a novel framework to seamlessly integrate HDSE into the
attention mechanism of existing graph transformers, allowing for simultaneous
application with other positional encodings. To apply graph transformers with
HDSE to large-scale graphs, we further propose a high-level HDSE that
effectively biases the linear transformers towards graph hierarchies. We
theoretically prove the superiority of HDSE over shortest path distances in
terms of expressivity and generalization. Empirically, we demonstrate that
graph transformers with HDSE excel in graph classification, regression on 7
graph-level datasets, and node classification on 11 large-scale graphs,
including those with up to a billion nodes.",2023-08-22,"Yuankai Luo, Hongkang Li, Lei Shi, Xiao-Ming Wu"
How Expressive are Graph Neural Networks in Recommendation?,"Graph Neural Networks (GNNs) have demonstrated superior performance on
various graph learning tasks, including recommendation, where they leverage
user-item collaborative filtering signals in graphs. However, theoretical
formulations of their capability are scarce, despite their empirical
effectiveness in state-of-the-art recommender models. Recently, research has
explored the expressiveness of GNNs in general, demonstrating that message
passing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that
GNNs combined with random node initialization are universal. Nevertheless, the
concept of ""expressiveness"" for GNNs remains vaguely defined. Most existing
works adopt the graph isomorphism test as the metric of expressiveness, but
this graph-level task may not effectively assess a model's ability in
recommendation, where the objective is to distinguish nodes of different
closeness. In this paper, we provide a comprehensive theoretical analysis of
the expressiveness of GNNs in recommendation, considering three levels of
expressiveness metrics: graph isomorphism (graph-level), node automorphism
(node-level), and topological closeness (link-level). We propose the
topological closeness metric to evaluate GNNs' ability to capture the
structural distance between nodes, which aligns closely with the objective of
recommendation. To validate the effectiveness of this new metric in evaluating
recommendation performance, we introduce a learning-less GNN algorithm that is
optimal on the new metric and can be optimal on the node-level metric with
suitable modification. We conduct extensive experiments comparing the proposed
algorithm against various types of state-of-the-art GNN models to explore the
explainability of the new metric in the recommendation task. For
reproducibility, implementation codes are available at
https://github.com/HKUDS/GTE.",2023-08-22,"Xuheng Cai, Lianghao Xia, Xubin Ren, Chao Huang"
"An impossibility result for Markov Chain Monte Carlo sampling from
  micro-canonical bipartite graph ensembles","Markov Chain Monte Carlo (MCMC) algorithms are commonly used to sample from
graph ensembles. Two graphs are neighbors in the state space if one can be
obtained from the other with only a few modifications, e.g., edge rewirings.
For many common ensembles, e.g., those preserving the degree sequences of
bipartite graphs, rewiring operations involving two edges are sufficient to
create a fully-connected state space, and they can be performed efficiently. We
show that, for ensembles of bipartite graphs with fixed degree sequences and
number of butterflies (k2,2 bi-cliques), there is no universal constant c such
that a rewiring of at most c edges at every step is sufficient for any such
ensemble to be fully connected. Our proof relies on an explicit construction of
a family of pairs of graphs with the same degree sequences and number of
butterflies, with each pair indexed by a natural c, and such that any sequence
of rewiring operations transforming one graph into the other must include at
least one rewiring operation involving at least c edges. Whether rewiring these
many edges is sufficient to guarantee the full connectivity of the state space
of any such ensemble remains an open question. Our result implies the
impossibility of developing efficient, graph-agnostic, MCMC algorithms for
these ensembles, as the necessity to rewire an impractically large number of
edges may hinder taking a step on the state space.",2023-08-21,"Giulia Preti, Gianmarco De Francisci Morales, Matteo Riondato"
DySuse: Susceptibility Estimation in Dynamic Social Networks,"Influence estimation aims to predict the total influence spread in social
networks and has received surged attention in recent years. Most current
studies focus on estimating the total number of influenced users in a social
network, and neglect susceptibility estimation that aims to predict the
probability of each user being influenced from the individual perspective. As a
more fine-grained estimation task, susceptibility estimation is full of
attractiveness and practical value. Based on the significance of susceptibility
estimation and dynamic properties of social networks, we propose a task, called
susceptibility estimation in dynamic social networks, which is even more
realistic and valuable in real-world applications. Susceptibility estimation in
dynamic networks has yet to be explored so far and is computationally
intractable to naively adopt Monte Carlo simulation to obtain the results. To
this end, we propose a novel end-to-end framework DySuse based on dynamic graph
embedding technology. Specifically, we leverage a structural feature module to
independently capture the structural information of influence diffusion on each
single graph snapshot. Besides, {we propose the progressive mechanism according
to the property of influence diffusion,} to couple the structural and temporal
information during diffusion tightly. Moreover, a self-attention block {is
designed to} further capture temporal dependency by flexibly weighting
historical timestamps. Experimental results show that our framework is superior
to the existing dynamic graph embedding models and has satisfactory prediction
performance in multiple influence diffusion models.",2023-08-21,"Yingdan Shi, Jingya Zhou, Congcong Zhang"
Modeling Random Networks with Heterogeneous Reciprocity,"Reciprocity, or the tendency of individuals to mirror behavior, is a key
measure that describes information exchange in a social network. Users in
social networks tend to engage in different levels of reciprocal behavior.
Differences in such behavior may indicate the existence of communities that
reciprocate links at varying rates. In this paper, we develop methodology to
model the diverse reciprocal behavior in growing social networks. In
particular, we present a preferential attachment model with heterogeneous
reciprocity that imitates the attraction users have for popular users, plus the
heterogeneous nature by which they reciprocate links. We compare Bayesian and
frequentist model fitting techniques for large networks, as well as
computationally efficient variational alternatives. Cases where the number of
communities are known and unknown are both considered. We apply the presented
methods to the analysis of a Facebook wallpost network where users have
non-uniform reciprocal behavior patterns. The fitted model captures the
heavy-tailed nature of the empirical degree distributions in the Facebook data
and identifies multiple groups of users that differ in their tendency to reply
to and receive responses to wallposts.",2023-08-19,"Daniel Cirkovic, Tiandong Wang"
Vulnerability of democratic electoral systems,"The two most common types of electoral systems (ES) used in electing national
legislatures are proportional representation and plurality voting. When they
are evaluated, most often the arguments come from social choice theory and
political sciences. The former overall uses an axiomatic approach including a
list of mathematical criteria a system should fulfill. The latter predominantly
focuses on the trade-off between proportionality of apportionment and
governability. However, there is no consensus on the best ES, nor on the set of
indexes and measures that would be the most important in such assessment.
Moreover, the ongoing debate about the fairness of national elections neglects
the study of their vulnerabilities. Here we address this research gap with a
framework that can measure electoral systems' vulnerability to different means
of influence. Using in silico analysis we show that plurality voting systems
are less stable than proportional representation. They are also more
susceptible to political agitators and media propaganda. A review of real-world
ES reveals possible improvements in their design leading to lower
susceptibility. Additionally, our simulation framework allows computation of
popular indexes, as the Gallagher index or the effective number of parties, in
different scenarios. Our work provides a new tool for dealing with modern
threats to democracy that could destabilize voting processes. Furthermore, our
results add an important argument in a long-standing discussion on evaluation
of ES.",2023-08-19,"Tomasz Raducha, Jarosław Klamut, Roger Cremades, Paul Bouman, Mateusz Wiliński"
"Unveiling the Collaborative Patterns of Artificial Intelligence
  Applications in Human Resource Management: A Social Network Analysis Approach","The integration of artificial intelligence (AI) into human resource
management (HRM) strategies has become increasingly common due to technological
advancements. This has spurred a new field of research focused on evaluating
the impact of AI adoption on business and individual outcomes, as well as how
to evaluate AI-enabled HRM practices. However, there is limited
cross-disciplinary research in this area, causing a fragmented body of
knowledge. To address this issue, social network analysis has been recognized
as a tool for analyzing and researching large-scale social phenomena in HRM.
The study of scientific co-authorship networks is one application of social
network analysis that can help identify the main components and trends in this
field. Using social network analysis indicators, the current study examined the
AI&HRM co-authorship network, which consists of 43,789 members and 81,891
scientific collaborations. The study analyzed articles related to AI&HRM
published between 2000 and 2023 extracted from the WOS citation database.
Through centrality measures, the most important members of the ""AI&HRM""
co-authorship network were identified using the TOPSIS method, which identified
twenty prominent researchers in this field. The study also examined the
keywords ""AI&HRM"" and the scientific cooperation network of nations,
universities, and communities. Overall, this study highlights the importance of
cross-disciplinary research and social network analysis in understanding the
implications of AI adoption in HRM.",2023-08-18,"Mehrdad Maghsoudi, Motahareh Kamrani Shahri, Mehrdad Agha Mohammad Ali Kermani, Rahim Khanizad"
"A Two-Part Machine Learning Approach to Characterizing Network
  Interference in A/B Testing","The reliability of controlled experiments, commonly referred to as ""A/B
tests,"" is often compromised by network interference, where the outcomes of
individual units are influenced by interactions with others. Significant
challenges in this domain include the lack of accounting for complex social
network structures and the difficulty in suitably characterizing network
interference. To address these challenges, we propose a machine learning-based
method. We introduce ""causal network motifs"" and utilize transparent machine
learning models to characterize network interference patterns underlying an A/B
test on networks. Our method's performance has been demonstrated through
simulations on both a synthetic experiment and a large-scale test on Instagram.
Our experiments show that our approach outperforms conventional methods such as
design-based cluster randomization and conventional analysis-based neighborhood
exposure mapping. Our approach provides a comprehensive and automated solution
to address network interference for A/B testing practitioners. This aids in
informing strategic business decisions in areas such as marketing effectiveness
and product customization.",2023-08-18,"Yuan Yuan, Kristen M. Altenburger"
Cooperation and interdependence in global science funding,"Investments in research and development are key to scientific and economic
growth and to the well-being of society. Scientific research demands
significant resources making national scientific investment a crucial driver of
scientific production. As scientific production becomes increasingly
multinational, it is critical to study how nations' scientific activities are
funded both domestically and internationally. By tracing research grants
acknowledged in scholarly publications, our study reveals a shifting duopoly of
China and the United States in the global funding landscape, with a contrasting
funding pattern; while China has surpassed the United States in publications
with acknowledged domestic and international funding, the United States largely
maintains its role as the most important global research partner. Our results
also highlight the precarity of low- and middle-income countries to global
funding disruptions. By revealing the complex interdependence and collaboration
between countries in the global scientific enterprise, this work informs future
studies investigating the national and global scientific enterprise and how
funding leads to both productive cooperation and vulnerable dependencies.",2023-08-16,"Lili Miao, Vincent Larivière, Feifei Wang, Yong-Yeol Ahn, Cassidy R. Sugimoto"
"Uncovering the Skillsets Required in Computer Science Jobs Using Social
  Network Analysis","The rapid growth of technology and computer science, which has led to a surge
in demand for skilled professionals in this field. The skill set required for
computer science jobs has evolved rapidly, creating challenges for those
already in the workforce who need to adapt their skills quickly to meet
industry demands. To stay ahead of the curve, it is essential to understand the
hottest skills needed in the field. The article introduces a new method for
analyzing job advertisements using social network analysis to identify the most
critical skills required by employers in the market. In this research, to form
the communication network of skills, first 5763 skills were collected from the
LinkedIn social network, then the relationship between skills was collected and
searched in 7777 computer science job advertisements, and finally, the balanced
communication network of skills was formed. The study analyzes the formed
communication network of skills in the computer science job market and
identifies four distinct communities of skills: Generalists, Infrastructure and
Security, Software Development, and Embedded Systems. The findings reveal that
employers value both hard and soft skills, such as programming languages and
teamwork. Communication skills were found to be the most important skill in the
labor market. Additionally, certain skills were highlighted based on their
centrality indices, including communication, English, SQL, Git, and business
skills, among others. The study provides valuable insights into the current
state of the computer science job market and can help guide individuals and
organizations in making informed decisions about skills acquisition and hiring
practices.",2023-08-16,Mehrdad Maghsoudi
"Graph Out-of-Distribution Generalization with Controllable Data
  Augmentation","Graph Neural Network (GNN) has demonstrated extraordinary performance in
classifying graph properties. However, due to the selection bias of training
and testing data (e.g., training on small graphs and testing on large graphs,
or training on dense graphs and testing on sparse graphs), distribution
deviation is widespread. More importantly, we often observe \emph{hybrid
structure distribution shift} of both scale and density, despite of one-sided
biased data partition. The spurious correlations over hybrid distribution
deviation degrade the performance of previous GNN methods and show large
instability among different datasets. To alleviate this problem, we propose
\texttt{OOD-GMixup} to jointly manipulate the training distribution with
\emph{controllable data augmentation} in metric space. Specifically, we first
extract the graph rationales to eliminate the spurious correlations due to
irrelevant information. Secondly, we generate virtual samples with perturbation
on graph rationale representation domain to obtain potential OOD training
samples. Finally, we propose OOD calibration to measure the distribution
deviation of virtual samples by leveraging Extreme Value Theory, and further
actively control the training distribution by emphasizing the impact of virtual
OOD samples. Extensive studies on several real-world datasets on graph
classification demonstrate the superiority of our proposed method over
state-of-the-art baselines.",2023-08-16,"Bin Lu, Xiaoying Gan, Ze Zhao, Shiyu Liang, Luoyi Fu, Xinbing Wang, Chenghu Zhou"
Community detection based on structural balance in signed networks,"In signed networks, some existing community detection methods treat negative
connections as intercommunity links and positive ones as intracommunity links.
However, it is important to recognize that negative links on real-world
networks also play a key role in maintaining community stability. In this work,
our aim is to identify communities that are not only densely connected but also
harmonious or balanced in terms of the nature of their relationships. Such
communities are more likely to be stable over time and less prone to conflicts.
Consequently, we propose a motif-based method to identify communities by
quantifying the importance of links in the local structural balance. The
results in synthetic and real-world networks show that the proposed method has
a higher performance in identifying the community. In addition, it demonstrates
strong robustness, i.e., remains insensitive to the balance of the network, and
accurately classifies communities in real-world networks.",2023-08-15,"Peng Zhang, Xianyu Xu, Leyang Xue"
"Integrated dataset for air travel and reported Zika virus cases in
  Colombia (Data and Resources Paper)","This open-access dataset provides consistent records of air travel volumes
between 205 airport catchments in Colombia and the associated number of
reported human cases of Zika virus within these catchments during the arbovirus
outbreak between October 2015 and September 2016. We associated in this dataset
the monthly air travel volumes provided by the Colombian Civil Aviation
Authority (AEROCIVIL) with the reported human cases of Zika Virus published by
The Pan American Health Organization (PAHO). Our methodology consists of
geocoding all the reported airports and identifying the catchment of each
airport using the municipalities' boundaries since reported human cases of Zika
Virus are available at the municipal level. In addition, we calculated the
total population at risk in each airport catchment by combining the total
population count in a catchment with the environmental suitability of the Aedes
aegypti mosquito, the vector for the Zika virus. We separated the monthly air
travel volumes into domestic and international based on the location of the
origin airport. The current dataset includes the total air travel volumes of
23,539,364 passengers on domestic flights and 11,592,197 on international ones.
We validated our dataset by comparing the monthly aggregated air travel volumes
between airport catchments to those predicted by the gravity model. We hope the
novel dataset will provide a resource to researchers studying the role of human
mobility in the spread of mosquito-borne diseases and modeling disease spread
in realistic networks.",2023-08-14,"Aiman Soliman, Priyam Mazumdar, Aaron Hoyle-Katz, Brian Allan, Allison Gardner"
Calling The Dead: Resilience In The WTC Communication Networks,"Organizations in emergency settings must cope with various sources of
disruption, most notably personnel loss. Death, incapacitation, or isolation of
individuals within an organizational communication network can impair
information passing, coordination, and connectivity, and may drive maladaptive
responses such as repeated attempts to contact lost personnel (``calling the
dead'') that themselves consume scarce resources. At the same time,
organizations may respond to such disruption by reorganizing to restore
function, a behavior that is fundamental to organizational resilience. Here, we
use empirically calibrated models of communication for 17 groups of responders
to the World Trade Center Disaster to examine the impact of exogenous removal
of personnel on communication activity and network resilience. We find that
removal of high-degree personnel and those in institutionally coordinative
roles is particularly damaging to these organizations, with specialist
responders being slower to adapt to losses. However, all organizations show
adaptations to disruption, in some cases becoming better connected and making
more complete use of personnel relative to control after experiencing losses.",2023-08-14,"Selena M. Livas, Scott Leo Renshaw, Carter T. Butts"
"Mainstream News Articles Co-Shared with Fake News Buttress
  Misinformation Narratives","Most prior and current research examining misinformation spread on social
media focuses on reports published by 'fake' news sources. These approaches
fail to capture another potential form of misinformation with a much larger
audience: factual news from mainstream sources ('real' news) repurposed to
promote false or misleading narratives. We operationalize narratives using an
existing unsupervised NLP technique and examine the narratives present in
misinformation content. We find that certain articles from reliable outlets are
shared by a disproportionate number of users who also shared fake news on
Twitter. We consider these 'real' news articles to be co-shared with fake news.
We show that co-shared articles contain existing misinformation narratives at a
significantly higher rate than articles from the same reliable outlets that are
not co-shared with fake news. This holds true even when articles are chosen
following strict criteria of reliability for the outlets and after accounting
for the alternative explanation of partisan curation of articles. For example,
we observe that a recent article published by The Washington Post titled
""Vaccinated people now make up a majority of COVID deaths"" was
disproportionately shared by Twitter users with a history of sharing
anti-vaccine false news reports. Our findings suggest a strategic repurposing
of mainstream news by conveyors of misinformation as a way to enhance the reach
and persuasiveness of misleading narratives. We also conduct a comprehensive
case study to help highlight how such repurposing can happen on Twitter as a
consequence of the inclusion of particular narratives in the framing of
mainstream news.",2023-08-12,"Pranav Goel, Jon Green, David Lazer, Philip Resnik"
"Latent Random Steps as Relaxations of Max-Cut, Min-Cut, and More","Algorithms for node clustering typically focus on finding homophilous
structure in graphs. That is, they find sets of similar nodes with many edges
within, rather than across, the clusters. However, graphs often also exhibit
heterophilous structure, as exemplified by (nearly) bipartite and tripartite
graphs, where most edges occur across the clusters. Grappling with such
structure is typically left to the task of graph simplification. We present a
probabilistic model based on non-negative matrix factorization which unifies
clustering and simplification, and provides a framework for modeling arbitrary
graph structure. Our model is based on factorizing the process of taking a
random walk on the graph. It permits an unconstrained parametrization, allowing
for optimization via simple gradient descent. By relaxing the hard clustering
to a soft clustering, our algorithm relaxes potentially hard clustering
problems to a tractable ones. We illustrate our algorithm's capabilities on a
synthetic graph, as well as simple unsupervised learning tasks involving
bipartite and tripartite clustering of orthographic and phonological data.",2023-08-12,"Sudhanshu Chanpuriya, Cameron Musco"
Improving Ego-Cluster for Network Effect Measurement,"The network effect, wherein one user's activity impacts another user, is
common in social network platforms. Many new features in social networks are
specifically designed to create a network effect, enhancing user engagement.
For instance, content creators tend to produce more when their articles and
posts receive positive feedback from followers. This paper discusses a new
cluster-level experimentation methodology for measuring creator-side metrics in
the context of A/B experiments. The methodology is designed to address cases
where the experiment randomization unit and the metric measurement unit differ.
It is a crucial part of LinkedIn's overall strategy to foster a robust creator
community and ecosystem. The method is developed based on widely-cited research
at LinkedIn but significantly improves the efficiency and flexibility of the
clustering algorithm. This improvement results in a stronger capability for
measuring creator-side metrics and an increased velocity for creator-related
experiments.",2023-08-11,"Wentao Su, Weitao Duan"
Using Twitter Data to Determine Hurricane Category: An Experiment,"Social media posts contain an abundant amount of information about public
opinion on major events, especially natural disasters such as hurricanes. Posts
related to an event, are usually published by the users who live near the place
of the event at the time of the event. Special correlation between the social
media data and the events can be obtained using data mining approaches. This
paper presents research work to find the mappings between social media data and
the severity level of a disaster. Specifically, we have investigated the
Twitter data posted during hurricanes Harvey and Irma, and attempted to find
the correlation between the Twitter data of a specific area and the hurricane
level in that area. Our experimental results indicate a positive correlation
between them. We also present a method to predict the hurricane category for a
specific area using relevant Twitter data.",2023-08-10,"Songhui Yue, Jyothsna Kondari, Aibek Musaev, Randy K. Smith, Songqing Yue"
"Complex Network Effects on the Robustness of Graph Convolutional
  Networks","Vertex classification -- the problem of identifying the class labels of nodes
in a graph -- has applicability in a wide variety of domains. Examples include
classifying subject areas of papers in citation networks or roles of machines
in a computer network. Vertex classification using graph convolutional networks
is susceptible to targeted poisoning attacks, in which both graph structure and
node attributes can be changed in an attempt to misclassify a target node. This
vulnerability decreases users' confidence in the learning method and can
prevent adoption in high-stakes contexts. Defenses have also been proposed,
focused on filtering edges before creating the model or aggregating information
from neighbors more robustly. This paper considers an alternative: we leverage
network characteristics in the training data selection process to improve
robustness of vertex classifiers.
  We propose two alternative methods of selecting training data: (1) to select
the highest-degree nodes and (2) to iteratively select the node with the most
neighbors minimally connected to the training set. In the datasets on which the
original attack was demonstrated, we show that changing the training set can
make the network much harder to attack. To maintain a given probability of
attack success, the adversary must use far more perturbations; often a factor
of 2--4 over the random training baseline. These training set selection methods
often work in conjunction with the best recently published defenses to provide
even greater robustness. While increasing the amount of randomly selected
training data sometimes results in a more robust classifier, the proposed
methods increase robustness substantially more. We also run a simulation study
in which we demonstrate conditions under which each of the two methods
outperforms the other, controlling for the graph topology, homophily of the
labels, and node attributes.",2023-08-10,"Benjamin A. Miller, Kevin Chan, Tina Eliassi-Rad"
"Preemptive Detection of Fake Accounts on Social Networks via Multi-Class
  Preferential Attachment Classifiers","In this paper, we describe a new algorithm called Preferential Attachment
k-class Classifier (PreAttacK) for detecting fake accounts in a social network.
Recently, several algorithms have obtained high accuracy on this problem.
However, they have done so by relying on information about fake accounts'
friendships or the content they share with others--the very things we seek to
prevent. PreAttacK represents a significant departure from these approaches. We
provide some of the first detailed distributional analyses of how new fake (and
real) accounts first attempt to request friends after joining a major network
(Facebook). We show that even before a new account has made friends or shared
content, these initial friend request behaviors evoke a natural multi-class
extension of the canonical Preferential Attachment model of social network
growth. We use this model to derive a new algorithm, PreAttacK. We prove that
in relevant problem instances, PreAttacK near-optimally approximates the
posterior probability that a new account is fake under this multi-class
Preferential Attachment model of new accounts' (not-yet-answered) friend
requests. These are the first provable guarantees for fake account detection
that apply to new users, and that do not require strong homophily assumptions.
This principled approach also makes PreAttacK the only algorithm with provable
guarantees that obtains state-of-the-art performance on new users on the global
Facebook network, where it converges to AUC=0.9 after new users send + receive
a total of just 20 not-yet-answered friend requests. For comparison,
state-of-the-art benchmarks do not obtain this AUC even after observing
additional data on new users' first 100 friend requests. Thus, unlike
mainstream algorithms, PreAttacK converges before the median new fake account
has made a single friendship (accepted friend request) with a human.",2023-08-10,"Adam Breuer, Nazanin Khosravani, Michael Tingley, Bradford Cottel"
"DegUIL: Degree-aware Graph Neural Networks for Long-tailed User Identity
  Linkage","User identity linkage (UIL), matching accounts of a person on different
social networks, is a fundamental task in cross-network data mining. Recent
works have achieved promising results by exploiting graph neural networks
(GNNs) to capture network structure. However, they rarely analyze the realistic
node-level bottlenecks that hinder UIL's performance. First, node degrees in a
graph vary widely and are long-tailed. A significant fraction of tail nodes
with small degrees are underrepresented due to limited structural information,
degrading linkage performance seriously. The second bottleneck usually
overlooked is super head nodes. It is commonly accepted that head nodes perform
well. However, we find that some of them with super high degrees also have
difficulty aligning counterparts, due to noise introduced by the randomness of
following friends in real-world social graphs. In pursuit of learning ideal
representations for these two groups of nodes, this paper proposes a
degree-aware model named DegUIL to narrow the degree gap. To this end, our
model complements missing neighborhoods for tail nodes and discards redundant
structural information for super head nodes in embeddings respectively.
Specifically, the neighboring bias is predicted and corrected locally by two
modules, which are trained using the knowledge from structurally adequate head
nodes. As a result, ideal neighborhoods are obtained for meaningful aggregation
in GNNs. Extensive experiments demonstrate the superiority of our model. Our
data and code can be found at https://github.com/Longmeix/DegUIL.",2023-08-10,"Meixiu Long, Siyuan Chen, Xin Du, Jiahai Wang"
Social Network Analysis and Validation of an Agent-Based Model,"Agent-based models (ABMs) simulate the formation and evolution of social
processes at a fundamental level by decoupling agent behavior from global
observations. In the case where ABM networks evolve over time as a result of
(or in conjunction with) agent states, there is a need for understanding the
relationship between the dynamic processes and network structure. Social
networks provide a natural set of tools for understanding the emergent
relationships of these systems. This work examines the utility of a collection
of network comparison methods for the purpose of tracking network changes in an
ABM over time or between model parameters. Among the techniques examined is a
novel graph pseudometric based on heat content asymptotics, which have been
shown to distinguish many isospectral graphs which are not isomorphic.
Additionally, we establish the use of observations about real-world networks
from network science (e.g. fat-tailed degree distribution, small-world
property) for ABM validation in the case where empirical population data is
unavailable. These methods are all demonstrated on systematic perturbations of
an original model simulating the formation of friendships in a population of
20,000 agents in Cincinnati, OH.",2023-08-09,"Karleigh Pine, Joel Klipfel, Jared Bennett, Nathaniel Bade, Christian Manasseh"
"TUBERAIDER: Attributing Coordinated Hate Attacks on YouTube Videos to
  their Source Communities","Alas, coordinated hate attacks, or raids, are becoming increasingly common
online. In a nutshell, these are perpetrated by a group of aggressors who
organize and coordinate operations on a platform (e.g., 4chan) to target
victims on another community (e.g., YouTube). In this paper, we focus on
attributing raids to their source community, paving the way for moderation
approaches that take the context (and potentially the motivation) of an attack
into consideration. We present TUBERAIDER, an attribution system achieving over
75% accuracy in detecting and attributing coordinated hate attacks on YouTube
videos. We instantiate it using links to YouTube videos shared on 4chan's /pol/
board, r/The_Donald, and 16 Incels-related subreddits. We use a peak detector
to identify a rise in the comment activity of a YouTube video, which signals
that an attack may be occurring. We then train a machine learning classifier
based on the community language (i.e., TF-IDF scores of relevant keywords) to
perform the attribution. We test TUBERAIDER in the wild and present a few case
studies of actual aggression attacks identified by it to showcase its
effectiveness.",2023-08-09,"Mohammad Hammas Saeed, Kostantinos Papadamou, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini"
Balanced Butterfly Counting in Bipartite-Network,"Bipartite graphs offer a powerful framework for modeling complex
relationships between two distinct types of vertices, incorporating
probabilistic, temporal, and rating-based information. While the research
community has extensively explored various types of bipartite relationships,
there has been a notable gap in studying Signed Bipartite Graphs, which capture
liking / disliking interactions in real-world networks such as
customer-rating-product and senator-vote-bill. Balance butterflies,
representing 2 x 2 bicliques, provide crucial insights into antagonistic
groups, balance theory, and fraud detection by leveraging the signed
information. However, such applications require counting balance butterflies
which remains unexplored. In this paper, we propose a new problem: counting
balance butterflies in a signed bipartite graph. To address this problem, we
adopt state-of-the-art algorithms for butterfly counting, establishing a smart
baseline that reduces the time complexity for solving our specific problem. We
further introduce a novel bucket approach specifically designed to count
balanced butterflies efficiently. We propose a parallelized version of the
bucketing approach to enhance performance. Extensive experimental studies on
nine real-world datasets demonstrate that our proposed bucket-based algorithm
is up to 120x faster over the baseline, and the parallel implementation of the
bucket-based algorithm is up to 45x faster over the single core execution.
Moreover, a real-world case study showcases the practical application and
relevance of counting balanced butterflies.",2023-08-09,"Apurba Das, Aman Abidi, Ajinkya Shingane, Mekala Kiran"
"BOPIM: Bayesian Optimization for influence maximization on temporal
  networks","The goal of influence maximization (IM) is to select a small set of seed
nodes which maximizes the spread of influence on a network. In this work, we
propose BOPIM, a Bayesian Optimization (BO) algorithm for IM on temporal
networks. The IM task is well-suited for a BO solution due to its expensive and
complicated objective function. We propose a simple surrogate function to model
the objective function and leverage Gaussian Process regression with shrinkage
priors to fit the model. A major difficulty in combinatorial BO is constructing
an appropriate covariance matrix. We overcome this challenge with a kernel
function based on the amount of overlap in seed set neighbors, thus tailoring
the solution to our IM application. This also allows us to use the Expected
Improvement acquisition function to choose the next point to evaluate. In
numerical experiments on real-world networks, we prove that BOPIM outperforms
competing methods and yields comparable influence spreads to a gold-standard
greedy algorithm while being as much as five times faster. We also demonstrate
the proposed method's ability to quantify uncertainty in optimal seed sets. To
our knowledge, this is the first attempt to look at uncertainty in the seed
sets for IM.",2023-08-09,Eric Yanchenko
"Opponents and proponents of the war in Ukraine in Russian social media:
  who are they?","Understanding the personality of Russians who support the war in Ukraine is
one of the key steps to understanding how this war became possible. However,
during the war, traditional sociological methods are not always applicable.
Social media provides an alternative source of what is inside people's heads.
In this paper, I compare the political identities, values, and interests of
social media users in Russia who hold a strong position for or against the war
in Ukraine. I collect data from VK, the most popular Russian social media
platform, and analyze self-filled profile information as well as the groups
that the users subscribed to. I found that proponents of the war tend to have a
weaker political identity (self-identified as ""moderate"") compared to
opponents, who specify it more precisely (often, but not limited to,
""liberal""). Additionally, the values of the proponents more frequently align
with those promoted by the Russian government, such as orthodoxy and family.
Despite these differences, pro-war and anti-war users share many common
interests, as evidenced by their subscriptions to the same groups focused on
music, history, and sport. When asked to state the most important trait in
people (a field users can fill in VK), the most frequent answer for both groups
is ""kindness and honesty"". The analysis results, in addition to contributing to
the understanding of public opinion in Russia, can be utilized for predicting
one's position on the war based on their social media profile.",2023-08-08,Alesya Sokolova
"Analysis of Insect-Plant Interactions Affected by Mining Operations, A
  Graph Mining Approach","The decline in ecological connections signifies the potential extinction of
species, which can be attributed to disruptions and alterations. The decrease
in interconnections among species reflects their susceptibility to changes. For
example, certain insects and plants that rely on exclusive interactions with a
limited number of species, or even a specific species, face the risk of
extinction if they lose these crucial connections. Currently, mining activities
pose significant harm to natural ecosystems, resulting in various adverse
environmental impacts. In this study, we utilized network science techniques to
analyze the ecosystem in a graph-based structure, aiming to conserve the
ecosystem affected by mining operations in the northern region of Scotland. The
research encompasses identifying the most vital members of the network,
establishing criteria for identifying communities within the network,
comparing, and evaluating them, using models to predict secondary extinctions
that occur when a species is removed from the network, and assessing the extent
of network damage. Our study's novelty is utilizing network science approaches
to investigate the biological data related to interactions between insects and
plants.",2023-08-08,"Ali Bayat, Mohammad Heydari, Amir Albadvi"
XFlow: Benchmarking Flow Behaviors over Graphs,"The occurrence of diffusion on a graph is a prevalent and significant
phenomenon, as evidenced by the spread of rumors, influenza-like viruses, smart
grid failures, and similar events. Comprehending the behaviors of flow is a
formidable task, due to the intricate interplay between the distribution of
seeds that initiate flow propagation, the propagation model, and the topology
of the graph. The study of networks encompasses a diverse range of academic
disciplines, including mathematics, physics, social science, and computer
science. This interdisciplinary nature of network research is characterized by
a high degree of specialization and compartmentalization, and the cooperation
facilitated by them is inadequate. From a machine learning standpoint, there is
a deficiency in a cohesive platform for assessing algorithms across various
domains. One of the primary obstacles to current research in this field is the
absence of a comprehensive curated benchmark suite to study the flow behaviors
under network scenarios.
  To address this disparity, we propose the implementation of a novel benchmark
suite that encompasses a variety of tasks, baseline models, graph datasets, and
evaluation tools. In addition, we present a comprehensive analytical framework
that offers a generalized approach to numerous flow-related tasks across
diverse domains, serving as a blueprint and roadmap. Drawing upon the outcomes
of our empirical investigation, we analyze the advantages and disadvantages of
current foundational models, and we underscore potential avenues for further
study. The datasets, code, and baseline models have been made available for the
public at: https://github.com/XGraphing/XFlow",2023-08-07,"Zijian Zhang, Zonghan Zhang, Zhiqian Chen"
"Quantifying the Impact of Large Language Models on Collective Opinion
  Dynamics","The process of opinion expression and exchange is a critical component of
democratic societies. As people interact with large language models (LLMs) in
the opinion shaping process different from traditional media, the impacts of
LLMs are increasingly recognized and being concerned. However, the knowledge
about how LLMs affect the process of opinion expression and exchange of social
opinion networks is very limited. Here, we create an opinion network dynamics
model to encode the opinions of LLMs, cognitive acceptability and usage
strategies of individuals, and simulate the impact of LLMs on opinion dynamics
in a variety of scenarios. The outcomes of the simulations inform about
effective demand-oriented opinion network interventions. The results from this
study suggested that the output opinion of LLMs has a unique and positive
effect on the collective opinion difference. The marginal effect of cognitive
acceptability on collective opinion formation is nonlinear and shows a
decreasing trend. When people partially rely on LLMs, the exchange process of
opinion becomes more intense and the diversity of opinion becomes more
favorable. In fact, there is 38.6% more opinion diversity when people all
partially rely on LLMs, compared to prohibiting the use of LLMs entirely. The
optimal diversity of opinion was found when the fractions of people who do not
use, partially rely on, and fully rely on LLMs reached roughly 4:12:1. Our
experiments also find that introducing extra agents with
opposite/neutral/random opinions, we can effectively mitigate the impact of
biased/toxic output from LLMs. Our findings provide valuable insights into
opinion dynamics in the age of LLMs, highlighting the need for customized
interventions tailored to specific scenarios to address the drawbacks of
improper output and use of LLMs.",2023-08-07,"Chao Li, Xing Su, Haoying Han, Cong Xue, Chunmo Zheng, Chao Fan"
Using Overlapping Methods to Counter Adversaries in Community Detection,"When dealing with large graphs, community detection is a useful data triage
tool that can identify subsets of the network that a data analyst should
investigate. In an adversarial scenario, the graph may be manipulated to avoid
scrutiny of certain nodes by the analyst. Robustness to such behavior is an
important consideration for data analysts in high-stakes scenarios such as
cyber defense and counterterrorism. In this paper, we evaluate the use of
overlapping community detection methods in the presence of adversarial attacks
aimed at lowering the priority of a specific vertex. We formulate the data
analyst's choice as a Stackelberg game in which the analyst chooses a community
detection method and the attacker chooses an attack strategy in response.
Applying various attacks from the literature to seven real network datasets, we
find that, when the attacker has a sufficient budget, overlapping community
detection methods outperform non-overlapping methods, often overwhelmingly so.
This is the case when the attacker can only add edges that connect to the
target and when the capability is added to add edges between neighbors of the
target. We also analyze the tradeoff between robustness in the presence of an
attack and performance when there is no attack. Our extensible analytic
framework enables network data analysts to take these considerations into
account and incorporate new attacks and community detection methods as they are
developed.",2023-08-06,"Benjamin A. Miller, Kevin Chan, Tina Eliassi-Rad"
"Harnessing the Web and Knowledge Graphs for Automated Impact Investing
  Scoring","The Sustainable Development Goals (SDGs) were introduced by the United
Nations in order to encourage policies and activities that help guarantee human
prosperity and sustainability. SDG frameworks produced in the finance industry
are designed to provide scores that indicate how well a company aligns with
each of the 17 SDGs. This scoring enables a consistent assessment of
investments that have the potential of building an inclusive and sustainable
economy. As a result of the high quality and reliability required by such
frameworks, the process of creating and maintaining them is time-consuming and
requires extensive domain expertise. In this work, we describe a data-driven
system that seeks to automate the process of creating an SDG framework. First,
we propose a novel method for collecting and filtering a dataset of texts from
different web sources and a knowledge graph relevant to a set of companies. We
then implement and deploy classifiers trained with this data for predicting
scores of alignment with SDGs for a given company. Our results indicate that
our best performing model can accurately predict SDG scores with a micro
average F1 score of 0.89, demonstrating the effectiveness of the proposed
solution. We further describe how the integration of the models for its use by
humans can be facilitated by providing explanations in the form of data
relevant to a predicted score. We find that our proposed solution enables
access to a large amount of information that analysts would normally not be
able to process, resulting in an accurate prediction of SDG scores at a
fraction of the cost.",2023-08-04,"Qingzhi Hu, Daniel Daza, Laurens Swinkels, Kristina Ūsaitė, Robbert-Jan 't Hoen, Paul Groth"
"RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph
  Classification","Graph classification is a crucial task in many real-world multimedia
applications, where graphs can represent various multimedia data types such as
images, videos, and social networks. Previous efforts have applied graph neural
networks (GNNs) in balanced situations where the class distribution is
balanced. However, real-world data typically exhibit long-tailed class
distributions, resulting in a bias towards the head classes when using GNNs and
limited generalization ability over the tail classes. Recent approaches mainly
focus on re-balancing different classes during model training, which fails to
explicitly introduce new knowledge and sacrifices the performance of the head
classes. To address these drawbacks, we propose a novel framework called
Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature
extractor and an unbiased classifier in a decoupled manner. In the feature
extractor training stage, we develop a graph retrieval module to search for
relevant graphs that directly enrich the intra-class diversity for the tail
classes. Moreover, we innovatively optimize a category-centered supervised
contrastive loss to obtain discriminative representations, which is more
suitable for long-tailed scenarios. In the classifier fine-tuning stage, we
balance the classifier weights with two weight regularization techniques, i.e.,
Max-norm and weight decay. Experiments on various popular benchmarks verify the
superiority of the proposed method against state-of-the-art approaches.",2023-08-04,"Zhengyang Mao, Wei Ju, Yifang Qin, Xiao Luo, Ming Zhang"
"Silence Speaks Volumes: Re-weighting Techniques for Under-Represented
  Users in Fake News Detection","Social media platforms provide a rich environment for analyzing user
behavior. Recently, deep learning-based methods have been a mainstream approach
for social media analysis models involving complex patterns. However, these
methods are susceptible to biases in the training data, such as participation
inequality. Basically, a mere 1% of users generate the majority of the content
on social networking sites, while the remaining users, though engaged to
varying degrees, tend to be less active in content creation and largely silent.
These silent users consume and listen to information that is propagated on the
platform. However, their voice, attitude, and interests are not reflected in
the online content, making the decision of the current methods predisposed
towards the opinion of the active users. So models can mistake the loudest
users for the majority. We propose to leverage re-weighting techniques to make
the silent majority heard, and in turn, investigate whether the cues from these
users can improve the performance of the current models for the downstream task
of fake news detection.",2023-08-03,"Mansooreh Karami, David Mosallanezhad, Paras Sheth, Huan Liu"
"I am a global citizen. Or am I not? International Business Schools
  students and Global Citizenship unified framework & a scoping literature
  review of the last decade (2013-2022)","This review examines the scientific articles of the last decade, approaching
the subject through the methodology of the scoping literature review. Starting
with the Boolean search global citizens AND education AND (international
business OR international business school) in the ScienceDirect, Emerald, and
Scopus databases, the review resulted in only scientific journal articles,
strictly targeted at tertiary education ONLY of international business schools
and ONLY in those articles that study global citizenship. For reasons of
up-to-date knowledge, the present literature was content with the final decade.
A total of 13 articles are recorded as a result of the aforementioned Boolean
search from a total of 216 articles identified in the first phase of the
search. The results will help the researchers to acquire the required knowledge
base for their research, the academics to incorporate new methods in their
teaching and the approach of their students, and the policymakers to adapt the
schools curricula according to the data from the articles present in the
literature review.",2023-08-03,Nikolaos Misirlis
"The Shapes of the Fourth Estate During the Pandemic: Profiling COVID-19
  News Consumption in Eight Countries","News media is often referred to as the Fourth Estate, a recognition of its
political power. New understandings of how media shape political beliefs and
influence collective behaviors are urgently needed in an era when public
opinion polls do not necessarily reflect election results and users influence
each other in real-time under algorithm-mediated content personalization. In
this work, we measure not only the average but also the distribution of
audience political leanings for different media across different countries. The
methodological components of these new measures include a high-fidelity
COVID-19 tweet dataset; high-precision user geolocation extraction; and user
political leaning estimated from the within-country retweet networks involving
local politicians. We focus on geolocated users from eight countries, profile
user leaning distribution for each country, and analyze bridging users who have
interactions across multiple countries. Except for France and Turkey, we
observe consistent bi-modal user leaning distributions in the other six
countries, and find that cross-country retweeting behaviors do not oscillate
across the partisan divide. More importantly, this study contributes a new set
of media bias estimates by averaging the leaning scores of users who share the
URLs from media domains. Through two validations, we find that the new average
audience leaning scores strongly correlate with existing media bias scores.
Lastly, we profile the COVID-19 news consumption by examining the audience
leaning distribution for top media in each country, and for selected media
across all countries. Those analyses help answer questions such as: Does center
media Reuters have a more balanced audience base than partisan media CNN in the
US? Does far-right media Breitbart attract any left-leaning readers in any
countries? Does CNN reach a more balanced audience base in the US than in the
UK?",2023-08-02,"Cai Yang, Lexing Xie, Siqi Wu"
"Shaping Online Dialogue: Examining How Community Rules Affect Discussion
  Structures on Reddit","Community rules play a key part in enabling or constraining the behaviors of
members in online communities. However, little is unknown regarding whether and
to what degree changing rules actually affects community dynamics. In this
paper, we seek to understand how these behavior-governing rules shape the
interactions between users, as well as the structure of their discussion. Using
the top communities on Reddit (i.e. subreddits), we first contribute a taxonomy
of behavior-based rule categories across Reddit. Then, we use a network
analysis perspective to discover how changing implementation of different rule
categories affects subreddits' user interaction and discussion networks over a
1.5 year period. Our study find several significant effects, including greater
clustering among users when subreddits increase rules focused on structural
regulation and how restricting allowable content surprisingly leads to more
interactions between users. Our findings contribute to research in proactive
moderation through rule setting, as well as lend valuable insights for online
community designers and moderators to achieve desired community dynamics.",2023-08-02,"Anna Fang, Wenjie Yang, Haiyi Zhu"
DYMOND: DYnamic MOtif-NoDes Network Generative Model,"Motifs, which have been established as building blocks for network structure,
move beyond pair-wise connections to capture longer-range correlations in
connections and activity. In spite of this, there are few generative graph
models that consider higher-order network structures and even fewer that focus
on using motifs in models of dynamic graphs. Most existing generative models
for temporal graphs strictly grow the networks via edge addition, and the
models are evaluated using static graph structure metrics -- which do not
adequately capture the temporal behavior of the network. To address these
issues, in this work we propose DYnamic MOtif-NoDes (DYMOND) -- a generative
model that considers (i) the dynamic changes in overall graph structure using
temporal motif activity and (ii) the roles nodes play in motifs (e.g., one node
plays the hub role in a wedge, while the remaining two act as spokes). We
compare DYMOND to three dynamic graph generative model baselines on real-world
networks and show that DYMOND performs better at generating graph structure and
node behavior similar to the observed network. We also propose a new
methodology to adapt graph structure metrics to better evaluate the temporal
aspect of the network. These metrics take into account the changes in overall
graph structure and the individual nodes' behavior over time.",2023-08-01,"Giselle Zeno, Timothy La Fond, Jennifer Neville"
Mathematical Foundations of Data Cohesion,"Data cohesion, a recently introduced measure inspired by social interactions,
uses distance comparisons to assess relative proximity. In this work, we
provide a collection of results which can guide the development of
cohesion-based methods in exploratory data analysis and human-aided
computation. Here, we observe the important role of highly clustered
""point-like"" sets and the ways in which cohesion allows such sets to take on
qualities of a single weighted point. In doing so, we see how cohesion
complements metric-adjacent measures of dissimilarity and responds to local
density. We conclude by proving that cohesion is the unique function with (i)
average value equal to one-half and (ii) the property that the influence of an
outlier is proportional to its mass. Properties of cohesion are illustrated
with examples throughout.",2023-08-01,Katherine E. Moore
"DiffusAL: Coupling Active Learning with Graph Diffusion for
  Label-Efficient Node Classification","Node classification is one of the core tasks on attributed graphs, but
successful graph learning solutions require sufficiently labeled data. To keep
annotation costs low, active graph learning focuses on selecting the most
qualitative subset of nodes that maximizes label efficiency. However, deciding
which heuristic is best suited for an unlabeled graph to increase label
efficiency is a persistent challenge. Existing solutions either neglect
aligning the learned model and the sampling method or focus only on limited
selection aspects. They are thus sometimes worse or only equally good as random
sampling. In this work, we introduce a novel active graph learning approach
called DiffusAL, showing significant robustness in diverse settings. Toward
better transferability between different graph structures, we combine three
independent scoring functions to identify the most informative node samples for
labeling in a parameter-free way: i) Model Uncertainty, ii) Diversity
Component, and iii) Node Importance computed via graph diffusion heuristics.
Most of our calculations for acquisition and training can be pre-processed,
making DiffusAL more efficient compared to approaches combining diverse
selection criteria and similarly fast as simpler heuristics. Our experiments on
various benchmark datasets show that, unlike previous methods, our approach
significantly outperforms random selection in 100% of all datasets and labeling
budgets tested.",2023-07-31,"Sandra Gilhuber, Julian Busch, Daniel Rotthues, Christian M. M. Frey, Thomas Seidl"
Changes in Policy Preferences in German Tweets during the COVID Pandemic,"Online social media have become an important forum for exchanging political
opinions. In response to COVID measures citizens expressed their policy
preferences directly on these platforms. Quantifying political preferences in
online social media remains challenging: The vast amount of content requires
scalable automated extraction of political preferences -- however fine grained
political preference extraction is difficult with current machine learning (ML)
technology, due to the lack of data sets. Here we present a novel data set of
tweets with fine grained political preference annotations. A text
classification model trained on this data is used to extract policy preferences
in a German Twitter corpus ranging from 2019 to 2022. Our results indicate that
in response to the COVID pandemic, expression of political opinions increased.
Using a well established taxonomy of policy preferences we analyse fine grained
political views and highlight changes in distinct political categories. These
analyses suggest that the increase in policy preference expression is dominated
by the categories pro-welfare, pro-education and pro-governmental
administration efficiency. All training data and code used in this study are
made publicly available to encourage other researchers to further improve
automated policy preference extraction methods. We hope that our findings
contribute to a better understanding of political statements in online social
media and to a better assessment of how COVID measures impact political
preferences.",2023-07-31,Felix Biessmann
Anatomy of an AI-powered malicious social botnet,"Large language models (LLMs) exhibit impressive capabilities in generating
realistic text across diverse subjects. Concerns have been raised that they
could be utilized to produce fake content with a deceptive intention, although
evidence thus far remains anecdotal. This paper presents a case study about a
Twitter botnet that appears to employ ChatGPT to generate human-like content.
Through heuristics, we identify 1,140 accounts and validate them via manual
annotation. These accounts form a dense cluster of fake personas that exhibit
similar behaviors, including posting machine-generated content and stolen
images, and engage with each other through replies and retweets.
ChatGPT-generated content promotes suspicious websites and spreads harmful
comments. While the accounts in the AI botnet can be detected through their
coordination patterns, current state-of-the-art LLM content classifiers fail to
discriminate between them and human accounts in the wild. These findings
highlight the threats posed by AI-enabled social bots.",2023-07-30,"Kai-Cheng Yang, Filippo Menczer"
"Street access, Informality and Development: A block level analysis
  across all of sub-Saharan Africa","Sustainable development is an imperative worldwide but metrics and data on
poverty and quality of life have remained too coarse and abstract to
characterize challenges adequately and guide practical progress. Nowhere is
this challenge greater than in Africa where we still know relatively little
about the systematic spatial details and scope of development. Here, we
leverage a complete, high-precision dataset of building footprints to identify
infrastructure deficits and infer informal settlements down to the street level
everywhere in sub-Saharan Africa. We identify a general pattern of informality
with urbanized areas showing, on average, greater access to infrastructure and
services than rural and periurban areas, each characterized by a statistically
consistent spectrum of uneven local development. We show that our physical
measures of informality are systematically associated with many indicators of
low human development, and that these form a single principal component
predicted by specific functional changes of the built environment. These
results demonstrate that the localization of sustainable development is
possible down to the street level at a continental scale and provide a general
distributed strategy for accelerating progress in infrastructure and service
expansion that taps local innovations in a way that is equitable and context
appropriate.",2023-07-30,"Luis M. A Bettencourt, Nicholas Marchio"
"Trends and Topics: Characterizing Echo Chambers' Topological Stability
  and In-group Attitudes","Social Network sites are fertile ground for several polluting phenomena
affecting online and offline spaces. Among these phenomena are included echo
chambers, closed systems in which the opinions expressed by the people inside
are exacerbated for the effect of the repetition, while opposite views are
actively excluded. This paper offers a framework to explore, in a
platform-independent manner, the topological changes through time of echo
chambers, while considering the content posted by users and the attitude
conveyed in discussing specific controversial issues.
  The proposed framework consists of four steps: (i) data collection and
annotation of users' ideology regarding a controversial topic, (ii)
construction of a dynamic network of interactions, (iii) ECs extraction and
analysis of their dynamics, and (iv) topic extraction and valence analysis. The
paper then enhances the formalization of the framework by conducting a case
study on Reddit threads about sociopolitical issues (gun control, American
politics, and minorities discrimination) during the first two years and a half
of Donald Trump's presidency.
  The results unveil that users often stay inside echo chambers over time.
Furthermore, in the analyzed discussions, the focus is on controversies related
to right-wing parties and specific events in American and Canadian politics.
The analysis of the attitude conveyed in the discussions shows a slight
inclination toward a more negative or neutral attitude when discussing
particularly sensitive issues, such as fascism, school shootings, or police
violence.",2023-07-28,"Erica Cau, Virginia Morini, Giulio Rossetti"
"Mixbiotic society measures: Comparison of organizational structures
  based on communication simulation","The philosophical world has proposed the concept of ""mixbiotic society,"" in
which individuals with freedom and diverse values mix and mingle to recognize
their respective ""fundamental incapability"" each other and sublimate into
solidarity, toward solving the issues of social isolation and fragmentation.
Based on this concept, the mixbiotic society measures have been proposed to
evaluate dynamic communication patterns with reference to classification in
cellular automata and particle reaction-diffusion that simulate living
phenomena. In this paper, we applied these measures to five typologies of
organizational structure (Red: impulsive, Amber: adaptive, Orange: achievement,
Green: pluralistic, and Teal: evolutionary) and evaluated their features.
Specifically, we formed star, tree, tree+jumpers, tree+more jumpers, and
small-world type networks corresponding to each of five typologies, conducted
communication simulations on these networks, and calculated values for
mixbiotic society measures. The results showed that Teal organization has the
highest value of the mixism measure among mixbiotic society measures, i.e., it
balances similarity (mixing) and dissimilarity (mingling) in communication, and
is living and mixbiotic between order and chaos. Measures other than mixism
showed that in Teal organization, information is not concentrated in a central
leader and that communication takes place among various members. This
evaluation of organizational structures shows that the mixbiotic society
measures is also useful for assessing organizational change. In the future,
these measures will be used not only in business organizations, but also in
digital democratic organizations and platform cooperatives in conjunction with
information technology.",2023-07-28,"Takeshi Kato, Jyunichi Miyakoshi, Tadayuki Matsumura, Yasuyuki Kudo, Ryuji Mine, Hiroyuki Mizuno, Yasuo Deguchi"
"BOURNE: Bootstrapped Self-supervised Learning Framework for Unified
  Graph Anomaly Detection","Graph anomaly detection (GAD) has gained increasing attention in recent years
due to its critical application in a wide range of domains, such as social
networks, financial risk management, and traffic analysis. Existing GAD methods
can be categorized into node and edge anomaly detection models based on the
type of graph objects being detected. However, these methods typically treat
node and edge anomalies as separate tasks, overlooking their associations and
frequent co-occurrences in real-world graphs. As a result, they fail to
leverage the complementary information provided by node and edge anomalies for
mutual detection. Additionally, state-of-the-art GAD methods, such as CoLA and
SL-GAD, heavily rely on negative pair sampling in contrastive learning, which
incurs high computational costs, hindering their scalability to large graphs.
To address these limitations, we propose a novel unified graph anomaly
detection framework based on bootstrapped self-supervised learning (named
BOURNE). We extract a subgraph (graph view) centered on each target node as
node context and transform it into a dual hypergraph (hypergraph view) as edge
context. These views are encoded using graph and hypergraph neural networks to
capture the representations of nodes, edges, and their associated contexts. By
swapping the context embeddings between nodes and edges and measuring the
agreement in the embedding space, we enable the mutual detection of node and
edge anomalies. Furthermore, BOURNE can eliminate the need for negative
sampling, thereby enhancing its efficiency in handling large graphs. Extensive
experiments conducted on six benchmark datasets demonstrate the superior
effectiveness and efficiency of BOURNE in detecting both node and edge
anomalies.",2023-07-28,"Jie Liu, Mengting He, Xuequn Shang, Jieming Shi, Bin Cui, Hongzhi Yin"
"A Secure Open-Source Intelligence Framework For Cyberbullying
  Investigation","Cyberbullying has become a pervasive issue based on the rise of cell phones
and internet usage affecting individuals worldwide. This paper proposes an
open-source intelligence pipeline using data from Twitter to track keywords
relevant to cyberbullying in social media to build dashboards for law
enforcement agents. We discuss the prevalence of cyberbullying on social media,
factors that compel individuals to indulge in cyberbullying, and the legal
implications of cyberbullying in different countries also highlight the lack of
direction, resources, training, and support that law enforcement officers face
in investigating cyberbullying cases. The proposed interventions for
cyberbullying involve collective efforts from various stakeholders, including
parents, law enforcement, social media platforms, educational institutions,
educators, and researchers. Our research provides a framework for cyberbullying
and provides a comprehensive view of the digital landscape for investigators to
track and identify cyberbullies, their tactics, and patterns. An OSINT
dashboard with real-time monitoring empowers law enforcement to swiftly take
action, protect victims, and make significant strides toward creating a safer
online environment.",2023-07-27,"Sylvia Worlali Azumah, Victor Adewopo, Zag ElSayed, Nelly Elsayed, Murat Ozer"
How to Train Your YouTube Recommender to Avoid Unwanted Videos,"YouTube provides features for users to indicate disinterest when presented
with unwanted recommendations, such as the ""Not interested"" and ""Don't
recommend channel"" buttons. These buttons purportedly allow the user to correct
""mistakes"" made by the recommendation system. Yet, relatively little is known
about the empirical efficacy of these buttons. Neither is much known about
users' awareness of and confidence in them. To address these gaps, we simulated
YouTube users with sock puppet agents. Each agent first executed a ""stain
phase"", where it watched many videos of an assigned topic; it then executed a
""scrub phase"", where it tried to remove recommendations from the assigned
topic. Each agent repeatedly applied a single scrubbing strategy, either
indicating disinterest in one of the videos visited in the stain phase
(disliking it or deleting it from the watch history), or indicating disinterest
in a video recommended on the homepage (clicking the ""not interested"" or ""don't
recommend channel"" button or opening the video and clicking the dislike
button). We found that the stain phase significantly increased the fraction of
the recommended videos dedicated to the assigned topic on the user's homepage.
For the scrub phase, using the ""Not interested"" button worked best,
significantly reducing such recommendations in all topics tested, on average
removing 88% of them. Neither the stain phase nor the scrub phase, however, had
much effect on videopage recommendations. We also ran a survey (N = 300) asking
adult YouTube users in the US whether they were aware of and used these buttons
before, as well as how effective they found these buttons to be. We found that
44% of participants were not aware that the ""Not interested"" button existed.
Those who were aware of it often used it to remove unwanted recommendations
(82.8%) and found it to be modestly effective (3.42 out of 5).",2023-07-27,"Alexander Liu, Siqi Wu, Paul Resnick"
Optimal Estimation in Mixed-Membership Stochastic Block Models,"Community detection is one of the most critical problems in modern network
science. Its applications can be found in various fields, from protein modeling
to social network analysis. Recently, many papers appeared studying the problem
of overlapping community detection, where each node of a network may belong to
several communities. In this work, we consider Mixed-Membership Stochastic
Block Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite
a general setting for modeling overlapping community structure in graphs. The
central question of this paper is to reconstruct relations between communities
given an observed network. We compare different approaches and establish the
minimax lower bound on the estimation error. Then, we propose a new estimator
that matches this lower bound. Theoretical results are proved under fairly
general conditions on the considered model. Finally, we illustrate the theory
in a series of experiments.",2023-07-26,"Fedor Noskov, Maxim Panov"
"A Dual-mode Local Search Algorithm for Solving the Minimum Dominating
  Set Problem","Given a graph, the minimum dominating set (MinDS) problem is to identify a
smallest set $D$ of vertices such that every vertex not in $D$ is adjacent to
at least one vertex in $D$. The MinDS problem is a classic $\mathcal{NP}$-hard
problem and has been extensively studied because of its many disparate
applications in network analysis. To solve this problem efficiently, many
heuristic approaches have been proposed to obtain a good solution within an
acceptable time limit. However, existing MinDS heuristic algorithms are always
limited by various tie-breaking cases when selecting vertices, which slows down
the effectiveness of the algorithms. In this paper, we design an efficient
local search algorithm for the MinDS problem, named DmDS -- a dual-mode local
search framework that probabilistically chooses between two distinct
vertex-swapping schemes. We further address limitations of other algorithms by
introducing vertex selection criterion based on the frequency of vertices added
to solutions to address tie-breaking cases, and a new strategy to improve the
quality of the initial solution via a greedy-based strategy integrated with
perturbation. We evaluate DmDS against the state-of-the-art algorithms on seven
datasets, consisting of 346 instances (or families) with up to tens of millions
of vertices. Experimental results show that DmDS obtains the best performance
in accuracy for almost all instances and finds much better solutions than
state-of-the-art MinDS algorithms on a broad range of large real-world graphs.",2023-07-25,"Enqiang Zhu, Yu Zhang, Shengzhi Wang, Darren Strash, Chanjuan Liu"
Public and private beliefs under disinformation in social networks,"We develop a model of opinion dynamics where agents in a social network seek
to learn a ground truth among a set of competing hypotheses. Agents in the
network form private beliefs about such hypotheses by aggregating their
neighbors' publicly stated beliefs, in an iterative fashion. This process
allows us to keep track of scenarios where private and public beliefs align,
leading to population-wide consensus on the ground truth, as well as scenarios
where the two sets of beliefs fail to converge. The latter scenario - which is
reminiscent of the phenomenon of cognitive dissonance - is induced by injecting
'conspirators' in the network, i.e., agents who actively spread disinformation
by not communicating accurately their private beliefs. We show that the agents'
cognitive dissonance non-trivially reaches its peak when conspirators are a
relatively small minority of the population, and that such an effect can be
mitigated - although not erased - by the presence of 'debunker' agents in the
network.",2023-07-25,"Diana Riazi, Giacomo Livan"
"Transferability of Graph Neural Networks using Graphon and Sampling
  Theories","Graph neural networks (GNNs) have become powerful tools for processing
graph-based information in various domains. A desirable property of GNNs is
transferability, where a trained network can swap in information from a
different graph without retraining and retain its accuracy. A recent method of
capturing transferability of GNNs is through the use of graphons, which are
symmetric, measurable functions representing the limit of large dense graphs.
In this work, we contribute to the application of graphons to GNNs by
presenting an explicit two-layer graphon neural network (WNN) architecture. We
prove its ability to approximate bandlimited graphon signals within a specified
error tolerance using a minimal number of network weights. We then leverage
this result, to establish the transferability of an explicit two-layer GNN over
all sufficiently large graphs in a convergent sequence. Our work addresses
transferability between both deterministic weighted graphs and simple random
graphs and overcomes issues related to the curse of dimensionality that arise
in other GNN results. The proposed WNN and GNN architectures offer practical
solutions for handling graph data of varying sizes while maintaining
performance guarantees without extensive retraining.",2023-07-25,"A. Martina Neuman, Jason J. Bramburger"
"Navigating the Web of Misinformation: A Framework for Misinformation
  Domain Detection Using Browser Traffic","The proliferation of misinformation and propaganda is a global challenge,
with profound effects during major crises such as the COVID-19 pandemic and the
Russian invasion of Ukraine. Understanding the spread of misinformation and its
social impacts requires identifying the news sources spreading false
information. While machine learning (ML) techniques have been proposed to
address this issue, ML models have failed to provide an efficient
implementation scenario that yields useful results. In prior research, the
precision of deployment in real traffic deteriorates significantly,
experiencing a decrement up to ten times compared to the results derived from
benchmark data sets. Our research addresses this gap by proposing a graph-based
approach to capture navigational patterns and generate traffic-based features
which are used to train a classification model. These navigational and
traffic-based features result in classifiers that present outstanding
performance when evaluated against real traffic. Moreover, we also propose
graph-based filtering techniques to filter out models to be classified by our
framework. These filtering techniques increase the signal-to-noise ratio of the
models to be classified, greatly reducing false positives and the computational
cost of deploying the model. Our proposed framework for the detection of
misinformation domains achieves a precision of 0.78 when evaluated in real
traffic. This outcome represents an improvement factor of over ten times over
those achieved in previous studies.",2023-07-24,"Mayana Pereira, Kevin Greene, Nilima Pisharody, Rahul Dodhia, Jacob N. Shapiro, Juan Lavista"
"A Comprehensive Bibliometric Analysis on Social Network Anonymization:
  Current Approaches and Future Directions","In recent decades, social network anonymization has become a crucial research
field due to its pivotal role in preserving users' privacy. However, the high
diversity of approaches introduced in relevant studies poses a challenge to
gaining a profound understanding of the field. In response to this, the current
study presents an exhaustive and well-structured bibliometric analysis of the
social network anonymization field. To begin our research, related studies from
the period of 2007-2022 were collected from the Scopus Database then
pre-processed. Following this, the VOSviewer was used to visualize the network
of authors' keywords. Subsequently, extensive statistical and network analyses
were performed to identify the most prominent keywords and trending topics.
Additionally, the application of co-word analysis through SciMAT and the
Alluvial diagram allowed us to explore the themes of social network
anonymization and scrutinize their evolution over time. These analyses
culminated in an innovative taxonomy of the existing approaches and
anticipation of potential trends in this domain. To the best of our knowledge,
this is the first bibliometric analysis in the social network anonymization
field, which offers a deeper understanding of the current state and an
insightful roadmap for future research in this domain.",2023-07-24,"Navid Yazdanjue, Hossein Yazdanjouei, Hassan Gharoun, Mohammad Sadegh Khorshidi, Morteza Rakhshaninejad, Amir H. Gandomi"
"Characterising the role of human behaviour in the effectiveness of
  contact-tracing applications","Albeit numerous countries relied on contact-tracing (CT) applications as an
epidemic control measure against the COVID-19 pandemic, the debate around their
effectiveness is still open. Most studies indicate that very high levels of
adoption are required to stop disease progression, placing the main interest of
policymakers in promoting app adherence. However, other factors of human
behaviour, like delays in adherence or heterogeneous compliance, are often
disregarded. To characterise the impact of human behaviour on the effectiveness
of CT apps we propose a multilayer network model reflecting the co-evolution of
an epidemic outbreak and the app adoption dynamics over a synthetic population
generated from survey data. The model was initialised to produce epidemic
outbreaks resembling the first wave of the COVID-19 pandemic and was used to
explore the impact of different changes in behavioural features in peak
incidence and maximal prevalence. The results corroborate the relevance of the
number of users for the effectiveness of CT apps but also highlight the need
for early adoption and, at least, moderate levels of compliance, which are
factors often not considered by most policymakers. The insight obtained was
used to identify a bottleneck in the implementation of several apps, such as
the Spanish CT app, where we hypothesise that a simplification of the reporting
system could result in increased effectiveness through a rise in the levels of
compliance.",2023-07-24,"Ariadna Fosch, Alberto Aleta, Yamir Moreno"
"Stochastic Step-wise Feature Selection for Exponential Random Graph
  Models (ERGMs)","Statistical analysis of social networks provides valuable insights into
complex network interactions across various scientific disciplines. However,
accurate modeling of networks remains challenging due to the heavy
computational burden and the need to account for observed network dependencies.
Exponential Random Graph Models (ERGMs) have emerged as a promising technique
used in social network modeling to capture network dependencies by
incorporating endogenous variables. Nevertheless, using ERGMs poses multiple
challenges, including the occurrence of ERGM degeneracy, which generates
unrealistic and meaningless network structures. To address these challenges and
enhance the modeling of collaboration networks, we propose and test a novel
approach that focuses on endogenous variable selection within ERGMs. Our method
aims to overcome the computational burden and improve the accommodation of
observed network dependencies, thereby facilitating more accurate and
meaningful interpretations of network phenomena in various scientific fields.
We conduct empirical testing and rigorous analysis to contribute to the
advancement of statistical techniques and offer practical insights for network
analysis.",2023-07-24,"Helal El-Zaatari, Fei Yu, Michael R Kosorok"
When can networks be inferred from observed groups?,"Collecting network data directly from network members can be challenging. One
alternative involves inferring a network from observed groups, for example,
inferring a network of scientific collaboration from researchers' observed
paper authorships. In this paper, I explore when an unobserved undirected
network of interest can accurately be inferred from observed groups. The
analysis uses simulations to experimentally manipulate the structure of the
unobserved network to be inferred, the number of groups observed, the extent to
which the observed groups correspond to cliques in the unobserved network, and
the method used to draw inferences. I find that when a small number of groups
are observed, an unobserved network can be accurately inferred using a simple
unweighted two-mode projection, provided that each group's membership closely
corresponds to a clique in the unobserved network. In contrast, when a large
number of groups are observed, an unobserved network can be accurately inferred
using a statistical backbone extraction model, even if the groups' memberships
are mostly random. These findings offer guidance for researchers seeking to
indirectly measure a network of interest using observations of groups.",2023-07-24,Zachary P. Neal
"Stochastic Degree Sequence Model with Edge Constraints (SDSM-EC) for
  Backbone Extraction","It is common to use the projection of a bipartite network to measure a
unipartite network of interest. For example, scientific collaboration networks
are often measured using a co-authorship network, which is the projection of a
bipartite author-paper network. Caution is required when interpreting the edge
weights that appear in such projections. However, backbone models offer a
solution by providing a formal statistical method for evaluating when an edge
in a projection is statistically significantly strong. In this paper, we
propose an extension to the existing Stochastic Degree Sequence Model (SDSM)
that allows the null model to include edge constraints (EC) such as prohibited
edges. We demonstrate the new SDSM-EC in toy data and empirical data on young
children's' play interactions, illustrating how it correctly omits noisy edges
from the backbone.",2023-07-24,"Zachary P. Neal, Jennifer Watling Neal"
"Analyzing the Strategy of Propaganda using Inverse Reinforcement
  Learning: Evidence from the 2022 Russian Invasion of Ukraine","The 2022 Russian invasion of Ukraine was accompanied by a large-scale,
pro-Russian propaganda campaign on social media. However, the strategy behind
the dissemination of propaganda has remained unclear, particularly how the
online discourse was strategically shaped by the propagandists' community.
Here, we analyze the strategy of the Twitter community using an inverse
reinforcement learning (IRL) approach. Specifically, IRL allows us to model
online behavior as a Markov decision process, where the goal is to infer the
underlying reward structure that guides propagandists when interacting with
users with a supporting or opposing stance toward the invasion. Thereby, we aim
to understand empirically whether and how between-user interactions are
strategically used to promote the proliferation of Russian propaganda. For
this, we leverage a large-scale dataset with 349,455 posts with pro-Russian
propaganda from 132,131 users. We show that bots and humans follow a different
strategy: bots respond predominantly to pro-invasion messages, suggesting that
they seek to drive virality; while messages indicating opposition primarily
elicit responses from humans, suggesting that they tend to engage in critical
discussions. To the best of our knowledge, this is the first study analyzing
the strategy behind propaganda from the 2022 Russian invasion of Ukraine
through the lens of IRL.",2023-07-24,"Dominique Geissler, Stefan Feuerriegel"
"Detecting disturbances in network-coupled dynamical systems with machine
  learning","Identifying disturbances in network-coupled dynamical systems without
knowledge of the disturbances or underlying dynamics is a problem with a wide
range of applications. For example, one might want to know which nodes in the
network are being disturbed and identify the type of disturbance. Here we
present a model-free method based on machine learning to identify such unknown
disturbances based only on prior observations of the system when forced by a
known training function. We find that this method is able to identify the
locations and properties of many different types of unknown disturbances using
a variety of known forcing functions. We illustrate our results both with
linear and nonlinear disturbances using food web and neuronal activity models.
Finally, we discuss how to scale our method to large networks.",2023-07-24,"Per Sebastian Skardal, Juan G. Restrepo"
On the information-theoretic formulation of network participation,"The participation coefficient is a widely used metric of the diversity of a
node's connections with respect to a modular partition of a network. An
information-theoretic formulation of this concept of connection diversity,
referred to here as participation entropy, has been introduced as the Shannon
entropy of the distribution of module labels across a node's connected
neighbors. While diversity metrics have been studied theoretically in other
literatures, including to index species diversity in ecology, many of these
results have not previously been applied to networks. Here we show that the
participation coefficient is a first-order approximation to participation
entropy and use the desirable additive properties of entropy to develop new
metrics of connection diversity with respect to multiple labelings of nodes in
a network, as joint and conditional participation entropies. The
information-theoretic formalism developed here allows new and more subtle types
of nodal connection patterns in complex networks to be studied.",2023-07-24,"Pavle Cajic, Dominic Agius, Oliver M. Cliff, James M. Shine, Joseph T. Lizier, Ben D. Fulcher"
"The Looming Threat of Fake and LLM-generated LinkedIn Profiles:
  Challenges and Opportunities for Detection and Prevention","In this paper, we present a novel method for detecting fake and Large
Language Model (LLM)-generated profiles in the LinkedIn Online Social Network
immediately upon registration and before establishing connections. Early fake
profile identification is crucial to maintaining the platform's integrity since
it prevents imposters from acquiring the private and sensitive information of
legitimate users and from gaining an opportunity to increase their credibility
for future phishing and scamming activities. This work uses textual information
provided in LinkedIn profiles and introduces the Section and Subsection Tag
Embedding (SSTE) method to enhance the discriminative characteristics of these
data for distinguishing between legitimate profiles and those created by
imposters manually or by using an LLM. Additionally, the dearth of a large
publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn
profiles for our research. We will release our dataset publicly for research
purposes. This is, to the best of our knowledge, the first large publicly
available LinkedIn dataset for fake LinkedIn account detection. Within our
paradigm, we assess static and contextualized word embeddings, including GloVe,
Flair, BERT, and RoBERTa. We show that the suggested method can distinguish
between legitimate and fake profiles with an accuracy of about 95% across all
word embeddings. In addition, we show that SSTE has a promising accuracy for
identifying LLM-generated profiles, despite the fact that no LLM-generated
profiles were employed during the training phase, and can achieve an accuracy
of approximately 90% when only 20 LLM-generated profiles are added to the
training set. It is a significant finding since the proliferation of several
LLMs in the near future makes it extremely challenging to design a single
system that can identify profiles created with various LLMs.",2023-07-21,"Navid Ayoobi, Sadat Shahriar, Arjun Mukherjee"
"Mixbiotic society measures: Assessment of community well-going as living
  system","Social isolation is caused by the impoverishment of community (atomism) and
fragmentation is caused by the enlargement of in-group (mobism), both of which
can be viewed as social problems related to communication. To solve these
problems, the philosophical world has proposed the concept of ""mixbiotic
society,"" in which individuals with freedom and diverse values mix and mingle
to recognize their respective ""fundamental incapability"" each other and
sublimate into solidarity. Based on this concept, this study proposes new
mixbiotic society measures to evaluate dynamic communication patterns with
reference to classification in cellular automata and particle reaction
diffusion that simulate living phenomena. Specifically, the hypothesis of
measures corresponding to the four classes was formulated, and the hypothesis
was validated by simulating the generation and disappearance of communication.
As a result, considering communication patterns as multidimensional vectors, it
found that the mean of Euclidean distance for ""mobism,"" the variance of the
relative change in distance for ""atomism,"" the composite measure that
multiplies the mean and variance of cosine similarity for ""mixism,"" which
corresponds to the well-going of mixbiotic society, and the almost zero
measures for ""nihilism,"" are suitable. Then, evaluating seven real-society
datasets using these measures, we showed that the mixism measure is useful for
assessing the livingness of communication, and that it is possible to typify
communities based on plural measures. The measures established in this study
are superior to conventional analysis in that they can evaluate dynamic
patterns, they are simple to calculate, and their meanings are easy to
interpret. As a future development, the mixbiotic society measures will be used
in the fields of digital democracy and platform cooperativism toward a
desirable society.",2023-07-21,"Takeshi Kato, Jyunichi Miyakoshi, Tadayuki Matsumura, Ryuji Mine, Hiroyuki Mizuno, Yasuo Deguchi"
"The connection between the spread of misinformation, time of day, and
  individual user activity patterns","Social media manipulation poses a significant threat to cognitive autonomy
and unbiased opinion formation. Prior literature explored the relationship
between online activity and emotional state, cognitive resources, sunlight and
weather. However, a limited understanding exists regarding the role of time of
day in content spread and the impact of user activity patterns on
susceptibility to mis- and disinformation. This work uncovers a strong
correlation between user activity patterns and the tendency to spread
manipulated content. Through quantitative analysis of Twitter data, we examine
how user activity throughout the day aligns with chronotypical archetypes.
Evening types exhibit a significantly higher inclination towards spreading
potentially manipulated content, which is generally more likely between 2:30 AM
and 4:15 AM. This knowledge can become crucial for developing targeted
interventions and strategies that mitigate misinformation spread by addressing
vulnerable periods and user groups more susceptible to manipulation.",2023-07-21,"Elisabeth Stockinger, Riccardo Gallotti, Carina I. Hausladen"
"Ensemble Learning based Anomaly Detection for IoT Cybersecurity via
  Bayesian Hyperparameters Sensitivity Analysis","The Internet of Things (IoT) integrates more than billions of intelligent
devices over the globe with the capability of communicating with other
connected devices with little to no human intervention. IoT enables data
aggregation and analysis on a large scale to improve life quality in many
domains. In particular, data collected by IoT contain a tremendous amount of
information for anomaly detection. The heterogeneous nature of IoT is both a
challenge and an opportunity for cybersecurity. Traditional approaches in
cybersecurity monitoring often require different kinds of data pre-processing
and handling for various data types, which might be problematic for datasets
that contain heterogeneous features. However, heterogeneous types of network
devices can often capture a more diverse set of signals than a single type of
device readings, which is particularly useful for anomaly detection. In this
paper, we present a comprehensive study on using ensemble machine learning
methods for enhancing IoT cybersecurity via anomaly detection. Rather than
using one single machine learning model, ensemble learning combines the
predictive power from multiple models, enhancing their predictive accuracy in
heterogeneous datasets rather than using one single machine learning model. We
propose a unified framework with ensemble learning that utilises Bayesian
hyperparameter optimisation to adapt to a network environment that contains
multiple IoT sensor readings. Experimentally, we illustrate their high
predictive power when compared to traditional methods.",2023-07-20,"Tin Lai, Farnaz Farid, Abubakar Bello, Fariza Sabrina"
"An Empirical Study on Fertility Proposals Using Multi-Grained Topic
  Analysis Methods","Fertility issues are closely related to population security, in 60 years
China's population for the first time in a negative growth trend, the change of
fertility policy is of great concern to the community. 2023 ""two sessions""
proposal ""suggests that the country in the form of legislation, the birth of
the registration of the cancellation of the marriage restriction"" This topic
was once a hot topic on the Internet, and ""unbundling"" the relationship between
birth registration and marriage has become the focus of social debate. In this
paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment
analysis to conduct multi-granularity semantic analysis of microblog comments.
It is found that the discussion on the proposal of ""removing marriage
restrictions from birth registration"" involves the individual, society and the
state at three dimensions, and is detailed into social issues such as personal
behaviour, social ethics and law, and national policy, with people's sentiment
inclined to be negative in most of the topics. Based on this, eight proposals
were made to provide a reference for governmental decision making and to form a
reference method for researching public opinion on political issues.",2023-07-19,Yulin Zhou
Modeling Rabbit-Holes on YouTube,"Numerous discussions have advocated the presence of a so called rabbit-hole
(RH) phenomenon on social media, interested in advanced personalization to
their users. This phenomenon is loosely understood as a collapse of mainstream
recommendations, in favor of ultra personalized ones that lock users into
narrow and specialized feeds. Yet quantitative studies are often ignoring
personalization, are of limited scale, and rely on manual tagging to track this
collapse. This precludes a precise understanding of the phenomenon based on
reproducible observations, and thus the continuous audits of platforms. In this
paper, we first tackle the scale issue by proposing a user-sided bot-centric
approach that enables large scale data collection, through autoplay walks on
recommendations. We then propose a simple theory that explains the appearance
of these RHs. While this theory is a simplifying viewpoint on a complex and
planet-wide phenomenon, it carries multiple advantages: it can be analytically
modeled, and provides a general yet rigorous definition of RHs. We define them
as an interplay between i) user interaction with personalization and ii) the
attraction strength of certain video categories, which cause users to quickly
step apart of mainstream recommendations made to fresh user profiles. We
illustrate these concepts by highlighting some RHs found after collecting more
than 16 million personalized recommendations on YouTube. A final validation
step compares our automatically-identified RHs against manually-identified RHs
from a previous research work. Together, those results pave the way for large
scale and automated audits of the RH effect in recommendation systems.",2023-07-19,"Erwan Le Merrer, Gilles Tredan, Ali Yesilkanat"
"With Flying Colors: Predicting Community Success in Large-scale
  Collaborative Campaigns","Online communities develop unique characteristics, establish social norms,
and exhibit distinct dynamics among their members. Activity in online
communities often results in concrete ``off-line'' actions with a broad
societal impact (e.g., political street protests and norms related to sexual
misconduct). While community dynamics, information diffusion, and online
collaborations have been widely studied in the past two decades, quantitative
studies that measure the effectiveness of online communities in promoting their
agenda are scarce. In this work, we study the correspondence between the
effectiveness of a community, measured by its success level in a competitive
online campaign, and the underlying dynamics between its members. To this end,
we define a novel task: predicting the success level of online communities in
Reddit's r/place - a large-scale distributed experiment that required
collaboration between community members. We consider an array of definitions
for success level; each is geared toward different aspects of collaborative
achievement. We experiment with several hybrid models, combining various types
of features. Our models significantly outperform all baseline models over all
definitions of `success level'. Analysis of the results and the factors that
contribute to the success of coordinated campaigns can provide a better
understanding of the resilience or the vulnerability of communities to online
social threats such as election interference or anti-science trends. We make
all data used for this study publicly available for further research.",2023-07-18,"Abraham Israeli, Oren Tsur"
"Resilience of the reported global human-nature interaction network to
  pandemic conditions","Understanding human-nature interactions and the architecture of coupled
human-nature systems is crucial for sustainable development. Cultural ecosystem
services (CES), defined as intangible benefits derived from nature exposure,
contribute to maintaining and improving human well-being. However, we have
limited understanding of how well-being benefits emerge from CES co-production.
In this study, for the first time, we estimated the global CES network from
self-reported interactions between nature features and human activities
underpinning CES co-production using social media. First, we used a bottom-up,
approach to define the global repertoire of nature features and human
activities used during CES co-production using 682,000 posts on Reddit. We then
sampled Twitter to estimate the co-occurrence of these features and activities
over the past five years, retrieving 41.7 millions tweets. These tweets were
used to estimate the CES bipartite network, where each link was weighted by the
number of times nature features and human activities co-occurred in tweets. We
expected to observe large changes in the CES network topology in relation to
the global mobility restrictions during the COVID-19 pandemic. This was not the
case and the global CES network was generally resilient. However, a higher
order singular value decomposition of the CES tensor revealed an impulse on the
link between self care activities and urban greenspace. This could be due to an
increased need for self care during the pandemic and urban greenspace enabling
CES to be produced locally. Thus, providing resilience for maintaining
well-being during the pandemic. Our user based analysis also indicated a shift
towards local CES production during the beginning of the pandemic. Thus,
supporting that CES was produced locally. These findings suggest an overall
need for CES and access to features providing CES in local communities.",2023-07-18,"Anne Cathrine Linder, David Lusseau"
Explaining conflict violence in terms of conflict actor dynamics,"We study the severity of conflict-related violence in Colombia at an
unprecedented granular scale in space and across time. Splitting the data into
different geographical regions and different historically-relevant eras, we
uncover variations in the patterns of conflict severity which we then explain
in terms of local conflict actors' different collective behaviors and/or
conditions using a simple mathematical model of conflict actors' grouping
dynamics (coalescence and fragmentation). Specifically, variations in the
approximate scaling values of the distributions of event lethalities can be
explained by the changing strength ratio of the local conflict actors for
distinct conflict periods and organizational regions. In this way, our findings
open the door to a new granular spectroscopy of human conflicts in terms of
local conflict actor strength ratios for any armed conflict.",2023-07-18,"Katerina Tkacova, Annette Idler, Neil Johnson, Eduardo López"
"Nested stochastic block model for simultaneously clustering networks and
  nodes","We introduce the nested stochastic block model (NSBM) to cluster a collection
of networks while simultaneously detecting communities within each network.
NSBM has several appealing features including the ability to work on unlabeled
networks with potentially different node sets, the flexibility to model
heterogeneous communities, and the means to automatically select the number of
classes for the networks and the number of communities within each network.
This is accomplished via a Bayesian model, with a novel application of the
nested Dirichlet process (NDP) as a prior to jointly model the between-network
and within-network clusters. The dependency introduced by the network data
creates nontrivial challenges for the NDP, especially in the development of
efficient samplers. For posterior inference, we propose several Markov chain
Monte Carlo algorithms including a standard Gibbs sampler, a collapsed Gibbs
sampler, and two blocked Gibbs samplers that ultimately return two levels of
clustering labels from both within and across the networks. Extensive
simulation studies are carried out which demonstrate that the model provides
very accurate estimates of both levels of the clustering structure. We also
apply our model to two social network datasets that cannot be analyzed using
any previous method in the literature due to the anonymity of the nodes and the
varying number of nodes in each network.",2023-07-18,"Nathaniel Josephs, Arash A. Amini, Marina Paez, Lizhen Lin"
"Examining the Effects of Degree Distribution and Homophily in Graph
  Learning Models","Despite a surge in interest in GNN development, homogeneity in benchmarking
datasets still presents a fundamental issue to GNN research. GraphWorld is a
recent solution which uses the Stochastic Block Model (SBM) to generate diverse
populations of synthetic graphs for benchmarking any GNN task. Despite its
success, the SBM imposed fundamental limitations on the kinds of graph
structure GraphWorld could create.
  In this work we examine how two additional synthetic graph generators can
improve GraphWorld's evaluation; LFR, a well-established model in the graph
clustering literature and CABAM, a recent adaptation of the Barabasi-Albert
model tailored for GNN benchmarking. By integrating these generators, we
significantly expand the coverage of graph space within the GraphWorld
framework while preserving key graph properties observed in real-world
networks. To demonstrate their effectiveness, we generate 300,000 graphs to
benchmark 11 GNN models on a node classification task. We find GNN performance
variations in response to homophily, degree distribution and feature signal.
Based on these findings, we classify models by their sensitivity to the new
generators under these properties. Additionally, we release the extensions made
to GraphWorld on the GitHub repository, offering further evaluation of GNN
performance on new graphs.",2023-07-17,"Mustafa Yasir, John Palowitch, Anton Tsitsulin, Long Tran-Thanh, Bryan Perozzi"
"Disentangling Node Attributes from Graph Topology for Improved
  Generalizability in Link Prediction","Link prediction is a crucial task in graph machine learning with diverse
applications. We explore the interplay between node attributes and graph
topology and demonstrate that incorporating pre-trained node attributes
improves the generalization power of link prediction models. Our proposed
method, UPNA (Unsupervised Pre-training of Node Attributes), solves the
inductive link prediction problem by learning a function that takes a pair of
node attributes and predicts the probability of an edge, as opposed to Graph
Neural Networks (GNN), which can be prone to topological shortcuts in graphs
with power-law degree distribution. In this manner, UPNA learns a significant
part of the latent graph generation mechanism since the learned function can be
used to add incoming nodes to a growing graph. By leveraging pre-trained node
attributes, we overcome observational bias and make meaningful predictions
about unobserved nodes, surpassing state-of-the-art performance (3X to 34X
improvement on benchmark datasets). UPNA can be applied to various pairwise
learning tasks and integrated with existing link prediction models to enhance
their generalizability and bolster graph generative models.",2023-07-17,"Ayan Chatterjee, Robin Walters, Giulia Menichetti, Tina Eliassi-Rad"
Simulation of Stance Perturbations,"In this work, we analyze the circumstances under which social influence
operations are likely to succeed. These circumstances include the selection of
Confederate agents to execute intentional perturbations and the selection of
Perturbation strategies. We use Agent-Based Modelling (ABM) as a simulation
technique to observe the effect of intentional stance perturbations on
scale-free networks. We develop a co-evolutionary social influence model to
interrogate the tradeoff between perturbing stance and maintaining influence
when these variables are linked through homophily. In our experiments, we
observe that stances in a network will converge in sufficient simulation
timesteps, influential agents are the best Confederates and the optimal
Perturbation strategy involves the cascade of local ego networks. Finally, our
experimental results support the theory of tipping points and are in line with
empirical findings suggesting that 20-25% of agents need to be Confederates
before a change in consensus can be achieved.",2023-07-17,"Peter Carragher, Lynnette Hui Xian Ng, Kathleen M. Carley"
Measuring Online Emotional Reactions to Events,"The rich and dynamic information environment of social media provides
researchers, policy makers, and entrepreneurs with opportunities to learn about
social phenomena in a timely manner. However, using this data to understand
social behavior is difficult due heterogeneity of topics and events discussed
in the highly dynamic online information environment. To address these
challenges, we present a method for systematically detecting and measuring
emotional reactions to offline events using change point detection on the time
series of collective affect, and further explaining these reactions using a
transformer-based topic model. We demonstrate the utility of the method on a
corpus of tweets from a large US metropolitan area between January and August,
2020, covering a period of great social change. We demonstrate that our method
is able to disaggregate topics to measure population's emotional and moral
reactions. This capability allows for better monitoring of population's
reactions during crises using online data.",2023-07-17,"Siyi Guo, Zihao He, Ashwin Rao, Eugene Jang, Yuanfeixue Nan, Fred Morstatter, Jeffrey Brantingham, Kristina Lerman"
"Prospect Theory Based Individual Irrationality Modelling and Behavior
  Inducement in Pandemic Control","It is critical to understand and model the behavior of individuals in a
pandemic, as well as identify effective ways to guide people's behavior in
order to better control the epidemic spread. However, current research fails to
account for the impact of users' irrationality in decision-making, which is a
prevalent factor in real-life scenarios. Additionally, existing disease control
methods rely on measures such as mandatory isolation and assume that
individuals will fully comply with these policies, which may not be true in
reality. Thus, it is critical to find effective ways to guide people's behavior
during an epidemic. To address these gaps, we propose a Prospect Theory-based
theoretical framework to model individuals' decision-making process in an
epidemic and analyze the impact of irrationality on the co-evolution of user
behavior and the epidemic. Our analysis shows that irrationality can lead
individuals to be more conservative when the risk of being infected is small,
while irrationality tends to make users be more risk-seeking when the risk of
being infected is high. We then propose a behavior inducement algorithm to
guide user behavior and control the spread of disease. Simulations and real
user tests validate our proposed model and analysis, and simulation results
show that our proposed behavior inducement algorithm can effectively guide
users' behavior.",2023-07-16,"Wenxiang Dong, H. Vicky Zhao"
"Did the Roll-Out of Community Notes Reduce Engagement With
  Misinformation on X/Twitter?","Developing interventions that successfully reduce engagement with
misinformation on social media is challenging. One intervention that has
recently gained great attention is X/Twitter's Community Notes (previously
known as ""Birdwatch""). Community Notes is a crowdsourced fact-checking approach
that allows users to write textual notes to inform others about potentially
misleading posts on X/Twitter. Yet, empirical evidence regarding its
effectiveness in reducing engagement with misinformation on social media is
missing. In this paper, we perform a large-scale empirical study to analyze
whether the introduction of the Community Notes feature and its roll-out to
users in the U.S. and around the world have reduced engagement with
misinformation on X/Twitter in terms of retweet volume and likes. We employ
Difference-in-Differences (DiD) models and Regression Discontinuity Design
(RDD) to analyze a comprehensive dataset consisting of all fact-checking notes
and corresponding source tweets since the launch of Community Notes in early
2021. Although we observe a significant increase in the volume of fact-checks
carried out via Community Notes, particularly for tweets from verified users
with many followers, we find no evidence that the introduction of Community
Notes significantly reduced engagement with misleading tweets on X/Twitter.
Rather, our findings suggest that Community Notes might be too slow to
effectively reduce engagement with misinformation in the early (and most viral)
stage of diffusion. Our work emphasizes the importance of evaluating
fact-checking interventions in the field and offers important implications to
enhance crowdsourced fact-checking strategies on social media.",2023-07-16,"Yuwei Chuai, Haoye Tian, Nicolas Pröllochs, Gabriele Lenzini"
"Real-time Traffic Classification for 5G NSA Encrypted Data Flows With
  Physical Channel Records","The classification of fifth-generation New-Radio (5G-NR) mobile network
traffic is an emerging topic in the field of telecommunications. It can be
utilized for quality of service (QoS) management and dynamic resource
allocation. However, traditional approaches such as Deep Packet Inspection
(DPI) can not be directly applied to encrypted data flows. Therefore, new
real-time encrypted traffic classification algorithms need to be investigated
to handle dynamic transmission. In this study, we examine the real-time
encrypted 5G Non-Standalone (NSA) application-level traffic classification
using physical channel records. Due to the vastness of their features,
decision-tree-based gradient boosting algorithms are a viable approach for
classification. We generate a noise-limited 5G NSA trace dataset with traffic
from multiple applications. We develop a new pipeline to convert sequences of
physical channel records into numerical vectors. A set of machine learning
models are tested, and we propose our solution based on Light Gradient Boosting
Machine (LGBM) due to its advantages in fast parallel training and low
computational burden in practical scenarios. Our experiments demonstrate that
our algorithm can achieve 95% accuracy on the classification task with a
state-of-the-art response time as quick as 10ms.",2023-07-15,"Xiao Fei, Philippe Martins, Jialiang Lu"
"Are Large Language Models a Threat to Digital Public Goods? Evidence
  from Activity on Stack Overflow","Large language models like ChatGPT efficiently provide users with information
about various topics, presenting a potential substitute for searching the web
and asking people for help online. But since users interact privately with the
model, these models may drastically reduce the amount of publicly available
human-generated data and knowledge resources. This substitution can present a
significant problem in securing training data for future models. In this work,
we investigate how the release of ChatGPT changed human-generated open data on
the web by analyzing the activity on Stack Overflow, the leading online Q\&A
platform for computer programming. We find that relative to its Russian and
Chinese counterparts, where access to ChatGPT is limited, and to similar forums
for mathematics, where ChatGPT is less capable, activity on Stack Overflow
significantly decreased. A difference-in-differences model estimates a 16\%
decrease in weekly posts on Stack Overflow. This effect increases in magnitude
over time, and is larger for posts related to the most widely used programming
languages. Posts made after ChatGPT get similar voting scores than before,
suggesting that ChatGPT is not merely displacing duplicate or low-quality
content. These results suggest that more users are adopting large language
models to answer questions and they are better substitutes for Stack Overflow
for languages for which they have more training data. Using models like ChatGPT
may be more efficient for solving certain programming problems, but its
widespread adoption and the resulting shift away from public exchange on the
web will limit the open data people and models can learn from in the future.",2023-07-14,"Maria del Rio-Chanona, Nadzeya Laurentsyeva, Johannes Wachs"
Nowcasting Temporal Trends Using Indirect Surveys,"Indirect surveys, in which respondents provide information about other people
they know, have been proposed for estimating (nowcasting) the size of a
\emph{hidden population} where privacy is important or the hidden population is
hard to reach. Examples include estimating casualties in an earthquake,
conditions among female sex workers, and the prevalence of drug use and
infectious diseases. The Network Scale-up Method (NSUM) is the classical
approach to developing estimates from indirect surveys, but it was designed for
one-shot surveys. Further, it requires certain assumptions and asking for or
estimating the number of individuals in each respondent's network. In recent
years, surveys have been increasingly deployed online and can collect data
continuously (e.g., COVID-19 surveys on Facebook during much of the pandemic).
Conventional NSUM can be applied to these scenarios by analyzing the data
independently at each point in time, but this misses the opportunity of
leveraging the temporal dimension. We propose to use the responses from
indirect surveys collected over time and develop analytical tools (i) to prove
that indirect surveys can provide better estimates for the trends of the hidden
population over time, as compared to direct surveys and (ii) to identify
appropriate temporal aggregations to improve the estimates. We demonstrate
through extensive simulations that our approach outperforms traditional NSUM
and direct surveying methods. We also empirically demonstrate the superiority
of our approach on a real indirect survey dataset of COVID-19 cases.",2023-07-13,"Ajitesh Srivastava, Juan Marcos Ramírez, Sergio Díaz-Aranda, Jose Aguilar, Antonio Ortega, Antonio Fernández Anta, Rosa Elvira Lillo"
"Unpacking polarization: Antagonism and Alignment in Signed Networks of
  Online Interaction","Political conflict is an essential element of democratic systems, but can
also threaten their existence if it becomes too intense. This happens
particularly when most political issues become aligned along the same major
fault line, splitting society into two antagonistic camps. In the 20th century,
major fault lines were formed by structural conflicts, like owners vs workers,
center vs periphery, etc. But these classical cleavages have since lost their
explanatory power. Instead of theorizing new cleavages, we present the FAULTANA
(FAULT-line Alignment Network Analysis) pipeline, a computational method to
uncover major fault lines in data of signed online interactions. Our method
makes it possible to quantify the degree of antagonism prevalent in different
online debates, as well as how aligned each debate is to the major fault line.
This makes it possible to identify the wedge issues driving polarization,
characterized by both intense antagonism and alignment. We apply our approach
to large-scale data sets of Birdwatch, a US-based Twitter fact-checking
community and the discussion forums of DerStandard, an Austrian online
newspaper. We find that both online communities are divided into two large
groups and that their separation follows political identities and topics. In
addition, for DerStandard, we pinpoint issues that reinforce societal fault
lines and thus drive polarization. We also identify issues that trigger online
conflict without strictly aligning with those dividing lines (e.g. COVID-19).
Our methods allow us to construct a time-resolved picture of affective
polarization that shows the separate contributions of cohesiveness and
divisiveness to the dynamics of alignment during contentious elections and
events.",2023-07-13,"Emma Fraxanet, Max Pellert, Simon Schweighofer, Vicenç Gómez, David Garcia"
Research Explosion: More Effort to Climb onto Shoulders of the Giant,"Fast-growing scientific publications present challenges to the scientific
community. In this paper, we describe their implications to researchers. As
references form explicit foundations for researchers to conduct a study, we
investigate the evolution in reference patterns based on 60.8 million papers
published from 1960 to 2015. The results demonstrate that recent papers contain
more references than older ones, especially the well-cited papers compared with
other papers. Well-cited papers receive 10 or more citations within 5 years of
publication. Their references cover a longer period from classic research to
very recent studies. Authors of well-cited papers are also farsighted to
discover the reference papers with good potential to receive high citation
numbers in near future. We also discover that the number of accumulative
publications has a negative impact on next-5-year citation count for most
fields except Chemistry, Materials science, Environmental science, Biology, and
Engineering. Our findings suggest that researchers are expected to devote more
effort to producing impactful research. Based on all these findings, we
strongly advise against judging researchers simply based on the number of their
publications. On the other hand, authors and reviewers should ensure that
published papers contain adequate contributions. The code for our analysis is
on GitHub: https://github.com/ECNU-Text-Computing/Research-Explosion.",2023-07-13,"Guoxiu He, Aixin Sun, Wei Lu"
Influential Simplices Mining via Simplicial Convolutional Network,"Simplicial complexes have recently been in the limelight of higher-order
network analysis, where a minority of simplices play crucial roles in
structures and functions due to network heterogeneity. We find a significant
inconsistency between identifying influential nodes and simplices. Therefore,
it remains elusive how to characterize simplices' influence and identify
influential simplices, despite the relative maturity of research on influential
nodes (0-simplices) identification. Meanwhile, graph neural networks (GNNs) are
potent tools that can exploit network topology and node features
simultaneously, but they struggle to tackle higher-order tasks. In this paper,
we propose a higher-order graph learning model, named influential simplices
mining neural network (ISMnet), to identify vital h-simplices in simplicial
complexes. It can tackle higher-order tasks by leveraging novel higher-order
presentations: hierarchical bipartite graphs and higher-order hierarchical
(HoH) Laplacians, where targeted simplices are grouped into a hub set and can
interact with other simplices. Furthermore, ISMnet employs learnable graph
convolutional operators in each HoH Laplacian domain to capture interactions
among simplices, and it can identify influential simplices of arbitrary order
by changing the hub set. Empirical results demonstrate that ISMnet
significantly outperforms existing methods in ranking 0-simplices (nodes) and
2-simplices. In general, this novel framework excels in identifying influential
simplices and promises to serve as a potent tool in higher-order network
analysis.",2023-07-11,"Yujie Zeng, Yiming Huang, Qiang Wu, Linyuan Lü"
"Excitements and Concerns in the Post-ChatGPT Era: Deciphering Public
  Perception of AI through Social Media Analysis","As AI systems become increasingly prevalent in various aspects of daily life,
gaining a comprehensive understanding of public perception towards these AI
systems has become increasingly essential for several reasons such as ethical
considerations, user experience, fear, disinformation, regulation,
collaboration, and co-creation. In this study, we investigate how mass social
media users perceive the recent rise of AI frameworks such as ChatGPT. We
collect a total of 33,912 comments in 388 unique subreddits spanning from
November 30, 2022 to June 8, 2023 using a list of AI-related keywords. We
employ BERTopic to uncover the major themes regarding AI on Reddit.
Additionally, we seek to gain deeper insights into public opinion by examining
the distribution of topics across different subreddits. We observe that
technology-related subreddits predominantly focus on the technical aspects of
AI models. On the other hand, non-tech subreddits show greater interest in
social issues such as concerns about job replacement or furlough. We leverage
zero-shot prompting to analyze the sentiment and perception of AI among
individual users. Through a comprehensive sentiment and emotion analysis, we
discover that tech-centric communities exhibit greater polarization compared to
non-tech communities when discussing AI topics. This research contributes to
our broader understanding of public opinion surrounding artificial
intelligence.",2023-07-11,"Weihong Qi, Jinsheng Pan, Hanjia Lyu, Jiebo Luo"
"Twotier -- A Layered Analysis of Backbone Members in a Moderate Sized
  Community Sports Organization","Backbone members are recognized as essential parts of an organization, yet
their role and mechanisms of functioning in networks are not fully understood.
In this paper, we propose a new framework called Twotier to analyze the
evolution of community sports organizations (CSOs) and the role of backbone
members. Tier-one establishes a dynamic user interaction network based on
grouping relationships, and weighted k-shell decomposition is used to select
backbone members. We perform community detection and capture the evolution of
two separate sub-networks: one formed by backbone members and the other formed
by other members. In Tier-two, the sub-networks are abstracted, revealing a
core-periphery structure in the organization where backbone members serve as
bridges connecting all parts of the network. Our findings suggest that relying
on backbone members can keep newcomers actively involved in rewarding
activities, while non-rewarding activities solidify relations between backbone
members.",2023-07-09,"Qingran Wang, Jia Yu, Mengjun Ding, Weiqiang Sun"
Social Media Analytics in Disaster Response: A Comprehensive Review,"Social media has emerged as a valuable resource for disaster management,
revolutionizing the way emergency response and recovery efforts are conducted
during natural disasters. This review paper aims to provide a comprehensive
analysis of social media analytics for disaster management. The abstract begins
by highlighting the increasing prevalence of natural disasters and the need for
effective strategies to mitigate their impact. It then emphasizes the growing
influence of social media in disaster situations, discussing its role in
disaster detection, situational awareness, and emergency communication. The
abstract explores the challenges and opportunities associated with leveraging
social media data for disaster management purposes. It examines methodologies
and techniques used in social media analytics, including data collection,
preprocessing, and analysis, with a focus on data mining and machine learning
approaches. The abstract also presents a thorough examination of case studies
and best practices that demonstrate the successful application of social media
analytics in disaster response and recovery. Ethical considerations and privacy
concerns related to the use of social media data in disaster scenarios are
addressed. The abstract concludes by identifying future research directions and
potential advancements in social media analytics for disaster management. The
review paper aims to provide practitioners and researchers with a comprehensive
understanding of the current state of social media analytics in disaster
management, while highlighting the need for continued research and innovation
in this field.",2023-07-08,Mohammadsepehr Karimiziarani
"Understanding the power-law nature of participation in community sports
  organizations","The improvement of living standards and awareness of chronic diseases have
increased the importance of community sports organizations in promoting the
physical activity levels of the public. However, limited understanding of human
behavior in this context often leads to suboptimal resource utilization. In
this study, we analyzed the participation behavior of 2,956 members with a time
span of 6 years in a community sports organization. Our study reveals that, at
the population level, the participation frequency in activities adheres to a
power-law distribution. To understand the underlying mechanisms driving crowd
participation, we introduce a novel behavioral model called HFBI
(Habit-Formation and Behavioral Inertia), demonstrating a robust fit to the
observed power-law distribution. The habit formation mechanism indicates that
individuals who are more engaged are more likely to maintain participation,
while the behavioral inertia mechanism suggests that individuals' willingness
to participate in activities diminishes with their absences from activities. At
the individual level, our analysis reveals a burst-quiet participation pattern,
with bursts often commencing with incentive activities. We also find a
power-law distribution in the intervals between individual participations. Our
research offers valuable insights into the complex dynamics of human
participation in community sports activity and provides a theoretical
foundation to inform intervention design. Furthermore, the flexibility of our
model enables its application to other data exhibiting power-law properties,
broadening its potential impact beyond the realm of community sports.",2023-07-08,"Jia Yu, Mengjun Ding, Weiqiang Sun, Weisheng Hu, Huiru Wang"
"Subjective Crowd Disagreements for Subjective Data: Uncovering
  Meaningful CrowdOpinion with Population-level Learning","Human-annotated data plays a critical role in the fairness of AI systems,
including those that deal with life-altering decisions or moderating
human-created web/social media content. Conventionally, annotator disagreements
are resolved before any learning takes place. However, researchers are
increasingly identifying annotator disagreement as pervasive and meaningful.
They also question the performance of a system when annotators disagree.
Particularly when minority views are disregarded, especially among groups that
may already be underrepresented in the annotator population. In this paper, we
introduce \emph{CrowdOpinion}\footnote{Accepted for publication at ACL 2023},
an unsupervised learning based approach that uses language features and label
distributions to pool similar items into larger samples of label distributions.
We experiment with four generative and one density-based clustering method,
applied to five linear combinations of label distributions and features. We use
five publicly available benchmark datasets (with varying levels of annotator
disagreements) from social media (Twitter, Gab, and Reddit). We also experiment
in the wild using a dataset from Facebook, where annotations come from the
platform itself by users reacting to posts. We evaluate \emph{CrowdOpinion} as
a label distribution prediction task using KL-divergence and a single-label
problem using accuracy measures.",2023-07-07,"Tharindu Cyril Weerasooriya, Sarah Luger, Saloni Poddar, Ashiqur R. KhudaBukhsh, Christopher M. Homan"
"Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug
  Trafficking Detection on Social Media","Social media platforms such as Instagram and Twitter have emerged as critical
channels for drug marketing and illegal sale. Detecting and labeling online
illicit drug trafficking activities becomes important in addressing this issue.
However, the effectiveness of conventional supervised learning methods in
detecting drug trafficking heavily relies on having access to substantial
amounts of labeled data, while data annotation is time-consuming and
resource-intensive. Furthermore, these models often face challenges in
accurately identifying trafficking activities when drug dealers use deceptive
language and euphemisms to avoid detection. To overcome this limitation, we
conduct the first systematic study on leveraging large language models (LLMs),
such as ChatGPT, to detect illicit drug trafficking activities on social media.
We propose an analytical framework to compose \emph{knowledge-informed
prompts}, which serve as the interface that humans can interact with and use
LLMs to perform the detection task. Additionally, we design a Monte Carlo
dropout based prompt optimization method to further to improve performance and
interpretability. Our experimental findings demonstrate that the proposed
framework outperforms other baseline language models in terms of drug
trafficking detection accuracy, showing a remarkable improvement of nearly
12\%. By integrating prior knowledge and the proposed prompts, ChatGPT can
effectively identify and label drug trafficking activities on social networks,
even in the presence of deceptive language and euphemisms used by drug dealers
to evade detection. The implications of our research extend to social networks,
emphasizing the importance of incorporating prior knowledge and scenario-based
prompts into analytical tools to improve online security and public safety.",2023-07-07,"Chuanbo Hu, Bin Liu, Xin Li, Yanfang Ye"
"4TCT, A 4chan Text Collection Tool","4chan is a popular online imageboard which has been widely studied due to an
observed concentration of far-right, antisemitic, racist, misogynistic, and
otherwise hateful material being posted to the site, as well as the emergence
of political movements and the evolution of memes which are posted there,
discussed in Section 1.1. We have created a tool developed in Python which
utilises the 4chan API to collect data from a selection of boards. This paper
accompanies the release of the code via the github repository:
https://github.com/jhculb/4TCT. We believe this tool will be of use to
academics studying 4chan by providing a tool for collection of data from 4chan
to sociological researchers, and potentially contributing to GESIS' Digital
Behavioural Data project.",2023-07-07,Jack H. Culbert
"Metropolitan Scale and Longitudinal Dataset of Anonymized Human Mobility
  Trajectories","Modeling and predicting human mobility trajectories in urban areas is an
essential task for various applications. The recent availability of large-scale
human movement data collected from mobile devices have enabled the development
of complex human mobility prediction models. However, human mobility prediction
methods are often trained and tested on different datasets, due to the lack of
open-source large-scale human mobility datasets amid privacy concerns, posing a
challenge towards conducting fair performance comparisons between methods. To
this end, we created an open-source, anonymized, metropolitan scale, and
longitudinal (90 days) dataset of 100,000 individuals' human mobility
trajectories, using mobile phone location data. The location pings are
spatially and temporally discretized, and the metropolitan area is undisclosed
to protect users' privacy. The 90-day period is composed of 75 days of
business-as-usual and 15 days during an emergency. To promote the use of the
dataset, we will host a human mobility prediction data challenge (`HuMob
Challenge 2023') using the human mobility dataset, which will be held in
conjunction with ACM SIGSPATIAL 2023.",2023-07-07,"Takahiro Yabe, Kota Tsubouchi, Toru Shimizu, Yoshihide Sekimoto, Kaoru Sezaki, Esteban Moro, Alex Pentland"
"What makes a successful rebuttal in computer science conferences? : A
  perspective on social interaction","With an exponential increase in submissions to top-tier Computer Science (CS)
conferences, more and more conferences have introduced a rebuttal stage to the
conference peer review process. The rebuttal stage can be modeled as social
interactions between authors and reviewers. A successful rebuttal often results
in an increased review score after the rebuttal stage. In this paper, we
conduct an empirical study to determine the factors contributing to a
successful rebuttal using over 3,000 papers and 13,000 reviews from ICLR2022,
one of the most prestigious computer science conferences. First, we observe a
significant difference in review scores before and after the rebuttal stage,
which is crucial for paper acceptance. Furthermore, we investigate factors from
the reviewer's perspective using signed social network analysis. A notable
finding is the increase in balanced network structure after the rebuttal stage.
Subsequently, we evaluate several quantifiable author rebuttal strategies and
their effects on review scores. These strategies can help authors in improving
their review scores. Finally, we used machine learning models to predict
rebuttal success and validated the impact of potential factors analyzed in this
paper. Our experiments demonstrate that the utilization of all features
proposed in this study can aid in predicting the success of the rebuttal. In
summary, this work presents a study on the impact factors of successful
rebuttals from both reviewers' and authors' perspectives and lays the
foundation for analyzing rebuttals with social network analysis.",2023-07-07,"Junjie Huang, Win-bin Huang, Yi Bu, Qi Cao, Huawei Shen, Xueqi Cheng"
"A Novel Site-Agnostic Multimodal Deep Learning Model to Identify
  Pro-Eating Disorder Content on Social Media","Over the last decade, there has been a vast increase in eating disorder
diagnoses and eating disorder-attributed deaths, reaching their zenith during
the Covid-19 pandemic. This immense growth derived in part from the stressors
of the pandemic but also from increased exposure to social media, which is rife
with content that promotes eating disorders. This study aimed to create a
multimodal deep learning model that can determine if a given social media post
promotes eating disorders based on a combination of visual and textual data. A
labeled dataset of Tweets was collected from Twitter, recently rebranded as X,
upon which twelve deep learning models were trained and evaluated. Based on
model performance, the most effective deep learning model was the multimodal
fusion of the RoBERTa natural language processing model and the MaxViT image
classification model, attaining accuracy and F1 scores of 95.9% and 0.959,
respectively. The RoBERTa and MaxViT fusion model, deployed to classify an
unlabeled dataset of posts from the social media sites Tumblr and Reddit,
generated results akin to those of previous research studies that did not
employ artificial intelligence-based techniques, indicating that deep learning
models can develop insights congruent to those of researchers. Additionally,
the model was used to conduct a time-series analysis of yet unseen Tweets from
eight Twitter hashtags, uncovering that, since 2014, the relative abundance of
content that promotes eating disorders has decreased drastically within those
communities. Despite this reduction, by 2018, content that promotes eating
disorders had either stopped declining or increased in ampleness anew on those
hashtags.",2023-07-06,Jonathan Feldman
"Pattern formation and bifurcation analysis of delay induced
  fractional-order epidemic spreading on networks","The spontaneous emergence of ordered structures, known as Turing patterns, in
complex networks is a phenomenon that holds potential applications across
diverse scientific fields, including biology, chemistry, and physics. Here, we
present a novel delayed fractional-order
susceptible-infected-recovered-susceptible (SIRS) reaction-diffusion model
functioning on a network, which is typically used to simulate disease
transmission but can also model rumor propagation in social contexts. Our
theoretical analysis establishes the Turing instability resulting from delay,
and we support our conclusions through numerical experiments. We identify the
unique impacts of delay, average network degree, and diffusion rate on pattern
formation. The primary outcomes of our study are: (i) Delays cause system
instability, mainly evidenced by periodic temporal fluctuations; (ii) The
average network degree produces periodic oscillatory states in uneven spatial
distributions; (iii) The combined influence of diffusion rate and delay results
in irregular oscillations in both time and space. However, we also find that
fractional-order can suppress the formation of spatiotemporal patterns. These
findings are crucial for comprehending the impact of network structure on the
dynamics of fractional-order systems.",2023-07-05,"Jiaying Zhou, Yong Ye, Alex Arenas, Sergio Gómez, Yi Zhao"
"A Versatile Hub Model For Efficient Information Propagation And Feature
  Selection","Hub structure, characterized by a few highly interconnected nodes surrounded
by a larger number of nodes with fewer connections, is a prominent topological
feature of biological brains, contributing to efficient information transfer
and cognitive processing across various species. In this paper, a mathematical
model of hub structure is presented. The proposed method is versatile and can
be broadly applied to both computational neuroscience and Recurrent Neural
Networks (RNNs) research. We employ the Echo State Network (ESN) as a means to
investigate the mechanistic underpinnings of hub structures. Our findings
demonstrate a substantial enhancement in performance upon incorporating the hub
structure. Through comprehensive mechanistic analyses, we show that the hub
structure improves model performance by facilitating efficient information
processing and better feature extractions.",2023-07-05,"Zhaoze Wang, Junsong Wang"
All in One: Multi-task Prompting for Graph Neural Networks,"Recently, ''pre-training and fine-tuning'' has been adopted as a standard
workflow for many graph tasks since it can take general graph knowledge to
relieve the lack of graph annotations from each application. However, graph
tasks with node level, edge level, and graph level are far diversified, making
the pre-training pretext often incompatible with these multiple tasks. This gap
may even cause a ''negative transfer'' to the specific application, leading to
poor results. Inspired by the prompt learning in natural language processing
(NLP), which has presented significant effectiveness in leveraging prior
knowledge for various NLP tasks, we study the prompting topic for graphs with
the motivation of filling the gap between pre-trained models and various graph
tasks. In this paper, we propose a novel multi-task prompting method for graph
models. Specifically, we first unify the format of graph prompts and language
prompts with the prompt token, token structure, and inserting pattern. In this
way, the prompting idea from NLP can be seamlessly introduced to the graph
area. Then, to further narrow the gap between various graph tasks and
state-of-the-art pre-training strategies, we further study the task space of
various graph applications and reformulate downstream problems to the
graph-level task. Afterward, we introduce meta-learning to efficiently learn a
better initialization for the multi-task prompt of graphs so that our prompting
framework can be more reliable and general for different tasks. We conduct
extensive experiments, results from which demonstrate the superiority of our
method.",2023-07-04,"Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, Jihong Guan"
An FTP Algorithm for Temporal Graph Untangling,"Several classical combinatorial problems have been considered and analysed on
temporal graphs. Recently, a variant of Vertex Cover on temporal graphs, called
MinTimelineCover, has been introduced to summarize timeline activities in
social networks. The problem asks to cover every temporal edge while minimizing
the total span of the vertices (where the span of a vertex is the length of the
timestamp interval it must remain active in, minus one). While the problem has
been shown to be NP-hard even in very restricted cases, its parameterized
complexity has not been fully understood. The problem is known to be in FPT
under the span parameter only for graphs with two timestamps, but the
parameterized complexity for the general case is open. We settle this open
problem by giving an FPT algorithm that is based on a combination of iterative
compression and a reduction to the Digraph Pair Cut problem, a powerful problem
that has received significant attention recently.",2023-07-03,"Riccardo Dondi, Manuel Lafond"
Disentangled Dynamic Intrusion Detection,"Network-based intrusion detection system (NIDS) monitors network traffic for
malicious activities, forming the frontline defense against increasing attacks
over information infrastructures. Although promising, our quantitative analysis
shows that existing methods perform inconsistently in declaring various
attacks, and perform poorly in few-shot intrusion detections. We reveal that
the underlying cause is entangled distributions of flow features. This
motivates us to propose DIDS-MFL, a disentangled intrusion detection method to
handle various intrusion detection scenarios. DIDS-MFL involves two key
components, respectively: a double Disentanglementbased Intrusion Detection
System (DIDS) and a plug-and-play Multi-scale Few-shot Learning-based (MFL)
intrusion detection module. Specifically, the proposed DIDS first disentangles
traffic features by a non-parameterized optimization, automatically
differentiating tens and hundreds of complex features of various attacks. Such
differentiated features will be further disentangled to highlight the
attack-specific features. Our DIDS additionally uses a novel graph diffusion
method that dynamically fuses the network topology in evolving data streams.
Furthermore, the proposed MFL involves an alternating optimization framework to
address the entangled representations in few-shot traffic threats with rigorous
derivation. MFL first captures multiscale information in latent space to
distinguish attack-specific information and then optimizes the disentanglement
term to highlight the attack-specific information. Finally, MFL fuses and
alternately solves them in an end-to-end way. Experiments show the superiority
of our proposed DIDS-MFL. Our code is available at
https://github.com/qcydm/DIDS-MFL",2023-07-02,"Chenyang Qiu, Guoshun Nan, Hongrui Xia, Zheng Weng, Xueting Wang, Meng Shen, Xiaofeng Tao, Jun Liu"
"Beyond Active Engagement: The Significance of Lurkers in a Polarized
  Twitter Debate","The emergence of new public forums in the shape of online social media has
introduced unprecedented challenges to public discourse, including
polarization, misinformation, and the emergence of echo chambers. While
existing research has extensively studied the behavior of active users within
echo chambers, little attention has been given to the hidden audience, also
known as lurkers, who passively consume content without actively engaging. This
study aims to estimate the share of the hidden audience and investigate their
interplay with the echo chamber effect. Using Twitter as a case study, we
analyze a polarized political debate to understand the engagement patterns and
factors influencing the hidden audience's presence. Our findings reveal a
relevant fraction of users that consume content without active interaction,
which underscores the importance of considering their presence in online
debates. Notably, our results indicate that the engagement of the hidden
audience is primarily influenced by factors such as the reliability of media
sources mentioned in tweets rather than the ideological stance of the user that
produced the content. These findings highlight the need for a comprehensive
understanding of the hidden audience's role in online debates and how they may
influence public opinion.",2023-06-30,"Anees Baqir, Yijing Chen, Fernando Diaz-Diaz, Sercan Kiyak, Thomas Louf, Virginia Morini, Valentina Pansanella, Maddalena Torricelli, Alessandro Galeazzi"
"LMBot: Distilling Graph Knowledge into Language Model for Graph-less
  Deployment in Twitter Bot Detection","As malicious actors employ increasingly advanced and widespread bots to
disseminate misinformation and manipulate public opinion, the detection of
Twitter bots has become a crucial task. Though graph-based Twitter bot
detection methods achieve state-of-the-art performance, we find that their
inference depends on the neighbor users multi-hop away from the targets, and
fetching neighbors is time-consuming and may introduce bias. At the same time,
we find that after finetuning on Twitter bot detection, pretrained language
models achieve competitive performance and do not require a graph structure
during deployment. Inspired by this finding, we propose a novel bot detection
framework LMBot that distills the knowledge of graph neural networks (GNNs)
into language models (LMs) for graph-less deployment in Twitter bot detection
to combat the challenge of data dependency. Moreover, LMBot is compatible with
graph-based and graph-less datasets. Specifically, we first represent each user
as a textual sequence and feed them into the LM for domain adaptation. For
graph-based datasets, the output of LMs provides input features for the GNN,
enabling it to optimize for bot detection and distill knowledge back to the LM
in an iterative, mutually enhancing process. Armed with the LM, we can perform
graph-less inference, which resolves the graph data dependency and sampling
bias issues. For datasets without graph structure, we simply replace the GNN
with an MLP, which has also shown strong performance. Our experiments
demonstrate that LMBot achieves state-of-the-art performance on four Twitter
bot detection benchmarks. Extensive studies also show that LMBot is more
robust, versatile, and efficient compared to graph-based Twitter bot detection
methods.",2023-06-30,"Zijian Cai, Zhaoxuan Tan, Zhenyu Lei, Zifeng Zhu, Hongrui Wang, Qinghua Zheng, Minnan Luo"
"Could Small Language Models Serve as Recommenders? Towards Data-centric
  Cold-start Recommendations","Recommendation systems help users find matched items based on their previous
behaviors. Personalized recommendation becomes challenging in the absence of
historical user-item interactions, a practical problem for startups known as
the system cold-start recommendation. While existing research addresses
cold-start issues for either users or items, we still lack solutions for system
cold-start scenarios. To tackle the problem, we propose PromptRec, a simple but
effective approach based on in-context learning of language models, where we
transform the recommendation task into the sentiment analysis task on natural
language containing user and item profiles. However, this naive approach
heavily relies on the strong in-context learning ability emerged from large
language models, which could suffer from significant latency for online
recommendations. To solve the challenge, we propose to enhance small language
models for recommender systems with a data-centric pipeline, which consists of:
(1) constructing a refined corpus for model pre-training; (2) constructing a
decomposed prompt template via prompt pre-training. They correspond to the
development of training data and inference data, respectively. The pipeline is
supported by a theoretical framework that formalizes the connection between
in-context recommendation and language modeling. To evaluate our approach, we
introduce a cold-start recommendation benchmark, and the results demonstrate
that the enhanced small language models can achieve comparable cold-start
recommendation performance to that of large models with only $17\%$ of the
inference time. To the best of our knowledge, this is the first study to tackle
the system cold-start recommendation problem. We believe our findings will
provide valuable insights for future works. The benchmark and implementations
are available at https://github.com/JacksonWuxs/PromptRec.",2023-06-29,"Xuansheng Wu, Huachi Zhou, Yucheng Shi, Wenlin Yao, Xiao Huang, Ninghao Liu"
Streaming phishing scam detection method on Ethereum,"Phishing is a widespread scam activity on Ethereum, causing huge financial
losses to victims. Most existing phishing scam detection methods abstract
accounts on Ethereum as nodes and transactions as edges, then use manual
statistics of static node features to obtain node embedding and finally
identify phishing scams through classification models. However, these methods
can not dynamically learn new Ethereum transactions. Since the phishing scams
finished in a short time, a method that can detect phishing scams in real-time
is needed. In this paper, we propose a streaming phishing scam detection
method. To achieve streaming detection and capture the dynamic changes of
Ethereum transactions, we first abstract transactions into edge features
instead of node features, and then design a broadcast mechanism and a storage
module, which integrate historical transaction information and neighbor
transaction information to strengthen the node embedding. Finally, the node
embedding can be learned from the storage module and the previous node
embedding. Experimental results show that our method achieves decent
performance on the Ethereum phishing scam detection task.",2023-06-29,"Wenjia Yu, Yijun Xia, Jieli Liu, Jiajing Wu"
"Bending the Automation Bias Curve: A Study of Human and AI-based
  Decision Making in National Security Contexts","Uses of artificial intelligence (AI), especially those powered by machine
learning approaches, are growing in sectors and societies around the world. How
will AI adoption proceed, especially in the international security realm?
Research on automation bias suggests that humans can often be overconfident in
AI, whereas research on algorithm aversion shows that, as the stakes of a
decision rise, humans become more cautious about trusting algorithms. We
theorize about the relationship between background knowledge about AI, trust in
AI, and how these interact with other factors to influence the probability of
automation bias in the international security context. We test these in a
preregistered task identification experiment across a representative sample of
9000 adults in 9 countries with varying levels of AI industries. The results
strongly support the theory, especially concerning AI background knowledge. A
version of the Dunning Kruger effect appears to be at play, whereby those with
the lowest level of experience with AI are slightly more likely to be
algorithm-averse, then automation bias occurs at lower levels of knowledge
before leveling off as a respondent's AI background reaches the highest levels.
Additional results show effects from the task's difficulty, overall AI trust,
and whether a human or AI decision aid is described as highly competent or less
competent.",2023-06-28,"Michael C. Horowitz, Lauren Kahn"
Social World Knowledge: Modeling and Applications,"Social world knowledge is a key ingredient in effective communication and
information processing by humans and machines alike. As of today, there exist
many knowledge bases that represent factual world knowledge. Yet, there is no
resource that is designed to capture social aspects of world knowledge. We
believe that this work makes an important step towards the formulation and
construction of such a resource. We introduce SocialVec, a general framework
for eliciting low-dimensional entity embeddings from the social contexts in
which they occur in social networks. In this framework, entities correspond to
highly popular accounts which invoke general interest. We assume that entities
that individual users tend to co-follow are socially related, and use this
definition of social context to learn the entity embeddings. Similar to word
embeddings which facilitate tasks that involve text semantics, we expect the
learned social entity embeddings to benefit multiple tasks of social flavor. In
this work, we elicited the social embeddings of roughly 200K entities from a
sample of 1.3M Twitter users and the accounts that they follow. We employ and
gauge the resulting embeddings on two tasks of social importance. First, we
assess the political bias of news sources in terms of entity similarity in the
social embedding space. Second, we predict the personal traits of individual
Twitter users based on the social embeddings of entities that they follow. In
both cases, we show advantageous or competitive performance using our approach
compared with task-specific baselines. We further show that existing entity
embedding schemes, which are fact-based, fail to capture social aspects of
knowledge. We make the learned social entity embeddings available to the
research community to support further exploration of social world knowledge and
its applications.",2023-06-28,"Nir Lotan, Einat Minkov"
"Highly engaging events reveal semantic and temporal compression in
  online community discourse","People nowadays express their opinions in online spaces, using different
forms of interactions such as posting, sharing and discussing with one another.
How do these digital traces change in response to events happening in the real
world? We leverage Reddit conversation data, exploiting its community-based
structure, to elucidate how offline events influence online user interactions
and behavior. Online conversations, as posts and comments, are analysed along
their temporal and semantic dimensions. Conversations tend to become repetitive
with a more limited vocabulary, develop at a faster pace and feature heightened
emotions. As the event approaches, the shifts occurring in conversations are
reflected in the users' dynamics. Users become more active and they exchange
information with a growing audience, despite using a less rich vocabulary and
repetitive messages. The recurring patterns we discovered are persistent across
a wide range of events and several contexts, representing a fingerprint of how
online dynamics change in response to real-world occurrences.",2023-06-26,"Antonio Desiderio, Anna Mancini, Giulio Cimini, Riccardo Di Clemente"
"Solving the Identifying Code Set Problem with Grouped Independent
  Support","An important problem in network science is finding an optimal placement of
sensors in nodes in order to uniquely detect failures in the network. This
problem can be modelled as an identifying code set (ICS) problem, introduced by
Karpovsky et al. in 1998. The ICS problem aims to find a cover of a set $S$,
s.t. the elements in the cover define a unique signature for each of the
elements of $S$, and to minimise the cover's cardinality. In this work, we
study a generalised identifying code set (GICS) problem, where a unique
signature must be found for each subset of $S$ that has a cardinality of at
most $k$ (instead of just each element of $S$). The concept of an independent
support of a Boolean formula was introduced by Chakraborty et al. in 2014 to
speed up propositional model counting, by identifying a subset of variables
whose truth assignments uniquely define those of the other variables.
  In this work, we introduce an extended version of independent support,
grouped independent support (GIS), and show how to reduce the GICS problem to
the GIS problem. We then propose a new solving method for finding a GICS, based
on finding a GIS. We show that the prior state-of-the-art approaches yield
integer-linear programming (ILP) models whose sizes grow exponentially with the
problem size and $k$, while our GIS encoding only grows polynomially with the
problem size and $k$. While the ILP approach can solve the GICS problem on
networks of at most 494 nodes, the GIS-based method can handle networks of up
to 21363 nodes; a $\sim 40\times$ improvement. The GIS-based method shows up to
a $520\times$ improvement on the ILP-based method in terms of median solving
time. For the majority of the instances that can be encoded and solved by both
methods, the cardinality of the solution returned by the GIS-based method is
less than $10\%$ larger than the cardinality of the solution found by the ILP
method.",2023-06-25,"Anna L. D. Latour, Arunabha Sen, Kuldeep S. Meel"
"Dynamic Link Prediction Using Graph Representation Learning with
  Enhanced Structure and Temporal Information","The links in many real networks are evolving with time. The task of dynamic
link prediction is to use past connection histories to infer links of the
network at a future time. How to effectively learn the temporal and structural
pattern of the network dynamics is the key. In this paper, we propose a graph
representation learning model based on enhanced structure and temporal
information (GRL\_EnSAT). For structural information, we exploit a combination
of a graph attention network (GAT) and a self-attention network to capture
structural neighborhood. For temporal dynamics, we use a masked self-attention
network to capture the dynamics in the link evolution. In this way, GRL\_EnSAT
not only learns low-dimensional embedding vectors but also preserves the
nonlinear dynamic feature of the evolving network. GRL\_EnSAT is evaluated on
four real datasets, in which GRL\_EnSAT outperforms most advanced baselines.
Benefiting from the dynamic self-attention mechanism, GRL\_EnSAT yields better
performance than approaches based on recursive graph evolution modeling.",2023-06-25,"Chaokai Wu, Yansong Wang, Tao Jia"
"Boosting Multitask Learning on Graphs through Higher-Order Task
  Affinities","Predicting node labels on a given graph is a widely studied problem with many
applications, including community detection and molecular graph prediction.
This paper considers predicting multiple node labeling functions on graphs
simultaneously and revisits this problem from a multitask learning perspective.
For a concrete example, consider overlapping community detection: each
community membership is a binary node classification task. Due to complex
overlapping patterns, we find that negative transfer is prevalent when we apply
naive multitask learning to multiple community detection, as task relationships
are highly nonlinear across different node labeling. To address the challenge,
we develop an algorithm to cluster tasks into groups based on a higher-order
task affinity measure. We then fit a multitask model on each task group,
resulting in a boosting procedure on top of the baseline model. We estimate the
higher-order task affinity measure between two tasks as the prediction loss of
one task in the presence of another task and a random subset of other tasks.
Then, we use spectral clustering on the affinity score matrix to identify task
grouping. We design several speedup techniques to compute the higher-order
affinity scores efficiently and show that they can predict negative transfers
more accurately than pairwise task affinities. We validate our procedure using
various community detection and molecular graph prediction data sets, showing
favorable results compared with existing methods. Lastly, we provide a
theoretical analysis to show that under a planted block model of tasks on
graphs, our affinity scores can provably separate tasks into groups.",2023-06-24,"Dongyue Li, Haotian Ju, Aneesh Sharma, Hongyang R. Zhang"
Temporal Analysis of Misinformation on Parler,"Social media platforms have facilitated the rapid spread of dis- and
mis-information. Parler, a US-based fringe social media platform that positions
itself as a champion of free-speech, has had substantial information integrity
issues. In this study, we seek to characterize temporal misinformation trends
on Parler. Comparing a dataset of 189 million posts and comments from Parler
against 1591 rated claims (false, barely true, half true, mostly true, pants on
fire, true) from Politifact, we identified 231,881 accuracy-labeled posts on
Parler. We used BERT-Topic to thematically analyze the Poltifact claims, and
then compared trends in these categories to real world events to contextualize
their distribution. We identified three distinct categories of misinformation
circulating on Parler: COVID-19, the 2020 presidential election, and the Black
Lives Matter movement. Our results are significant, with a surprising 69.2% of
posts in our dataset found to be 'false' and 7.6% 'barely true'. We also found
that when Parler posts ('parleys') containing misinformation were posted
increased around major events (e.g., George Floyd's murder).",2023-06-24,"Eliana Norton, Thaïs Thomas, Akaash Kolluri, Torie Hyunsik Kim, Dhiraj Murthy"
The effect of distant connections on node anonymity in complex networks,"Ensuring privacy of individuals is of paramount importance to social network
analysis research. Previous work assessed anonymity in a network based on the
non-uniqueness of a node's ego network. In this work, we show that this
approach does not adequately account for the strong de-anonymizing effect of
distant connections. We first propose the use of d-k-anonymity, a novel measure
that takes knowledge up to distance d of a considered node into account.
Second, we introduce anonymity-cascade, which exploits the so-called
infectiousness of uniqueness: mere information about being connected to another
unique node can make a given node uniquely identifiable. These two approaches,
together with relevant ""twin node"" processing steps in the underlying graph
structure, offer practitioners flexible solutions, tunable in precision and
computation time. This enables the assessment of anonymity in large-scale
networks with up to millions of nodes and edges. Experiments on graph models
and a wide range of real-world networks show drastic decreases in anonymity
when connections at distance 2 are considered. Moreover, extending the
knowledge beyond the ego network with just one extra link often already
decreases overall anonymity by over 50%. These findings have important
implications for privacy-aware sharing of sensitive network data.",2023-06-23,"Rachel G. de Jong, Mark P. J. van der Loo, Frank W. Takes"
Fast Maximum $k$-Plex Algorithms Parameterized by Small Degeneracy Gaps,"Given a graph, a $k$-plex is a set of vertices in which each vertex is not
adjacent to at most $k-1$ other vertices in the set. The maximum $k$-plex
problem, which asks for the largest $k$-plex from the given graph, is an
important but computationally challenging problem in applications such as graph
mining and community detection. So far, there are many practical algorithms,
but without providing theoretical explanations on their efficiency. We define a
novel parameter of the input instance, $g_k(G)$, the gap between the degeneracy
bound and the size of the maximum $k$-plex in the given graph, and present an
exact algorithm parameterized by this $g_k(G)$, which has a worst-case running
time polynomial in the size of the input graph and exponential in $g_k(G)$. In
real-world inputs, $g_k(G)$ is very small, usually bounded by $O(\log{(|V|)})$,
indicating that the algorithm runs in polynomial time. We further extend our
discussion to an even smaller parameter $cg_k(G)$, the gap between the
community-degeneracy bound and the size of the maximum $k$-plex, and show that
without much modification, our algorithm can also be parameterized by
$cg_k(G)$. To verify the empirical performance of these algorithms, we carry
out extensive experiments to show that these algorithms are competitive with
the state-of-the-art algorithms. In particular, for large $k$ values such as
$15$ and $20$, our algorithms dominate the existing algorithms. Finally,
empirical analysis is performed to illustrate the effectiveness of the
parameters and other key components in the implementation.",2023-06-23,"Zhengren Wang, Yi Zhou, Chunyu Luo, Mingyu Xiao, Jin-Kao Hao"
Understanding (Ir)rational Herding Online,"Investigations of social influence in collective decision-making have become
possible due to recent technologies and platforms that record interactions in
far larger groups than could be studied before. Herding and its impact on
decision-making are critical areas of practical interest and research study.
However, despite theoretical work suggesting that it matters whether
individuals choose who to imitate based on cues such as experience or whether
they herd at random, there is little empirical analysis of this distinction. To
demonstrate the distinction between what the literature calls ""rational"" and
""irrational"" herding, we use data on tens of thousands of loans from a
well-established online peer-to-peer (p2p) lending platform. First, we employ
an empirical measure of memory in complex systems to measure herding in
lending. Then, we illustrate a network-based approach to visualize herding.
Finally, we model the impact of herding on collective outcomes. Our study
reveals that loan performance is not solely determined by whether the lenders
engage in herding or not. Instead, the interplay between herding and the
imitated lenders' prior success on the platform predicts loan outcomes. In
short, herds led by expert lenders tend to pick loans that do not default. We
discuss the implications of this under-explored aspect of herding for platform
designers, borrowers, and lenders. Our study advances collective intelligence
theories based on a case of high-stakes group decision-making online.",2023-06-22,"Henry K. Dambanemuya, Johannes Wachs, Emőke-Ágnes Horvát"
"HOFA: Twitter Bot Detection with Homophily-Oriented Augmentation and
  Frequency Adaptive Attention","Twitter bot detection has become an increasingly important and challenging
task to combat online misinformation, facilitate social content moderation, and
safeguard the integrity of social platforms. Though existing graph-based
Twitter bot detection methods achieved state-of-the-art performance, they are
all based on the homophily assumption, which assumes users with the same label
are more likely to be connected, making it easy for Twitter bots to disguise
themselves by following a large number of genuine users. To address this issue,
we proposed HOFA, a novel graph-based Twitter bot detection framework that
combats the heterophilous disguise challenge with a homophily-oriented graph
augmentation module (Homo-Aug) and a frequency adaptive attention module
(FaAt). Specifically, the Homo-Aug extracts user representations and computes a
k-NN graph using an MLP and improves Twitter's homophily by injecting the k-NN
graph. For the FaAt, we propose an attention mechanism that adaptively serves
as a low-pass filter along a homophilic edge and a high-pass filter along a
heterophilic edge, preventing user features from being over-smoothed by their
neighborhood. We also introduce a weight guidance loss to guide the frequency
adaptive attention module. Our experiments demonstrate that HOFA achieves
state-of-the-art performance on three widely-acknowledged Twitter bot detection
benchmarks, which significantly outperforms vanilla graph-based bot detection
techniques and strong heterophilic baselines. Furthermore, extensive studies
confirm the effectiveness of our Homo-Aug and FaAt module, and HOFA's ability
to demystify the heterophilous disguise challenge.",2023-06-22,"Sen Ye, Zhaoxuan Tan, Zhenyu Lei, Ruijie He, Hongrui Wang, Qinghua Zheng, Minnan Luo"
Misinformation as Information Pollution,"Social media feed algorithms are designed to optimize online social
engagements for the purpose of maximizing advertising profits, and therefore
have an incentive to promote controversial posts including misinformation. By
thinking about misinformation as information pollution, we can draw parallels
with environmental policy for countering pollution such as carbon taxes.
Similar to pollution, a Pigouvian tax on misinformation provides economic
incentives for social media companies to control the spread of misinformation
more effectively to avoid or reduce their misinformation tax, while preserving
some degree of freedom in platforms' response. In this paper, we highlight a
bird's eye view of a Pigouvian misinformation tax and discuss the key questions
and next steps for implementing such a taxing scheme.",2023-06-21,"Ashkan Kazemi, Rada Mihalcea"
Spatial Heterophily Aware Graph Neural Networks,"Graph Neural Networks (GNNs) have been broadly applied in many urban
applications upon formulating a city as an urban graph whose nodes are urban
objects like regions or points of interest. Recently, a few enhanced GNN
architectures have been developed to tackle heterophily graphs where connected
nodes are dissimilar. However, urban graphs usually can be observed to possess
a unique spatial heterophily property; that is, the dissimilarity of neighbors
at different spatial distances can exhibit great diversity. This property has
not been explored, while it often exists. To this end, in this paper, we
propose a metric, named Spatial Diversity Score, to quantitatively measure the
spatial heterophily and show how it can influence the performance of GNNs.
Indeed, our experimental investigation clearly shows that existing heterophilic
GNNs are still deficient in handling the urban graph with high spatial
diversity score. This, in turn, may degrade their effectiveness in urban
applications. Along this line, we propose a Spatial Heterophily Aware Graph
Neural Network (SHGNN), to tackle the spatial diversity of heterophily of urban
graphs. Based on the key observation that spatially close neighbors on the
urban graph present a more similar mode of difference to the central node, we
first design a rotation-scaling spatial aggregation module, whose core idea is
to properly group the spatially close neighbors and separately process each
group with less diversity inside. Then, a heterophily-sensitive spatial
interaction module is designed to adaptively capture the commonality and
diverse dissimilarity in different spatial groups. Extensive experiments on
three real-world urban datasets demonstrate the superiority of our SHGNN over
several its competitors.",2023-06-21,"Congxi Xiao, Jingbo Zhou, Jizhou Huang, Tong Xu, Hui Xiong"
"Understanding human mobility patterns in Chicago: an analysis of taxi
  data using clustering techniques","Understanding human mobility patterns is important in applications as diverse
as urban planning, public health, and political organizing. One rich source of
data on human mobility is taxi ride data. Using the city of Chicago as a case
study, we examine data from taxi rides in 2016 with the goal of understanding
how neighborhoods are interconnected. This analysis will provide a sense of
which neighborhoods individuals are using taxis to travel between, suggesting
regions to focus new public transit development efforts. Additionally, this
analysis will map traffic circulation patterns and provide an understanding of
where in the city people are traveling from and where they are heading to -
perhaps informing traffic or road pollution mitigation efforts. For the first
application, representing the data as an undirected graph will suffice. Transit
lines run in both directions so simply a knowledge of which neighborhoods have
high rates of taxi travel between them provides an argument for placing public
transit along those routes. However, in order to understand the flow of people
throughout a city, we must make a distinction between the neighborhood from
which people are departing and the areas to which they are arriving - this
requires methods that can deal with directed graphs. All developed codes can be
found at https://github.com/Nikunj-Gupta/Spectral-Clustering-Directed-Graphs.",2023-06-21,"Harish Chauhan, Nikunj Gupta, Zoe Haskell-Craig"
Hypergraph Classification via Persistent Homology,"Persistent homology is a mathematical tool used for studying the shape of
data by extracting its topological features. It has gained popularity in
network science due to its applicability in various network mining problems,
including clustering, graph classification, and graph neural networks. The
definition of persistent homology for graphs is relatively straightforward, as
graphs possess distinct intrinsic distances and a simplicial complex structure.
However, hypergraphs present a challenge in preserving topological information
since they may not have a simplicial complex structure. In this paper, we
define several topological characterizations of hypergraphs in defining
hypergraph persistent homology to prioritize different higher-order structures
within hypergraphs. We further use these persistent homology filtrations in
classifying four different real-world hypergraphs and compare their performance
to the state-of-the-art graph neural network models. Experimental results
demonstrate that persistent homology filtrations are effective in classifying
hypergraphs and outperform the baseline models. To the best of our knowledge,
this study represents the first systematic attempt to tackle the hypergraph
classification problem using persistent homology.",2023-06-20,"Mehmet Emin Aktas, Thu Nguyen, Rakin Riza, Muhammad Ifte Islam, Esra Akbas"
Size Matters: Large Graph Generation with HiGGs,"Large graphs are present in a variety of domains, including social networks,
civil infrastructure, and the physical sciences to name a few. Graph generation
is similarly widespread, with applications in drug discovery, network analysis
and synthetic datasets among others. While GNN (Graph Neural Network) models
have been applied in these domains their high in-memory costs restrict them to
small graphs. Conversely less costly rule-based methods struggle to reproduce
complex structures. We propose HIGGS (Hierarchical Generation of Graphs) as a
model-agnostic framework of producing large graphs with realistic local
structures. HIGGS uses GNN models with conditional generation capabilities to
sample graphs in hierarchies of resolution. As a result HIGGS has the capacity
to extend the scale of generated graphs from a given GNN model by quadratic
order. As a demonstration we implement HIGGS using DiGress, a recent
graph-diffusion model, including a novel edge-predictive-diffusion variant
edge-DiGress. We use this implementation to generate categorically attributed
graphs with tens of thousands of nodes. These HIGGS generated graphs are far
larger than any previously produced using GNNs. Despite this jump in scale we
demonstrate that the graphs produced by HIGGS are, on the local scale, more
realistic than those from the rule-based model BTER.",2023-06-20,"Alex O. Davies, Nirav S. Ajmeri, Telmo M. Silva Filho"
Variational Disentangled Graph Auto-Encoders for Link Prediction,"With the explosion of graph-structured data, link prediction has emerged as
an increasingly important task. Embedding methods for link prediction utilize
neural networks to generate node embeddings, which are subsequently employed to
predict links between nodes. However, the existing embedding methods typically
take a holistic strategy to learn node embeddings and ignore the entanglement
of latent factors. As a result, entangled embeddings fail to effectively
capture the underlying information and are vulnerable to irrelevant
information, leading to unconvincing and uninterpretable link prediction
results. To address these challenges, this paper proposes a novel framework
with two variants, the disentangled graph auto-encoder (DGAE) and the
variational disentangled graph auto-encoder (VDGAE). Our work provides a
pioneering effort to apply the disentanglement strategy to link prediction. The
proposed framework infers the latent factors that cause edges in the graph and
disentangles the representation into multiple channels corresponding to unique
latent factors, which contributes to improving the performance of link
prediction. To further encourage the embeddings to capture mutually exclusive
latent factors, we introduce mutual information regularization to enhance the
independence among different channels. Extensive experiments on various
real-world benchmarks demonstrate that our proposed methods achieve
state-of-the-art results compared to a variety of strong baselines on link
prediction tasks. Qualitative analysis on the synthetic dataset also
illustrates that the proposed methods can capture distinct latent factors that
cause links, providing empirical evidence that our models are able to explain
the results of link prediction to some extent. All code will be made publicly
available upon publication of the paper.",2023-06-20,"Jun Fu, Xiaojuan Zhang, Shuang Li, Dali Chen"
Structural Gender Imbalances in Ballet Collaboration Networks,"Ballet, a mainstream performing art predominantly associated with women,
exhibits significant gender imbalances in leading positions. However, the
collaboration's structural composition on gender representation in the field
remains unexplored. Our study investigates the gendered labor force composition
and collaboration patterns in ballet creations. Our findings reveal gender
disparities in ballet creations aligned with gendered collaboration patterns
and women occupying more peripheral network positions respect to men.
Productivity disparities show women accessing 20-25\% of ballet creations
compared to men. Mathematically derived perception errors show the
underestimation of women artists' representation within ballet collaboration
networks, potentially impacting women's careers in the field. Our study
highlights the structural disadvantages that women face in ballet and
emphasizes the need for a more inclusive and equal professional environment to
improve the career development of women in the ballet industry. These insights
contribute to a broader understanding of structural gender imbalances in
artistic domains and can inform cultural organizations about potential
affirmative actions towards a better representation of women leaders in ballet.",2023-06-19,"Yessica Herrera-Guzmán, Eun Lee, Heetae Kim"
"Unsupervised Framework for Evaluating and Explaining Structural Node
  Embeddings of Graphs","An embedding is a mapping from a set of nodes of a network into a real vector
space. Embeddings can have various aims like capturing the underlying graph
topology and structure, node-to-node relationship, or other relevant
information about the graph, its subgraphs or nodes themselves. A practical
challenge with using embeddings is that there are many available variants to
choose from. Selecting a small set of most promising embeddings from the long
list of possible options for a given task is challenging and often requires
domain expertise. Embeddings can be categorized into two main types: classical
embeddings and structural embeddings. Classical embeddings focus on learning
both local and global proximity of nodes, while structural embeddings learn
information specifically about the local structure of nodes' neighbourhood. For
classical node embeddings there exists a framework which helps data scientists
to identify (in an unsupervised way) a few embeddings that are worth further
investigation. Unfortunately, no such framework exists for structural
embeddings. In this paper we propose a framework for unsupervised ranking of
structural graph embeddings. The proposed framework, apart from assigning an
aggregate quality score for a structural embedding, additionally gives a data
scientist insights into properties of this embedding. It produces information
which predefined node features the embedding learns, how well it learns them,
and which dimensions in the embedded space represent the predefined node
features. Using this information the user gets a level of explainability to an
otherwise complex black-box embedding algorithm.",2023-06-19,"Ashkan Dehghan, Kinga Siuta, Agata Skorupka, Andrei Betlen, David Miller, Bogumil Kaminski, Pawel Pralat"
Focusing on Relevant Responses for Multi-modal Rumor Detection,"In the absence of an authoritative statement about a rumor, people may expose
the truth behind such rumor through their responses on social media. Most rumor
detection methods aggregate the information of all the responses and have made
great progress. However, due to the different backgrounds of users, the
responses have different relevance for discovering th suspicious points hidden
in a rumor claim. The methods that focus on all the responding tweets would
dilute the effect of the critical ones. Moreover, for a multi-modal rumor
claim, the focus of a user may be on several words in the text or an object in
the image, so the different modalities should be considered to select the
relevant responses and verify the claim. In this paper, we propose a novel
multi-modal rumor detection model, termed Focal Reasoning Model (FoRM), to
filter out the irrelevant responses and further conduct fine-grained reasoning
with the multi-modal claim and corresponding responses. Concretely, there are
two main components in our FoRM: the coarse-grained selection and the
fine-grained reasoning. The coarse-grained selection component leverages the
post-level features of the responses to verify the claim and learns a relevant
score of each response. Based on the relevant scores, the most relevant
responses are reserved as the critical ones to the further reasoning. In the
fine-grained reasoning component, we design a relation attention module to
explore the fine-grained relations, i.e., token-to-token and token-to-object
relations, between the reserved responses and the multi-modal claim for finding
out the valuable clues. Extensive experiments have been conducted on two
real-world datasets, and the results demonstrate that our proposed model
outperforms all the baselines.",2023-06-18,"Jun Li, Yi Bin, Liang Peng, Yang Yang, Yangyang Li, Hao Jin, Zi Huang"
Adversaries with Limited Information in the Friedkin--Johnsen Model,"In recent years, online social networks have been the target of adversaries
who seek to introduce discord into societies, to undermine democracies and to
destabilize communities. Often the goal is not to favor a certain side of a
conflict but to increase disagreement and polarization. To get a mathematical
understanding of such attacks, researchers use opinion-formation models from
sociology, such as the Friedkin--Johnsen model, and formally study how much
discord the adversary can produce when altering the opinions for only a small
set of users. In this line of work, it is commonly assumed that the adversary
has full knowledge about the network topology and the opinions of all users.
However, the latter assumption is often unrealistic in practice, where user
opinions are not available or simply difficult to estimate accurately.
  To address this concern, we raise the following question: Can an attacker sow
discord in a social network, even when only the network topology is known? We
answer this question affirmatively. We present approximation algorithms for
detecting a small set of users who are highly influential for the disagreement
and polarization in the network. We show that when the adversary radicalizes
these users and if the initial disagreement/polarization in the network is not
very high, then our method gives a constant-factor approximation on the setting
when the user opinions are known. To find the set of influential users, we
provide a novel approximation algorithm for a variant of MaxCut in graphs with
positive and negative edge weights. We experimentally evaluate our methods,
which have access only to the network topology, and we find that they have
similar performance as methods that have access to the network topology and all
user opinions. We further present an NP-hardness proof, which was an open
question by Chen and Racz [IEEE Trans. Netw. Sci. Eng., 2021].",2023-06-17,"Sijing Tu, Stefan Neumann, Aristides Gionis"
Dual Node and Edge Fairness-Aware Graph Partition,"Fair graph partition of social networks is a crucial step toward ensuring
fair and non-discriminatory treatments in unsupervised user analysis. Current
fair partition methods typically consider node balance, a notion pursuing a
proportionally balanced number of nodes from all demographic groups, but ignore
the bias induced by imbalanced edges in each cluster. To address this gap, we
propose a notion edge balance to measure the proportion of edges connecting
different demographic groups in clusters. We analyze the relations between node
balance and edge balance, then with line graph transformations, we propose a
co-embedding framework to learn dual node and edge fairness-aware
representations for graph partition. We validate our framework through several
social network datasets and observe balanced partition in terms of both nodes
and edges along with good utility. Moreover, we demonstrate our fair partition
can be used as pseudo labels to facilitate graph neural networks to behave
fairly in node classification and link prediction tasks.",2023-06-16,"Tingwei Liu, Peizhao Li, Hongfu Liu"
Self-supervised Learning and Graph Classification under Heterophily,"Self-supervised learning has shown its promising capability in graph
representation learning in recent work. Most existing pre-training strategies
usually choose the popular Graph neural networks (GNNs), which can be seen as a
special form of low-pass filter, fail to effectively capture heterophily. In
this paper, we first present an experimental investigation exploring the
performance of low-pass and high-pass filters in heterophily graph
classification, where the results clearly show that high-frequency signal is
important for learning heterophily graph representation. On the other hand, it
is still unclear how to effectively capture the structural pattern of graphs
and how to measure the capability of the self-supervised pre-training strategy
in capturing graph structure. To address the problem, we first design a
quantitative metric to Measure Graph Structure (MGS), which analyzes
correlation between structural similarity and embedding similarity of graph
pairs. Then, to enhance the graph structural information captured by
self-supervised learning, we propose a novel self-supervised strategy for
Pre-training GNNs based on the Metric (PGM). Extensive experiments validate our
pre-training strategy achieves state-of-the-art performance for molecular
property prediction and protein function prediction. In addition, we find
choosing the suitable filter sometimes may be better than designing good
pre-training strategies for heterophily graph classification.",2023-06-14,"Yilin Ding, Zhen Liu, Hao Hao"
Learning on Graphs under Label Noise,"Node classification on graphs is a significant task with a wide range of
applications, including social analysis and anomaly detection. Even though
graph neural networks (GNNs) have produced promising results on this task,
current techniques often presume that label information of nodes is accurate,
which may not be the case in real-world applications. To tackle this issue, we
investigate the problem of learning on graphs with label noise and develop a
novel approach dubbed Consistent Graph Neural Network (CGNN) to solve it.
Specifically, we employ graph contrastive learning as a regularization term,
which promotes two views of augmented nodes to have consistent representations.
Since this regularization term cannot utilize label information, it can enhance
the robustness of node representations to label noise. Moreover, to detect
noisy labels on the graph, we present a sample selection technique based on the
homophily assumption, which identifies noisy nodes by measuring the consistency
between the labels with their neighbors. Finally, we purify these confident
noisy labels to permit efficient semantic graph learning. Extensive experiments
on three well-known benchmark datasets demonstrate the superiority of our CGNN
over competing approaches.",2023-06-14,"Jingyang Yuan, Xiao Luo, Yifang Qin, Yusheng Zhao, Wei Ju, Ming Zhang"
Detect Depression from Social Networks with Sentiment Knowledge Sharing,"Social network plays an important role in propagating people's viewpoints,
emotions, thoughts, and fears. Notably, following lockdown periods during the
COVID-19 pandemic, the issue of depression has garnered increasing attention,
with a significant portion of individuals resorting to social networks as an
outlet for expressing emotions. Using deep learning techniques to discern
potential signs of depression from social network messages facilitates the
early identification of mental health conditions. Current efforts in detecting
depression through social networks typically rely solely on analyzing the
textual content, overlooking other potential information. In this work, we
conduct a thorough investigation that unveils a strong correlation between
depression and negative emotional states. The integration of such associations
as external knowledge can provide valuable insights for detecting depression.
Accordingly, we propose a multi-task training framework, DeSK, which utilizes
shared sentiment knowledge to enhance the efficacy of depression detection.
Experiments conducted on both Chinese and English datasets demonstrate the
cross-lingual effectiveness of DeSK.",2023-06-13,"Yan Shi, Yao Tian, Chengwei Tong, Chunyan Zhu, Qianqian Li, Mengzhu Zhang, Wei Zhao, Yong Liao, Pengyuan Zhou"
"Noisy Positive-Unlabeled Learning with Self-Training for Speculative
  Knowledge Graph Reasoning","This paper studies speculative reasoning task on real-world knowledge graphs
(KG) that contain both \textit{false negative issue} (i.e., potential true
facts being excluded) and \textit{false positive issue} (i.e., unreliable or
outdated facts being included). State-of-the-art methods fall short in the
speculative reasoning ability, as they assume the correctness of a fact is
solely determined by its presence in KG, making them vulnerable to false
negative/positive issues. The new reasoning task is formulated as a noisy
Positive-Unlabeled learning problem. We propose a variational framework, namely
nPUGraph, that jointly estimates the correctness of both collected and
uncollected facts (which we call \textit{label posterior}) and updates model
parameters during training. The label posterior estimation facilitates
speculative reasoning from two perspectives. First, it improves the robustness
of a label posterior-aware graph encoder against false positive links. Second,
it identifies missing facts to provide high-quality grounds of reasoning. They
are unified in a simple yet effective self-training procedure. Empirically,
extensive experiments on three benchmark KG and one Twitter dataset with
various degrees of false negative/positive cases demonstrate the effectiveness
of nPUGraph.",2023-06-13,"Ruijie Wang, Baoyu Li, Yichen Lu, Dachun Sun, Jinning Li, Yuchen Yan, Shengzhong Liu, Hanghang Tong, Tarek F. Abdelzaher"
"To be a pro-vax or not, the COVID-19 vaccine conundrum on Twitter","The most surprising observation reported by the study in (arXiv:2208.13523),
involving stance detection of COVID-19 vaccine related tweets during the first
year of pandemic, is the presence of a significant number of users (~2 million)
who posted tweets with both anti-vax and pro-vax stances. This is a sizable
cohort even when the stance detection noise is considered. In this paper, we
tried to get deeper understanding of this 'dual-stance' group. Out of this
group, 60% of users have more pro-vax tweets than anti-vax tweets and 17% have
the same number of tweets in both classes. The rest have more anti-vax tweets,
and they were highly active in expressing concerns about mandate and safety of
a fast-tracked vaccine, while also tweeted some updates about vaccine
development. The leaning pro-vax group have opposite composition: more vaccine
updates and some posts about concerns. It is important to note that vaccine
concerns were not always genuine and had a large dose of misinformation. 43% of
the balanced group have only tweeted one tweet of each type during our study
period and are the less active participants in the vaccine discourse. Our
temporal study also shows that the change-of-stance behaviour became really
significant once the trial results of COVID-19 vaccine were announced to the
public, and it appears as the change of stance towards pro-vax is a reaction to
people changing their opinion towards anti-vax. Our study finished at Mar 23,
2021 when the conundrum was still going strong. The dilemma might be a
reflection of the uncertain and stressful times, but it also highlights the
importance of building public trust to combat prevalent misinformation.",2023-06-11,"Zainab Zaidi, Mengbin Ye, Shanika Karunasekera, Yoshihisa Kashima"
"You Can Tell a Cybercriminal by the Company they Keep: A Framework to
  Infer the Relevance of Underground Communities to the Threat Landscape","The criminal underground is populated with forum marketplaces where,
allegedly, cybercriminals share and trade knowledge, skills, and cybercrime
products. However, it is still unclear whether all marketplaces matter the same
in the overall threat landscape. To effectively support trade and avoid
degenerating into scams-for-scammers places, underground markets must address
fundamental economic problems (such as moral hazard, adverse selection) that
enable the exchange of actual technology and cybercrime products (as opposed to
repackaged malware or years-old password databases). From the relevant
literature and manual investigation, we identify several mechanisms that
marketplaces implement to mitigate these problems, and we condense them into a
market evaluation framework based on the Business Model Canvas. We use this
framework to evaluate which mechanisms `successful' marketplaces have in place,
and whether these differ from those employed by `unsuccessful' marketplaces. We
test the framework on 23 underground forum markets by searching 836 aliases of
indicted cybercriminals to identify `successful' marketplaces. We find evidence
that marketplaces whose administrators are impartial in trade, verify their
sellers, and have the right economic incentives to keep the market functional
are more likely to be credible sources of threat.",2023-06-09,"Michele Campobasso, Radu Rădulescu, Sylvan Brons, Luca Allodi"
"On Performance Discrepancies Across Local Homophily Levels in Graph
  Neural Networks","Graph Neural Network (GNN) research has highlighted a relationship between
high homophily (i.e., the tendency of nodes of the same class to connect) and
strong predictive performance in node classification. However, recent work has
found the relationship to be more nuanced, demonstrating that simple GNNs can
learn in certain heterophilous settings. To resolve these conflicting findings
and align closer to real-world datasets, we go beyond the assumption of a
global graph homophily level and study the performance of GNNs when the local
homophily level of a node deviates from the global homophily level. Through
theoretical and empirical analysis, we systematically demonstrate how shifts in
local homophily can introduce performance degradation, leading to performance
discrepancies across local homophily levels. We ground the practical
implications of this work through granular analysis on five real-world datasets
with varying global homophily levels, demonstrating that (a) GNNs can fail to
generalize to test nodes that deviate from the global homophily of a graph, and
(b) high local homophily does not necessarily confer high performance for a
node. We further show that GNNs designed for globally heterophilous graphs can
alleviate performance discrepancy by improving performance across local
homophily levels, offering a new perspective on how these GNNs achieve stronger
global performance.",2023-06-08,"Donald Loveland, Jiong Zhu, Mark Heimann, Benjamin Fish, Michael T. Schaub, Danai Koutra"
"Hybrid Graph: A Unified Graph Representation with Datasets and
  Benchmarks for Complex Graphs","Graphs are widely used to encapsulate a variety of data formats, but
real-world networks often involve complex node relations beyond only being
pairwise. While hypergraphs and hierarchical graphs have been developed and
employed to account for the complex node relations, they cannot fully represent
these complexities in practice. Additionally, though many Graph Neural Networks
(GNNs) have been proposed for representation learning on higher-order graphs,
they are usually only evaluated on simple graph datasets. Therefore, there is a
need for a unified modelling of higher-order graphs, and a collection of
comprehensive datasets with an accessible evaluation framework to fully
understand the performance of these algorithms on complex graphs. In this
paper, we introduce the concept of hybrid graphs, a unified definition for
higher-order graphs, and present the Hybrid Graph Benchmark (HGB). HGB contains
23 real-world hybrid graph datasets across various domains such as biology,
social media, and e-commerce. Furthermore, we provide an extensible evaluation
framework and a supporting codebase to facilitate the training and evaluation
of GNNs on HGB. Our empirical study of existing GNNs on HGB reveals various
research opportunities and gaps, including (1) evaluating the actual
performance improvement of hypergraph GNNs over simple graph GNNs; (2)
comparing the impact of different sampling strategies on hybrid graph learning
methods; and (3) exploring ways to integrate simple graph and hypergraph
information. We make our source code and full datasets publicly available at
https://zehui127.github.io/hybrid-graph-benchmark/.",2023-06-08,"Zehui Li, Xiangyu Zhao, Mingzhu Shen, Guy-Bart Stan, Pietro Liò, Yiren Zhao"
Epidemic spreading in group-structured populations,"Individuals involved in common group activities/settings -- e.g., college
students that are enrolled in the same class and/or live in the same dorm --
are exposed to recurrent contacts of physical proximity. These contacts are
known to mediate the spread of an infectious disease, however, it is not
obvious how the properties of the spreading process are determined by the
structure of and the interrelation among the group settings that are at the
root of those recurrent interactions. Here, we show that reshaping the
organization of groups within a population can be used as an effective strategy
to decrease the severity of an epidemic. Specifically, we show that when group
structures are sufficiently correlated -- e.g., the likelihood for two students
living in the same dorm to attend the same class is sufficiently high --
outbreaks are longer but milder than for uncorrelated group structures. Also,
we show that the effectiveness of interventions for disease containment
increases as the correlation among group structures increases. We demonstrate
the practical relevance of our findings by taking advantage of data about
housing and attendance of students at the Indiana University campus in
Bloomington. By appropriately optimizing the assignment of students to dorms
based on their enrollment, we are able to observe a two- to five-fold reduction
in the severity of simulated epidemic processes.",2023-06-07,"Siddharth Patwardhan, Varun K. Rao, Santo Fortunato, Filippo Radicchi"
"Limits, approximation and size transferability for GNNs on sparse graphs
  via graphops","Can graph neural networks generalize to graphs that are different from the
graphs they were trained on, e.g., in size? In this work, we study this
question from a theoretical perspective. While recent work established such
transferability and approximation results via graph limits, e.g., via graphons,
these only apply non-trivially to dense graphs. To include frequently
encountered sparse graphs such as bounded-degree or power law graphs, we take a
perspective of taking limits of operators derived from graphs, such as the
aggregation operation that makes up GNNs. This leads to the recently introduced
limit notion of graphops (Backhausz and Szegedy, 2022). We demonstrate how the
operator perspective allows us to develop quantitative bounds on the distance
between a finite GNN and its limit on an infinite graph, as well as the
distance between the GNN on graphs of different sizes that share structural
properties, under a regularity assumption verified for various graph sequences.
Our results hold for dense and sparse graphs, and various notions of graph
limits.",2023-06-07,"Thien Le, Stefanie Jegelka"
How to Find Opinion Leader on the Online Social Network?,"Online social networks (OSNs) provide a platform for individuals to share
information, exchange ideas and build social connections beyond in-person
interactions. For a specific topic or community, opinion leaders are
individuals who have a significant influence on others' opinions. Detecting and
modeling opinion leaders is crucial as they play a vital role in shaping public
opinion and driving online conversations. Existing research have extensively
explored various methods for detecting opinion leaders, but there is a lack of
consensus between definitions and methods. It is important to note that the
term ""important node"" in graph theory does not necessarily align with the
concept of ""opinion leader"" in social psychology. This paper aims to address
this issue by introducing the methodologies for identifying influential nodes
in OSNs and providing a corresponding definition of opinion leaders in relation
to social psychology. The key novelty is to review connections and
cross-compare different approaches that have origins in: graph theory, natural
language processing, social psychology, control theory, and graph sampling. We
discuss how they tell a different technical tale of influence and also propose
how some of the approaches can be combined via networked dynamical systems
modeling. A case study is performed on Twitter data to compare the performance
of different methodologies discussed. The primary objective of this work is to
elucidate the progression of opinion leader detection on OSNs and inspire
further research in understanding the dynamics of opinion evolution within the
field.",2023-06-07,"Bailu Jin, Mengbang Zou, Zhuangkun Wei, Weisi Guo"
Orphan Articles: The Dark Matter of Wikipedia,"With 60M articles in more than 300 language versions, Wikipedia is the
largest platform for open and freely accessible knowledge. While the available
content has been growing continuously at a rate of around 200K new articles
each month, very little attention has been paid to the accessibility of the
content. One crucial aspect of accessibility is the integration of hyperlinks
into the network so the articles are visible to readers navigating Wikipedia.
In order to understand this phenomenon, we conduct the first systematic study
of orphan articles, which are articles without any incoming links from other
Wikipedia articles, across 319 different language versions of Wikipedia. We
find that a surprisingly large extent of content, roughly 15\% (8.8M) of all
articles, is de facto invisible to readers navigating Wikipedia, and thus,
rightfully term orphan articles as the dark matter of Wikipedia. We also
provide causal evidence through a quasi-experiment that adding new incoming
links to orphans (de-orphanization) leads to a statistically significant
increase of their visibility in terms of the number of pageviews. We further
highlight the challenges faced by editors for de-orphanizing articles,
demonstrate the need to support them in addressing this issue, and provide
potential solutions for developing automated tools based on cross-lingual
approaches. Overall, our work not only unravels a key limitation in the link
structure of Wikipedia and quantitatively assesses its impact, but also
provides a new perspective on the challenges of maintenance associated with
content creation at scale in Wikipedia.",2023-06-06,"Akhil Arora, Robert West, Martin Gerlach"
Minimizing Hitting Time between Disparate Groups with Shortcut Edges,"Structural bias or segregation of networks refers to situations where two or
more disparate groups are present in the network, so that the groups are highly
connected internally, but loosely connected to each other. In many cases it is
of interest to increase the connectivity of disparate groups so as to, e.g.,
minimize social friction, or expose individuals to diverse viewpoints. A
commonly-used mechanism for increasing the network connectivity is to add edge
shortcuts between pairs of nodes. In many applications of interest, edge
shortcuts typically translate to recommendations, e.g., what video to watch, or
what news article to read next. The problem of reducing structural bias or
segregation via edge shortcuts has recently been studied in the literature, and
random walks have been an essential tool for modeling navigation and
connectivity in the underlying networks. Existing methods, however, either do
not offer approximation guarantees, or engineer the objective so that it
satisfies certain desirable properties that simplify the optimization~task. In
this paper we address the problem of adding a given number of shortcut edges in
the network so as to directly minimize the average hitting time and the maximum
hitting time between two disparate groups. Our algorithm for minimizing average
hitting time is a greedy bicriteria that relies on supermodularity. In
contrast, maximum hitting time is not supermodular. Despite, we develop an
approximation algorithm for that objective as well, by leveraging connections
with average hitting time and the asymmetric k-center problem.",2023-06-06,"Florian Adriaens, Honglian Wang, Aristides Gionis"
"Computational Agent-based Models in Opinion Dynamics: A Survey on Social
  Simulations and Empirical Studies","Understanding how an individual changes its attitude, belief, and opinion due
to other people's social influences is vital because of its wide implications.
A core methodology that is used to study the change of attitude under social
influences is agent-based model (ABM). The goal of this review paper is to
compare and contrast existing ABMs, which I classify into two families, the
deductive ABMs and the inductive ABMs. The former subsumes social simulation
studies, and the latter involves human experiments. To facilitate the
comparison between ABMs of different formulations, I propose a general unified
formulation, in which all ABMs can be viewed as special cases. In addition, I
show the connections between deductive ABMs and inductive ABMs, and point out
their strengths and limitations. At the end of the paper, I identify
underexplored areas and suggest future research directions.",2023-06-06,"Yun-Shiuan Chuang, Timothy T. Rogers"
Quantum Blockchain Miners Provide Massive Energy Savings,"Blockchain-based cryptocurrencies have become an extremely important,
highly-used, technology. A major criticism of cryptocurrencies, however, is
their energy consumption. In May 2022 Bitcoin alone was reported to be
consuming 150 terawatt-hours of electricity annually; more than many entire
countries. Hence, any meaningful efficiency increase in this process would have
a tremendous positive impact. Meanwhile, practical applications of quantum
information technologies, and in particular of near-term quantum computers
(NISQ) continue to be an important research question. Here, we study the
efficiency benefits of moving cryptocurrency mining from current ASIC-based
miners to quantum, and in particular NISQ, miners. While the time-efficiency
benefits of quantum technologies is extremely well-studied, here we focus on
energy savings. We show that the transition to quantum-based mining could incur
an energy saving, by relatively conservative estimates, of about roughly
126.7TWH, or put differently the total energy consumption of Sweden in 2020.",2023-06-06,"Joseph Kearney, Carlos A Perez-Delgado"
Structural Re-weighting Improves Graph Domain Adaptation,"In many real-world applications, graph-structured data used for training and
testing have differences in distribution, such as in high energy physics (HEP)
where simulation data used for training may not match real experiments. Graph
domain adaptation (GDA) is a method used to address these differences. However,
current GDA primarily works by aligning the distributions of node
representations output by a single graph neural network encoder shared across
the training and testing domains, which may often yield sub-optimal solutions.
This work examines different impacts of distribution shifts caused by either
graph structure or node attributes and identifies a new type of shift, named
conditional structure shift (CSS), which current GDA approaches are provably
sub-optimal to deal with. A novel approach, called structural reweighting
(StruRW), is proposed to address this issue and is tested on synthetic graphs,
four benchmark datasets, and a new application in HEP. StruRW has shown
significant performance improvement over the baselines in the settings with
large graph structure shifts, and reasonable performance improvement when node
attribute shift dominates.",2023-06-05,"Shikun Liu, Tianchun Li, Yongbin Feng, Nhan Tran, Han Zhao, Qiu Qiang, Pan Li"
Classification of Edge-dependent Labels of Nodes in Hypergraphs,"A hypergraph is a data structure composed of nodes and hyperedges, where each
hyperedge is an any-sized subset of nodes. Due to the flexibility in hyperedge
size, hypergraphs represent group interactions (e.g., co-authorship by more
than two authors) more naturally and accurately than ordinary graphs.
Interestingly, many real-world systems modeled as hypergraphs contain
edge-dependent node labels, i.e., node labels that vary depending on
hyperedges. For example, on co-authorship datasets, the same author (i.e., a
node) can be the primary author in a paper (i.e., a hyperedge) but the
corresponding author in another paper (i.e., another hyperedge).
  In this work, we introduce a classification of edge-dependent node labels as
a new problem. This problem can be used as a benchmark task for hypergraph
neural networks, which recently have attracted great attention, and also the
usefulness of edge-dependent node labels has been verified in various
applications. To tackle this problem, we propose WHATsNet, a novel hypergraph
neural network that represents the same node differently depending on the
hyperedges it participates in by reflecting its varying importance in the
hyperedges. To this end, WHATsNet models the relations between nodes within
each hyperedge, using their relative centrality as positional encodings. In our
experiments, we demonstrate that WHATsNet significantly and consistently
outperforms ten competitors on six real-world hypergraphs, and we also show
successful applications of WHATsNet to (a) ranking aggregation, (b) node
clustering, and (c) product return prediction.",2023-06-05,"Minyoung Choe, Sunwoo Kim, Jaemin Yoo, Kijung Shin"
"Media Bias and Polarization through the Lens of a Markov Switching
  Latent Space Network Model","News outlets are now more than ever incentivized to provide their audience
with slanted news, while the intrinsic homophilic nature of online social media
may exacerbate polarized opinions. Here, we propose a new dynamic latent space
model for time-varying online audience-duplication networks, which exploits
social media content to conduct inference on media bias and polarization of
news outlets. Our model contributes to the literature in several directions: 1)
we provide a model-embedded data-driven interpretation for the latent leaning
of news outlets in terms of media bias; 2) we endow our model with
Markov-switching dynamics to capture polarization regimes while maintaining a
parsimonious specification; 3) we contribute to the literature on the
statistical properties of latent space network models. The proposed model is
applied to a set of data on the online activity of national and local news
outlets from four European countries in the years 2015 and 2016. We find
evidence of a strong positive correlation between our media slant measure and a
well-grounded external source of media bias. In addition, we provide insight
into the polarization regimes across the four countries considered.",2023-06-05,"Roberto Casarin, Antonio Peruzzi, Mark F. J. Steel"
Networked Communication for Decentralised Agents in Mean-Field Games,"We introduce networked communication to the mean-field game framework, in
particular to oracle-free settings where $N$ decentralised agents learn along a
single, non-episodic run of the empirical system. We prove that our
architecture has sample guarantees bounded between those of the centralised-
and independent-learning cases. We provide the order of the difference in these
bounds in terms of network structure and number of communication rounds, and
also contribute a policy-update stability guarantee. We discuss how the sample
guarantees of the three theoretical algorithms do not actually result in
practical convergence. We therefore show that in practical settings where the
theoretical parameters are not observed (leading to poor estimation of the
Q-function), our communication scheme significantly accelerates convergence
over the independent case (and sometimes even the centralised case), without
relying on the assumption of a centralised learner. We contribute further
practical enhancements to all three theoretical algorithms, allowing us to
present their first empirical demonstrations. Our experiments confirm that we
can remove several of the theoretical assumptions of the algorithms, and
display the empirical convergence benefits brought by our new networked
communication. We additionally show that the networked approach has significant
advantages, over both the centralised and independent alternatives, in terms of
robustness to unexpected learning failures and to changes in population size.",2023-06-05,"Patrick Benjamin, Alessandro Abate"
"Structure-free Graph Condensation: From Large-scale Graphs to Condensed
  Graph-free Data","Graph condensation, which reduces the size of a large-scale graph by
synthesizing a small-scale condensed graph as its substitution, has immediate
benefits for various graph learning tasks. However, existing graph condensation
methods rely on the joint optimization of nodes and structures in the condensed
graph, and overlook critical issues in effectiveness and generalization
ability. In this paper, we advocate a new Structure-Free Graph Condensation
paradigm, named SFGC, to distill a large-scale graph into a small-scale graph
node set without explicit graph structures, i.e., graph-free data. Our idea is
to implicitly encode topology structure information into the node attributes in
the synthesized graph-free data, whose topology is reduced to an identity
matrix. Specifically, SFGC contains two collaborative components: (1) a
training trajectory meta-matching scheme for effectively synthesizing
small-scale graph-free data; (2) a graph neural feature score metric for
dynamically evaluating the quality of the condensed data. Through training
trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors
between the large-scale graph and the condensed small-scale graph-free data,
ensuring comprehensive and compact transfer of informative knowledge to the
graph-free data. Afterward, the underlying condensed graph-free data would be
dynamically evaluated with the graph neural feature score, which is a
closed-form metric for ensuring the excellent expressiveness of the condensed
graph-free data. Extensive experiments verify the superiority of SFGC across
different condensation ratios.",2023-06-05,"Xin Zheng, Miao Zhang, Chunyang Chen, Quoc Viet Hung Nguyen, Xingquan Zhu, Shirui Pan"
"Densest Diverse Subgraphs: How to Plan a Successful Cocktail Party with
  Diversity","Dense subgraph discovery methods are routinely used in a variety of
applications including the identification of a team of skilled individuals for
collaboration from a social network. However, when the network's node set is
associated with a sensitive attribute such as race, gender, religion, or
political opinion, the lack of diversity can lead to lawsuits.
  In this work, we focus on the problem of finding a densest diverse subgraph
in a graph whose nodes have different attribute values/types that we refer to
as colors. We propose two novel formulations motivated by different realistic
scenarios. Our first formulation, called the densest diverse subgraph problem
(DDSP), guarantees that no color represents more than some fraction of the
nodes in the output subgraph, which generalizes the state-of-the-art due to
Anagnostopoulos et al. (CIKM 2020). By varying the fraction we can range the
diversity constraint and interpolate from a diverse dense subgraph where all
colors have to be equally represented to an unconstrained dense subgraph. We
design a scalable $\Omega(1/\sqrt{n})$-approximation algorithm, where $n$ is
the number of nodes. Our second formulation is motivated by the setting where
any specified color should not be overlooked. We propose the densest
at-least-$\vec{k}$-subgraph problem (Dal$\vec{k}$S), a novel generalization of
the classic Dal$k$S, where instead of a single value $k$, we have a vector
${\mathbf k}$ of cardinality demands with one coordinate per color class. We
design a $1/3$-approximation algorithm using linear programming together with
an acceleration technique. Computational experiments using synthetic and
real-world datasets demonstrate that our proposed algorithms are effective in
extracting dense diverse clusters.",2023-06-04,"Atsushi Miyauchi, Tianyi Chen, Konstantinos Sotiropoulos, Charalampos E. Tsourakakis"
The disruption index is biased by citation inflation,"A recent analysis of scientific publication and patent citation networks by
Park et al. (Nature, 2023) suggests that publications and patents are becoming
less disruptive over time. Here we show that the reported decrease in
disruptiveness is an artifact of systematic shifts in the structure of citation
networks unrelated to innovation system capacity. Instead, the decline is
attributable to 'citation inflation', an unavoidable characteristic of real
citation networks that manifests as a systematic time-dependent bias and
renders cross-temporal analysis challenging. One driver of citation inflation
is the ever-increasing lengths of reference lists over time, which in turn
increases the density of links in citation networks, and causes the disruption
index to converge to 0. A second driver is attributable to shifts in the
construction of reference lists, which is increasingly impacted by
self-citations that increase in the rate of triadic closure in citation
networks, and thus confounds efforts to measure disruption, which is itself a
measure of triadic closure. Combined, these two systematic shifts render the
disruption index temporally biased, and unsuitable for cross-temporal analysis.
The impact of this systematic bias further stymies efforts to correlate
disruption to other measures that are also time-dependent, such as team size
and citation counts. In order to demonstrate this fundamental measurement
problem, we present three complementary lines of critique (deductive, empirical
and computational modeling), and also make available an ensemble of synthetic
citation networks that can be used to test alternative citation-based indices
for systematic bias.",2023-06-02,"Alexander M. Petersen, Felber Arroyave, Fabio Pammolli"
Influence Maximization with Fairness at Scale (Extended Version),"In this paper, we revisit the problem of influence maximization with
fairness, which aims to select k influential nodes to maximise the spread of
information in a network, while ensuring that selected sensitive user
attributes are fairly affected, i.e., are proportionally similar between the
original network and the affected users. Recent studies on this problem focused
only on extremely small networks, hence the challenge remains on how to achieve
a scalable solution, applicable to networks with millions or billions of nodes.
We propose an approach that is based on learning node representations for fair
spread from diffusion cascades, instead of the social connectivity s.t. we can
deal with very large graphs. We propose two data-driven approaches: (a)
fairness-based participant sampling (FPS), and (b) fairness as context (FAC).
Spread related user features, such as the probability of diffusing information
to others, are derived from the historical information cascades, using a deep
neural network. The extracted features are then used in selecting influencers
that maximize the influence spread, while being also fair with respect to the
chosen sensitive attributes. In FPS, fairness and cascade length information
are considered independently in the decision-making process, while FAC
considers these information facets jointly and considers correlations between
them. The proposed algorithms are generic and represent the first policy-driven
solutions that can be applied to arbitrary sets of sensitive attributes at
scale. We evaluate the performance of our solutions on a real-world public
dataset (Sina Weibo) and on a hybrid real-synthethic dataset (Digg), which
exhibit all the facets that we exploit, namely diffusion network, diffusion
traces, and user profiles. These experiments show that our methods outperform
the state-the-art solutions in terms of spread, fairness, and scalability.",2023-06-02,"Yuting Feng, Ankitkumar Patel, Bogdan Cautis, Hossein Vahabi"
A Survey of Densest Subgraph Discovery on Large Graphs,"With the prevalence of graphs for modeling complex relationships among
objects, the topic of graph mining has attracted a great deal of attention from
both academic and industrial communities in recent years. As one of the most
fundamental problems in graph mining, the densest subgraph discovery (DSD)
problem has found a wide spectrum of real applications, such as discovery of
filter bubbles in social media, finding groups of actors propagating
misinformation in social media, social network community detection, graph index
construction, regulatory motif discovery in DNA, fake follower detection, and
so on. Theoretically, DSD closely relates to other fundamental graph problems,
such as network flow and bipartite matching. Triggered by these applications
and connections, DSD has garnered much attention from the database, data
mining, theory, and network communities.
  In this survey, we first highlight the importance of DSD in various
real-world applications and the unique challenges that need to be addressed.
Subsequently, we classify existing DSD solutions into several groups, which
cover around 50 research papers published in many well-known venues (e.g.,
SIGMOD, PVLDB, TODS, WWW), and conduct a thorough review of these solutions in
each group. Afterwards, we analyze and compare the models and solutions in
these works. Finally, we point out a list of promising future research
directions. It is our hope that this survey not only helps researchers have a
better understanding of existing densest subgraph models and solutions, but
also provides insights and identifies directions for future study.",2023-06-02,"Wensheng Luo, Chenhao Ma, Yixiang Fang, Laks V. S. Lakshmanan"
Learning the effective order of a hypergraph dynamical system,"Dynamical systems on hypergraphs can display a rich set of behaviours not
observable for systems with pairwise interactions. Given a distributed
dynamical system with a putative hypergraph structure, an interesting question
is thus how much of this hypergraph structure is actually necessary to
faithfully replicate the observed dynamical behaviour. To answer this question,
we propose a method to determine the minimum order of a hypergraph necessary to
approximate the corresponding dynamics accurately. Specifically, we develop an
analytical framework that allows us to determine this order when the type of
dynamics is known. We utilize these ideas in conjunction with a hypergraph
neural network to directly learn the dynamics itself and the resulting order of
the hypergraph from both synthetic and real data sets consisting of observed
system trajectories.",2023-06-02,"Leonie Neuhäuser, Michael Scholkemper, Francesco Tudisco, Michael T. Schaub"
"Leveraging Natural Language Processing For Public Health Screening On
  YouTube: A COVID-19 Case Study","Background: Social media platforms have become a viable source of medical
information, with patients and healthcare professionals using them to share
health-related information and track diseases. Similarly, YouTube, the largest
video-sharing platform in the world contains vlogs where individuals talk about
their illnesses. The aim of our study was to investigate the use of Natural
Language Processing (NLP) to identify the spoken content of YouTube vlogs
related to the diagnosis of Coronavirus disease of 2019 (COVID-19) for public
health screening. Methods: COVID-19 videos on YouTube were searched using
relevant keywords. A total of 1000 videos being spoken in English were
downloaded out of which 791 were classified as vlogs, 192 were non-vlogs, and
17 were deleted by the channel. The videos were converted into a textual format
using Microsoft Streams. The textual data was preprocessed using basic and
advanced preprocessing methods. A lexicon of 200 words was created which
contained words related to COVID-19. The data was analyzed using topic
modeling, word clouds, and lexicon matching. Results: The word cloud results
revealed discussions about COVID-19 symptoms like ""fever"", along with generic
terms such as ""mask"" and ""isolation"". Lexical analysis demonstrated that in
96.46% of videos, patients discussed generic terms, and in 95.45% of videos,
people talked about COVID-19 symptoms. LDA Topic Modeling results also
generated topics that successfully captured key themes and content related to
our investigation of COVID-19 diagnoses in YouTube vlogs. Conclusion: By
leveraging NLP techniques on YouTube vlogs public health practitioners can
enhance their ability to mitigate the effects of pandemics and effectively
respond to public health challenges.",2023-06-01,"Ahrar Bin Aslam, Zafi Sherhan Syed, Muhammad Faiz Khan, Asghar Baloch, Muhammad Shehram Shah Syed"
"A Multi-Modal Latent-Features based Service Recommendation System for
  the Social Internet of Things","The Social Internet of Things (SIoT), is revolutionizing how we interact with
our everyday lives. By adding the social dimension to connecting devices, the
SIoT has the potential to drastically change the way we interact with smart
devices. This connected infrastructure allows for unprecedented levels of
convenience, automation, and access to information, allowing us to do more with
less effort. However, this revolutionary new technology also brings an eager
need for service recommendation systems. As the SIoT grows in scope and
complexity, it becomes increasingly important for businesses and individuals,
and SIoT objects alike to have reliable sources for products, services, and
information that are tailored to their specific needs. Few works have been
proposed to provide service recommendations for SIoT environments. However,
these efforts have been confined to only focusing on modeling user-item
interactions using contextual information, devices' SIoT relationships, and
correlation social groups but these schemes do not account for latent semantic
item-item structures underlying the sparse multi-modal contents in SIoT
environment. In this paper, we propose a latent-based SIoT recommendation
system that learns item-item structures and aggregates multiple modalities to
obtain latent item graphs which are then used in graph convolutions to inject
high-order affinities into item representations. Experiments showed that the
proposed recommendation system outperformed state-of-the-art SIoT
recommendation methods and validated its efficacy at mining latent
relationships from multi-modal features.",2023-06-01,"Amar Khelloufi, Huansheng Ning, Abdenacer Naouri, Abdelkarim Ben Sada, Attia Qammar, Abdelkader Khalil, Sahraoui Dhelim, Lingfeng Mao"
"Pitfalls in Link Prediction with Graph Neural Networks: Understanding
  the Impact of Target-link Inclusion & Better Practices","While Graph Neural Networks (GNNs) are remarkably successful in a variety of
high-impact applications, we demonstrate that, in link prediction, the common
practices of including the edges being predicted in the graph at training
and/or test have outsized impact on the performance of low-degree nodes. We
theoretically and empirically investigate how these practices impact node-level
performance across different degrees. Specifically, we explore three issues
that arise: (I1) overfitting; (I2) distribution shift; and (I3) implicit test
leakage. The former two issues lead to poor generalizability to the test data,
while the latter leads to overestimation of the model's performance and
directly impacts the deployment of GNNs. To address these issues in a
systematic way, we introduce an effective and efficient GNN training framework,
SpotTarget, which leverages our insight on low-degree nodes: (1) at training
time, it excludes a (training) edge to be predicted if it is incident to at
least one low-degree node; and (2) at test time, it excludes all test edges to
be predicted (thus, mimicking real scenarios of using GNNs, where the test data
is not included in the graph). SpotTarget helps researchers and practitioners
adhere to best practices for learning from graph data, which are frequently
overlooked even by the most widely-used frameworks. Our experiments on various
real-world datasets show that SpotTarget makes GNNs up to 15x more accurate in
sparse graphs, and significantly improves their performance for low-degree
nodes in dense graphs.",2023-06-01,"Jing Zhu, Yuhang Zhou, Vassilis N. Ioannidis, Shengyi Qian, Wei Ai, Xiang Song, Danai Koutra"
Reconstructing Graph Diffusion History from a Single Snapshot,"Diffusion on graphs is ubiquitous with numerous high-impact applications. In
these applications, complete diffusion histories play an essential role in
terms of identifying dynamical patterns, reflecting on precaution actions, and
forecasting intervention effects. Despite their importance, complete diffusion
histories are rarely available and are highly challenging to reconstruct due to
ill-posedness, explosive search space, and scarcity of training data. To date,
few methods exist for diffusion history reconstruction. They are exclusively
based on the maximum likelihood estimation (MLE) formulation and require to
know true diffusion parameters. In this paper, we study an even harder problem,
namely reconstructing Diffusion history from A single SnapsHot} (DASH), where
we seek to reconstruct the history from only the final snapshot without knowing
true diffusion parameters. We start with theoretical analyses that reveal a
fundamental limitation of the MLE formulation. We prove: (a) estimation error
of diffusion parameters is unavoidable due to NP-hardness of diffusion
parameter estimation, and (b) the MLE formulation is sensitive to estimation
error of diffusion parameters. To overcome the inherent limitation of the MLE
formulation, we propose a novel barycenter formulation: finding the barycenter
of the posterior distribution of histories, which is provably stable against
the estimation error of diffusion parameters. We further develop an effective
solver named DIffusion hiTting Times with Optimal proposal (DITTO) by reducing
the problem to estimating posterior expected hitting times via the
Metropolis--Hastings Markov chain Monte Carlo method (M--H MCMC) and employing
an unsupervised graph neural network to learn an optimal proposal to accelerate
the convergence of M--H MCMC. We conduct extensive experiments to demonstrate
the efficacy of the proposed method.",2023-06-01,"Ruizhong Qiu, Dingsu Wang, Lei Ying, H. Vincent Poor, Yifang Zhang, Hanghang Tong"
"VMap: An Interactive Rectangular Space-filling Visualization for
  Map-like Vertex-centric Graph Exploration","We present VMap, a map-like rectangular space-filling visualization, to
perform vertex-centric graph exploration. Existing visualizations have limited
support for quality optimization among rectangular aspect ratios, vertex-edge
intersection, and data encoding accuracy. To tackle this problem, VMap
integrates three novel components: (1) a desired-aspect-ratio (DAR) rectangular
partitioning algorithm, (2) a two-stage rectangle adjustment algorithm, and (3)
a simulated annealing based heuristic optimizer. First, to generate a
rectangular space-filling layout of an input graph, we subdivide the 2D
embedding of the graph into rectangles with optimization of rectangles' aspect
ratios toward a desired aspect ratio. Second, to route graph edges between
rectangles without vertex-edge occlusion, we devise a two-stage algorithm to
adjust a rectangular layout to insert border space between rectangles. Third,
to produce and arrange rectangles by considering multiple visual criteria, we
design a simulated annealing based heuristic optimization to adjust vertices'
2D embedding to support trade-offs among aspect ratio quality and the encoding
accuracy of vertices' weights and adjacency. We evaluated the effectiveness of
VMap on both synthetic and application datasets. The resulting rectangular
layout has better aspect ratio quality on synthetic data compared with the
existing method for the rectangular partitioning of 2D points. On three
real-world datasets, VMap achieved better encoding accuracy and attained faster
generation speed compared with existing methods on graphs' rectangular layout
generation. We further illustrate the usefulness of VMap for vertex-centric
graph exploration through three case studies on visualizing social networks,
representing academic communities, and displaying geographic information.",2023-05-31,"Jiayi Xu, Han-Wei Shen"
"Exploring the Journey to Drug Overdose: Applying the Journey to Crime
  Framework to Drug Sales Locations and Overdose Death Locations","Drug overdose is a pressing public health concern in the United States,
resulting in a significant number of fatalities each year. In this study, we
employ the Journey to Crime (JTC) framework borrowed from the field of
environmental criminology to examine the association between drug sales
locations and overdose death locations. In this research, our objective is to
elucidate the trajectory of overdose victims to overdose locations, aiming to
enhance the distribution of overdose services and interventions. To the best of
our knowledge, no previous studies have applied the JTC framework to
investigate drug overdose deaths. By scrutinizing data obtained from the
Hamilton County, OH Coroners, and the Cincinnati Police Department, we endeavor
to explore the plausible correlation between overdose deaths and drug sales
locations. Our findings underscore the necessity of implementing a
comprehensive strategy to curtail overdose deaths. This strategy should
encompass various facets, including targeted efforts to reduce the
accessibility of illicit drugs, the enhancement of responses to overdose
incidents through a collaborative multidisciplinary approach, and the
availability of data to inform evidence-based strategies and facilitate outcome
evaluation. By shedding light on the relationship between drug sales locations
and overdose death locations through the utilization of the JTC framework, this
study contributes valuable insights to the field of drug overdose prevention.
It emphasizes the significance of adopting multifaceted approaches to address
this public health crisis effectively. Ultimately, our research aims to inform
the development of evidence-based interventions and policies that can mitigate
the occurrence and impact of drug overdoses in our communities.",2023-05-31,"Murat Ozer, Ismail Onat, Halil Akbas, Nelly Elsayed, Zag ElSayed, Said Varlioglu"
"OVNS: Opportunistic Variable Neighborhood Search for Heaviest Subgraph
  Problem in Social Networks","We propose a hybrid heuristic algorithm for solving the Heaviest k-Subgraph
Problem in online social networks -- a combinatorial graph optimization problem
central to many important applications in weighted social networks, including
detection of coordinated behavior, maximizing diversity of a group of users,
and detecting social groups. Our approach builds upon an existing metaheuristic
framework known as Variable Neighborhood Search and takes advantage of
empirical insights about social network structures to derive an improved
optimization heuristic. We conduct benchmarks in both real life social networks
as well as synthetic networks and demonstrate that the proposed modifications
match and in the majority of cases supersede those of the current
state-of-the-art approaches.",2023-05-31,"Ville P. Saarinen, Ted Hsuan Yun Chen, Mikko Kivelä"
"BotArtist: Generic approach for bot detection in Twitter via
  semi-automatic machine learning pipeline","Twitter, as one of the most popular social networks, provides a platform for
communication and online discourse. Unfortunately, it has also become a target
for bots and fake accounts, resulting in the spread of false information and
manipulation. This paper introduces a semi-automatic machine learning pipeline
(SAMLP) designed to address the challenges correlated with machine learning
model development. Through this pipeline, we develop a comprehensive bot
detection model named BotArtist, based on user profile features. SAMLP
leverages nine distinct publicly available datasets to train the BotArtist
model. To assess BotArtist's performance against current state-of-the-art
solutions, we select 35 existing Twitter bot detection methods, each utilizing
a diverse range of features. Our comparative evaluation of BotArtist and these
existing methods, conducted across nine public datasets under standardized
conditions, reveals that the proposed model outperforms existing solutions by
almost 10%, in terms of F1-score, achieving an average score of 83.19 and 68.5
over specific and general approaches respectively. As a result of this
research, we provide a dataset of the extracted features combined with
BotArtist predictions over the 10.929.533 Twitter user profiles, collected via
Twitter API during the 2022 Russo-Ukrainian War, over a 16-month period. This
dataset was created in collaboration with [Shevtsov et al., 2022a] where the
original authors share anonymized tweets on the discussion of the
Russo-Ukrainian war with a total amount of 127.275.386 tweets. The combination
of the existing text dataset and the provided labeled bot and human profiles
will allow for the future development of a more advanced bot detection large
language model in the post-Twitter API era.",2023-05-31,"Alexander Shevtsov, Despoina Antonakaki, Ioannis Lamprou, Polyvios Pratikakis, Sotiris Ioannidis"
A Multi-Factorial Analysis of Polarization on Social Media,"Polarization is an increasingly worrying phenomenon within social media.
Recent work has made it possible to detect and even quantify polarization.
Nevertheless, the few existing metrics, although defined in a continuous space,
often lead to a unimodal distribution of data once applied to users'
interactions, making the distinction between polarized and non-polarized users
difficult to draw. Furthermore, each metric relies on a single factor and does
not reflect the overall user behavior. Modeling polarization in a single form
runs the risk of obscuring inter-individual differences. In this paper, we
propose to have a deeper look at polarized online behaviors and to compare
individual metrics. We collected about 300K retweets from 1K French users
between January and July 2022 on Twitter. Each retweet is related to the highly
controversial vaccine debate. Results show that a multi-factorial analysis
leads to the identification of distinct and potentially explainable behavioral
classes. This finer understanding of behaviors is an essential step to adapt
news recommendation strategies so that no user gets locked into an echo chamber
or filter bubble.",2023-05-31,"Celina Treuillier, Sylvain Castagnos, Armelle Brun"
HiGen: Hierarchical Graph Generative Networks,"Most real-world graphs exhibit a hierarchical structure, which is often
overlooked by existing graph generation methods. To address this limitation, we
propose a novel graph generative network that captures the hierarchical nature
of graphs and successively generates the graph sub-structures in a
coarse-to-fine fashion. At each level of hierarchy, this model generates
communities in parallel, followed by the prediction of cross-edges between
communities using separate neural networks. This modular approach enables
scalable graph generation for large and complex graphs. Moreover, we model the
output distribution of edges in the hierarchical graph with a multinomial
distribution and derive a recursive factorization for this distribution. This
enables us to generate community graphs with integer-valued edge weights in an
autoregressive manner. Empirical studies demonstrate the effectiveness and
scalability of our proposed generative model, achieving state-of-the-art
performance in terms of graph quality across various benchmark datasets. The
code is available at https://github.com/Karami-m/HiGen_main.",2023-05-30,Mahdi Karami
FakeSwarm: Improving Fake News Detection with Swarming Characteristics,"The proliferation of fake news poses a serious threat to society, as it can
misinform and manipulate the public, erode trust in institutions, and undermine
democratic processes. To address this issue, we present FakeSwarm, a fake news
identification system that leverages the swarming characteristics of fake news.
To extract the swarm behavior, we propose a novel concept of fake news swarming
characteristics and design three types of swarm features, including principal
component analysis, metric representation, and position encoding. We evaluate
our system on a public dataset and demonstrate the effectiveness of
incorporating swarm features in fake news identification, achieving an f1-score
and accuracy of over 97% by combining all three types of swarm features.
Furthermore, we design an online learning pipeline based on the hypothesis of
the temporal distribution pattern of fake news emergence, validated on a topic
with early emerging fake news and a shortage of text samples, showing that
swarm features can significantly improve recall rates in such cases. Our work
provides a new perspective and approach to fake news detection and highlights
the importance of considering swarming characteristics in detecting fake news.",2023-05-30,"Jun Wu, Xuesong Ye"
"An Optimization-based Approach To Node Role Discovery in Networks:
  Approximating Equitable Partitions","Similar to community detection, partitioning the nodes of a network according
to their structural roles aims to identify fundamental building blocks of a
network. The found partitions can be used, e.g., to simplify descriptions of
the network connectivity, to derive reduced order models for dynamical
processes unfolding on processes, or as ingredients for various graph mining
tasks. In this work, we offer a fresh look on the problem of role extraction
and its differences to community detection and present a definition of node
roles related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and
equitable partitions. We study two associated optimization problems (cost
functions) grounded in ideas from graph isomorphism testing, and present
theoretical guarantees associated to the solutions of these problems. Finally,
we validate our approach via a novel ""role-infused partition benchmark"", a
network model from which we can sample networks in which nodes are endowed with
different roles in a stochastic way.",2023-05-30,"Michael Scholkemper, Michael T. Schaub"
Defense Against Shortest Path Attacks,"Identifying shortest paths between nodes in a network is an important task in
applications involving routing of resources. Recent work has shown that a
malicious actor can manipulate a graph to make traffic between two nodes of
interest follow their target path. In this paper, we develop a defense against
such attacks by modifying the weights of the graph that users observe. The
defender must balance inhibiting the attacker against any negative effects of
the defense on benign users. Specifically, the defender's goals are: (a) to
recommend the shortest paths possible to users, (b) for the lengths of the
shortest paths in the published graph to be close to those of the same paths in
the true graph, and (c) to minimize the probability of an attack. We formulate
the defense as a Stackelberg game in which the defender is the leader and the
attacker is the follower. In this context, we also consider a zero-sum version
of the game, in which the defender's goal is to minimize cost while achieving
the minimum possible attack probability. We show that this problem is NP-hard
and propose heuristic solutions based on increasing edge weights along target
paths in both the zero-sum and non-zero-sum settings. Relaxing some constraints
of the original problem, we formulate a linear program for local optimization
around a feasible point. We present defense results with both synthetic and
real network datasets and show that these methods often reach the lower bound
of the defender's cost.",2023-05-30,"Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld"
"The Role Of Social Media On Selected Businesses In Nigeria In The Era Of
  Covid-19 Pandemic","As several countries were experiencing unprecedented economic slowdowns due
to the outbreak of COVID-19 pandemic in early 2020, small business enterprises
started adapting to digital technologies for business transactions. However, in
Africa, particularly Nigeria, COVID-19 pandemic resulted to some financial
crisis that impacted negatively on the sustainability of small and medium-sized
(SMEs) businesses. Thus, this study examined the role of social media on
selected SMEs in Nigeria in the heat of the COVID-19 pandemic that led to
several lock downs in a bid to curtail the spread of the virus. Cross-sectional
survey research design was used alongside convenience population sampling
techniques. The population was categorised based on selected SMEs businesses,
while a quantitative research approach was adopted, and primary data were
collected using a questionnaire. The questionnaires were administered to owners
and operators of SMEs in Ikotun and Ikeja areas of Lagos State, Nigeria. A
total of 190 questionnaires were distributed, where 183 usable responses were
analysed. The findings of the study show that SMEs were aware of the usefulness
of social media to their businesses as they largely leveraged it in conducting
their businesses during the national lockdowns. The study recommended that
labour/trade unions should sensitise and encourage business owners on the
benefits of continuous use of social media in carrying out their business
transactions.",2023-05-30,"Cajetan Ihemebiri, Elochukwu Ukwandu, Lizzy Ofusori, Comfort Olebara"
"Criteria Tell You More than Ratings: Criteria Preference-Aware Light
  Graph Convolution for Effective Multi-Criteria Recommendation","The multi-criteria (MC) recommender system, which leverages MC rating
information in a wide range of e-commerce areas, is ubiquitous nowadays.
Surprisingly, although graph neural networks (GNNs) have been widely applied to
develop various recommender systems due to GNN's high expressive capability in
learning graph representations, it has been still unexplored how to design MC
recommender systems with GNNs. In light of this, we make the first attempt
towards designing a GNN-aided MC recommender system. Specifically, rather than
straightforwardly adopting existing GNN-based recommendation methods, we devise
a novel criteria preference-aware light graph convolution CPA-LGC method, which
is capable of precisely capturing the criteria preference of users as well as
the collaborative signal in complex high-order connectivities. To this end, we
first construct an MC expansion graph that transforms user--item MC ratings
into an expanded bipartite graph to potentially learn from the collaborative
signal in MC ratings. Next, to strengthen the capability of criteria preference
awareness, CPA-LGC incorporates newly characterized embeddings, including
user-specific criteria-preference embeddings and item-specific criterion
embeddings, into our graph convolution model. Through comprehensive evaluations
using four real-world datasets, we demonstrate (a) the superiority over
benchmark MC recommendation methods and benchmark recommendation methods using
GNNs with tremendous gains, (b) the effectiveness of core components in
CPA-LGC, and (c) the computational efficiency.",2023-05-30,"Jin-Duk Park, Siqing Li, Xin Cao, Won-Yong Shin"
"LonXplain: Lonesomeness as a Consequence of Mental Disturbance in Reddit
  Posts","Social media is a potential source of information that infers latent mental
states through Natural Language Processing (NLP). While narrating real-life
experiences, social media users convey their feeling of loneliness or isolated
lifestyle, impacting their mental well-being. Existing literature on
psychological theories points to loneliness as the major consequence of
interpersonal risk factors, propounding the need to investigate loneliness as a
major aspect of mental disturbance. We formulate lonesomeness detection in
social media posts as an explainable binary classification problem, discovering
the users at-risk, suggesting the need of resilience for early control. To the
best of our knowledge, there is no existing explainable dataset, i.e., one with
human-readable, annotated text spans, to facilitate further research and
development in loneliness detection causing mental disturbance. In this work,
three experts: a senior clinical psychologist, a rehabilitation counselor, and
a social NLP researcher define annotation schemes and perplexity guidelines to
mark the presence or absence of lonesomeness, along with the marking of
text-spans in original posts as explanation, in 3,521 Reddit posts. We expect
the public release of our dataset, LonXplain, and traditional classifiers as
baselines via GitHub.",2023-05-30,"Muskan Garg, Chandni Saxena, Debabrata Samanta, Bonnie J. Dorr"
"Pandemic Culture Wars: Partisan Differences in the Moral Language of
  COVID-19 Discussions","Effective response to pandemics requires coordinated adoption of mitigation
measures, like masking and quarantines, to curb a virus's spread. However, as
the COVID-19 pandemic demonstrated, political divisions can hinder consensus on
the appropriate response. To better understand these divisions, our study
examines a vast collection of COVID-19-related tweets. We focus on five
contentious issues: coronavirus origins, lockdowns, masking, education, and
vaccines. We describe a weakly supervised method to identify issue-relevant
tweets and employ state-of-the-art computational methods to analyze moral
language and infer political ideology. We explore how partisanship and moral
language shape conversations about these issues. Our findings reveal
ideological differences in issue salience and moral language used by different
groups. We find that conservatives use more negatively-valenced moral language
than liberals and that political elites use moral rhetoric to a greater extent
than non-elites across most issues. Examining the evolution and moralization on
divisive issues can provide valuable insights into the dynamics of COVID-19
discussions and assist policymakers in better understanding the emergence of
ideological divisions.",2023-05-29,"Ashwin Rao, Siyi Guo, Sze-Yuh Nina Wang, Fred Morstatter, Kristina Lerman"
"minOffense: Inter-Agreement Hate Terms for Stable Rules, Concepts,
  Transitivities, and Lattices","Hate speech classification has become an important problem due to the spread
of hate speech on social media platforms. For a given set of Hate Terms lists
(HTs-lists) and Hate Speech data (HS-data), it is challenging to understand
which hate term contributes the most for hate speech classification. This paper
contributes two approaches to quantitatively measure and qualitatively
visualise the relationship between co-occurring Hate Terms (HTs). Firstly, we
propose an approach for the classification of hate-speech by producing a Severe
Hate Terms list (Severe HTs-list) from existing HTs-lists. To achieve our goal,
we proposed three metrics (Hatefulness, Relativeness, and Offensiveness) to
measure the severity of HTs. These metrics assist to create an Inter-agreement
HTs-list, which explains the contribution of an individual hate term toward
hate speech classification. Then, we used the Offensiveness metric values of
HTs above a proposed threshold minimum Offense (minOffense) to generate a new
Severe HTs-list. To evaluate our approach, we used three hate speech datasets
and six hate terms lists. Our approach shown an improvement from 0.845 to 0.923
(best) as compared to the baseline. Secondly, we also proposed Stable Hate Rule
(SHR) mining to provide ordered co-occurrence of various HTs with minimum
Stability (minStab). The SHR mining detects frequently co-occurring HTs to form
Stable Hate Rules and Concepts. These rules and concepts are used to visualise
the graphs of Transitivities and Lattices formed by HTs.",2023-05-29,"Animesh Chaturvedi, Rajesh Sharma"
Self-attention Dual Embedding for Graphs with Heterophily,"Graph Neural Networks (GNNs) have been highly successful for the node
classification task. GNNs typically assume graphs are homophilic, i.e.
neighboring nodes are likely to belong to the same class. However, a number of
real-world graphs are heterophilic, and this leads to much lower classification
accuracy using standard GNNs. In this work, we design a novel GNN which is
effective for both heterophilic and homophilic graphs. Our work is based on
three main observations. First, we show that node features and graph topology
provide different amounts of informativeness in different graphs, and therefore
they should be encoded independently and prioritized in an adaptive manner.
Second, we show that allowing negative attention weights when propagating graph
topology information improves accuracy. Finally, we show that asymmetric
attention weights between nodes are helpful. We design a GNN which makes use of
these observations through a novel self-attention mechanism. We evaluate our
algorithm on real-world graphs containing thousands to millions of nodes and
show that we achieve state-of-the-art results compared to existing GNNs. We
also analyze the effectiveness of the main components of our design on
different graphs.",2023-05-28,"Yurui Lai, Taiyan Zhang, Rui Fan"
"Inferring Individual Direct Causal Effects Under Heterogeneous Peer
  Influence","Causal inference in networks should account for interference, which occurs
when a unit's outcome is influenced by treatments or outcomes of peers.
Heterogeneous peer influence (HPI) occurs when a unit's outcome is influenced
differently by different peers based on their attributes and relationships, or
when each unit has a different susceptibility to peer influence. Existing
solutions to estimating direct causal effects under interference consider
either homogeneous influence from peers or specific heterogeneous influence
mechanisms (e.g., based on local neighborhood structure). This paper presents a
methodology for estimating individual direct causal effects in the presence of
HPI where the mechanism of influence is not known a priori. We propose a
structural causal model for networks that can capture different possible
assumptions about network structure, interference conditions, and causal
dependence and enables reasoning about identifiability in the presence of HPI.
We find potential heterogeneous contexts using the causal model and propose a
novel graph neural network-based estimator to estimate individual direct causal
effects. We show that state-of-the-art methods for individual direct effect
estimation produce biased results in the presence of HPI, and that our proposed
estimator is robust.",2023-05-27,"Shishir Adhikari, Elena Zheleva"
"Cloud Computing: Applications, Challenges and Open Issues","Cloud computing is one of the innovative computing, which deals with storing
and accessing data and programs over the Internet [1]. It is the delivery of
computing resources and services, such as storing of data on servers and
databases, providing networking facilities and software development platforms
over the Internet. It provides the flexibility of resources for everyone. These
services are provided via data centers, which are located in various parts of
the world [2, 3]. Cloud computing makes access to these resources to everyone
on a global scale at a very minimal cost and significantly higher speed. These
servers provide services to the users, which would have cost a lot of
computational power to them if they had to buy them. The first mention of cloud
computing was referenced in a Compaq internal document released in 1996 [4].
Cloud computing was then commercialized in 2006 when Amazon released elastic
compute cloud (EC2). Furthermore, Google released Google app engine in 2008 and
Microsoft Azure services were launched in October 2008, which increased the
competition in the area of cloud computing. Since then these companies have
done a lot of development in cloud computing.",2023-05-27,"Sahil Mishra, Sanjaya Kumar Panda"
"DotHash: Estimating Set Similarity Metrics for Link Prediction and
  Document Deduplication","Metrics for set similarity are a core aspect of several data mining tasks. To
remove duplicate results in a Web search, for example, a common approach looks
at the Jaccard index between all pairs of pages. In social network analysis, a
much-celebrated metric is the Adamic-Adar index, widely used to compare node
neighborhood sets in the important problem of predicting links. However, with
the increasing amount of data to be processed, calculating the exact similarity
between all pairs can be intractable. The challenge of working at this scale
has motivated research into efficient estimators for set similarity metrics.
The two most popular estimators, MinHash and SimHash, are indeed used in
applications such as document deduplication and recommender systems where large
volumes of data need to be processed. Given the importance of these tasks, the
demand for advancing estimators is evident. We propose DotHash, an unbiased
estimator for the intersection size of two sets. DotHash can be used to
estimate the Jaccard index and, to the best of our knowledge, is the first
method that can also estimate the Adamic-Adar index and a family of related
metrics. We formally define this family of metrics, provide theoretical bounds
on the probability of estimate errors, and analyze its empirical performance.
Our experimental results indicate that DotHash is more accurate than the other
estimators in link prediction and detecting duplicate documents with the same
complexity and similar comparison time.",2023-05-27,"Igor Nunes, Mike Heddes, Pere Vergés, Danny Abraham, Alexander Veidenbaum, Alexandru Nicolau, Tony Givargis"
Automated Summarization of Stack Overflow Posts,"Software developers often resort to Stack Overflow (SO) to fill their
programming needs. Given the abundance of relevant posts, navigating them and
comparing different solutions is tedious and time-consuming. Recent work has
proposed to automatically summarize SO posts to concise text to facilitate the
navigation of SO posts. However, these techniques rely only on information
retrieval methods or heuristics for text summarization, which is insufficient
to handle the ambiguity and sophistication of natural language. This paper
presents a deep learning based framework called ASSORT for SO post
summarization. ASSORT includes two complementary learning methods, ASSORT_S and
ASSORT_{IS}, to address the lack of labeled training data for SO post
summarization. ASSORT_S is designed to directly train a novel ensemble learning
model with BERT embeddings and domainspecific features to account for the
unique characteristics of SO posts. By contrast, ASSORT_{IS} is designed to
reuse pre-trained models while addressing the domain shift challenge when no
training data is present (i.e., zero-shot learning). Both ASSORT_S and
ASSORT_{IS} outperform six existing techniques by at least 13% and 7%
respectively in terms of the F1 score. Furthermore, a human study shows that
participants significantly preferred summaries generated by ASSORT_S and
ASSORT_{IS} over the best baseline, while the preference difference between
ASSORT_S and ASSORT_{IS} was small.",2023-05-26,"Bonan Kou, Muhao Chen, Tianyi Zhang"
Seeding with Differentially Private Network Information,"In public health interventions such as the distribution of preexposure
prophylaxis (PrEP) for HIV prevention, decision makers rely on seeding
algorithms to identify key individuals who can amplify the impact of their
interventions. In such cases, building a complete sexual activity network is
often infeasible due to privacy concerns. Instead, contact tracing can provide
influence samples, that is, sequences of sexual contacts without requiring
complete network information. This presents two challenges: protecting
individual privacy in contact data and adapting seeding algorithms to work
effectively with incomplete network information. To solve these two problems,
we study privacy guarantees for influence maximization algorithms when the
social network is unknown and the inputs are samples of prior influence
cascades that are collected at random and need privacy protection. Building on
recent results that address seeding with costly network information, our
privacy-preserving algorithms introduce randomization in the collected data or
the algorithm output and can bound the privacy loss of each node (or group of
nodes) in deciding to include their data in the algorithm input. We provide
theoretical guarantees of seeding performance with a limited sample size
subject to differential privacy budgets in both central and local privacy
regimes. Simulations on synthetic random graphs and empirically grounded sexual
contacts of men who have sex with men reveal the diminishing value of network
information with decreasing privacy budget in both regimes and graceful
decrease in performance with decreasing privacy budget in the central regime.
Achieving good performance with local privacy guarantees requires relatively
higher privacy budgets that confirm our theoretical expectations.",2023-05-26,"M. Amin Rahimian, Fang-Yi Yu, Yuxin Liu, Carlos Hurtado"
"Hate Raids on Twitch: Understanding Real-Time Human-Bot Coordinated
  Attacks in Live Streaming Communities","Online harassment and content moderation have been well-documented in online
communities. However, new contexts and systems always bring new ways of
harassment and need new moderation mechanisms. This study focuses on hate
raids, a form of group attack in real-time in live streaming communities.
Through a qualitative analysis of hate raids discussion in the Twitch subreddit
(r/Twitch), we found that (1) hate raids as a human-bot coordinated group
attack leverages the live stream system to attack marginalized streamers and
other potential groups with(out) breaking the rules, (2) marginalized streamers
suffer compound harms with insufficient support from the platform, (3)
moderation strategies are overwhelmingly technical, but streamers still
struggle to balance moderation and participation considering their
marginalization status and needs. We use affordances as a lens to explain how
hate raids happens in live streaming systems and propose moderation-by-design
as a lens when developing new features or systems to mitigate the potential
abuse of such designs.",2023-05-25,"Jie Cai, Sagnik Chowdhury, Hongyang Zhou, Donghee Yvette Wohn"
Demystifying Oversmoothing in Attention-Based Graph Neural Networks,"Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where
increasing network depth leads to homogeneous node representations. While
previous work has established that Graph Convolutional Networks (GCNs)
exponentially lose expressive power, it remains controversial whether the graph
attention mechanism can mitigate oversmoothing. In this work, we provide a
definitive answer to this question through a rigorous mathematical analysis, by
viewing attention-based GNNs as nonlinear time-varying dynamical systems and
incorporating tools and techniques from the theory of products of inhomogeneous
matrices and the joint spectral radius. We establish that, contrary to popular
belief, the graph attention mechanism cannot prevent oversmoothing and loses
expressive power exponentially. The proposed framework extends the existing
results on oversmoothing for symmetric GCNs to a significantly broader class of
GNN models, including random walk GCNs, Graph Attention Networks (GATs) and
(graph) transformers. In particular, our analysis accounts for asymmetric,
state-dependent and time-varying aggregation operators and a wide range of
common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.",2023-05-25,"Xinyi Wu, Amir Ajorlou, Zihui Wu, Ali Jadbabaie"
A Higher-Order Temporal H-Index for Evolving Networks,"The H-index of a node in a static network is the maximum value $h$ such that
at least $h$ of its neighbors have a degree of at least $h$. Recently, a
generalized version, the $n$-th order H-index, was introduced, allowing to
relate degree centrality, H-index, and the $k$-core of a node. We extend the
$n$-th order H-index to temporal networks and define corresponding temporal
centrality measures and temporal core decompositions. Our $n$-th order temporal
H-index respects the reachability in temporal networks leading to node
rankings, which reflect the importance of nodes in spreading processes. We
derive natural decompositions of temporal networks into subgraphs with strong
temporal coherence. We analyze a recursive computation scheme and develop a
highly scalable streaming algorithm. Our experimental evaluation demonstrates
the efficiency of our algorithms and the conceptional validity of our approach.
Specifically, we show that the $n$-th order temporal H-index is a strong
heuristic for identifying super-spreaders in evolving social networks and
detects temporally well-connected components.",2023-05-25,"Lutz Oettershagen, Nils M. Kriege, Petra Mutzel"
Applications of Intelligent Systems in Green Technology,"Intelligent Systems (ISs) are technologically advanced machines, which
perceive and respond to the environment around them. They are usually of
various forms ranging from software to hardware. ISs are generally the fusion
of Artificial Intelligence (AI), robotics and Internet of things (IoT). In
order to strengthen ISs, one of the key technologies is green technology (GT).
It refers to the continuously advancing methods and materials, which cover
techniques for producing energy to non-toxic cleaning products. It may also be
broadened to saving energy, and reducing toxic and waste materials in the
environment. The motto of GT can be achieved by using the ISs. In this paper,
we present various applications of ISs in GT. Moreover, we discuss various
possible solutions using ISs in order to overcome the on-going real-life
problems.",2023-05-25,"Sahil Mishra, Sanjaya Kumar Panda"
Editable Graph Neural Network for Node Classifications,"Despite Graph Neural Networks (GNNs) have achieved prominent success in many
graph-based learning problem, such as credit risk assessment in financial
networks and fake news detection in social networks. However, the trained GNNs
still make errors and these errors may cause serious negative impact on
society. \textit{Model editing}, which corrects the model behavior on wrongly
predicted target samples while leaving model predictions unchanged on unrelated
samples, has garnered significant interest in the fields of computer vision and
natural language processing. However, model editing for graph neural networks
(GNNs) is rarely explored, despite GNNs' widespread applicability. To fill the
gap, we first observe that existing model editing methods significantly
deteriorate prediction accuracy (up to $50\%$ accuracy drop) in GNNs while a
slight accuracy drop in multi-layer perception (MLP). The rationale behind this
observation is that the node aggregation in GNNs will spread the editing effect
throughout the whole graph. This propagation pushes the node representation far
from its original one. Motivated by this observation, we propose
\underline{E}ditable \underline{G}raph \underline{N}eural \underline{N}etworks
(EGNN), a neighbor propagation-free approach to correct the model prediction on
misclassified nodes. Specifically, EGNN simply stitches an MLP to the
underlying GNNs, where the weights of GNNs are frozen during model editing. In
this way, EGNN disables the propagation during editing while still utilizing
the neighbor propagation scheme for node prediction to obtain satisfactory
results. Experiments demonstrate that EGNN outperforms existing baselines in
terms of effectiveness (correcting wrong predictions with lower accuracy drop),
generalizability (correcting wrong predictions for other similar nodes), and
efficiency (low training time and memory) on various graph datasets.",2023-05-24,"Zirui Liu, Zhimeng Jiang, Shaochen Zhong, Kaixiong Zhou, Li Li, Rui Chen, Soo-Hyun Choi, Xia Hu"
"Quantifying Collection Lag in European Modern and Contemporary Art
  Museums","Museum collection strategies are governed by a variety of factors, including
topical focus, acquisition funds, availability of works in the art market,
donations and specific coincidental opportunities. Yet, it remains unclear if
more fundamental collection patterns emerge, exist, and are shared between
museums, which could for example allow an established artist to estimate when a
contemporary art museum would acquire their works. Here we collect and analyze
data from 12 European contemporary art museums, taking into account artwork
creation dates, collection acquisition dates, and the associated artist age at
both points in time. From this simple quantitative construct we are able to
reveal a striking gradient of museum profiles at the aggregate level. This lag
can function to constitute a macroeconomic index of ""mean museum collection
lag"", ranging from 3 years in the most dynamic cases (Kiasma) to 33 years in
the most established institutions (Reina Sofia). Meanwhile, on the granular
level, plotting artist age over collection year, and using artist-age vs
artwork-collection matrices, a detailed picture becomes evident, where
individual museums are characterized by shared patterns and a rich
heterogeneity of ideographic details. Regularities include continuous
acquisitions, systematic acquisition of older materials over time, and brief
bursts, where whole oeuvres of individual artists join specific collections.
Hence, we are able to shed light on the detailed collection history of museums,
transcending the anecdotal nature of art historical storytelling via the
provision of a quantitative context. Our approach of cultural data analysis
combines expertise in art, art history, computational social science, and
computer science. Our joint perspective builds a bridge between and serves an
audience of museum professionals, art market actors, collectors, and individual
artists alike.",2023-05-23,"Mar Canet Solà, Antonina Korepanova, Ksenia Mukhina, Maximilian Schich"
"Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes
  From Text-To-Image Models","State-of-the-art Text-to-Image models like Stable Diffusion and DALLE$\cdot$2
are revolutionizing how people generate visual content. At the same time,
society has serious concerns about how adversaries can exploit such models to
generate unsafe images. In this work, we focus on demystifying the generation
of unsafe images and hateful memes from Text-to-Image models. We first
construct a typology of unsafe images consisting of five categories (sexually
explicit, violent, disturbing, hateful, and political). Then, we assess the
proportion of unsafe images generated by four advanced Text-to-Image models
using four prompt datasets. We find that these models can generate a
substantial percentage of unsafe images; across four models and four prompt
datasets, 14.56% of all generated images are unsafe. When comparing the four
models, we find different risk levels, with Stable Diffusion being the most
prone to generating unsafe content (18.92% of all generated images are unsafe).
Given Stable Diffusion's tendency to generate more unsafe content, we evaluate
its potential to generate hateful meme variants if exploited by an adversary to
attack a specific individual or community. We employ three image editing
methods, DreamBooth, Textual Inversion, and SDEdit, which are supported by
Stable Diffusion. Our evaluation result shows that 24% of the generated images
using DreamBooth are hateful meme variants that present the features of the
original hateful meme and the target individual/community; these generated
images are comparable to hateful meme variants collected from the real world.
Overall, our results demonstrate that the danger of large-scale generation of
unsafe images is imminent. We discuss several mitigating measures, such as
curating training data, regulating prompts, and implementing safety filters,
and encourage better safeguard tools to be developed to prevent unsafe
generation.",2023-05-23,"Yiting Qu, Xinyue Shen, Xinlei He, Michael Backes, Savvas Zannettou, Yang Zhang"
Analysis of Media Writing Style Bias through Text-Embedding Networks,"With the rise of phenomena like `fake news' and the growth of heavily-biased
media ecosystems, there has been increased attention on understanding and
evaluating media bias. Of particular note in the evaluation of media bias is
writing style bias, which includes lexical bias and framing bias. We propose a
novel approach to evaluating writing style bias that utilizes natural language
similarity estimation and a network-based representation of the shared content
between articles to perform bias characterization. Our proposed method presents
a new means of evaluating writing style bias that does not rely on human
experts or knowledge of a media producer's publication procedures. The results
of experimentation on real-world vaccine mandate data demonstrates the utility
of the technique and how the standard bias labeling procedures of only having
one bias label for a media producer is insufficient to truly characterize the
bias of that media producer.",2023-05-22,"Iain J. Cruickshank, Jessica Zhu, Nathaniel D. Bastian"
CrowdWeb: A Visualization Tool for Mobility Patterns in Smart Cities,"Human mobility patterns refer to the regularities and trends in the way
people move, travel, or navigate through different geographical locations over
time. Detecting human mobility patterns is essential for a variety of
applications, including smart cities, transportation management, and disaster
response. The accuracy of current mobility prediction models is less than 25%.
The low accuracy is mainly due to the fluid nature of human movement.
Typically, humans do not adhere to rigid patterns in their daily activities,
making it difficult to identify hidden regularities in their data. To address
this issue, we proposed a web platform to visualize human mobility patterns by
abstracting the locations into a set of places to detect more realistic
patterns. However, the platform was initially designed to detect individual
mobility patterns, making it unsuitable for representing the crowd in a smart
city scale. Therefore, we extend the platform to visualize the mobility of
multiple users from a city-scale perspective. Our platform allows users to
visualize a graph of visited places based on their historical records using a
modified PrefixSpan approach. Additionally, the platform synchronizes,
aggregates, and displays crowd mobility patterns across various time intervals
within a smart city. We showcase our platform using a real dataset.",2023-05-22,"Yisheng Alison Zheng, Abdallah Lakhdari, Amani Abusafia, Shing Tai Tony Lui, Athman Bouguettaya"
The theory of percolation on hypergraphs,"Hypergraphs capture the higher-order interactions in complex systems and
always admit a factor graph representation, consisting of a bipartite network
of nodes and hyperedges. As hypegraphs are ubiquitous, investigating hypergraph
robustness is a problem of major research interest. In the literature the
robustness of hypergraphs as been so far only treated adopting factor-graph
percolation which describe well higher-order interactions which remain
functional even after the removal of one of more of their nodes. This approach,
however, fall short to describe situations in which higher-order interactions
fail when anyone of their nodes is removed, this latter scenario applying for
instance to supply chains, catalytic networks, protein-interaction networks,
networks of chemical reactions, etc. Here we show that in these cases the
correct process to investigate is hypergraph percolation with is distinct from
factor graph percolation. We build a message-passing theory of hypergraph
percolation and we investigate its critical behavior using generating function
formalism supported by Monte Carlo simulations on random graph and real data.
Notably, we show that the node percolation threshold on hypergraphs exceeds
node percolation threshold on factor graphs. Furthermore we show that
differently from what happens in ordinary graphs, on hypergraphs the node
percolation threshold and hyperedge percolation threshold do not coincide, with
the node percolation threshold exceeding the hyperedge percolation threshold.
These results demonstrate that any fat-tailed cardinality distribution of
hyperedges cannot lead to the hyper-resilience phenomenon in hypergraphs in
contrast to their factor graphs, where the divergent second moment of a
cardinality distribution guarantees zero percolation threshold.",2023-05-20,"Ginestra Bianconi, Sergey N. Dorogovtsev"
Socio-Linguistic Characteristics of Coordinated Inauthentic Accounts,"Online manipulation is a pressing concern for democracies, but the actions
and strategies of coordinated inauthentic accounts, which have been used to
interfere in elections, are not well understood. We analyze a five
million-tweet multilingual dataset related to the 2017 French presidential
election, when a major information campaign led by Russia called ""#MacronLeaks""
took place. We utilize heuristics to identify coordinated inauthentic accounts
and detect attitudes, concerns and emotions within their tweets, collectively
known as socio-linguistic characteristics. We find that coordinated accounts
retweet other coordinated accounts far more than expected by chance, while
being exceptionally active just before the second round of voting.
Concurrently, socio-linguistic characteristics reveal that coordinated accounts
share tweets promoting a candidate at three times the rate of non-coordinated
accounts. Coordinated account tactics also varied in time to reflect news
events and rounds of voting. Our analysis highlights the utility of
socio-linguistic characteristics to inform researchers about tactics of
coordinated accounts and how these may feed into online social manipulation.",2023-05-19,"Keith Burghardt, Ashwin Rao, Siyi Guo, Zihao He, Georgios Chochlakis, Baruah Sabyasachee, Andrew Rojecki, Shri Narayanan, Kristina Lerman"
"IKDSumm: Incorporating Key-phrases into BERT for extractive Disaster
  Tweet Summarization","Online social media platforms, such as Twitter, are one of the most valuable
sources of information during disaster events. Therefore, humanitarian
organizations, government agencies, and volunteers rely on a summary of this
information, i.e., tweets, for effective disaster management. Although there
are several existing supervised and unsupervised approaches for automated tweet
summary approaches, these approaches either require extensive labeled
information or do not incorporate specific domain knowledge of disasters.
Additionally, the most recent approaches to disaster summarization have
proposed BERT-based models to enhance the summary quality. However, for further
improved performance, we introduce the utilization of domain-specific knowledge
without any human efforts to understand the importance (salience) of a tweet
which further aids in summary creation and improves summary quality. In this
paper, we propose a disaster-specific tweet summarization framework, IKDSumm,
which initially identifies the crucial and important information from each
tweet related to a disaster through key-phrases of that tweet. We identify
these key-phrases by utilizing the domain knowledge (using existing ontology)
of disasters without any human intervention. Further, we utilize these
key-phrases to automatically generate a summary of the tweets. Therefore, given
tweets related to a disaster, IKDSumm ensures fulfillment of the summarization
key objectives, such as information coverage, relevance, and diversity in
summary without any human intervention. We evaluate the performance of IKDSumm
with 8 state-of-the-art techniques on 12 disaster datasets. The evaluation
results show that IKDSumm outperforms existing techniques by approximately
2-79% in terms of ROUGE-N F1-score.",2023-05-19,"Piyush Kumar Garg, Roshni Chakraborty, Srishti Gupta, Sourav Kumar Dandapat"
"PORTRAIT: a hybrid aPproach tO cReate extractive ground-TRuth summAry
  for dIsaster evenT","Disaster summarization approaches provide an overview of the important
information posted during disaster events on social media platforms, such as,
Twitter. However, the type of information posted significantly varies across
disasters depending on several factors like the location, type, severity, etc.
Verification of the effectiveness of disaster summarization approaches still
suffer due to the lack of availability of good spectrum of datasets along with
the ground-truth summary. Existing approaches for ground-truth summary
generation (ground-truth for extractive summarization) relies on the wisdom and
intuition of the annotators. Annotators are provided with a complete set of
input tweets from which a subset of tweets is selected by the annotators for
the summary. This process requires immense human effort and significant time.
Additionally, this intuition-based selection of the tweets might lead to a high
variance in summaries generated across annotators. Therefore, to handle these
challenges, we propose a hybrid (semi-automated) approach (PORTRAIT) where we
partly automate the ground-truth summary generation procedure. This approach
reduces the effort and time of the annotators while ensuring the quality of the
created ground-truth summary. We validate the effectiveness of PORTRAIT on 5
disaster events through quantitative and qualitative comparisons of
ground-truth summaries generated by existing intuitive approaches, a
semi-automated approach, and PORTRAIT. We prepare and release the ground-truth
summaries for 5 disaster events which consist of both natural and man-made
disaster events belonging to 4 different countries. Finally, we provide a study
about the performance of various state-of-the-art summarization approaches on
the ground-truth summaries generated by PORTRAIT using ROUGE-N F1-scores.",2023-05-19,"Piyush Kumar Garg, Roshni Chakraborty, Sourav Kumar Dandapat"
"Comfort Foods and Community Connectedness: Investigating Diet Change
  during COVID-19 Using YouTube Videos on Twitter","Unprecedented lockdowns at the start of the COVID-19 pandemic have
drastically changed the routines of millions of people, potentially impacting
important health-related behaviors. In this study, we use YouTube videos
embedded in tweets about diet, exercise and fitness posted before and during
COVID-19 to investigate the influence of the pandemic lockdowns on diet and
nutrition. In particular, we examine the nutritional profile of the foods
mentioned in the transcript, description and title of each video in terms of
six macronutrients (protein, energy, fat, sodium, sugar, and saturated fat).
These macronutrient values were further linked to demographics to assess if
there are specific effects on those potentially having insufficient access to
healthy sources of food. Interrupted time series analysis revealed a
considerable shift in the aggregated macronutrient scores before and during
COVID-19. In particular, whereas areas with lower incomes showed decrease in
energy, fat, and saturated fat, those with higher percentage of African
Americans showed an elevation in sodium. Word2Vec word similarities and odds
ratio analysis suggested a shift from popular diets and lifestyle bloggers
before the lockdowns to the interest in a variety of healthy foods, communal
sharing of quick and easy recipes, as well as a new emphasis on comfort foods.
To the best of our knowledge, this work is novel in terms of linking attention
signals in tweets, content of videos, their nutrients profile, and aggregate
demographics of the users. The insights made possible by this combination of
resources are important for monitoring the secondary health effects of social
distancing, and informing social programs designed to alleviate these effects.",2023-05-19,"Yelena Mejova, Lydia Manikonda"
"Radicalized by Thinness: Using a Model of Radicalization to Understand
  Pro-Anorexia Communities on Twitter","The rise in eating disorders, a condition with serious health complications,
has been linked to the proliferation of idealized body images on social media
platforms. However, the relationship between social media and eating disorders
is more complex, with online platforms potentially enabling harmful behaviors
by linking people to ``pro-ana'' communities that promote eating disorders. We
conceptualize the growth of harmful pro-ana communities as a process of online
radicalization. We show that a model of radicalization explains how individuals
are driven to conversations about extreme behaviors, like fasting, to achieve
the ``thin body'' goal, and how these conversations are validated by pro-ana
communities. By facilitating social connections to like-minded others, a shared
group identity and emotional support, social media platforms can trap
individuals within toxic echo chambers that normalize extreme disordered eating
behaviors and other forms of self-harm. Characterizing and quantifying the role
of online communities in amplifying harmful conversations will support the
development of strategies to mitigate their impact and promote better mental
health.",2023-05-18,"Kristina Lerman, Aryan Karnati, Shuchan Zhou, Siyi Chen, Sudesh Kumar, Zihao He, Joanna Yau, Abigail Horn"
"MetaGAD: Meta Representation Adaptation for Few-Shot Graph Anomaly
  Detection","Graph anomaly detection has long been an important problem in various domains
pertaining to information security such as financial fraud, social spam and
network intrusion. The majority of existing methods are performed in an
unsupervised manner, as labeled anomalies in a large scale are often too
expensive to acquire. However, the identified anomalies may turn out to be
uninteresting data instances due to the lack of prior knowledge. In real-world
scenarios, it is often feasible to obtain limited labeled anomalies, which have
great potential to advance graph anomaly detection. However, the work exploring
limited labeled anomalies and a large amount of unlabeled nodes in graphs to
detect anomalies is relatively limited. Therefore, in this paper, we study an
important problem of few-shot graph anomaly detection. Nonetheless, it is
challenging to fully leverage the information of few-shot anomalous nodes due
to the irregularity of anomalies and the overfitting issue in the few-shot
learning. To tackle the above challenges, we propose a novel meta-learning
based framework, MetaGAD, that learns to adapt the knowledge from
self-supervised learning to few-shot supervised learning for graph anomaly
detection. In specific, we formulate the problem as a bi-level optimization,
ensuring MetaGAD converging to minimizing the validation loss, thus enhancing
the generalization capacity. The comprehensive experiments on six real-world
datasets with synthetic anomalies and ""organic"" anomalies (available in the
datasets) demonstrate the effectiveness of MetaGAD in detecting anomalies with
few-shot anomalies. The code is available at
https://github.com/XiongxiaoXu/MetaGAD.",2023-05-18,"Xiongxiao Xu, Kaize Ding, Canyu Chen, Kai Shu"
"Analytic relationship of relative synchronizability to network structure
  and motifs","Synchronization phenomena on networks have attracted much attention in
studies of neural, social, economic, and biological systems, yet we still lack
a systematic understanding of how relative synchronizability relates to
underlying network structure. Indeed, this question is of central importance to
the key theme of how dynamics on networks relate to their structure more
generally. We present an analytic technique to directly measure the relative
synchronizability of noise-driven time-series processes on networks, in terms
of the directed network structure. We consider both discrete-time
auto-regressive processes and continuous-time Ornstein-Uhlenbeck dynamics on
networks. Our technique builds on computation of the network covariance matrix
in the space orthogonal to the synchronized state, enabling it to be more
general than previous work in not requiring either symmetric (undirected) or
diagonalizable connectivity matrices, and allowing arbitrary self-link weights.
More importantly, our approach quantifies the relative synchronisation
specifically in terms of the contribution of process motif (walk) structures.
We demonstrate that in general the relative abundance of process motifs with
convergent directed walks (including feedback and feedforward loops) hinders
synchronizability. We also reveal subtle differences between the motifs
involved for discrete or continuous-time dynamics. Our insights analytically
explain several known general results regarding synchronizability of networks,
including that small-world and regular networks are less synchronizable than
random networks.",2023-05-17,"Joseph T. Lizier, Frank Bauer, Fatihcan M. Atay, Jürgen Jost"
"Improving Link Prediction in Social Networks Using Local and Global
  Features: A Clustering-based Approach","Link prediction problem has increasingly become prominent in many domains
such as social network analyses, bioinformatics experiments, transportation
networks, criminal investigations and so forth. A variety of techniques has
been developed for link prediction problem, categorized into 1) similarity
based approaches which study a set of features to extract similar nodes; 2)
learning based approaches which extract patterns from the input data; 3)
probabilistic statistical approaches which optimize a set of parameters to
establish a model which can best compute formation probability. However,
existing literatures lack approaches which utilize strength of each approach by
integrating them to achieve a much more productive one. To tackle the link
prediction problem, we propose an approach based on the combination of first
and second group methods; the existing studied works use just one of these
categories. Our two-phase developed method firstly determines new features
related to the position and dynamic behavior of nodes, which enforce the
approach more efficiency compared to approaches using mere measures. Then, a
subspace clustering algorithm is applied to group social objects based on the
computed similarity measures which differentiate the strength of clusters;
basically, the usage of local and global indices and the clustering information
plays an imperative role in our link prediction process. Some extensive
experiments held on real datasets including Facebook, Brightkite and HepTh
indicate good performances of our proposal method. Besides, we have
experimentally verified our approach with some previous techniques in the area
to prove the supremacy of ours.",2023-05-17,"Safiye Ghasemi, Amin Zarei"
"Agent Heterogeneity Mediates Extremism in an Adaptive Social Network
  Model","An existing model of opinion dynamics on an adaptive social network is
extended to introduce update policy heterogeneity, representing the fact that
individual differences between social animals can affect their tendency to
form, and be influenced by, their social bonds with other animals. As in the
original model, the opinions and social connections of a population of model
agents change due to three social processes: conformity, homophily and
neophily. Here, however, we explore the case in which each node's
susceptibility to these three processes is parameterised by node-specific
values drawn independently at random from some distribution. This introduction
of heterogeneity increases both the degree of extremism and connectedness in
the final population (relative to comparable homogeneous networks) and leads to
significant assortativity with respect to node update policy parameters as well
as node opinions. Each node's update policy parameters also predict properties
of the community that they will belong to in the final network configuration.
These results suggest that update policy heterogeneity in social populations
may have a significant impact on the formation of extremist communities in
real-world populations.",2023-05-17,"Seth Bullock, Hiroki Sayama"
Link prediction for ex ante influence maximization on temporal networks,"Influence maximization (IM) is the task of finding the most important nodes
in order to maximize the spread of influence or information on a network. This
task is typically studied on static or temporal networks where the complete
topology of the graph is known. In practice, however, the seed nodes must be
selected before observing the future evolution of the network. In this work, we
consider this realistic ex ante setting where $p$ time steps of the network
have been observed before selecting the seed nodes. Then the influence is
calculated after the network continues to evolve for a total of $T>p$ time
steps. We address this problem by using statistical, non-negative matrix
factorization and graph neural networks link prediction algorithms to predict
the future evolution of the network and then apply existing influence
maximization algorithms on the predicted networks. Additionally, the output of
the link prediction methods can be used to construct novel IM algorithms. We
apply the proposed methods to eight real-world and synthetic networks to
compare their performance using the Susceptible-Infected (SI) diffusion model.
We demonstrate that it is possible to construct quality seed sets in the ex
ante setting as we achieve influence spread within 87\% of the optimal spread
on seven of eight network. In many settings, choosing seed nodes based only
historical edges provides results comparable to the results treating the future
graph snapshots as known. The proposed heuristics based on the link prediction
model are also some of the best-performing methods. These findings indicate
that, for these eight networks under the SI model, the latent process which
determines the most influential nodes may not have large temporal variation.
Thus, knowing the future status of the network is not necessary to obtain good
results for ex ante IM.",2023-05-17,"Eric Yanchenko, Tsuyoshi Murata, Petter Holme"
"Mastering Long-Tail Complexity on Graphs: Characterization, Learning,
  and Generalization","In the context of long-tail classification on graphs, the vast majority of
existing work primarily revolves around the development of model debiasing
strategies, intending to mitigate class imbalances and enhance the overall
performance. Despite the notable success, there is very limited literature that
provides a theoretical tool for characterizing the behaviors of long-tail
classes in graphs and gaining insight into generalization performance in
real-world scenarios. To bridge this gap, we propose a generalization bound for
long-tail classification on graphs by formulating the problem in the fashion of
multi-task learning, i.e., each task corresponds to the prediction of one
particular class. Our theoretical results show that the generalization
performance of long-tail classification is dominated by the overall loss range
and the task complexity. Building upon the theoretical findings, we propose a
novel generic framework HierTail for long-tail classification on graphs. In
particular, we start with a hierarchical task grouping module that allows us to
assign related tasks into hypertasks and thus control the complexity of the
task space; then, we further design a balanced contrastive learning module to
adaptively balance the gradients of both head and tail classes to control the
loss range across all tasks in a unified fashion. Extensive experiments
demonstrate the effectiveness of HierTail in characterizing long-tail classes
on real graphs, which achieves up to 12.9% improvement over the leading
baseline method in accuracy.",2023-05-17,"Haohui Wang, Baoyu Jing, Kaize Ding, Yada Zhu, Wei Cheng, Si Zhang, Yonghui Fan, Liqing Zhang, Dawei Zhou"
"Public Perception of Generative AI on Twitter: An Empirical Study Based
  on Occupation and Usage","The emergence of generative AI has sparked substantial discussions, with the
potential to have profound impacts on society in all aspects. As emerging
technologies continue to advance, it is imperative to facilitate their proper
integration into society, managing expectations and fear. This paper
investigates users' perceptions of generative AI using 3M posts on Twitter from
January 2019 to March 2023, especially focusing on their occupation and usage.
We find that people across various occupations, not just IT-related ones, show
a strong interest in generative AI. The sentiment toward generative AI is
generally positive, and remarkably, their sentiments are positively correlated
with their exposure to AI. Among occupations, illustrators show exceptionally
negative sentiment mainly due to concerns about the unethical usage of artworks
in constructing AI. People use ChatGPT in diverse ways, and notably the casual
usage in which they ""play with"" ChatGPT tends to associate with positive
sentiments. After the release of ChatGPT, people's interest in AI in general
has increased dramatically; however, the topic with the most significant
increase and positive sentiment is related to crypto, indicating the
hype-worthy characteristics of generative AI. These findings would offer
valuable lessons for policymaking on the emergence of new technology and also
empirical insights for the considerations of future human-AI symbiosis.",2023-05-16,"Kunihiro Miyazaki, Taichi Murayama, Takayuki Uchiba, Jisun An, Haewoon Kwak"
"Community Notes vs. Snoping: How the Crowd Selects Fact-Checking Targets
  on Social Media","Deploying links to fact-checking websites (so-called ""snoping"") is a common
intervention that can be used by social media users to refute misleading
claims. However, its real-world effect may be limited as it suffers from low
visibility and distrust towards professional fact-checkers. As a remedy,
Twitter launched its community-based fact-checking system Community Notes on
which fact-checks are carried out by actual Twitter users and directly shown on
the fact-checked tweets. Yet, an understanding of how fact-checking via
Community Notes differs from snoping is absent. In this study, we analyze
differences in how contributors to Community Notes and Snopers select their
targets when fact-checking social media posts. For this purpose, we analyze two
unique datasets from Twitter: (a) 25,912 community-created fact-checks from
Twitter's Community Notes platform; and (b) 52,505 ""snopes"" that debunk tweets
via fact-checking replies linking to professional fact-checking websites. We
find that Notes contributors and Snopers focus on different targets when
fact-checking social media content. For instance, Notes contributors tend to
fact-check posts from larger accounts with higher social influence and are
relatively less likely to endorse/emphasize the accuracy of not misleading
posts. Fact-checking targets of Notes contributors and Snopers rarely overlap;
however, those overlapping exhibit a high level of agreement in the
fact-checking assessment. Moreover, we demonstrate that Snopers fact-check
social media posts at a higher speed. Altogether, our findings imply that
different fact-checking approaches -- carried out on the same social media
platform -- can result in vastly different social media posts getting
fact-checked. This has important implications for future research on
misinformation, which should not rely on a single fact-checking approach when
compiling misinformation datasets.",2023-05-16,"Moritz Pilarski, Kirill Solovev, Nicolas Pröllochs"
"Dynamic Causal Explanation Based Diffusion-Variational Graph Neural
  Network for Spatio-temporal Forecasting","Graph neural networks (GNNs), especially dynamic GNNs, have become a research
hotspot in spatio-temporal forecasting problems. While many dynamic graph
construction methods have been developed, relatively few of them explore the
causal relationship between neighbour nodes. Thus, the resulting models lack
strong explainability for the causal relationship between the neighbour nodes
of the dynamically generated graphs, which can easily lead to a risk in
subsequent decisions. Moreover, few of them consider the uncertainty and noise
of dynamic graphs based on the time series datasets, which are ubiquitous in
real-world graph structure networks. In this paper, we propose a novel Dynamic
Diffusion-Variational Graph Neural Network (DVGNN) for spatio-temporal
forecasting. For dynamic graph construction, an unsupervised generative model
is devised. Two layers of graph convolutional network (GCN) are applied to
calculate the posterior distribution of the latent node embeddings in the
encoder stage. Then, a diffusion model is used to infer the dynamic link
probability and reconstruct causal graphs in the decoder stage adaptively. The
new loss function is derived theoretically, and the reparameterization trick is
adopted in estimating the probability distribution of the dynamic graphs by
Evidence Lower Bound during the backpropagation period. After obtaining the
generated graphs, dynamic GCN and temporal attention are applied to predict
future states. Experiments are conducted on four real-world datasets of
different graph structures in different domains. The results demonstrate that
the proposed DVGNN model outperforms state-of-the-art approaches and achieves
outstanding Root Mean Squared Error result while exhibiting higher robustness.
Also, by F1-score and probability distribution analysis, we demonstrate that
DVGNN better reflects the causal relationship and uncertainty of dynamic
graphs.",2023-05-16,"Guojun Liang, Prayag Tiwari, Sławomir Nowaczyk, Stefan Byttner, Fernando Alonso-Fernandez"
"An assessment of measuring local levels of homelessness through proxy
  social media signals","Recent studies suggest social media activity can function as a proxy for
measures of state-level public health, detectable through natural language
processing. We present results of our efforts to apply this approach to
estimate homelessness at the state level throughout the US during the period
2010-2019 and 2022 using a dataset of roughly 1 million geotagged tweets
containing the substring ``homeless.'' Correlations between
homelessness-related tweet counts and ranked per capita homelessness volume,
but not general-population densities, suggest a relationship between the
likelihood of Twitter users to personally encounter or observe homelessness in
their everyday lives and their likelihood to communicate about it online. An
increase to the log-odds of ``homeless'' appearing in an English-language
tweet, as well as an acceleration in the increase in average tweet sentiment,
suggest that tweets about homelessness are also affected by trends at the
nation-scale. Additionally, changes to the lexical content of tweets over time
suggest that reversals to the polarity of national or state-level trends may be
detectable through an increase in political or service-sector language over the
semantics of charity or direct appeals. An analysis of user account type also
revealed changes to Twitter-use patterns by accounts authored by individuals
versus entities that may provide an additional signal to confirm changes to
homelessness density in a given jurisdiction. While a computational approach to
social media analysis may provide a low-cost, real-time dataset rich with
information about nationwide and localized impacts of homelessness and
homelessness policy, we find that practical issues abound, limiting the
potential of social media as a proxy to complement other measures of
homelessness.",2023-05-15,"Yoshi Meke Bird, Sarah E. Grobe, Michael V. Arnold, Sean P. Rogers, Mikaela I. Fudolig, Julia Witte Zimmerman, Christopher M. Danforth, Peter Sheridan Dodds"
"Why Rumors Spread Fast in Social Networks, and How to Stop It","We study a rumor spreading model where individuals are connected via a
network structure. Initially, only a small subset of the individuals are
spreading a rumor. Each individual who is connected to a spreader, starts
spreading the rumor with some probability as a function of their trust in the
spreader, quantified by the Jaccard similarity index. Furthermore, the
probability that a spreader diffuses the rumor decreases over time until they
fully lose their interest and stop spreading.
  We focus on determining the graph parameters which govern the magnitude and
pace that the rumor spreads in this model. We prove that for the rumor to
spread to a sizable fraction of the individuals, the network needs to enjoy
``strong'' expansion properties and most nodes should be in ``well-connected''
communities. Both of these characteristics are, arguably, present in real-world
social networks up to a certain degree, shedding light on the driving force
behind the extremely fast spread of rumors in social networks.
  Furthermore, we formulate a large range of countermeasures to cease the
spread of a rumor. We introduce four fundamental criteria which a
countermeasure ideally should possess. We evaluate all the proposed
countermeasures by conducting experiments on real-world social networks such as
Facebook and Twitter. We conclude that our novel decentralized countermeasures
(which are executed by the individuals) generally outperform the previously
studied centralized ones (which need to be imposed by a third entity such as
the government).",2023-05-15,"Ahad N. Zehmakan, Charlotte Out, Sajjad Hesamipour Khelejan"
Decoupled Graph Neural Networks for Large Dynamic Graphs,"Real-world graphs, such as social networks, financial transactions, and
recommendation systems, often demonstrate dynamic behavior. This phenomenon,
known as graph stream, involves the dynamic changes of nodes and the emergence
and disappearance of edges. To effectively capture both the structural and
temporal aspects of these dynamic graphs, dynamic graph neural networks have
been developed. However, existing methods are usually tailored to process
either continuous-time or discrete-time dynamic graphs, and cannot be
generalized from one to the other. In this paper, we propose a decoupled graph
neural network for large dynamic graphs, including a unified dynamic
propagation that supports efficient computation for both continuous and
discrete dynamic graphs. Since graph structure-related computations are only
performed during the propagation process, the prediction process for the
downstream task can be trained separately without expensive graph computations,
and therefore any sequence model can be plugged-in and used. As a result, our
algorithm achieves exceptional scalability and expressiveness. We evaluate our
algorithm on seven real-world datasets of both continuous-time and
discrete-time dynamic graphs. The experimental results demonstrate that our
algorithm achieves state-of-the-art performance in both kinds of dynamic
graphs. Most notably, the scalability of our algorithm is well illustrated by
its successful application to large graphs with up to over a billion temporal
edges and over a hundred million nodes.",2023-05-14,"Yanping Zheng, Zhewei Wei, Jiajun Liu"
Origins of Face-to-face Interaction with Kin in US Cities,"People interact face-to-face on a frequent basis if (i) they live nearby and
(ii) make the choice to meet. The first constitutes an availability of social
ties; the second a propensity to interact with those ties. Despite being
distinct social processes, most large-scale human interaction studies overlook
these separate influences. Here, we study trends of interaction, availability,
and propensity across US cities for a critical, abundant, and understudied type
of social tie: extended family that live locally in separate households. We
observe a systematic decline in interactions as a function of city population,
which we attribute to decreased non-coresident local family availability. In
contrast, interaction propensity and duration are either independent of or
increase with city population. The large-scale patterns of availability and
interaction propensity we discover, derived from analyzing the American Time
Use Survey and Pew Social Trends Survey data, unveil previously-unknown effects
on several social processes such as the effectiveness of pandemic-related
social interventions, drivers affecting residential choice, and the ability of
kin to provide care to family.",2023-05-13,"Jericho McLeod, Unchitta Kan, Eduardo López"
"Detecting Coordinated Inauthentic Behavior in Likes on Social Media:
  Proof of Concept","Coordinated inauthentic behavior is used as a tool on social media to shape
public opinion by elevating or suppressing topics using systematic engagements
-- e.g. through *likes* or similar reactions. In an honest world, reactions may
be informative to users when selecting on what to spend their attention:
through the wisdom of crowds, summed reactions may help identifying relevant
and high-quality content. This is nullified by coordinated inauthentic liking.
To restore wisdom-of-crowds effects, it is therefore desirable to separate the
inauthentic agents from the wise crowd, and use only the latter as a voting
*jury* on the relevance of a post. To this end, we design two *jury selection
procedures* (JSPs) that discard agents classified as inauthentic. Using machine
learning techniques, both cluster on binary vote data -- one using a Gaussian
Mixture Model (GMM JSP), one the k-means algorithm (KM JSP) -- and label agents
by logistic regression. We evaluate the jury selection procedures with an
agent-based model, and show that the GMM JSP detects more inauthentic agents,
but both JSPs select juries with vastly increased correctness of vote by
majority. This proof of concept provides an argument for the release of
reactions data from social media platforms through a direct use-case in the
fight against online misinformation.",2023-05-12,"Laura Jahn, Rasmus K. Rendsvig, Jacob Stærk-Østergaard"
Can we Quantify Trust? Towards a Trust-based Resilient SIoT Network,"The emerging yet promising paradigm of the Social Internet of Things (SIoT)
integrates the notion of the Internet of Things with human social networks. In
SIoT, objects, i.e., things, have the capability to socialize with the other
objects in the SIoT network and can establish their social network autonomously
by modeling human behaviour. The notion of trust is imperative in realizing
these characteristics of socialization in order to assess the reliability of
autonomous collaboration. The perception of trust is evolving in the era of
SIoT as an extension to traditional security triads in an attempt to offer
secure and reliable services, and is considered as an imperative aspect of any
SIoT system for minimizing the probable risk of autonomous decision-making.
This research investigates the idea of trust quantification by employing trust
measurement in terms of direct trust, indirect trust as a recommendation, and
the degree of SIoT relationships in terms of social similarities
(community-of-interest, friendship, and co-work relationships). A weighted sum
approach is subsequently employed to synthesize all the trust features in order
to ascertain a single trust score. The experimental evaluation demonstrates the
effectiveness of the proposed model in segregating trustworthy and
untrustworthy objects and via identifying the dynamic behaviour (i.e.,
trust-related attacks) of the SIoT objects.",2023-05-12,"Subhash Sagar, Adnan Mahmood, Quan Z. Sheng, Munazza Zaib, Farhan Sufyan"
"Semantic Random Walk for Graph Representation Learning in Attributed
  Graphs","In this study, we focus on the graph representation learning (a.k.a. network
embedding) in attributed graphs. Different from existing embedding methods that
treat the incorporation of graph structure and semantic as the simple
combination of two optimization objectives, we propose a novel semantic graph
representation (SGR) method to formulate the joint optimization of the two
heterogeneous sources into a common high-order proximity based framework.
Concretely, we first construct an auxiliary weighted graph, where the complex
homogeneous and heterogeneous relations among nodes and attributes in the
original graph are comprehensively encoded. Conventional embedding methods that
consider high-order topology proximities can then be easily applied to the
newly constructed graph to learn the representations of both node and attribute
while capturing the nonlinear high-order intrinsic correlation inside or among
graph structure and semantic. The learned attribute embeddings can also
effectively support some semantic-oriented inference tasks (e.g., semantic
community detection), helping to reveal the graph's deep semantic. The
effectiveness of SGR is further verified on a series of real graphs, where it
achieves impressive performance over other baselines.",2023-05-11,Meng Qin
"Prior Global Search Stability on Finite Graphs with Uncertainty. May
  Greedy Search Win?","This research paper addresses the stability of search algorithms in complex
networks when dealing with incomplete information or uncertainty. We propose a
theoretical model to investigate whether a global search algorithm with
incomplete prior information can be outperformed by a stochastic greedy search
on average. The model incorporates random variables to perturb edge weights in
the graph, thus capturing the uncertainty of available information. Our
findings indicate that some graphs and uncertainty model parameters exist where
the global search algorithm fails under uncertainty conditions, while the
random greedy search performs better. We derive a critical curve that separates
stable from unstable graphs for global search with incomplete information.
Interestingly, the critical curve's behavior changes from monotonic to
bell-shaped depending on the uncertainty parameters. We test our proposed model
through numerical simulations on various synthetic and real-world graphs with
different structures. Our results offer insights into the design and
optimization of search algorithms for network-based applications, such as
communication networks, social networks, and biological networks. We also
discuss the study of memory and associative learning in miniature insects,
highlighting the potential of efficient search and walking strategies for small
robots or devices that operate in a limited area in space.",2023-05-10,"Andrey Ananev, Aleksey Khlyupin"
"Evaluating Twitter's Algorithmic Amplification of Low-Credibility
  Content: An Observational Study","Artificial intelligence (AI)-powered recommender systems play a crucial role
in determining the content that users are exposed to on social media platforms.
However, the behavioural patterns of these systems are often opaque,
complicating the evaluation of their impact on the dissemination and
consumption of disinformation and misinformation. To begin addressing this
evidence gap, this study presents a measurement approach that uses observed
digital traces to infer the status of algorithmic amplification of
low-credibility content on Twitter over a 14-day period in January 2023. Using
an original dataset of 2.7 million posts on COVID-19 and climate change
published on the platform, this study identifies tweets sharing information
from low-credibility domains, and uses a bootstrapping model with two
stratifications, a tweet's engagement level and a user's followers level, to
compare any differences in impressions generated between low-credibility and
high-credibility samples. Additional stratification variables of toxicity,
political bias, and verified status are also examined. This analysis provides
valuable observational evidence on whether the Twitter algorithm favours the
visibility of low-credibility content, with results indicating that tweets
containing low-credibility URL domains perform significantly better than tweets
that do not across both datasets. Furthermore, high toxicity tweets and those
with right-leaning bias see heightened amplification, as do low-credibility
tweets from verified accounts. This suggests that Twitter s recommender system
may have facilitated the diffusion of false content, even when originating from
notoriously low-credibility sources.",2023-05-10,Giulio Corsi
"Topology and spectral interconnectivities of higher-order multilayer
  networks","Multilayer networks have permeated all the sciences as a powerful
mathematical abstraction for interdependent heterogenous complex systems such
as multimodal brain connectomes, transportation, ecological systems, and
scientific collaboration. But describing such systems through a purely
graph-theoretic formalism presupposes that the interactions that define the
underlying infrastructures and support their functions are only pairwise-based;
a strong assumption likely leading to oversimplifications. Indeed, most
interdependent systems intrinsically involve higher-order intra- and
inter-layer interactions. For instance, ecological systems involve interactions
among groups within and in-between species, collaborations and citations link
teams of coauthors to articles and vice versa, interactions might exist among
groups of friends from different social networks, etc. While higher-order
interactions have been studied for monolayer systems through the language of
simplicial complexes and hypergraphs, a broad and systematic formalism
incorporating them into the realm of multilayer systems is still lacking. Here,
we introduce the concept of crossimplicial multicomplexes as a general
formalism for modelling interdependent systems involving higher-order intra-
and inter-layer connections. Subsequently, we introduce cross-homology and its
spectral counterpart, the cross-Laplacian operators, to establish a rigorous
mathematical framework for quantifying global and local intra- and inter-layer
topological structures in such systems. When applied to multilayer networks,
these cross-Laplacians provide powerful methods for detecting clusters in one
layer that are controlled by hubs in another layer. We call such hubs spectral
cross-hubs and define spectral persistence as a way to rank them according to
their emergence along the cross-Laplacian spectra.",2023-05-10,"Elkaïoum M. Moutuou, Obaï B. K. Ali, Habib Benali"
"A Statistical Model of Bipartite Networks: Application to Cosponsorship
  in the United States Senate","Many networks in political and social research are bipartite, with edges
connecting exclusively across two distinct types of nodes. A common example
includes cosponsorship networks, in which legislators are connected indirectly
through the bills they support. Yet most existing network models are designed
for unipartite networks, where edges can arise between any pair of nodes.
However, using a unipartite network model to analyze bipartite networks, as
often done in practice, can result in aggregation bias and artificially
high-clustering -- a particularly insidious problem when studying the role
groups play in network formation. To address these methodological problems, we
develop a statistical model of bipartite networks theorized to be generated
through group interactions by extending the popular mixed-membership stochastic
blockmodel. Our model allows researchers to identify the groups of nodes,
within each node type in the bipartite structure, that share common patterns of
edge formation. The model also incorporates both node and dyad-level covariates
as the predictors of group membership and of observed dyadic relations. We
develop an efficient computational algorithm for fitting the model, and apply
it to cosponsorship data from the United States Senate. We show that
legislators in a Senate that was perfectly split along party lines were able to
remain productive and pass major legislation by forming non-partisan,
power-brokering coalitions that found common ground through their collaboration
on low-stakes bills. We also find evidence for norms of reciprocity, and
uncover the substantial role played by policy expertise in the formation of
cosponsorships between senators and legislation. We make an open-source
software package available that makes it possible for other researchers to
uncover similar insights from bipartite networks.",2023-05-10,"Adeline Lo, Santiago Olivella, Kosuke Imai"
"Efficient pattern-based anomaly detection in a network of multivariate
  devices","Many organisations manage service quality and monitor a large set devices and
servers where each entity is associated with telemetry or physical sensor data
series. Recently, various methods have been proposed to detect behavioural
anomalies, however existing approaches focus on multivariate time series and
ignore communication between entities. Moreover, we aim to support end-users in
not only in locating entities and sensors causing an anomaly at a certain
period, but also explain this decision. We propose a scalable approach to
detect anomalies using a two-step approach. First, we recover relations between
entities in the network, since relations are often dynamic in nature and caused
by an unknown underlying process. Next, we report anomalies based on an
embedding of sequential patterns. Pattern mining is efficient and supports
interpretation, i.e. patterns represent frequent occurring behaviour in time
series. We extend pattern mining to filter sequential patterns based on
frequency, temporal constraints and minimum description length. We collect and
release two public datasets for international broadcasting and X from an
Internet company. \textit{BAD} achieves an overall F1-Score of 0.78 on 9
benchmark datasets, significantly outperforming the best baseline by 3\%.
Additionally, \textit{BAD} is also an order-of-magnitude faster than
state-of-the-art anomaly detection methods.",2023-05-07,"Len Feremans, Boris Cule, Bart Goethals"
Complex contagion in social systems with distrust,"Social systems are characterized by the presence of group interactions and by
the existence of both trust and distrust relations. Although there is a wide
literature on signed social networks, where positive signs associated to the
links indicate trust, friendship, agreement, while negative signs represent
distrust, antagonism, and disagreement, very little is known about the effect
that signed interactions can have on the spreading of social behaviors when
higher-order interactions are taken into account. In this paper we focus on
processes of complex contagion, such as the adoption of social norms, where
exposure to multiple sources is needed for the contagion to occur. Complex
contagion has been recently modeled by higher-order networks, such as
simplicial complexes, which allow transmission to happen not only through the
links connecting pair of nodes, but also in group interactions, namely over
simplices of dimension larger or equal than two. Here, we introduce a model of
complex contagion on signed simplicial complexes, and we investigate the role
played by trust and distrust on the dynamics of a social contagion process. The
presence of higher-order signed structures in our model naturally induces new
infection and recovery mechanisms. Through numerical simulations and analytical
results in the mean-field approximation, we show how distrust determines the
way the system moves from a state where no individuals adopt the social
behavior, to a state where a finite fraction of the population actively spreads
it. Interestingly, the fraction of spreading individuals displays a
non-monotonic dependence on the average number of connections between
individuals. We then investigate how social balance affects social contagion,
finding that balanced triads either promote or impede contagion based on the
relative abundance of fully trusted relations.",2023-05-06,"Jean-François de Kemmeter, Luca Gallo, Fabrizio Boncoraglio, Vito Latora, Timoteo Carletti"
Zoo Guide to Network Embedding,"Networks have provided extremely successful models of data and complex
systems. Yet, as combinatorial objects, networks do not have in general
intrinsic coordinates and do not typically lie in an ambient space. The process
of assigning an embedding space to a network has attracted lots of interest in
the past few decades, and has been efficiently applied to fundamental problems
in network inference, such as link prediction, node classification, and
community detection. In this review, we provide a user-friendly guide to the
network embedding literature and current trends in this field which will allow
the reader to navigate through the complex landscape of methods and approaches
emerging from the vibrant research activity on these subjects.",2023-05-05,"Anthony Baptista, Rubén J. Sánchez-García, Anaïs Baudot, Ginestra Bianconi"
Analysis of h-index for research awards,"In order to advance academic research, it is important to assess and evaluate
the academic influence of researchers and the findings they produce. Citation
metrics are universally used methods to evaluate researchers. Amongst the
several variations of citation metrics, the h-index proposed by Hirsch has
become the leading measure. Recent work shows that h-index is not an effective
measure to determine scientific impact - due to changing authorship patterns.
This can be mitigated by using h-index of a paper to compute h- index of an
author. We show that using fractional allocation of h-index gives better
results. In this work, we reapply two indices based on the h-index of a single
paper. The indices are referred to as: hp-index and hp-frac-index. We run
large-scale experiments in three different fields with about a million
publications and 3,000 authors. We also compare h-index of a paper with nine
h-index like metrics. Our experiments show that hp-frac-index provides a unique
ranking when compared to h-index. It also performs better than h-index in
providing higher ranks to the awarded researcher.",2023-05-05,"Aashay Singhal, Kamalakar Karlapalem"
"Review and Assessment of Digital Twin--Oriented Social Network
  Simulators","The ability to faithfully represent real social networks is critical from the
perspective of testing various what-if scenarios which are not feasible to be
implemented in a real system as the system's state would be irreversibly
changed. High fidelity simulators allow one to investigate the consequences of
different actions before introducing them to the real system. For example, in
the context of social systems, an accurate social network simulator can be a
powerful tool used to guide policy makers, help companies plan their
advertising campaigns or authorities to analyse fake news spread. In this study
we explore different Social Network Simulators (SNSs) and assess to what extent
they are able to mimic the real social networks. We conduct a critical review
and assessment of existing Social Network Simulators under the Digital
Twin-Oriented Modelling framework proposed in our previous study. We
subsequently extend one of the most promising simulators from the evaluated
ones, to facilitate generation of social networks of varied structural
complexity levels. This extension brings us one step closer to a Digital Twin
Oriented SNS (DT Oriented SNS). We also propose an approach to assess the
similarity between real and simulated networks with the composite performance
indexes based on both global and local structural measures, while taking
runtime of the simulator as an indicator of its efficiency. We illustrate
various characteristics of the proposed DT Oriented SNS using a well known
Karate Club network as an example. While not considered to be of sufficient
complexity, the simulator is intended as one of the first steps on a journey
towards building a Digital Twin of a social network that perfectly mimics the
reality.",2023-05-05,"Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial"
"Structural Group Unfairness: Measurement and Mitigation by means of the
  Effective Resistance","Social networks contribute to the distribution of social capital, defined as
the relationships, norms of trust and reciprocity within a community or society
that facilitate cooperation and collective action. Therefore, better positioned
members in a social network benefit from faster access to diverse information
and higher influence on information dissemination. A variety of methods have
been proposed in the literature to measure social capital at an individual
level. However, there is a lack of methods to quantify social capital at a
group level, which is particularly important when the groups are defined on the
grounds of protected attributes. To fill this gap, we propose to measure the
social capital of a group of nodes by means of the effective resistance and
emphasize the importance of considering the entire network topology. Grounded
in spectral graph theory, we introduce three effective resistance-based
measures of group social capital, namely group isolation, group diameter and
group control, where the groups are defined according to the value of a
protected attribute. We denote the social capital disparity among different
groups in a network as structural group unfairness, and propose to mitigate it
by means of a budgeted edge augmentation heuristic that systematically
increases the social capital of the most disadvantaged group. In experiments on
real-world networks, we uncover significant levels of structural group
unfairness when using gender as the protected attribute, with females being the
most disadvantaged group in comparison to males. We also illustrate how our
proposed edge augmentation approach is able to not only effectively mitigate
the structural group unfairness but also increase the social capital of all
groups in the network.",2023-05-05,"Adrian Arnaiz-Rodriguez, Georgina Curto, Nuria Oliver"
"Cognitive Reframing of Negative Thoughts through Human-Language Model
  Interaction","A proven therapeutic technique to overcome negative thoughts is to replace
them with a more hopeful ""reframed thought."" Although therapy can help people
practice and learn this Cognitive Reframing of Negative Thoughts, clinician
shortages and mental health stigma commonly limit people's access to therapy.
In this paper, we conduct a human-centered study of how language models may
assist people in reframing negative thoughts. Based on psychology literature,
we define a framework of seven linguistic attributes that can be used to
reframe a thought. We develop automated metrics to measure these attributes and
validate them with expert judgements from mental health practitioners. We
collect a dataset of 600 situations, thoughts and reframes from practitioners
and use it to train a retrieval-enhanced in-context learning model that
effectively generates reframed thoughts and controls their linguistic
attributes. To investigate what constitutes a ""high-quality"" reframe, we
conduct an IRB-approved randomized field study on a large mental health website
with over 2,000 participants. Amongst other findings, we show that people
prefer highly empathic or specific reframes, as opposed to reframes that are
overly positive. Our findings provide key implications for the use of LMs to
assist people in overcoming negative thoughts.",2023-05-04,"Ashish Sharma, Kevin Rushton, Inna Wanyin Lin, David Wadden, Khendra G. Lucas, Adam S. Miner, Theresa Nguyen, Tim Althoff"
Heterogeneous message passing for heterogeneous networks,"Message passing (MP) is a computational technique used to find approximate
solutions to a variety of problems defined on networks. MP approximations are
generally accurate in locally tree-like networks but require corrections to
maintain their accuracy level in networks rich with short cycles. However, MP
may already be computationally challenging on very large networks and
additional costs incurred by correcting for cycles could be prohibitive. We
show how the issue can be addressed. By allowing each node in the network to
have its own level of approximation, one can focus on improving the accuracy of
MP approaches in a targeted manner. We perform a systematic analysis of 109
real-world networks and show that our node-based MP approximation is able to
increase both the accuracy and speed of traditional MP approaches. We find
that, compared to conventional MP, a heterogeneous approach based on a simple
heuristic is more accurate in 81% of tested networks, faster in 64% of cases,
and both more accurate and faster in 49% of cases.",2023-05-03,"George T. Cantwell, Alec Kirkley, Filippo Radicchi"
Stochastic cellular automaton model of culture formation,"We introduce a stochastic cellular automaton as a model for culture and
border formation. The model can be conceptualized as a game where the expansion
rate of cultures is quantified in terms of their area and perimeter in such a
way that approximately geometrically round cultures get a competitive
advantage. We first analyse the model with periodic boundary conditions, where
we study how the model can end up in a fixed state, i.e. freezes. Then we
implement the model on the European geography with mountains and rivers. We see
how the model reproduces some qualitative features of European culture
formation, namely that rivers and mountains are more frequently borders between
cultures, mountainous regions tend to have higher cultural diversity and the
central European plain has less clear cultural borders.",2023-05-03,"Frederik Ravn Klausen, Asbjørn Bækgaard Lauritsen"
Temporal Betweenness Centrality on Shortest Walks Variants,"Betweenness centrality has been extensively studied since its introduction in
1977 as a measure of node importance in graphs. This measure has found use in
various applications and has been extended to temporal graphs with time-labeled
edges. Recent research by Buss et al. and Rymar et al. has shown that it is
possible to compute the shortest path betweenness centrality of all nodes in a
temporal graph in $O(n^3\,T^2)$ and $O(n^2\,m\,T^2)$ time, respectively, where
$T$ is the maximum time, $m$ is the number of temporal edges, and $n$ is the
number of nodes. These approaches considered paths that do not take into
account contributions from intermediate temporal nodes.
  In this paper, we study the classical temporal betweenness centrality paths
that we call \textit{passive} shortest paths, as well as an alternative variant
that we call \textit{active} shortest paths, which takes into account
contributions from all temporal nodes. We present an improved analysis of the
running time of the classical algorithm for computing betweenness centrality of
all nodes, reducing the time complexity to $O(n\,m\,T+ n^2\,T)$. Furthermore,
for active paths, we show that the betweenness centrality can be computed in
$O(n\,m\,T+ n^2\,T^2)$. We also show that our results hold for different
shortest paths variants.
  Finally, we provide an open-source implementation of our algorithms and
conduct experiments on several real-world datasets. We compare the results of
the two variants on both the node and time dimensions of the temporal graph,
and we also compare the temporal betweenness centrality to its static
counterpart. Our experiments suggest that for the shortest foremost variant
looking only at the first $10\%$ of the temporal interaction is a very good
approximation for the overall top ranked nodes.",2023-05-01,Mehdi Naima
"Behavioral Forensics in Social Networks: Identifying Misinformation,
  Disinformation and Refutation Spreaders Using Machine Learning","With the ever-increasing spread of misinformation on online social networks,
it has become very important to identify the spreaders of misinformation
(unintentional), disinformation (intentional), and misinformation refutation.
It can help in educating the first, stopping the second, and soliciting the
help of the third category, respectively, in the overall effort to counter
misinformation spread. Existing research to identify spreaders is limited to
binary classification (true vs false information spreaders). However, people's
intention (whether naive or malicious) behind sharing misinformation can only
be understood after observing their behavior after exposure to both the
misinformation and its refutation which the existing literature lacks to
consider. In this paper, we propose a labeling mechanism to label people as one
of the five defined categories based on the behavioral actions they exhibit
when exposed to misinformation and its refutation. However, everyone does not
show behavioral actions but is part of a network. Therefore, we use their
network features, extracted through deep learning-based graph embedding models,
to train a machine learning model for the prediction of the classes. We name
our approach behavioral forensics since it is an evidence-based investigation
of suspicious behavior which is spreading misinformation and disinformation in
our case. After evaluating our proposed model on a real-world Twitter dataset,
we achieved 77.45% precision and 75.80% recall in detecting the malicious
actors, who shared the misinformation even after receiving its refutation. Such
behavior shows intention, and hence these actors can rightfully be called
agents of disinformation spread.",2023-05-01,"Euna Mehnaz Khan, Ayush Ram, Bhavtosh Rath, Emily Vraga, Jaideep Srivastava"
"Deep Graph Representation Learning and Optimization for Influence
  Maximization","Influence maximization (IM) is formulated as selecting a set of initial users
from a social network to maximize the expected number of influenced users.
Researchers have made great progress in designing various traditional methods,
and their theoretical design and performance gain are close to a limit. In the
past few years, learning-based IM methods have emerged to achieve stronger
generalization ability to unknown graphs than traditional ones. However, the
development of learning-based IM methods is still limited by fundamental
obstacles, including 1) the difficulty of effectively solving the objective
function; 2) the difficulty of characterizing the diversified underlying
diffusion patterns; and 3) the difficulty of adapting the solution under
various node-centrality-constrained IM variants. To cope with the above
challenges, we design a novel framework DeepIM to generatively characterize the
latent representation of seed sets, and we propose to learn the diversified
information diffusion pattern in a data-driven and end-to-end manner. Finally,
we design a novel objective function to infer optimal seed sets under flexible
node-centrality-based budget constraints. Extensive analyses are conducted over
both synthetic and real-world datasets to demonstrate the overall performance
of DeepIM. The code and data are available at:
https://github.com/triplej0079/DeepIM.",2023-05-01,"Chen Ling, Junji Jiang, Junxiang Wang, My Thai, Lukas Xue, James Song, Meikang Qiu, Liang Zhao"
Prospects of BRICS currency dominance in international trade,"During his state visit to China in April 2023, Brazilian President Lula
proposed the creation of a trade currency supported by the BRICS countries.
Using the United Nations Comtrade database, providing the frame of the world
trade network associated to 194 UN countries during the decade 2010 - 2020, we
study a mathematical model of influence battle of three currencies, namely, the
US dollar, the euro, and such a hypothetical BRICS currency. In this model, a
country trade preference for one of the three currencies is determined by a
multiplicative factor based on trade flows between countries and their relative
weights in the global international trade. The three currency seed groups are
formed by 9 eurozone countries for the euro, 5 Anglo-Saxon countries for the US
dollar and the 5 BRICS countries for the new proposed currency. The countries
belonging to these 3 currency seed groups trade only with their own associated
currency whereas the other countries choose their preferred trade currency as a
function of the trade relations with their commercial partners. The trade
currency preferences of countries are determined on the basis of a Monte Carlo
modeling of Ising type interactions in magnetic spin systems commonly used to
model opinion formation in social networks. We adapt here these models to the
world trade network analysis. The results obtained from our mathematical
modeling of the structure of the global trade network show that as early as
2012 about 58 percent of countries would have preferred to trade with the BRICS
currency, 23 percent with the euro and 19 percent with the US dollar. Our
results announce favorable prospects for a dominance of the BRICS currency in
international trade, if only trade relations are taken into account, whereas
political and other aspects are neglected.",2023-04-30,"Célestin Coquidé, José Lages, Dima L. Shepelyansky"
"Learning, Diversity and Adaptation in Changing Environments: The Role of
  Weak Links","Adaptation to dynamic conditions requires a certain degree of diversity. If
all agents take the best current action, learning that the underlying state has
changed and behavior should adapt will be slower. Diversity is harder to
maintain when there is fast communication between agents, because they tend to
find out and pursue the best action rapidly. We explore these issues using a
model of (Bayesian) learning over a social network. Agents learn rapidly from
and may also have incentives to coordinate with others to whom they are
connected via strong links. We show, however, that when the underlying
environment changes sufficiently rapidly, any network consisting of just strong
links will do only a little better than random choice in the long run. In
contrast, networks combining strong and weak links, whereby the latter type of
links transmit information only slowly, can achieve much higher long-run
average payoffs. The best social networks are those that combine a large
fraction of agents into a strongly-connected component, while still maintaining
a sufficient number of smaller communities that make diverse choices and
communicate with this component via weak links.",2023-04-30,"Daron Acemoglu, Asuman Ozdaglar, Sarath Pattathil"
Spectral clustering in the Gaussian mixture block model,"Gaussian mixture block models are distributions over graphs that strive to
model modern networks: to generate a graph from such a model, we associate each
vertex $i$ with a latent feature vector $u_i \in \mathbb{R}^d$ sampled from a
mixture of Gaussians, and we add edge $(i,j)$ if and only if the feature
vectors are sufficiently similar, in that $\langle u_i,u_j \rangle \ge \tau$
for a pre-specified threshold $\tau$. The different components of the Gaussian
mixture represent the fact that there may be different types of nodes with
different distributions over features -- for example, in a social network each
component represents the different attributes of a distinct community. Natural
algorithmic tasks associated with these networks are embedding (recovering the
latent feature vectors) and clustering (grouping nodes by their mixture
component).
  In this paper we initiate the study of clustering and embedding graphs
sampled from high-dimensional Gaussian mixture block models, where the
dimension of the latent feature vectors $d\to \infty$ as the size of the
network $n \to \infty$. This high-dimensional setting is most appropriate in
the context of modern networks, in which we think of the latent feature space
as being high-dimensional. We analyze the performance of canonical spectral
clustering and embedding algorithms for such graphs in the case of 2-component
spherical Gaussian mixtures, and begin to sketch out the
information-computation landscape for clustering and embedding in these models.",2023-04-29,"Shuangping Li, Tselil Schramm"
"Popularity Ratio Maximization: Surpassing Competitors through Influence
  Propagation","In this paper, we present an algorithmic study on how to surpass competitors
in popularity by strategic promotions in social networks. We first propose a
novel model, in which we integrate the Preferential Attachment (PA) model for
popularity growth with the Independent Cascade (IC) model for influence
propagation in social networks called PA-IC model. In PA-IC, a popular item and
a novice item grab shares of popularity from the natural popularity growth via
the PA model, while the novice item tries to gain extra popularity via
influence cascade in a social network. The popularity ratio is defined as the
ratio of the popularity measure between the novice item and the popular item.
We formulate Popularity Ratio Maximization (PRM) as the problem of selecting
seeds in multiple rounds to maximize the popularity ratio in the end. We
analyze the popularity ratio and show that it is monotone but not submodular.
To provide an effective solution, we devise a surrogate objective function and
show that empirically it is very close to the original objective function while
theoretically, it is monotone and submodular. We design two efficient
algorithms, one for the overlapping influence and non-overlapping seeds (across
rounds) setting and the other for the non-overlapping influence and overlapping
seed setting, and further discuss how to deal with other models and problem
variants. Our empirical evaluation further demonstrates that the proposed
PRM-IMM method consistently achieves the best popularity promotion compared to
other methods. Our theoretical and empirical analyses shed light on the
interplay between influence maximization and preferential attachment in social
networks.",2023-04-28,"Hao Liao, Sheng Bi, Jiao Wu, Wei Zhang, Mingyang Zhou, Rui Mao, Wei Chen"
Generation and Influence of Eccentric Ideas on Social Networks,"Studying extreme ideas in routine choices and discussions is of utmost
importance to understand the increasing polarization in society. In this study,
we focus on understanding the generation and influence of extreme ideas in
routine conversations which we label ""eccentric"" ideas. The eccentricity of any
idea is defined as the deviation of that idea from the norm of the social
neighborhood. We collected and analyzed data from two completely different
sources: public social media and online experiments in a controlled
environment. We compared the popularity of ideas against their eccentricity to
understand individuals' fascination towards eccentricity. We found that more
eccentric ideas have a higher probability of getting a greater number of
""likes"". Additionally, we demonstrate that the social neighborhood of an
individual conceals eccentricity changes in one's own opinions and facilitates
generation of eccentric ideas at a collective level.",2023-04-27,"Sriniwas Pandey, Yiding Cao, Yingjun Dong, Minjun Kim, Neil G. MacLaren, Shelley D. Dionne, Francis J. Yammarino, Hiroki Sayama"
"communication of information in systems of heterogenious agents and
  systems' dynamics","Communication of information in complex systems can be considered as major
driver of systems evolution. What matters is not the communicated information
by itself but rather the meaning that is supplied to the information. However
informational exchange in a system of heterogenious agents, which code and
decode information with different meaning processing structures, is more
complex than simple input-output model. The structural difference of coding and
decoding algorithms in a system of three or more groups of agents, entertaining
different sets of communication codes,provide a source of additional options
which has an impact on system's dynamics. The mechanisms of meaning and
information processing can be evaluated analytically ion a model framework. The
results show that model predictions acccurately fit empirically observed data
in systems of different origions.",2023-04-27,Inga Ivanova
"Network Analysis as a Tool for Shaping Conservation and Development
  Policy: A Case Study of Timber Market Optimization in India","The incorporation of trees on farms can help to improve livelihoods and build
resilience among small-holder farmers in developing countries. On-farm trees
can help gen- erate additional income from commercial tree harvest as well as
contribute significant environmental benefits and ecosystem services to
increase resiliency. Long-term benefits from tree-based livelihoods, however,
depend on sustainable timber harvesting. In this paper, we discuss the
potential for network analysis as a tool to inform conservation and development
decision-making. Specifically, we formulate the commercial tree market between
farmers and traders as a transportation problem and optimize the transactions.
We create a model of the commercial tree market in the Bilaspur district of
Himachal Pradesh, India based on a detailed dataset of market interactions
between farmers and timber traders, using the existing road network of this
region. Using this model, we perform a maximum-flow-minimum-cost optimization
for tree commodity flow. We compare the results of our optimized model with
actual flow within the network, and we find a high potential to increase
efficiency of market transactions within this region, noting a significant
reduction to the minimum- cost flow value for our optimized model compared to
the flow cost for actual transactions. We propose that using this network flow
optimization model to strategically distribute permits can reduce costs
associated with market transactions. Our results suggest that this direct
policy action would be beneficial to the region. Finally, we suggest that cost
savings could be used to establish tree planting programs to support a
long-term sustainable tree market. Shaping policies to address these market
inefficiencies in developing regions could help support and elevate tree-based
livelihoods for farmers, traders, and industries.",2023-04-27,"Xiou Ge, Sarah E. Brown, Pushpendra Rana, Lav R. Varshney, Daniel C. Miller"
"Rumor Detection with Hierarchical Representation on Bipartite Adhoc
  Event Trees","The rapid growth of social media has caused tremendous effects on information
propagation, raising extreme challenges in detecting rumors. Existing rumor
detection methods typically exploit the reposting propagation of a rumor
candidate for detection by regarding all reposts to a rumor candidate as a
temporal sequence and learning semantics representations of the repost
sequence. However, extracting informative support from the topological
structure of propagation and the influence of reposting authors for debunking
rumors is crucial, which generally has not been well addressed by existing
methods. In this paper, we organize a claim post in circulation as an adhoc
event tree, extract event elements, and convert it to bipartite adhoc event
trees in terms of both posts and authors, i.e., author tree and post tree.
Accordingly, we propose a novel rumor detection model with hierarchical
representation on the bipartite adhoc event trees called BAET. Specifically, we
introduce word embedding and feature encoder for the author and post tree,
respectively, and design a root-aware attention module to perform node
representation. Then we adopt the tree-like RNN model to capture the structural
correlations and propose a tree-aware attention module to learn tree
representation for the author tree and post tree, respectively. Extensive
experimental results on two public Twitter datasets demonstrate the
effectiveness of BAET in exploring and exploiting the rumor propagation
structure and the superior detection performance of BAET over state-of-the-art
baseline methods.",2023-04-27,"Qi Zhang, Yayi Yang, Chongyang Shi, An Lao, Liang Hu, Shoujin Wang, Usman Naseem"
Centrality-Based Node Feature Augmentation for Robust Network Alignment,"Network alignment (NA) is the task of discovering node correspondences across
multiple networks. Although NA methods have achieved remarkable success in a
myriad of scenarios, their effectiveness is not without additional information
such as prior anchor links and/or node features, which may not always be
available due to privacy concerns or access restrictions. To tackle this
challenge, we propose Grad-Align+, a novel NA method built upon a recent
state-of-the-art NA method, the so-called Grad-Align, that gradually discovers
a part of node pairs until all node pairs are found. In designing Grad-Align+,
we account for how to augment node features in the sense of performing the NA
task and how to design our NA method by maximally exploiting the augmented node
features. To achieve this goal, Grad-Align+ consists of three key components:
1) centrality-based node feature augmentation (CNFA), 2) graph neural network
(GNN)-aided embedding similarity calculation alongside the augmented node
features, and 3) gradual NA with similarity calculation using aligned
cross-network neighbor-pairs (ACNs). Through comprehensive experiments, we
demonstrate that Grad-Align+ exhibits (a) the superiority over benchmark NA
methods, (b) empirical validations as well as our theoretical findings to see
the effectiveness of CNFA, (c) the influence of each component, (d) the
robustness to network noises, and (e) the computational efficiency.",2023-04-25,"Jin-Duk Park, Cong Tran, Won-Yong Shin, Xin Cao"
"When Do Graph Neural Networks Help with Node Classification?
  Investigating the Impact of Homophily Principle on Node Distinguishability","Homophily principle, i.e., nodes with the same labels are more likely to be
connected, has been believed to be the main reason for the performance
superiority of Graph Neural Networks (GNNs) over Neural Networks on node
classification tasks. Recent research suggests that, even in the absence of
homophily, the advantage of GNNs still exists as long as nodes from the same
class share similar neighborhood patterns. However, this argument only
considers intra-class Node Distinguishability (ND) but neglects inter-class ND,
which provides incomplete understanding of homophily on GNNs. In this paper, we
first demonstrate such deficiency with examples and argue that an ideal
situation for ND is to have smaller intra-class ND than inter-class ND. To
formulate this idea and study ND deeply, we propose Contextual Stochastic Block
Model for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error
(PBE) and negative generalized Jeffreys divergence, to quantify ND. With the
metrics, we visualize and analyze how graph filters, node degree distributions
and class variances influence ND, and investigate the combined effect of intra-
and inter-class ND. Besides, we discovered the mid-homophily pitfall, which
occurs widely in graph datasets. Furthermore, we verified that, in real-work
tasks, the superiority of GNNs is indeed closely related to both intra- and
inter-class ND regardless of homophily levels. Grounded in this observation, we
propose a new hypothesis-testing based performance metric beyond homophily,
which is non-linear, feature-based and can provide statistical threshold value
for GNNs' the superiority. Experiments indicate that it is significantly more
effective than the existing homophily metrics on revealing the advantage and
disadvantage of graph-aware modes on both synthetic and benchmark real-world
datasets.",2023-04-25,"Sitao Luan, Chenqing Hua, Minkai Xu, Qincheng Lu, Jiaqi Zhu, Xiao-Wen Chang, Jie Fu, Jure Leskovec, Doina Precup"
"Attraction by pairwise coherence explains the emergence of ideological
  sorting","Political polarization has become a growing concern in democratic societies,
as it drives tribal alignments and erodes civic deliberation among citizens.
Given its prevalence across different countries, previous research has sought
to understand under which conditions people tend to endorse extreme opinions.
However, in polarized contexts, citizens not only adopt more extreme views but
also become correlated across issues that are, a priori, seemingly unrelated.
This phenomenon, known as ""ideological sorting"", has been receiving greater
attention in recent years but the micro-level mechanisms underlying its
emergence remain poorly understood. Here, we study the conditions under which a
social dynamic system is expected to become ideologically sorted as a function
of the mechanisms of interaction between its individuals. To this end, we
developed and analyzed a multidimensional agent-based model that incorporates
two mechanisms: homophily (where people tend to interact with those holding
similar opinions) and pairwise-coherence favoritism (where people tend to
interact with ingroups holding politically coherent opinions). We numerically
integrated the model's master equations that perfectly describe the system's
dynamics and found that ideological sorting only emerges in models that include
pairwise-coherence favoritism. We then compared the model's outcomes with
empirical data from 24,035 opinions across 67 topics and found that
pairwise-coherence favoritism is significantly present in datasets that measure
political attitudes but absent across topics not considered related to
politics. Overall, this work combines theoretical approaches from system
dynamics with model-based analyses of empirical data to uncover a potential
mechanism underlying the pervasiveness of ideological sorting.",2023-04-25,"Federico Zimmerman, Lucía Pedraza, Joaquín Navajas, Pablo Balenzuela"
Human intuition as a defense against attribute inference,"Attribute inference - the process of analyzing publicly available data in
order to uncover hidden information - has become a major threat to privacy,
given the recent technological leap in machine learning. One way to tackle this
threat is to strategically modify one's publicly available data in order to
keep one's private information hidden from attribute inference. We evaluate
people's ability to perform this task, and compare it against algorithms
designed for this purpose. We focus on three attributes: the gender of the
author of a piece of text, the country in which a set of photos was taken, and
the link missing from a social network. For each of these attributes, we find
that people's effectiveness is inferior to that of AI, especially when it comes
to hiding the attribute in question. Moreover, when people are asked to modify
the publicly available information in order to hide these attributes, they are
less likely to make high-impact modifications compared to AI. This suggests
that people are unable to recognize the aspects of the data that are critical
to an inference algorithm. Taken together, our findings highlight the
limitations of relying on human intuition to protect privacy in the age of AI,
and emphasize the need for algorithmic support to protect private information
from attribute inference.",2023-04-24,"Marcin Waniek, Navya Suri, Abdullah Zameek, Bedoor AlShebli, Talal Rahwan"
"Understanding Lexical Biases when Identifying Gang-related Social Media
  Communications","Individuals involved in gang-related activity use mainstream social media
including Facebook and Twitter to express taunts and threats as well as grief
and memorializing. However, identifying the impact of gang-related activity in
order to serve community member needs through social media sources has a unique
set of challenges. This includes the difficulty of ethically identifying
training data of individuals impacted by gang activity and the need to account
for a non-standard language style commonly used in the tweets from these
individuals. Our study provides evidence of methods where natural language
processing tools can be helpful in efficiently identifying individuals who may
be in need of community care resources such as counselors, conflict mediators,
or academic/professional training programs. We demonstrate that our binary
logistic classifier outperforms baseline standards in identifying individuals
impacted by gang-related violence using a sample of gang-related tweets
associated with Chicago. We ultimately found that the language of a tweet is
highly relevant and that uses of ``big data'' methods or machine learning
models need to better understand how language impacts the model's performance
and how it discriminates among populations.",2023-04-22,"Dhiraj Murthy, Constantine Caramanis, Koustav Rudra"
Users volatility on Reddit and Voat,"Social media platforms are like giant arenas where users can rely on
different content and express their opinions through likes, comments, and
shares. However, do users welcome different perspectives or only listen to
their preferred narratives? This paper examines how users explore the digital
space and allocate their attention among communities on two social networks,
Voat and Reddit. By analysing a massive dataset of about 215 million comments
posted by about 16 million users on Voat and Reddit in 2019 we find that most
users tend to explore new communities at a decreasing rate, meaning they have a
limited set of preferred groups they visit regularly. Moreover, we provide
evidence that preferred communities of users tend to cover similar topics
throughout the year. We also find that communities have a high turnover of
users, meaning that users come and go frequently showing a high volatility that
strongly departs from a null model simulating users' behaviour.",2023-04-21,"Niccolò Di Marco, Matteo Cinelli, Shayan Alipour, Walter Quattrociocchi"
"Reducing Opinion Echo-Chambers by Intelligent Placement of
  Moderate-Minded Agents","In the era of social media, people frequently share their own opinions online
on various issues and also in the way, get exposed to others' opinions. Be it
for selective exposure of news feed recommendation algorithms or our own
inclination to listen to opinions that support ours, the result is that we get
more and more exposed to opinions closer to ours. Further, any population is
inherently heterogeneous i.e. people will hold a varied range of opinions
regarding a topic and showcase a varied range of openness to get influenced by
others. In this paper, we demonstrate the different behavior put forward by
open- and close-minded agents towards an issue, when allowed to freely intermix
and communicate.
  We have shown that the intermixing among people leads to formation of opinion
echo chambers i.e. a small closed network of people who hold similar opinions
and are not affected by opinions of people outside the network. Echo chambers
are evidently harmful for a society because it inhibits free healthy
communication among all and thus, prevents exchange of opinions, spreads
misinformation and increases extremist beliefs. This calls for reduction in
echo chambers, because a total consensus of opinion is neither possible nor is
welcome. We show that the number of echo chambers depends on the number of
close-minded agents and cannot be lessened by increasing the number of
open-minded agents. We identify certain 'moderate'-minded agents, who possess
the capability of manipulating and reducing the number of echo chambers. The
paper proposes an algorithm for intelligent placement of moderate-minded agents
in the opinion-time spectrum by which the opinion echo chambers can be
maximally reduced. With various experimental setups, we demonstrate that the
proposed algorithm fares well when compared to placement of other agents (open-
or close-minded) and random placement of 'moderate'-minded agents.",2023-04-21,"Prithwish Jana, Romit Roy Choudhury, Niloy Ganguly"
The Death of Renaissance Scientist,"Scholars are often categorized into two types: hedgehogs (specialists), who
focus on working within a specific research field, and foxes (generalists), who
actively contribute to a variety of fields. Despite the familiar anecdotes and
popularity of this distinction, its empirical foundation has remained largely
unexamined. We examine whether the research style of being a fox or a hedgehog
is a stable personal trait or an evolving strategy over a scientist's career.
Analyzing 2.3 million scholars' publication records over a century, we find
that research styles exhibit remarkable stability. Notably, the proportion of
fox-like scientists has dramatically declined in the past century, a phenomenon
we term ""the death of Renaissance scientists."" This decline is particularly
significant as science shifts toward team collaboration. Teams of foxes
consistently outperform teams of hedgehogs in generating new ideas and
directions, as confirmed by two emerging innovation metrics for papers:
atypicality and disruption. Our research is the first to quantify the process
and consequences of the decline of Renaissance scientists. By doing so, we
establish a universal link between research styles, demographic shifts, and
innovative output.",2023-04-21,"Zak Risha, Yiling Lin, Erin Leahey, Lingfei Wu"
"A simplicity bubble problem and zemblanity in digitally intermediated
  societies","In this article, we discuss the ubiquity of Big Data and machine learning in
society and propose that it evinces the need of further investigation of their
fundamental limitations. We extend the ``too much information tends to behave
like very little information'' phenomenon to formal knowledge about lawlike
universes and arbitrary collections of computably generated datasets. This
gives rise to the simplicity bubble problem, which refers to a learning
algorithm equipped with a formal theory that can be deceived by a dataset to
find a locally optimal model which it deems to be the global one. In the
context of lawlike (computable) universes and formal learning systems, we show
that there is a ceiling above which formal knowledge cannot further decrease
the probability of zemblanitous findings, should the randomly generated data
made available to the formal learning system be sufficiently large in
comparison to their joint complexity. Zemblanity, the opposite of serendipity,
is defined by an undesirable but expected finding that reveals an underlying
problem or negative consequence in a given model or theory, which is in
principle predictable in case the formal theory contains sufficient
information. We also argue that this is an epistemological limitation that may
generate unpredictable problems in digitally intermediated societies.",2023-04-21,"Felipe S. Abrahão, Ricardo P. Cavassane, Michael Winter, Mariana Vitti Rodrigues, Itala M. L. D'Ottaviano"
A User-Driven Framework for Regulating and Auditing Social Media,"People form judgments and make decisions based on the information that they
observe. A growing portion of that information is not only provided, but
carefully curated by social media platforms. Although lawmakers largely agree
that platforms should not operate without any oversight, there is little
consensus on how to regulate social media. There is consensus, however, that
creating a strict, global standard of ""acceptable"" content is untenable (e.g.,
in the US, it is incompatible with Section 230 of the Communications Decency
Act and the First Amendment).
  In this work, we propose that algorithmic filtering should be regulated with
respect to a flexible, user-driven baseline. We provide a concrete framework
for regulating and auditing a social media platform according to such a
baseline. In particular, we introduce the notion of a baseline feed: the
content that a user would see without filtering (e.g., on Twitter, this could
be the chronological timeline). We require that the feeds a platform filters
contain ""similar"" informational content as their respective baseline feeds, and
we design a principled way to measure similarity. This approach is motivated by
related suggestions that regulations should increase user agency. We present an
auditing procedure that checks whether a platform honors this requirement.
Notably, the audit needs only black-box access to a platform's filtering
algorithm, and it does not access or infer private user information. We provide
theoretical guarantees on the strength of the audit. We further show that
requiring closeness between filtered and baseline feeds does not impose a large
performance cost, nor does it create echo chambers.",2023-04-20,"Sarah H. Cen, Aleksander Madry, Devavrat Shah"
The Enmity Paradox,"The ""friendship paradox"" of social networks states that, on average, ""your
friends have more friends than you do."" Here, we theoretically and empirically
explore a related and overlooked paradox we refer to as the ""enmity paradox.""
We use empirical data from 24,687 people living in 176 villages in rural
Honduras. We show that, for a real negative undirected network (created by
symmetrizing antagonistic interactions), the paradox exists as it does in the
positive world. Specifically, a person's enemies have more enemies, on average,
than a person does. Furthermore, in a mixed world of positive and negative
ties, we study the conditions for the existence of the paradox, both
theoretically and empirically, finding that, for instance, a person's friends
typically have more enemies than a person does. We also confirm the
""generalized"" enmity paradox for nontopological attributes in real data,
analogous to the generalized friendship paradox (e.g., the claim that a
person's enemies are richer, on average, than a person is). As a consequence,
the naturally occurring variance in the degree distribution of both friendship
and antagonism in social networks can skew people's perceptions of the social
world.",2023-04-20,"Amir Ghasemian, Nicholas A. Christakis"
IMoG -- a methodology for modeling future microelectronic innovations,"[Context and motivation] The automotive industry is currently undergoing a
fundamental transformation towards software defined vehicles. The automotive
market of the future demands a higher level of automation, electrification of
the power train, and individually configurable comfort functions.
[Question/problem] These demands pose a challenge to the automotive development
cycle, because they introduce complexity by larger and not yet well explored
design spaces that are difficult to manage. [Principal ideas/results] To cope
with these challenges, the main players along the value chain have an increased
interest in collaborating and aligning their development efforts along joint
roadmaps. Roadmap development can be viewed as a field of requirements
engineering with the goal to capture product aspects on an appropriate level of
abstraction to speed up investment decisions, reduce communication overhead and
parallelize development activities, while complying with competition laws.
[Contribution] In this paper, we present a refinement of the ""Innovation
Modeling Grid"" (IMoG), which encompasses a methodology, a process and a
proposed notation to support joint analysis of development roadmaps. IMoG is
focused on the automotive domain, yet there are clear potentials for other
applications.",2023-04-18,"Oliver Klemp, Bernd Westphal, Stefan Puch"
"Are footpaths encroached by shared e-scooters? Spatio-temporal Analysis
  of Micro-mobility Services","Micro-mobility services (e.g., e-bikes, e-scooters) are increasingly popular
among urban communities, being a flexible transport option that brings both
opportunities and challenges. As a growing mode of transportation, insights
gained from micro-mobility usage data are valuable in policy formulation and
improving the quality of services. Existing research analyses patterns and
features associated with usage distributions in different localities, and
focuses on either temporal or spatial aspects. In this paper, we employ a
combination of methods that analyse both spatial and temporal characteristics
related to e-scooter trips in a more granular level, enabling observations at
different time frames and local geographical zones that prior analysis wasn't
able to do. The insights obtained from anonymised, restricted data on shared
e-scooter rides show the applicability of the employed method on regulated,
privacy preserving micro-mobility trip data. Our results showed population
density is the topmost important feature, and it associates with e-scooter
usage positively. Population owning motor vehicles is negatively associated
with shared e-scooter trips, suggesting a reduction in e-scooter usage among
motor vehicle owners. Furthermore, we found that the effect of humidity is more
important than precipitation in predicting hourly e-scooter trip count. Buffer
analysis showed, nearly 29% trips were stopped, and 27% trips were started on
the footpath, revealing higher utilisation of footpaths for parking e-scooters
in Melbourne.",2023-04-18,"Hiruni Kegalle, Danula Hettiachchi, Jeffrey Chan, Flora Salim, Mark Sanderson"
"TAP: A Comprehensive Data Repository for Traffic Accident Prediction in
  Road Networks","Road safety is a major global public health concern. Effective traffic crash
prediction can play a critical role in reducing road traffic accidents.
However, Existing machine learning approaches tend to focus on predicting
traffic accidents in isolation, without considering the potential relationships
between different accident locations within road networks. To incorporate graph
structure information, graph-based approaches such as Graph Neural Networks
(GNNs) can be naturally applied. However, applying GNNs to the accident
prediction problem faces challenges due to the lack of suitable
graph-structured traffic accident datasets. To bridge this gap, we have
constructed a real-world graph-based Traffic Accident Prediction (TAP) data
repository, along with two representative tasks: accident occurrence prediction
and accident severity prediction. With nationwide coverage, real-world network
topology, and rich geospatial features, this data repository can be used for a
variety of traffic-related tasks. We further comprehensively evaluate eleven
state-of-the-art GNN variants and two non-graph-based machine learning methods
using the created datasets. Significantly facilitated by the proposed data, we
develop a novel Traffic Accident Vulnerability Estimation via Linkage (TRAVEL)
model, which is designed to capture angular and directional information from
road networks. We demonstrate that the proposed model consistently outperforms
the baselines. The data and code are available on GitHub
(https://github.com/baixianghuang/travel).",2023-04-17,"Baixiang Huang, Bryan Hooi, Kai Shu"
Stochastic Subgraph Neighborhood Pooling for Subgraph Classification,"Subgraph classification is an emerging field in graph representation learning
where the task is to classify a group of nodes (i.e., a subgraph) within a
graph. Subgraph classification has applications such as predicting the cellular
function of a group of proteins or identifying rare diseases given a collection
of phenotypes. Graph neural networks (GNNs) are the de facto solution for node,
link, and graph-level tasks but fail to perform well on subgraph classification
tasks. Even GNNs tailored for graph classification are not directly
transferable to subgraph classification as they ignore the external topology of
the subgraph, thus failing to capture how the subgraph is located within the
larger graph. The current state-of-the-art models for subgraph classification
address this shortcoming through either labeling tricks or multiple
message-passing channels, both of which impose a computation burden and are not
scalable to large graphs. To address the scalability issue while maintaining
generalization, we propose Stochastic Subgraph Neighborhood Pooling (SSNP),
which jointly aggregates the subgraph and its neighborhood (i.e., external
topology) information without any computationally expensive operations such as
labeling tricks. To improve scalability and generalization further, we also
propose a simple data augmentation pre-processing step for SSNP that creates
multiple sparse views of the subgraph neighborhood. We show that our model is
more expressive than GNNs without labeling tricks. Our extensive experiments
demonstrate that our models outperform current state-of-the-art methods (with a
margin of up to 2%) while being up to 3X faster in training.",2023-04-17,"Shweta Ann Jacob, Paul Louis, Amirali Salehi-Abari"
"Unpacking How Decentralized Autonomous Organizations (DAOs) Work in
  Practice","Decentralized Autonomous Organizations (DAOs) have emerged as a novel way to
coordinate a group of (pseudonymous) entities towards a shared vision (e.g.,
promoting sustainability), utilizing self-executing smart contracts on
blockchains to support decentralized governance and decision-making. In just a
few years, over 4,000 DAOs have been launched in various domains, such as
investment, education, health, and research. Despite such rapid growth and
diversity, it is unclear how these DAOs actually work in practice and to what
extent they are effective in achieving their goals. Given this, we aim to
unpack how (well) DAOs work in practice. We conducted an in-depth analysis of a
diverse set of 10 DAOs of various categories and smart contracts, leveraging
on-chain (e.g., voting results) and off-chain data (e.g., community
discussions) as well as our interviews with DAO organizers/members.
Specifically, we defined metrics to characterize key aspects of DAOs, such as
the degrees of decentralization and autonomy. We observed CompoundDAO,
AssangeDAO, Bankless, and Krausehouse having poor decentralization in voting,
while decentralization has improved over time for one-person-one-vote DAOs
(e.g., Proof of Humanity). Moreover, the degree of autonomy varies among DAOs,
with some (e.g., Compound and Krausehouse) relying more on third parties than
others. Lastly, we offer a set of design implications for future DAO systems
based on our findings.",2023-04-17,"Tanusree Sharma, Yujin Kwon, Kornrapat Pongmala, Henry Wang, Andrew Miller, Dawn Song, Yang Wang"
"Analyzing Activity and Suspension Patterns of Twitter Bots Attacking
  Turkish Twitter Trends by a Longitudinal Dataset","Twitter bots amplify target content in a coordinated manner to make them
appear popular, which is an astroturfing attack. Such attacks promote certain
keywords to push them to Twitter trends to make them visible to a broader
audience. Past work on such fake trends revealed a new astroturfing attack
named ephemeral astroturfing that employs a very unique bot behavior in which
bots post and delete generated tweets in a coordinated manner. As such, it is
easy to mass-annotate such bots reliably, making them a convenient source of
ground truth for bot research. In this paper, we detect and disclose over
212,000 such bots targeting Turkish trends, which we name astrobots. We also
analyze their activity and suspension patterns. We found that Twitter purged
those bots en-masse 6 times since June 2018. However, the adversaries reacted
quickly and deployed new bots that were created years ago. We also found that
many such bots do not post tweets apart from promoting fake trends, which makes
it challenging for bot detection methods to detect them. Our work provides
insights into platforms' content moderation practices and bot detection
research. The dataset is publicly available at
https://github.com/tugrulz/EphemeralAstroturfing.",2023-04-16,Tuğrulcan Elmas
Multi-View Graph Representation Learning Beyond Homophily,"Unsupervised graph representation learning(GRL) aims to distill diverse graph
information into task-agnostic embeddings without label supervision. Due to a
lack of support from labels, recent representation learning methods usually
adopt self-supervised learning, and embeddings are learned by solving a
handcrafted auxiliary task(so-called pretext task). However, partially due to
the irregular non-Euclidean data in graphs, the pretext tasks are generally
designed under homophily assumptions and cornered in the low-frequency signals,
which results in significant loss of other signals, especially high-frequency
signals widespread in graphs with heterophily. Motivated by this limitation, we
propose a multi-view perspective and the usage of diverse pretext tasks to
capture different signals in graphs into embeddings. A novel framework, denoted
as Multi-view Graph Encoder(MVGE), is proposed, and a set of key designs are
identified. More specifically, a set of new pretext tasks are designed to
encode different types of signals, and a straightforward operation is
propxwosed to maintain both the commodity and personalization in both the
attribute and the structural levels. Extensive experiments on synthetic and
real-world network datasets show that the node representations learned with
MVGE achieve significant performance improvements in three different downstream
tasks, especially on graphs with heterophily. Source code is available at
\url{https://github.com/G-AILab/MVGE}.",2023-04-15,"Bei Lin, You Li, Ning Gui, Zhuopeng Xu, Zhiwu Yu"
"On the convergence of nonlinear averaging dynamics with three-body
  interactions on hypergraphs","Complex networked systems in fields such as physics, biology, and social
sciences often involve interactions that extend beyond simple pairwise ones.
Hypergraphs serve as powerful modeling tools for describing and analyzing the
intricate behaviors of systems with multi-body interactions. Herein, we
investigate a discrete-time nonlinear averaging dynamics with three-body
interactions: an underlying hypergraph, comprising triples as hyperedges,
delineates the structure of these interactions, while the vertices update their
states through a weighted, state-dependent average of neighboring pairs'
states. This dynamics captures reinforcing group effects, such as peer
pressure, and exhibits higher-order dynamical effects resulting from a complex
interplay between initial states, hypergraph topology, and nonlinearity of the
update. Differently from linear averaging dynamics on graphs with two-body
interactions, this model does not converge to the average of the initial states
but rather induces a shift. By assuming random initial states and by making
some regularity and density assumptions on the hypergraph, we prove that the
dynamics converges to a multiplicatively-shifted average of the initial states,
with high probability. We further characterize the shift as a function of two
parameters describing the initial state and interaction strength, as well as
the convergence time as a function of the hypergraph structure.",2023-04-14,"Emilio Cruciani, Emanuela L. Giacomelli, Jinyeop Lee"
"Divergences in Following Patterns between Influential Twitter Users and
  Their Audiences across Dimensions of Identity","Identity spans multiple dimensions; however, the relative salience of a
dimension of identity can vary markedly from person to person. Furthermore,
there is often a difference between one's internal identity (how salient
different aspects of one's identity are to oneself) and external identity (how
salient different aspects are to the external world). We attempt to capture the
internal and external saliences of different dimensions of identity for
influential users (""influencers"") on Twitter using the follow graph. We
consider an influencer's ""ego-centric"" profile, which is determined by their
personal following patterns and is largely in their direct control, and their
""audience-centric"" profile, which is determined by the following patterns of
their audience and is outside of their direct control. Using these following
patterns we calculate a corresponding salience metric that quantifies how
important a certain dimension of identity is to an individual. We find that
relative to their audiences, influencers exhibit more salience in race in their
ego-centric profiles and less in religion and politics. One practical
application of these findings is to identify ""bridging"" influencers that can
connect their sizeable audiences to people from traditionally underheard
communities. This could potentially increase the diversity of views audiences
are exposed to through a trusted conduit (i.e. an influencer they already
follow) and may lead to a greater voice for influencers from communities of
color or women.",2023-04-14,"Suyash Fulay, Nabeel Gillani, Deb Roy"
Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter,"Vaccine hesitancy continues to be a main challenge for public health
officials during the COVID-19 pandemic. As this hesitancy undermines vaccine
campaigns, many researchers have sought to identify its root causes, finding
that the increasing volume of anti-vaccine misinformation on social media
platforms is a key element of this problem. We explored Twitter as a source of
misleading content with the goal of extracting overlapping cultural and
political beliefs that motivate the spread of vaccine misinformation. To do
this, we have collected a data set of vaccine-related Tweets and annotated them
with the help of a team of annotators with a background in communications and
journalism. Ultimately we hope this can lead to effective and targeted public
health communication strategies for reaching individuals with anti-vaccine
beliefs. Moreover, this information helps with developing Machine Learning
models to automatically detect vaccine misinformation posts and combat their
negative impacts. In this paper, we present Vax-Culture, a novel Twitter
COVID-19 dataset consisting of 6373 vaccine-related tweets accompanied by an
extensive set of human-provided annotations including vaccine-hesitancy stance,
indication of any misinformation in tweets, the entities criticized and
supported in each tweet and the communicated message of each tweet. Moreover,
we define five baseline tasks including four classification and one sequence
generation tasks, and report the results of a set of recent transformer-based
models for them. The dataset and code are publicly available at
https://github.com/mrzarei5/Vax-Culture.",2023-04-13,"Mohammad Reza Zarei, Michael Christensen, Sarah Everts, Majid Komeili"
"BotMoE: Twitter Bot Detection with Community-Aware Mixtures of
  Modal-Specific Experts","Twitter bot detection has become a crucial task in efforts to combat online
misinformation, mitigate election interference, and curb malicious propaganda.
However, advanced Twitter bots often attempt to mimic the characteristics of
genuine users through feature manipulation and disguise themselves to fit in
diverse user communities, posing challenges for existing Twitter bot detection
models. To this end, we propose BotMoE, a Twitter bot detection framework that
jointly utilizes multiple user information modalities (metadata, textual
content, network structure) to improve the detection of deceptive bots.
Furthermore, BotMoE incorporates a community-aware Mixture-of-Experts (MoE)
layer to improve domain generalization and adapt to different Twitter
communities. Specifically, BotMoE constructs modal-specific encoders for
metadata features, textual content, and graphical structure, which jointly
model Twitter users from three modal-specific perspectives. We then employ a
community-aware MoE layer to automatically assign users to different
communities and leverage the corresponding expert networks. Finally, user
representations from metadata, text, and graph perspectives are fused with an
expert fusion layer, combining all three modalities while measuring the
consistency of user information. Extensive experiments demonstrate that BotMoE
significantly advances the state-of-the-art on three Twitter bot detection
benchmarks. Studies also confirm that BotMoE captures advanced and evasive
bots, alleviates the reliance on training data, and better generalizes to new
and previously unseen user communities.",2023-04-13,"Yuhan Liu, Zhaoxuan Tan, Heng Wang, Shangbin Feng, Qinghua Zheng, Minnan Luo"
"Hyperbolic Geometric Graph Representation Learning for
  Hierarchy-imbalance Node Classification","Learning unbiased node representations for imbalanced samples in the graph
has become a more remarkable and important topic. For the graph, a significant
challenge is that the topological properties of the nodes (e.g., locations,
roles) are unbalanced (topology-imbalance), other than the number of training
labeled nodes (quantity-imbalance). Existing studies on topology-imbalance
focus on the location or the local neighborhood structure of nodes, ignoring
the global underlying hierarchical properties of the graph, i.e., hierarchy. In
the real-world scenario, the hierarchical structure of graph data reveals
important topological properties of graphs and is relevant to a wide range of
applications. We find that training labeled nodes with different hierarchical
properties have a significant impact on the node classification tasks and
confirm it in our experiments. It is well known that hyperbolic geometry has a
unique advantage in representing the hierarchical structure of graphs.
Therefore, we attempt to explore the hierarchy-imbalance issue for node
classification of graph neural networks with a novelty perspective of
hyperbolic geometry, including its characteristics and causes. Then, we propose
a novel hyperbolic geometric hierarchy-imbalance learning framework, named
HyperIMBA, to alleviate the hierarchy-imbalance issue caused by uneven
hierarchy-levels and cross-hierarchy connectivity patterns of labeled
nodes.Extensive experimental results demonstrate the superior effectiveness of
HyperIMBA for hierarchy-imbalance node classification tasks.",2023-04-11,"Xingcheng Fu, Yuecen Wei, Qingyun Sun, Haonan Yuan, Jia Wu, Hao Peng, Jianxin Li"
"Effects of Algorithmic Trend Promotion: Evidence from Coordinated
  Campaigns in Twitter's Trending Topics","In addition to more personalized content feeds, some leading social media
platforms give a prominent role to content that is more widely popular. On
Twitter, ""trending topics"" identify popular topics of conversation on the
platform, thereby promoting popular content which users might not have
otherwise seen through their network. Hence, ""trending topics"" potentially play
important roles in influencing the topics users engage with on a particular
day. Using two carefully constructed data sets from India and Turkey, we study
the effects of a hashtag appearing on the trending topics page on the number of
tweets produced with that hashtag. We specifically aim to answer the question:
How many new tweeting using that hashtag appear because a hashtag is labeled as
trending? We distinguish the effects of the trending topics page from network
exposure and find there is a statistically significant, but modest, return to a
hashtag being featured on trending topics. Analysis of the types of users
impacted by trending topics shows that the feature helps less popular and new
users to discover and spread content outside their network, which they
otherwise might not have been able to do.",2023-04-08,"Joseph Schlessinger, Kiran Garimella, Maurice Jakesch, Dean Eckles"
Contrastive Cross-Domain Sequential Recommendation,"Cross-Domain Sequential Recommendation (CDSR) aims to predict future
interactions based on user's historical sequential interactions from multiple
domains. Generally, a key challenge of CDSR is how to mine precise cross-domain
user preference based on the intra-sequence and inter-sequence item
interactions. Existing works first learn single-domain user preference only
with intra-sequence item interactions, and then build a transferring module to
obtain cross-domain user preference. However, such a pipeline and implicit
solution can be severely limited by the bottleneck of the designed transferring
module, and ignores to consider inter-sequence item relationships. In this
paper, we propose C^2DSR to tackle the above problems to capture precise user
preferences. The main idea is to simultaneously leverage the intra- and inter-
sequence item relationships, and jointly learn the single- and cross- domain
user preferences. Specifically, we first utilize a graph neural network to mine
inter-sequence item collaborative relationship, and then exploit sequential
attentive encoder to capture intra-sequence item sequential relationship. Based
on them, we devise two different sequential training objectives to obtain user
single-domain and cross-domain representations. Furthermore, we present a novel
contrastive cross-domain infomax objective to enhance the correlation between
single- and cross- domain user representations by maximizing their mutual
information. To validate the effectiveness of C^2DSR, we first re-split four
e-comerce datasets, and then conduct extensive experiments to demonstrate the
effectiveness of our approach C^2DSR.",2023-04-08,"Jiangxia Cao, Xin Cong, Jiawei Sheng, Tingwen Liu, Bin Wang"
Clique Densification in Networks,"Real-world networks are rarely static. Recently, there has been increasing
interest in both network growth and network densification, in which the number
of edges scales superlinearly with the number of nodes. Less studied but
equally important, however, are scaling laws of higher-order cliques, which can
drive clustering and network redundancy. In this paper, we study how cliques
grow with network size, by analyzing several empirical networks from emails to
Wikipedia interactions. Our results show superlinear scaling laws whose
exponents increase with clique size, in contrast to predictions from a previous
model. We then show that these results are in qualitative agreement with a new
model that we propose, the Local Preferential Attachment Model, where an
incoming node links not only to a target node but also to its higher-degree
neighbors. Our results provide new insights into how networks grow and where
network redundancy occurs.",2023-04-07,"Haochen Pi, Keith Burghardt, Allon G. Percus, Kristina Lerman"
Large-Scale Analysis of New Employee Network Dynamics,"The COVID-19 pandemic has accelerated digital transformations across
industries, but also introduced new challenges into workplaces, including the
difficulties of effectively socializing with colleagues when working remotely.
This challenge is exacerbated for new employees who need to develop workplace
networks from the outset. In this paper, by analyzing a large-scale telemetry
dataset of more than 10,000 Microsoft employees who joined the company in the
first three months of 2022, we describe how new employees interact and
telecommute with their colleagues during their ``onboarding'' period. Our
results reveal that although new hires are gradually expanding networks over
time, there still exists significant gaps between their network statistics and
those of tenured employees even after the six-month onboarding phase. We also
observe that heterogeneity exists among new employees in how their networks
change over time, where employees whose job tasks do not necessarily require
extensive and diverse connections could be at a disadvantaged position in this
onboarding process. By investigating how web-based people recommendations in
organizational knowledge base facilitate new employees naturally expand their
networks, we also demonstrate the potential of web-based applications for
addressing the aforementioned socialization challenges. Altogether, our
findings provide insights on new employee network dynamics in remote and hybrid
work environments, which may help guide organizational leaders and web
application developers on quantifying and improving the socialization
experiences of new employees in digital workplaces.",2023-04-07,"Yulin Yu, Longqi Yang, Siân Lindley, Mengting Wan"
"How Do US Congress Members Advertise Climate Change: An Analysis Of Ads
  Run On Meta's Platforms","Ensuring transparency and integrity in political communication on climate
change has arguably never been more important than today. Yet we know little
about how politicians focus on, talk about, and portray climate change on
social media. Here we study it from the perspective of political advertisement.
We use Meta's Ad Library to collect 602,546 ads that have been issued by US
Congress members since mid-2018. Out of those only 19,176 (3.2%) are
climate-related. Analyzing this data, we find that Democrats focus
substantially more on climate change than Republicans, with 99.7% of all
climate-related ads stemming from Democratic politicians. In particular, we
find this is driven by a small core of Democratic politicians, where 72% of all
impressions can be attributed to 10 politicians. Interestingly, we find a
significant difference in the average amount of impressions generated per
dollar spent between the two parties. Republicans generate on average 188% more
impressions with their climate ads for the same money spent as Democrats. We
build models to explain the differences and find that demographic factors only
partially explain the variance. Our results demonstrate differences of
climate-related advertisements of US congress members and reveal differences in
advertising characteristics between the two political parties. We anticipate
our work to be a starting point for further studies about climate-related ads
on Meta's platforms.",2023-04-06,"Laurenz Aisenpreis, Gustav Gyrst, Vedran Sekara"
Inductive Graph Unlearning,"As a way to implement the ""right to be forgotten"" in machine learning,
\textit{machine unlearning} aims to completely remove the contributions and
information of the samples to be deleted from a trained model without affecting
the contributions of other samples. Recently, many frameworks for machine
unlearning have been proposed, and most of them focus on image and text data.
To extend machine unlearning to graph data, \textit{GraphEraser} has been
proposed. However, a critical issue is that \textit{GraphEraser} is
specifically designed for the transductive graph setting, where the graph is
static and attributes and edges of test nodes are visible during training. It
is unsuitable for the inductive setting, where the graph could be dynamic and
the test graph information is invisible in advance. Such inductive capability
is essential for production machine learning systems with evolving graphs like
social media and transaction networks. To fill this gap, we propose the
\underline{{\bf G}}\underline{{\bf U}}ided \underline{{\bf I}}n\underline{{\bf
D}}uctiv\underline{{\bf E}} Graph Unlearning framework (GUIDE). GUIDE consists
of three components: guided graph partitioning with fairness and balance,
efficient subgraph repair, and similarity-based aggregation. Empirically, we
evaluate our method on several inductive benchmarks and evolving transaction
graphs. Generally speaking, GUIDE can be efficiently implemented on the
inductive graph learning tasks for its low graph partition cost, no matter on
computation or structure information. The code will be available here:
https://github.com/Happy2Git/GUIDE.",2023-04-06,"Cheng-Long Wang, Mengdi Huai, Di Wang"
GIF: A General Graph Unlearning Strategy via Influence Function,"With the greater emphasis on privacy and security in our society, the problem
of graph unlearning -- revoking the influence of specific data on the trained
GNN model, is drawing increasing attention. However, ranging from machine
unlearning to recently emerged graph unlearning methods, existing efforts
either resort to retraining paradigm, or perform approximate erasure that fails
to consider the inter-dependency between connected neighbors or imposes
constraints on GNN structure, therefore hard to achieve satisfying
performance-complexity trade-offs.
  In this work, we explore the influence function tailored for graph
unlearning, so as to improve the unlearning efficacy and efficiency for graph
unlearning. We first present a unified problem formulation of diverse graph
unlearning tasks \wrt node, edge, and feature. Then, we recognize the crux to
the inability of traditional influence function for graph unlearning, and
devise Graph Influence Function (GIF), a model-agnostic unlearning method that
can efficiently and accurately estimate parameter changes in response to a
$\epsilon$-mass perturbation in deleted data. The idea is to supplement the
objective of the traditional influence function with an additional loss term of
the influenced neighbors due to the structural dependency. Further deductions
on the closed-form solution of parameter changes provide a better understanding
of the unlearning mechanism. We conduct extensive experiments on four
representative GNN models and three benchmark datasets to justify the
superiority of GIF for diverse graph unlearning tasks in terms of unlearning
efficacy, model utility, and unlearning efficiency. Our implementations are
available at \url{https://github.com/wujcan/GIF-torch/}.",2023-04-06,"Jiancan Wu, Yi Yang, Yuchun Qian, Yongduo Sui, Xiang Wang, Xiangnan He"
"Unveiling the Dynamics of Censorship, COVID-19 Regulations, and Protest:
  An Empirical Study of Chinese Subreddit r/china_irl","The COVID-19 pandemic has intensified numerous social issues that warrant
academic investigation. Although information dissemination has been extensively
studied, the silenced voices and censored content also merit attention due to
their role in mobilizing social movements. In this paper, we provide empirical
evidence to explore the relationships among COVID-19 regulations, censorship,
and protest through a series of social incidents occurred in China during 2022.
We analyze the similarities and differences between censored articles and
discussions on r/china\_irl, the most popular Chinese-speaking subreddit, and
scrutinize the temporal dynamics of government censorship activities and their
impact on user engagement within the subreddit. Furthermore, we examine users'
linguistic patterns under the influence of a censorship-driven environment. Our
findings reveal patterns in topic recurrence, the complex interplay between
censorship activities, user subscription, and collective commenting behavior,
as well as potential linguistic adaptation strategies to circumvent censorship.
These insights hold significant implications for researchers interested in
understanding the survival mechanisms of marginalized groups within censored
information ecosystems.",2023-04-06,"Siyi Zhou, Luca Luceri, Emilio Ferrara"
"A Post-Training Framework for Improving Heterogeneous Graph Neural
  Networks","Recent years have witnessed the success of heterogeneous graph neural
networks (HGNNs) in modeling heterogeneous information networks (HINs). In this
paper, we focus on the benchmark task of HGNNs, i.e., node classification, and
empirically find that typical HGNNs are not good at predicting the label of a
test node whose receptive field (1) has few training nodes from the same
category or (2) has multiple training nodes from different categories. A
possible explanation is that their message passing mechanisms may involve
noises from different categories, and cannot fully explore task-specific
knowledge such as the label dependency between distant nodes. Therefore,
instead of introducing a new HGNN model, we propose a general post-training
framework that can be applied on any pretrained HGNNs to further inject
task-specific knowledge and enhance their prediction performance. Specifically,
we first design an auxiliary system that estimates node labels based on (1) a
global inference module of multi-channel label propagation and (2) a local
inference module of network schema-aware prediction. The mechanism of our
auxiliary system can complement the pretrained HGNNs by providing extra
task-specific knowledge. During the post-training process, we will strengthen
both system-level and module-level consistencies to encourage the cooperation
between a pretrained HGNN and our auxiliary system. In this way, both systems
can learn from each other for better performance. In experiments, we apply our
framework to four typical HGNNs. Experimental results on three benchmark
datasets show that compared with pretrained HGNNs, our post-training framework
can enhance Micro-F1 by a relative improvement of 3.9% on average. Code, data
and appendix are available at https://github.com/GXM1141/HGPF.",2023-04-03,"Cheng Yang, Xumeng Gong, Chuan Shi, Philip S. Yu"
Graph Mining for Cybersecurity: A Survey,"The explosive growth of cyber attacks nowadays, such as malware, spam, and
intrusions, caused severe consequences on society. Securing cyberspace has
become an utmost concern for organizations and governments. Traditional Machine
Learning (ML) based methods are extensively used in detecting cyber threats,
but they hardly model the correlations between real-world cyber entities. In
recent years, with the proliferation of graph mining techniques, many
researchers investigated these techniques for capturing correlations between
cyber entities and achieving high performance. It is imperative to summarize
existing graph-based cybersecurity solutions to provide a guide for future
studies. Therefore, as a key contribution of this paper, we provide a
comprehensive review of graph mining for cybersecurity, including an overview
of cybersecurity tasks, the typical graph mining techniques, and the general
process of applying them to cybersecurity, as well as various solutions for
different cybersecurity tasks. For each task, we probe into relevant methods
and highlight the graph types, graph approaches, and task levels in their
modeling. Furthermore, we collect open datasets and toolkits for graph-based
cybersecurity. Finally, we outlook the potential directions of this field for
future research.",2023-04-02,"Bo Yan, Cheng Yang, Chuan Shi, Yong Fang, Qi Li, Yanfang Ye, Junping Du"
"Social Honeypot for Humans: Luring People through Self-managed Instagram
  Pages","Social Honeypots are tools deployed in Online Social Networks (OSN) to
attract malevolent activities performed by spammers and bots. To this end,
their content is designed to be of maximum interest to malicious users.
However, by choosing an appropriate content topic, this attractive mechanism
could be extended to any OSN users, rather than only luring malicious actors.
As a result, honeypots can be used to attract individuals interested in a wide
range of topics, from sports and hobbies to more sensitive subjects like
political views and conspiracies. With all these individuals gathered in one
place, honeypot owners can conduct many analyses, from social to marketing
studies.
  In this work, we introduce a novel concept of social honeypot for attracting
OSN users interested in a generic target topic. We propose a framework based on
fully-automated content generation strategies and engagement plans to mimic
legit Instagram pages. To validate our framework, we created 21 self-managed
social honeypots (i.e., pages) on Instagram, covering three topics, four
content generation strategies, and three engaging plans. In nine weeks, our
honeypots gathered a total of 753 followers, 5387 comments, and 15739 likes.
These results demonstrate the validity of our approach, and through statistical
analysis, we examine the characteristics of effective social honeypots.",2023-03-31,"Sara Bardi, Mauro Conti, Luca Pajola, Pier Paolo Tricomi"
FairGen: Towards Fair Graph Generation,"There have been tremendous efforts over the past decades dedicated to the
generation of realistic graphs in a variety of domains, ranging from social
networks to computer networks, from gene regulatory networks to online
transaction networks. Despite the remarkable success, the vast majority of
these works are unsupervised in nature and are typically trained to minimize
the expected graph reconstruction loss, which would result in the
representation disparity issue in the generated graphs, i.e., the protected
groups (often minorities) contribute less to the objective and thus suffer from
systematically higher errors. In this paper, we aim to tailor graph generation
to downstream mining tasks by leveraging label information and user-preferred
parity constraints. In particular, we start from the investigation of
representation disparity in the context of graph generative models. To mitigate
the disparity, we propose a fairness-aware graph generative model named
FairGen. Our model jointly trains a label-informed graph generation module and
a fair representation learning module by progressively learning the behaviors
of the protected and unprotected groups, from the `easy' concepts to the `hard'
ones. In addition, we propose a generic context sampling strategy for graph
generative models, which is proven to be capable of fairly capturing the
contextual information of each group with a high probability. Experimental
results on seven real-world data sets, including web-based graphs, demonstrate
that FairGen (1) obtains performance on par with state-of-the-art graph
generative models across nine network properties, (2) mitigates the
representation disparity issues in the generated graphs, and (3) substantially
boosts the model performance by up to 17% in downstream tasks via data
augmentation.",2023-03-30,"Lecheng Zheng, Dawei Zhou, Hanghang Tong, Jiejun Xu, Yada Zhu, Jingrui He"
"Taureau: A Stock Market Movement Inference Framework Based on Twitter
  Sentiment Analysis","With the advent of fast-paced information dissemination and retrieval, it has
become inherently important to resort to automated means of predicting stock
market prices. In this paper, we propose Taureau, a framework that leverages
Twitter sentiment analysis for predicting stock market movement. The aim of our
research is to determine whether Twitter, which is assumed to be representative
of the general public, can give insight into the public perception of a
particular company and has any correlation to that company's stock price
movement. We intend to utilize this correlation to predict stock price
movement. We first utilize Tweepy and getOldTweets to obtain historical tweets
indicating public opinions for a set of top companies during periods of major
events. We filter and label the tweets using standard programming libraries. We
then vectorize and generate word embedding from the obtained tweets. Afterward,
we leverage TextBlob, a state-of-the-art sentiment analytics engine, to assess
and quantify the users' moods based on the tweets. Next, we correlate the
temporal dimensions of the obtained sentiment scores with monthly stock price
movement data. Finally, we design and evaluate a predictive model to forecast
stock price movement from lagged sentiment scores. We evaluate our framework
using actual stock price movement data to assess its ability to predict
movement direction.",2023-03-30,"Nicholas Milikich, Joshua Johnson"
"Matrix Product Belief Propagation for reweighted stochastic dynamics
  over graphs","Stochastic processes on graphs can describe a great variety of phenomena
ranging from neural activity to epidemic spreading. While many existing methods
can accurately describe typical realizations of such processes, computing
properties of extremely rare events is a hard task. Particularly so in the case
of recurrent models, in which variables may return to a previously visited
state. Here, we build on the matrix product cavity method, extending it
fundamentally in two directions: first, we show how it can be applied to Markov
processes biased by arbitrary reweighting factors that concentrate most of the
probability mass on rare events. Second, we introduce an efficient scheme to
reduce the computational cost of a single node update from exponential to
polynomial in the node degree. Two applications are considered: inference of
infection probabilities from sparse observations within the SIRS epidemic
model, and the computation of both typical observables and large deviations of
several kinetic Ising models.",2023-03-30,"Stefano Crotti, Alfredo Braunstein"
"Who You Play Affects How You Play: Predicting Sports Performance Using
  Graph Attention Networks With Temporal Convolution","This study presents a novel deep learning method, called GATv2-GCN, for
predicting player performance in sports. To construct a dynamic player
interaction graph, we leverage player statistics and their interactions during
gameplay. We use a graph attention network to capture the attention that each
player pays to each other, allowing for more accurate modeling of the dynamic
player interactions. To handle the multivariate player statistics time series,
we incorporate a temporal convolution layer, which provides the model with
temporal predictive power. We evaluate the performance of our model using
real-world sports data, demonstrating its effectiveness in predicting player
performance. Furthermore, we explore the potential use of our model in a sports
betting context, providing insights into profitable strategies that leverage
our predictive power. The proposed method has the potential to advance the
state-of-the-art in player performance prediction and to provide valuable
insights for sports analytics and betting industries.",2023-03-29,"Rui Luo, Vikram Krishnamurthy"
Emotional Framing in the Spreading of False and True Claims,"The explosive growth of online misinformation, such as false claims, has
affected the social behavior of online users. In order to be persuasive and
mislead the audience, false claims are made to trigger emotions in their
audience. This paper contributes to understanding how misinformation in social
media is shaped by investigating the emotional framing that authors of the
claims try to create for their audience. We investigate how, firstly, the
existence of emotional framing in the claims depends on the topic and
credibility of the claims. Secondly, we explore how emotionally framed content
triggers emotional response posts by social media users, and how emotions
expressed in claims and corresponding users' response posts affect their
sharing behavior on social media. Analysis of four data sets covering different
topics (politics, health, Syrian war, and COVID-19) reveals that authors shape
their claims depending on the topic area to pass targeted emotions to their
audience. By analysing responses to claims, we show that the credibility of the
claim influences the distribution of emotions that the claim incites in its
audience. Moreover, our analysis shows that emotions expressed in the claims
are repeated in the users' responses. Finally, the analysis of users' sharing
behavior shows that negative emotional framing such as anger, fear, and sadness
of false claims leads to more interaction among users than positive emotions.
This analysis also reveals that in the claims that trigger happy responses,
true claims result in more sharing compared to false claims.",2023-03-29,"Akram Sadat Hosseini, Steffen Staab"
Topological Point Cloud Clustering,"We present Topological Point Cloud Clustering (TPCC), a new method to cluster
points in an arbitrary point cloud based on their contribution to global
topological features. TPCC synthesizes desirable features from spectral
clustering and topological data analysis and is based on considering the
spectral properties of a simplicial complex associated to the considered point
cloud. As it is based on considering sparse eigenvector computations, TPCC is
similarly easy to interpret and implement as spectral clustering. However, by
focusing not just on a single matrix associated to a graph created from the
point cloud data, but on a whole set of Hodge-Laplacians associated to an
appropriately constructed simplicial complex, we can leverage a far richer set
of topological features to characterize the data points within the point cloud
and benefit from the relative robustness of topological techniques against
noise. We test the performance of TPCC on both synthetic and real-world data
and compare it with classical spectral clustering.",2023-03-29,"Vincent P. Grande, Michael T. Schaub"
"Using Semantic Similarity and Text Embedding to Measure the Social Media
  Echo of Strategic Communications","Online discourse covers a wide range of topics and many actors tailor their
content to impact online discussions through carefully crafted messages and
targeted campaigns. Yet the scale and diversity of online media content make it
difficult to evaluate the impact of a particular message. In this paper, we
present a new technique that leverages semantic similarity to quantify the
change in the discussion after a particular message has been published. We use
a set of press releases from environmental organisations and tweets from the
climate change debate to show that our novel approach reveals a heavy-tailed
distribution of response in online discourse to strategic communications.",2023-03-29,"Tristan J. B. Cann, Ben Dennes, Travis Coan, Saffron O'Neill, Hywel T. P. Williams"
"Canary in Twitter Mine: Collecting Phishing Reports from Experts and
  Non-experts","The rise in phishing attacks via e-mail and short message service (SMS) has
not slowed down at all. The first thing we need to do to combat the
ever-increasing number of phishing attacks is to collect and characterize more
phishing cases that reach end users. Without understanding these
characteristics, anti-phishing countermeasures cannot evolve. In this study, we
propose an approach using Twitter as a new observation point to immediately
collect and characterize phishing cases via e-mail and SMS that evade
countermeasures and reach users. Specifically, we propose CrowdCanary, a system
capable of structurally and accurately extracting phishing information (e.g.,
URLs and domains) from tweets about phishing by users who have actually
discovered or encountered it. In our three months of live operation,
CrowdCanary identified 35,432 phishing URLs out of 38,935 phishing reports,
31,960 (90.2%) of these phishing URLs were later detected by the anti-virus
engine. We analyzed users who shared phishing threats by categorizing them into
two groups: experts and non-experts. As a results, we discovered that
CrowdCanary extracts non-expert report-specific information, like company brand
name in tweets, phishing attack details from tweet images, and pre-redirect
landing page information.",2023-03-28,"Hiroki Nakano, Daiki Chiba, Takashi Koide, Naoki Fukushi, Takeshi Yagi, Takeo Hariu, Katsunari Yoshioka, Tsutomu Matsumoto"
"Not cool, calm or collected: Using emotional language to detect COVID-19
  misinformation","COVID-19 misinformation on social media platforms such as twitter is a threat
to effective pandemic management. Prior works on tweet COVID-19 misinformation
negates the role of semantic features common to twitter such as charged
emotions. Thus, we present a novel COVID-19 misinformation model, which uses
both a tweet emotion encoder and COVID-19 misinformation encoder to predict
whether a tweet contains COVID-19 misinformation. Our emotion encoder was
fine-tuned on a novel annotated dataset and our COVID-19 misinformation encoder
was fine-tuned on a subset of the COVID-HeRA dataset. Experimental results show
superior results using the combination of emotion and misinformation encoders
as opposed to a misinformation classifier alone. Furthermore, extensive result
analysis was conducted, highlighting low quality labels and mismatched label
distributions as key limitations to our study.",2023-03-27,"Gabriel Asher, Phil Bohlman, Karsten Kleyensteuber"
"Stance Inference in Twitter through Graph Convolutional Collaborative
  Filtering Networks with Minimal Supervision","Social Media (SM) has become a stage for people to share thoughts, emotions,
opinions, and almost every other aspect of their daily lives. This abundance of
human interaction makes SM particularly attractive for social sensing.
Especially during polarizing events such as political elections or referendums,
users post information and encourage others to support their side, using
symbols such as hashtags to represent their attitudes. However, many users
choose not to attach hashtags to their messages, use a different language, or
show their position only indirectly. Thus, automatically identifying their
opinions becomes a more challenging task. To uncover these implicit
perspectives, we propose a collaborative filtering model based on Graph
Convolutional Networks that exploits the textual content in messages and the
rich connections between users and topics. Moreover, our approach only requires
a small annotation effort compared to state-of-the-art solutions. Nevertheless,
the proposed model achieves competitive performance in predicting individuals'
stances. We analyze users' attitudes ahead of two constitutional referendums in
Chile in 2020 and 2022. Using two large Twitter datasets, our model achieves
improvements of 3.4% in recall and 3.6% in accuracy over the baselines.",2023-03-27,"Zhiwei Zhou, Erick Elejalde"
Chromatic Community Structure Detection,"The detection of community structure is probably one of the hottest trends in
complex network research as it reveals the internal organization of people,
molecules or processes behind social, biological or computer networks\dots The
issue is to provide a network partition representative of this organization so
that each community presumably gathers nodes sharing a common mission, purpose
or property. Usually the identification is based on the difference between the
connectivity density of the interior and the boundary of a community. Indeed,
nodes sharing a common purpose or property are expected to interact closely.
Although this rule appears mostly relevant, some fundamental scientific
problems like disease module detection highlight the inability to determine
significantly the communities under this connectivity rule. The main reason is
that the connectivity density is not correlated to a shared property or
purpose. Therefore, another paradigm is required for properly formalize this
issue in order to meaningfully detect these communities. In this article we
study the community formation from this new principle. Considering colors
formally figures the shared properties, the issue is thus to maximize group of
nodes with the same color within communities.. We study this novel community
framework by introducing new measurement called \emph{chromarity} assessing the
quality of the community structure regarding this constraint. Next we propose
an algorithm solving the community structure detection based on this new
community formation paradigm.",2023-03-27,Franck Delaplace
Hypergraphx: a library for higher-order network analysis,"From social to biological systems, many real-world systems are characterized
by higher-order, non-dyadic interactions. Such systems are conveniently
described by hypergraphs, where hyperedges encode interactions among an
arbitrary number of units. Here, we present an open-source python library,
hypergraphx (HGX), providing a comprehensive collection of algorithms and
functions for the analysis of higher-order networks. These include different
ways to convert data across distinct higher-order representations, a large
variety of measures of higher-order organization at the local and the
mesoscale, statistical filters to sparsify higher-order data, a wide array of
static and dynamic generative models, and an implementation of different
dynamical processes with higher-order interactions. Our computational framework
is general, and allows to analyse hypergraphs with weighted, directed, signed,
temporal and multiplex group interactions. We provide visual insights on
higher-order data through a variety of different visualization tools. We
accompany our code with an extended higher-order data repository, and
demonstrate the ability of HGX to analyse real-world systems through a
systematic analysis of a social network with higher-order interactions. The
library is conceived as an evolving, community-based effort, which will further
extend its functionalities over the years. Our software is available at
https://github.com/HGX-Team/hypergraphx",2023-03-27,"Quintino Francesco Lotito, Martina Contisciani, Caterina De Bacco, Leonardo Di Gaetano, Luca Gallo, Alberto Montresor, Federico Musciotto, Nicolò Ruggeri, Federico Battiston"
"How creative versus technical constraints affect individual learning in
  an online innovation community","Online innovation communities allow for a search for novel solutions within a
design space bounded by constraints. Past research has focused on the effect of
creative constraints on individual projects, but less is known about how
constraints affect learning from repeated design submissions and the effect of
the technical constraints that are integral to online platforms. How do
creative versus technical constraints affect individual learning in exploring a
design space in online communities? We analyzed ten years of data from an
online innovation community that crowdsourced 136,989 design submissions from
33,813 individuals. We leveraged data from two types of design
contests-creatively constrained and unconstrained-running in parallel on the
platform, and we evaluated a natural experiment where a platform change reduced
technical constraints. We find that creative constraints lead to high rates of
learning only if technical constraints are sufficiently relaxed. Our findings
have implications for the management of creative design work and the downstream
effects of the technical constraints of the information systems that support
online innovation communities.",2023-03-27,"Victor P. Seidel, Christoph Riedl"
A longitudinal study of the top 1% toxic Twitter profiles,"Toxicity is endemic to online social networks including Twitter. It follows a
Pareto like distribution where most of the toxicity is generated by a very
small number of profiles and as such, analyzing and characterizing these toxic
profiles is critical. Prior research has largely focused on sporadic, event
centric toxic content to characterize toxicity on the platform. Instead, we
approach the problem of characterizing toxic content from a profile centric
point of view. We study 143K Twitter profiles and focus on the behavior of the
top 1 percent producers of toxic content on Twitter, based on toxicity scores
of their tweets availed by Perspective API. With a total of 293M tweets,
spanning 16 years of activity, the longitudinal data allow us to reconstruct
the timelines of all profiles involved. We use these timelines to gauge the
behavior of the most toxic Twitter profiles compared to the rest of the Twitter
population. We study the pattern of tweet posting from highly toxic accounts,
based on the frequency and how prolific they are, the nature of hashtags and
URLs, profile metadata, and Botometer scores. We find that the highly toxic
profiles post coherent and well articulated content, their tweets keep to a
narrow theme with lower diversity in hashtags, URLs, and domains, they are
thematically similar to each other, and have a high likelihood of bot like
behavior, likely to have progenitors with intentions to influence, based on
high fake followers score. Our work contributes insight into the top 1 percent
of toxic profiles on Twitter and establishes the profile centric approach to
investigate toxicity on Twitter to be beneficial.",2023-03-26,"Hina Qayyum, Benjamin Zi Hao Zhao, Ian D. Wood, Muhammad Ikram, Mohamed Ali Kaafar, Nicolas Kourtellis"
"Edge Ranking of Graphs in Transportation Networks using a Graph Neural
  Network (GNN)","Many networks, such as transportation, power, and water distribution, can be
represented as graphs. Crucial challenge in graph representations is
identifying the importance of graph edges and their influence on overall
network efficiency and information flow performance. For example, important
edges in a transportation network are those roads that, when affected, will
significantly alter the network's overall efficiency. Commonly used approach to
finding such important edges is ``edge betweenness centrality'' (EBC), an edge
ranking measure to determine the influential edges of the graph based on
connectivity and information spread. Computing the EBC utilizing the common
Brandes algorithm involves calculating the shortest paths for every node pair,
which can be computationally expensive and restrictive, especially for large
graphs. Changes in the graph parameters, e.g., in the edge weight or the
addition and deletion of nodes or edges, require the recalculation of the EBC.
As the main contribution, we propose an approximate method to estimate the EBC
using a Graph Neural Network (GNN), a deep learning-based approach. We show
that it is computationally efficient compared to the conventional method,
especially for large graphs. The proposed method of GNN-based edge ranking is
evaluated on several synthetic graphs and a real-world transportation data set.
We show that this framework can estimate the approximate edge ranking much
faster compared to the conventional method. This approach is inductive, i.e.,
training and testing are performed on different sets of graphs with varying
numbers of nodes and edges. The proposed method is especially suitable for
applications on large-scale networks when edge information is desired, for
example, in urban infrastructure improvement projects, power, and water network
resilience analyses, and optimizing resource allocations in engineering
networks.",2023-03-25,"Debasish Jana, Sven Malama, Sriram Narasimhan, Ertugrul Taciroglu"
"The generation and regulation of public opinion on multiplex social
  networks","The dissemination of information and the development of public opinion are
essential elements of most social media platforms and are often described as
distinct, man-made occurrences. However, what is often disregarded is the
interdependence between these two phenomena. Information dissemination serves
as the foundation for the formation of public opinion, while public opinion, in
turn, drives the spread of information. In our study, we model the
co-evolutionary relationship between information and public opinion on
heterogeneous multiplex networks. This model takes into account a minority of
individuals with steadfast opinions and a majority of individuals with
fluctuating views. Our findings reveal the equilibrium state of public opinion
in this model and a linear relationship between mainstream public opinion and
extreme individuals. Additionally, we propose a strategy for regulating public
opinion by adjusting the positions of extreme groups, which could serve as a
basis for implementing health policies influenced by public opinion.",2023-03-24,"Zhong Zhang, Jian-liang Wu, Cun-quan Qu, Fei Jing"
Soft Skills Centrality in Graduate Studies Offerings,"Is it possible to measure how critical soft skills like leadership or
teamwork are from the viewpoint of graduate studies offerings? This paper
provides a conceptual and methodological framework that introduces the concept
of a bipartite network as a practical way to estimate the importance of soft
skills as socio-emotional abilities trained in graduate studies. We examined
230 graduate programs offered by 49 higher education institutions in Colombia
to estimate the empirical importance of soft skills from the viewpoint of
graduate studies offerings. The results show that: a) graduate programs in
Colombia share 31 soft skills in their intended learning outcomes; b) the
centrality of these skills varies as a function of the graduate program,
although this variation was not statistically significant; and c) while most
central soft skills tend to be those related to creativity (i.e., creation or
generation of ideas or projects), leadership (to lead or teamwork), and
analytical orientation (e.g., evaluating situations and solving problems), less
central were those related to empathy (i.e., understanding others and
acknowledgment of others), ethical thinking, and critical thinking, posing the
question if too much emphasis on most visible skills might imply an unbalance
in the opportunities to enhancing other soft skills such as ethical thinking.",2023-03-23,"María del Pilar García-Chitiva, Juan C. Correa"
"No Love Among Haters: Negative Interactions Reduce Hate Community
  Engagement","While online hate groups pose significant risks to the health of online
platforms and safety of marginalized groups, little is known about what causes
users to become active in hate groups and the effect of social interactions on
furthering their engagement. We address this gap by first developing tools to
find hate communities within Reddit, and then augment 11 subreddits extracted
with 14 known hateful subreddits (25 in total). Using causal inference methods,
we evaluate the effect of replies on engagement in hateful subreddits by
comparing users who receive replies to their first comment (the treatment) to
equivalent control users who do not. We find users who receive replies are less
likely to become engaged in hateful subreddits than users who do not, while the
opposite effect is observed for a matched sample of similar-sized non-hateful
subreddits. Using the Google Perspective API and VADER, we discover that
hateful community first-repliers are more toxic, negative, and attack the
posters more often than non-hateful first-repliers. In addition, we uncover a
negative correlation between engagement and attacks or toxicity of
first-repliers. We simulate the cumulative engagement of hateful and
non-hateful subreddits under the contra-positive scenario of friendly
first-replies, finding that attacks dramatically reduce engagement in hateful
subreddits. These results counter-intuitively imply that, although
under-moderated communities allow hate to fester, the resulting environment is
such that direct social interaction does not encourage further participation,
thus endogenously constraining the harmful role that these communities could
play as recruitment venues for antisocial beliefs.",2023-03-23,"Daniel Hickey, Matheus Schmitz, Daniel Fessler, Paul Smaldino, Goran Muric, Keith Burghardt"
"A Novel Patent Similarity Measurement Methodology: Semantic Distance and
  Technological Distance","Patent similarity analysis plays a crucial role in evaluating the risk of
patent infringement. Nonetheless, this analysis is predominantly conducted
manually by legal experts, often resulting in a time-consuming process. Recent
advances in natural language processing technology offer a promising avenue for
automating this process. However, methods for measuring similarity between
patents still rely on experts manually classifying patents. Due to the recent
development of artificial intelligence technology, a lot of research is being
conducted focusing on the semantic similarity of patents using natural language
processing technology. However, it is difficult to accurately analyze patent
data, which are legal documents representing complex technologies, using
existing natural language processing technologies. To address these
limitations, we propose a hybrid methodology that takes into account
bibliographic similarity, measures the similarity between patents by
considering the semantic similarity of patents, the technical similarity
between patents, and the bibliographic information of patents. Using natural
language processing techniques, we measure semantic similarity based on patent
text and calculate technical similarity through the degree of coexistence of
International patent classification (IPC) codes. The similarity of
bibliographic information of a patent is calculated using the special
characteristics of the patent: citation information, inventor information, and
assignee information. We propose a model that assigns reasonable weights to
each similarity method considered. With the help of experts, we performed
manual similarity evaluations on 420 pairs and evaluated the performance of our
model based on this data. We have empirically shown that our method outperforms
recent natural language processing techniques.",2023-03-23,"Yongmin Yoo, Cheonkam Jeong, Sanguk Gim, Junwon Lee, Zachary Schimke, Deaho Seo"
"Using word embeddings to analyse audience effects and individual
  differences in parenting Subreddits","Human beings adapt their language to the audience they interact with. To
study the impact of audience and gender in a natural setting, we choose a
domain where gender plays a particularly salient role: parenting. We collect
posts from the three popular parenting Subreddits (i.e., topical communities on
Reddit) r/Daddit, r/Mommit, and r/Parenting. These three Subreddits gather
different audiences, respectively, self-identifying as fathers and mothers
(ostensibly single-gender), and parents (explicitly mixed-gender). By selecting
a sample of users who have published on both a single-gender and a mixed-gender
Subreddit, we are able to explore both audience and gender effects. We analyse
posts with word embeddings by adding the username as a token in the corpus.
This way, we are able to compare user-tokens to word-tokens and measure their
similarity. We also investigate individual differences in this context by
comparing users who exhibit significant changes in their behaviour (high
self-monitors) with those who show less variation (low self-monitors). Results
show that r/Parenting users generally discuss a great diversity of topics while
fathers focus more on advising others on educational and family matters.
Mothers in r/Mommit distinguish themselves from other groups by primarily
discussing topics such as medical care, sleep and potty training, and food.
Both mothers and fathers celebrate parenting events and describe or comment on
the physical appearance of their children with a single-gender audience. In
terms of individual differences, we find that, especially on r/Parenting, high
self-monitors tend to conform more to the norms of the Subreddit by discussing
more of the topics associated with the Subreddit. In conclusion, this study
shows how mothers and fathers express different concerns and change their
behaviour for different group-based audiences.",2023-03-22,"Melody Sepahpour-Fard, Michael Quayle, Maria Schuld, Taha Yasseri"
"Examining the Impact of Provenance-Enabled Media on Trust and Accuracy
  Perceptions","In recent years, industry leaders and researchers have proposed to use
technical provenance standards to address visual misinformation spread through
digitally altered media. By adding immutable and secure provenance information
such as authorship and edit date to media metadata, social media users could
potentially better assess the validity of the media they encounter. However, it
is unclear how end users would respond to provenance information, or how to
best design provenance indicators to be understandable to laypeople. We
conducted an online experiment with 595 participants from the US and UK to
investigate how provenance information altered users' accuracy perceptions and
trust in visual content shared on social media. We found that provenance
information often lowered trust and caused users to doubt deceptive media,
particularly when it revealed that the media was composited. We additionally
tested conditions where the provenance information itself was shown to be
incomplete or invalid, and found that these states have a significant impact on
participants' accuracy perceptions and trust in media, leading them, in some
cases, to disbelieve honest media. Our findings show that provenance, although
enlightening, is still not a concept well-understood by users, who confuse
media credibility with the orthogonal (albeit related) concept of provenance
credibility. We discuss how design choices may contribute to provenance
(mis)understanding, and conclude with implications for usable provenance
systems, including clearer interfaces and user education.",2023-03-21,"K. J. Kevin Feng, Nick Ritchie, Pia Blumenthal, Andy Parsons, Amy X. Zhang"
Dynamic Vertex Replacement Grammars,"Context-free graph grammars have shown a remarkable ability to model
structures in real-world relational data. However, graph grammars lack the
ability to capture time-changing phenomena since the left-to-right transitions
of a production rule do not represent temporal change. In the present work, we
describe dynamic vertex-replacement grammars (DyVeRG), which generalize vertex
replacement grammars in the time domain by providing a formal framework for
updating a learned graph grammar in accordance with modifications to its
underlying data. We show that DyVeRG grammars can be learned from, and used to
generate, real-world dynamic graphs faithfully while remaining
human-interpretable. We also demonstrate their ability to forecast by computing
dyvergence scores, a novel graph similarity measurement exposed by this
framework.",2023-03-21,"Daniel Gonzalez Cedre, Justus Isaiah Hibshman, Timothy La Fond, Grant Boquet, Tim Weninger"
A Cheeger Inequality for Size-Specific Conductance,"The $\mu$-conductance measure proposed by Lovasz and Simonovits is a
size-specific conductance score that identifies the set with smallest
conductance while disregarding those sets with volume smaller than a $\mu$
fraction of the whole graph. Using $\mu$-conductance enables us to study in new
ways. In this manuscript we propose a modified spectral cut that is a natural
relaxation of the integer program of $\mu$-conductance and show the optimum of
this program has a two-sided Cheeger inequality with $\mu$-conductance.",2023-03-20,"Yufan Huang, David F. Gleich"
"Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and
  Cross-Attention","Massive rumors usually appear along with breaking news or trending topics,
seriously hindering the truth. Existing rumor detection methods are mostly
focused on the same domain, and thus have poor performance in cross-domain
scenarios due to domain shift. In this work, we propose an end-to-end
instance-wise and prototype-wise contrastive learning model with a
cross-attention mechanism for cross-domain rumor detection. The model not only
performs cross-domain feature alignment but also enforces target samples to
align with the corresponding prototypes of a given source domain. Since target
labels in a target domain are unavailable, we use a clustering-based approach
with carefully initialized centers by a batch of source domain samples to
produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair
of source data and target data with the same labels to learn domain-invariant
representations. Because the samples in a domain pair tend to express similar
semantic patterns, especially on the people's attitudes (e.g., supporting or
denying) towards the same category of rumors, the discrepancy between a pair of
the source domain and target domain will be decreased. We conduct experiments
on four groups of cross-domain datasets and show that our proposed model
achieves state-of-the-art performance.",2023-03-20,"Hongyan Ran, Caiyan Jia"
"Data driven approach to sparsification of reaction diffusion complex
  network systems","Graph sparsification is an area of interest in computer science and applied
mathematics. Sparsification of a graph, in general, aims to reduce the number
of edges in the network while preserving specific properties of the graph, like
cuts and subgraph counts. Computing the sparsest cuts of a graph is known to be
NP-hard, and sparsification routines exists for generating linear sized
sparsifiers in almost quadratic running time $O(n^{2 + \epsilon})$.
Consequently, obtaining a sparsifier can be a computationally demanding task
and the complexity varies based on the level of sparsity required. In this
study, we extend the concept of sparsification to the realm of
reaction-diffusion complex systems. We aim to address the challenge of reducing
the number of edges in the network while preserving the underlying flow
dynamics. To tackle this problem, we adopt a relaxed approach considering only
a subset of trajectories. We map the network sparsification problem to a data
assimilation problem on a Reduced Order Model (ROM) space with constraints
targeted at preserving the eigenmodes of the Laplacian matrix under
perturbations. The Laplacian matrix ($L = D - A$) is the difference between the
diagonal matrix of degrees ($D$) and the graph's adjacency matrix ($A$). We
propose approximations to the eigenvalues and eigenvectors of the Laplacian
matrix subject to perturbations for computational feasibility and include a
custom function based on these approximations as a constraint on the data
assimilation framework. We demonstrate the extension of our framework to
achieve sparsity in parameter sets for Neural Ordinary Differential Equations
(neural ODEs).",2023-03-19,"Abhishek Ajayakumar, Soumyendu Raha"
On the rise of fear speech in online social media,"Recently, social media platforms are heavily moderated to prevent the spread
of online hate speech, which is usually fertile in toxic words and is directed
toward an individual or a community. Owing to such heavy moderation, newer and
more subtle techniques are being deployed. One of the most striking among these
is fear speech. Fear speech, as the name suggests, attempts to incite fear
about a target community. Although subtle, it might be highly effective, often
pushing communities toward a physical conflict. Therefore, understanding their
prevalence in social media is of paramount importance. This article presents a
large-scale study to understand the prevalence of 400K fear speech and over
700K hate speech posts collected from Gab.com. Remarkably, users posting a
large number of fear speech accrue more followers and occupy more central
positions in social networks than users posting a large number of hate speech.
They can also reach out to benign users more effectively than hate speech users
through replies, reposts, and mentions. This connects to the fact that, unlike
hate speech, fear speech has almost zero toxic content, making it look
plausible. Moreover, while fear speech topics mostly portray a community as a
perpetrator using a (fake) chain of argumentation, hate speech topics hurl
direct multitarget insults, thus pointing to why general users could be more
gullible to fear speech. Our findings transcend even to other platforms
(Twitter and Facebook) and thus necessitate using sophisticated moderation
policies and mass awareness to combat fear speech.",2023-03-18,"Punyajoy Saha, Kiran Garimella, Narla Komal Kalyan, Saurabh Kumar Pandey, Pauras Mangesh Meher, Binny Mathew, Animesh Mukherjee"
"Empowering Young Learners to Explore Blockchain with User-Friendly
  Tools: A Method Using Google Blockly and NFTs","As blockchain technology continues to gain attention, there is a growing need
to make it more accessible to young learners in K-12 education. However, the
technical complexity and lack of accessible tools have been identified as
significant barriers to adoption. Our paper proposes a new method for
empowering NFTs by continuously updating their metadata using an API layer. The
approach aims to reduce the barriers to entry and enable K-12 students to
explore blockchain technology in the same way they learn computational thinking
through visual programming tools like Scratch. Our method utilizes Google
Blockly, a visual programming language, to make updating NFT metadata more
accessible and engaging for young learners. By leveraging a familiar and
engaging visual programming language, students can develop their computational
thinking skills and explore blockchain technology in a fun and intuitive way.
The paper discusses the benefits of using NFTs as a learning tool, including
how they can help students understand the concept of digital ownership and
value. Overall, our proposed method has the potential to promote student
engagement and understanding of blockchain technology, which could have
significant implications for the future of education.",2023-03-17,"Yun-Cheng Tsai, Jiun-Yu Huang, Da-Ru Chiou"
Authority without Care: Moral Values behind the Mask Mandate Response,"Face masks are one of the cheapest and most effective non-pharmaceutical
interventions available against airborne diseases such as COVID-19.
Unfortunately, they have been met with resistance by a substantial fraction of
the populace, especially in the U.S. In this study, we uncover the latent moral
values that underpin the response to the mask mandate, and paint them against
the country's political backdrop. We monitor the discussion about masks on
Twitter, which involves almost 600k users in a time span of 7 months. By using
a combination of graph mining, natural language processing, topic modeling,
content analysis, and time series analysis, we characterize the responses to
the mask mandate of both those in favor and against them. We base our analysis
on the theoretical frameworks of Moral Foundation Theory and Hofstede's
cultural dimensions. Our results show that, while the anti-mask stance is
associated with a conservative political leaning, the moral values expressed by
its adherents diverge from the ones typically used by conservatives. In
particular, the expected emphasis on the values of authority and purity is
accompanied by an atypical dearth of in-group loyalty. We find that after the
mandate, both pro- and anti-mask sides decrease their emphasis on care about
others, and increase their attention on authority and fairness, further
politicizing the issue. In addition, the mask mandate reverses the expression
of Individualism-Collectivism between the two sides, with an increase of
individualism in the anti-mask narrative, and a decrease in the pro-mask one.
We argue that monitoring the dynamics of moral positioning is crucial for
designing effective public health campaigns that are sensitive to the
underlying values of the target audience.",2023-03-16,"Yelena Mejova, Kyrieki Kalimeri, Gianmarco De Francisci Morales"
Optimal Intervention on Weighted Networks via Edge Centrality,"Suppose there is a spreading process such as an infectious disease
propagating on a graph. How would we reduce the number of affected nodes in the
spreading process? This question appears in recent studies about implementing
mobility interventions on mobility networks (Chang et al. (2021)). A practical
algorithm to reduce infections on unweighted graphs is to remove edges with the
highest edge centrality score (Tong et al. (2012)), which is the product of two
adjacent nodes' eigenscores. However, mobility networks have weighted edges;
Thus, an intervention measure would involve edge-weight reduction besides edge
removal. Motivated by this example, we revisit the problem of minimizing top
eigenvalue(s) on weighted graphs by decreasing edge weights up to a fixed
budget. We observe that the edge centrality score of Tong et al. (2012) is
equal to the gradient of the largest eigenvalue of $WW^{\top}$, where $W$
denotes the weight matrix of the graph. We then present generalized edge
centrality scores as the gradient of the sum of the largest $r$ eigenvalues of
$WW^{\top}$. With this generalization, we design an iterative algorithm to find
the optimal edge-weight reduction to shrink the largest $r$ eigenvalues of
$WW^{\top}$ under a given edge-weight reduction budget. We also extend our
algorithm and its guarantee to time-varying graphs, whose weights evolve over
time. We perform a detailed empirical study to validate our approach. Our
algorithm significantly reduces the number of infections compared with existing
methods on eleven weighted networks. Further, we illustrate several properties
of our algorithm, including the benefit of choosing the rank $r$, fast
convergence to global optimum, and an almost linear runtime per iteration.",2023-03-16,"Dongyue Li, Tina Eliassi-Rad, Hongyang R. Zhang"
CS-TGN: Community Search via Temporal Graph Neural Networks,"Searching for local communities is an important research challenge that
allows for personalized community discovery and supports advanced data analysis
in various complex networks, such as the World Wide Web, social networks, and
brain networks. The evolution of these networks over time has motivated several
recent studies to identify local communities in temporal networks. Given any
query nodes, Community Search aims to find a densely connected subgraph
containing query nodes. However, existing community search approaches in
temporal networks have two main limitations: (1) they adopt pre-defined
subgraph patterns to model communities, which cannot find communities that do
not conform to these patterns in real-world networks, and (2) they only use the
aggregation of disjoint structural information to measure quality, missing the
dynamic of connections and temporal properties. In this paper, we propose a
query-driven Temporal Graph Convolutional Network (CS-TGN) that can capture
flexible community structures by learning from the ground-truth communities in
a data-driven manner. CS-TGN first combines the local query-dependent structure
and the global graph embedding in each snapshot of the network and then uses a
GRU cell with contextual attention to learn the dynamics of interactions and
update node embeddings over time. We demonstrate how this model can be used for
interactive community search in an online setting, allowing users to evaluate
the found communities and provide feedback. Experiments on real-world temporal
graphs with ground-truth communities validate the superior quality of the
solutions obtained and the efficiency of our model in both temporal and
interactive static settings.",2023-03-15,"Farnoosh Hashemi, Ali Behrouz, Milad Rezaei Hajidehi"
Characterizing and Predicting Social Correction on Twitter,"Online misinformation has been a serious threat to public health and society.
Social media users are known to reply to misinformation posts with
counter-misinformation messages, which have been shown to be effective in
curbing the spread of misinformation. This is called social correction.
However, the characteristics of tweets that attract social correction versus
those that do not remain unknown. To close the gap, we focus on answering the
following two research questions: (1) ``Given a tweet, will it be countered by
other users?'', and (2) ``If yes, what will be the magnitude of countering
it?''. This exploration will help develop mechanisms to guide users'
misinformation correction efforts and to measure disparity across users who get
corrected. In this work, we first create a novel dataset with 690,047 pairs of
misinformation tweets and counter-misinformation replies. Then, stratified
analysis of tweet linguistic and engagement features as well as tweet posters'
user attributes are conducted to illustrate the factors that are significant in
determining whether a tweet will get countered. Finally, predictive classifiers
are created to predict the likelihood of a misinformation tweet to get
countered and the degree to which that tweet will be countered. The code and
data is accessible on https://github.com/claws-lab/social-correction-twitter.",2023-03-15,"Yingchen Ma, Bing He, Nathan Subrahmanian, Srijan Kumar"
Graph Neural Network Surrogates of Fair Graph Filtering,"Graph filters that transform prior node values to posterior scores via edge
propagation often support graph mining tasks affecting humans, such as
recommendation and ranking. Thus, it is important to make them fair in terms of
satisfying statistical parity constraints between groups of nodes (e.g.,
distribute score mass between genders proportionally to their representation).
To achieve this while minimally perturbing the original posteriors, we
introduce a filter-aware universal approximation framework for posterior
objectives. This defines appropriate graph neural networks trained at runtime
to be similar to filters but also locally optimize a large class of objectives,
including fairness-aware ones. Experiments on a collection of 8 filters and 5
graphs show that our approach performs equally well or better than alternatives
in meeting parity constraints while preserving the AUC of score-based community
member recommendation and creating minimal utility loss in prior diffusion.",2023-03-14,"Emmanouil Krasanakis, Symeon Papadopoulos"
"Examining the impacts of privacy awareness on user's self-disclosure on
  social media","This research aims to investigate the impact of users' privacy awareness on
their self-disclosing behavior. Our primary research question is to investigate
how young social media users feel about the benefits and risks of disclosing
them-selves on social media and how risk-benefit awareness influences the
assess-ment of their self-disclosure. Based on the data we recorded, the factor
analysis, and three-way ANOVA, we conclude that users who know more about
privacy benefits share more on social media (F= 36.291; df 1; sig < .001) while
those who know less about the benefits disclose less on social media. According
to the analysis, users who know more about self-disclosure risks share less on
so-cial media (F= 7.001; df 1; sig < .001). Users disclose less information on
so-cial media platforms based on the different levels of their risk perceptions
(df 3, F=.715, sig < 0.5). This indicates that risks on social media platforms
vary to some degree. We saw that people's sharing habits based on their levels
of risk, benefits, and social media platforms can vary. One thing that remained
certain was users' main benefit for engaging and disclosing on social media is
their need to stay in touch with friends and their need for community. On the
flip side, the main risk was the need not to be impersonated and misunderstood
by people. Based on a simple frequency analysis of the open-ended questions we
asked In our data collection, the most highlighted words in our responses were
""people"" and ""friends"". These were the two main words that stood out in all the
data we collected concerning the benefits, risks, and intention to
self-disclose.",2023-03-14,"Kijung Lee, Prudence Attablayo"
"Traffic4cast at NeurIPS 2022 -- Predict Dynamics along Graph Edges from
  Sparse Node Data: Whole City Traffic and ETA from Stationary Vehicle
  Detectors","The global trends of urbanization and increased personal mobility force us to
rethink the way we live and use urban space. The Traffic4cast competition
series tackles this problem in a data-driven way, advancing the latest methods
in machine learning for modeling complex spatial systems over time. In this
edition, our dynamic road graph data combine information from road maps,
$10^{12}$ probe data points, and stationary vehicle detectors in three cities
over the span of two years. While stationary vehicle detectors are the most
accurate way to capture traffic volume, they are only available in few
locations. Traffic4cast 2022 explores models that have the ability to
generalize loosely related temporal vertex data on just a few nodes to predict
dynamic future traffic states on the edges of the entire road graph. In the
core challenge, participants are invited to predict the likelihoods of three
congestion classes derived from the speed levels in the GPS data for the entire
road graph in three cities 15 min into the future. We only provide vehicle
count data from spatially sparse stationary vehicle detectors in these three
cities as model input for this task. The data are aggregated in 15 min time
bins for one hour prior to the prediction time. For the extended challenge,
participants are tasked to predict the average travel times on super-segments
15 min into the future - super-segments are longer sequences of road segments
in the graph. The competition results provide an important advance in the
prediction of complex city-wide traffic states just from publicly available
sparse vehicle data and without the need for large amounts of real-time
floating vehicle data.",2023-03-14,"Moritz Neun, Christian Eichenberger, Henry Martin, Markus Spanring, Rahul Siripurapu, Daniel Springer, Leyan Deng, Chenwang Wu, Defu Lian, Min Zhou, Martin Lumiste, Andrei Ilie, Xinhua Wu, Cheng Lyu, Qing-Long Lu, Vishal Mahajan, Yichao Lu, Jiezhang Li, Junjun Li, Yue-Jiao Gong, Florian Grötschla, Joël Mathys, Ye Wei, He Haitao, Hui Fang, Kevin Malm, Fei Tang, Michael Kopp, David Kreil, Sepp Hochreiter"
"Sinkhorn-Flow: Predicting Probability Mass Flow in Dynamical Systems
  Using Optimal Transport","Predicting how distributions over discrete variables vary over time is a
common task in time series forecasting. But whereas most approaches focus on
merely predicting the distribution at subsequent time steps, a crucial piece of
information in many settings is to determine how this probability mass flows
between the different elements over time. We propose a new approach to
predicting such mass flow over time using optimal transport. Specifically, we
propose a generic approach to predicting transport matrices in end-to-end deep
learning systems, replacing the standard softmax operation with Sinkhorn
iterations. We apply our approach to the task of predicting how communities
will evolve over time in social network settings, and show that the approach
improves substantially over alternative prediction methods. We specifically
highlight results on the task of predicting faction evolution in Ukrainian
parliamentary voting.",2023-03-14,"Mukul Bhutani, J. Zico Kolter"
"Bounded-Confidence Models of Opinion Dynamics with Adaptive Confidence
  Bounds","People's opinions change with time as they interact with each other. In a
bounded-confidence model (BCM) of opinion dynamics, individuals (which are
represented by the nodes of a network) have continuous-valued opinions and are
influenced by neighboring nodes whose opinions are sufficiently similar to
theirs (i.e., are within a confidence bound). In this paper, we formulate and
analyze discrete-time BCMs with heterogeneous and adaptive confidence bounds.
We introduce two new models: (1) a BCM with synchronous opinion updates that
generalizes the Hegselmann--Krause (HK) model and (2) a BCM with asynchronous
opinion updates that generalizes the Deffuant--Weisbuch (DW) model. We
analytically and numerically explore our adaptive BCMs' limiting behaviors,
including the confidence-bound dynamics, the formation of clusters of nodes
with similar opinions, and the time evolution of an ""effective graph"", which is
a time-dependent subgraph of a network with edges between nodes that {are
currently receptive to each other.} For a variety of networks and a wide range
of values of the parameters that control the increase and decrease of
confidence bounds, we demonstrate numerically that our adaptive BCMs result in
fewer major opinion clusters and longer convergence times than the baseline
(i.e., nonadaptive) BCMs. We also show that our adaptive BCMs can have adjacent
nodes that converge to the same opinion but are not {receptive to each other.}
This qualitative behavior does not occur in the associated baseline BCMs.",2023-03-14,"Grace J. Li, Jiajie Luo, Mason A. Porter"
Can Workers Meaningfully Consent to Workplace Wellbeing Technologies?,"Sensing technologies deployed in the workplace can unobtrusively collect
detailed data about individual activities and group interactions that are
otherwise difficult to capture. A hopeful application of these technologies is
that they can help businesses and workers optimize productivity and wellbeing.
However, given the workplace's inherent and structural power dynamics, the
prevalent approach of accepting tacit compliance to monitor work activities
rather than seeking workers' meaningful consent raises privacy and ethical
concerns. This paper unpacks the challenges workers face when consenting to
workplace wellbeing technologies. Using a hypothetical case to prompt
reflection among six multi-stakeholder focus groups involving 15 participants,
we explored participants' expectations and capacity to consent to these
technologies. We sketched possible interventions that could better support
meaningful consent to workplace wellbeing technologies by drawing on critical
computing and feminist scholarship -- which reframes consent from a purely
individual choice to a structural condition experienced at the individual level
that needs to be freely given, reversible, informed, enthusiastic, and specific
(FRIES). The focus groups revealed how workers are vulnerable to ""meaningless""
consent -- as they may be subject to power dynamics that minimize their ability
to withhold consent and may thus experience an erosion of autonomy, also
undermining the value of data gathered in the name of ""wellbeing."" To
meaningfully consent, participants wanted changes to the technology and to the
policies and practices surrounding the technology. Our mapping of what prevents
workers from meaningfully consenting to workplace wellbeing technologies
(challenges) and what they require to do so (interventions) illustrates how the
lack of meaningful consent is a structural problem requiring socio-technical
solutions.",2023-03-13,"Shreya Chowdhary, Anna Kawakami, Mary L. Gray, Jina Suh, Alexandra Olteanu, Koustuv Saha"
"Social network analysis of manga: similarities to real-world social
  networks and trends over decades","Manga, Japanese comics, has been popular on a global scale. Social networks
among characters, which are often called character networks, may be a
significant contributor to their popularity. We collected data from 162 popular
manga that span over 70 years and analyzed their character networks. First, we
found that many of static and temporal properties of the character networks are
similar to those of real human social networks. Second, the character networks
of most manga are protagonist-centered such that a single protagonist interacts
with the majority of other characters. Third, the character networks for manga
mainly targeting boys have shifted to denser and less protagonist-centered
networks and with fewer characters over decades. Manga mainly targeting girls
showed the opposite trend except for the downward trend in the number of
characters. The present study, which relies on manga data sampled on an
unprecedented scale, paves the way for further population studies of character
networks and other aspects of comics.",2023-03-13,"Kashin Sugishita, Naoki Masuda"
"Prospecting Community Development Strength based on Economic Graph: From
  Categorization to Scoring","Recent years have witnessed a growing number of researches on community
characterization. In contrast to the large body of researches on the
categorical measures (rise or decline) for evaluating the community
development, we propose to estimate the community development strength (to
which degree the rise or decline is). More specifically, given already known
categorical information of community development, we are attempting to quantify
the community development strength, which is of great interest. Motivated by
the increasing availability of large-scale data on the network between entities
among communities, we investigate how to score the the community's development
strength. We formally define our task as prospecting community development
strength from categorization based on multi-relational network information and
identify two challenges as follows: (1) limited guidance for integrating entity
multi-relational network in quantifying the community development strength; (2)
the existence of selection effect that the community development strength has
on network formation. Aiming at these challenges, we start by a hybrid of
discriminative and generative approaches on multi-relational network-based
community development strength quantification. Then a network generation
process is exploited to debias the selection process. In the end, we
empirically evaluate the proposed model by applying it to quantify enterprise
business development strength. Experimental results demonstrate the
effectiveness of the proposed method.",2023-03-11,Chang Liao
"Measuring and Detecting Virality on Social Media: The Case of Twitter's
  Viral Tweets Topic","Social media posts may go viral and reach large numbers of people within a
short period of time. Such posts may threaten the public dialogue if they
contain misleading content, making their early detection highly crucial.
Previous works proposed their own metrics to annotate if a tweet is viral or
not in order to automatically detect them later. However, such metrics may not
accurately represent viral tweets or may introduce too many false positives. In
this work, we use the ground truth data provided by Twitter's ""Viral Tweets""
topic to review the current metrics and also propose our own metric. We find
that a tweet is more likely to be classified as viral by Twitter if the ratio
of retweets to its author's followers exceeds some threshold. We found this
threshold to be 2.16 in our experiments. This rule results in less false
positives although it favors smaller accounts. We also propose a
transformers-based model to early detect viral tweets which reports an F1 score
of 0.79. The code and the tweet ids are publicly available at:
https://github.com/tugrulz/ViralTweets",2023-03-10,"Tuğrulcan Elmas, Stephane Selim, Célia Houssiaux"
"Revisiting the relevance of traditional genres: a network analysis of
  fiction readers' preferences","We investigate how well traditional fiction genres like Fantasy, Thriller,
and Literature represent readers' preferences. Using user data from Goodreads
we construct a book network where two books are strongly linked if the same
people tend to read or enjoy them both. We then partition this network into
communities of similar books and assign each a list of subjects from The Open
Library to serve as a proxy for traditional genres. Our analysis reveals that
the network communities correspond to existing combinations of traditional
genres, but that the exact communities differ depending on whether we consider
books that people read or books that people enjoy.
  In addition, we apply principal component analysis to the data and find that
the variance in the book communities is best explained by two factors: the
maturity/childishness and realism/fantastical nature of the books. We propose
using this maturity-realism plane as a coarse classification tool for stories.",2023-03-09,"Taom Sakal, Stephen Proulx"
Phase transition for detecting a small community in a large network,"How to detect a small community in a large network is an interesting problem,
including clique detection as a special case, where a naive degree-based
$\chi^2$-test was shown to be powerful in the presence of an Erd\H{o}s-Renyi
background. Using Sinkhorn's theorem, we show that the signal captured by the
$\chi^2$-test may be a modeling artifact, and it may disappear once we replace
the Erd\H{o}s-Renyi model by a broader network model. We show that the recent
SgnQ test is more appropriate for such a setting. The test is optimal in
detecting communities with sizes comparable to the whole network, but has never
been studied for our setting, which is substantially different and more
challenging. Using a degree-corrected block model (DCBM), we establish phase
transitions of this testing problem concerning the size of the small community
and the edge densities in small and large communities. When the size of the
small community is larger than $\sqrt{n}$, the SgnQ test is optimal for it
attains the computational lower bound (CLB), the information lower bound for
methods allowing polynomial computation time. When the size of the small
community is smaller than $\sqrt{n}$, we establish the parameter regime where
the SgnQ test has full power and make some conjectures of the CLB. We also
study the classical information lower bound (LB) and show that there is always
a gap between the CLB and LB in our range of interest.",2023-03-09,"Jiashun Jin, Zheng Tracy Ke, Paxton Turner, Anru R. Zhang"
Fitting Low-rank Models on Egocentrically Sampled Partial Networks,"The statistical modeling of random networks has been widely used to uncover
interaction mechanisms in complex systems and to predict unobserved links in
real-world networks. In many applications, network connections are collected
via egocentric sampling: a subset of nodes is sampled first, after which all
links involving this subset are recorded; all other information is missing.
Compared with the assumption of ``uniformly missing at random"", egocentrically
sampled partial networks require specially designed modeling strategies.
Current statistical methods are either computationally infeasible or based on
intuitive designs without theoretical justification. Here, we propose an
approach to fit general low-rank models for egocentrically sampled networks,
which include several popular network models. This method is based on graph
spectral properties and is computationally efficient for large-scale networks.
It results in consistent recovery of missing subnetworks due to egocentric
sampling for sparse networks. To our knowledge, this method offers the first
theoretical guarantee for egocentric partial network estimation in the scope of
low-rank models. We evaluate the technique on several synthetic and real-world
networks and show that it delivers competitive performance in link prediction
tasks.",2023-03-09,"Angus Chan, Tianxi Li"
Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection,"Hate speech in social media is a growing phenomenon, and detecting such toxic
content has recently gained significant traction in the research community.
Existing studies have explored fine-tuning language models (LMs) to perform
hate speech detection, and these solutions have yielded significant
performance. However, most of these studies are limited to detecting hate
speech only in English, neglecting the bulk of hateful content that is
generated in other languages, particularly in low-resource languages.
Developing a classifier that captures hate speech and nuances in a low-resource
language with limited data is extremely challenging. To fill the research gap,
we propose HateMAML, a model-agnostic meta-learning-based framework that
effectively performs hate speech detection in low-resource languages. HateMAML
utilizes a self-supervision strategy to overcome the limitation of data
scarcity and produces better LM initialization for fast adaptation to an unseen
target language (i.e., cross-lingual transfer) or other hate speech datasets
(i.e., domain generalization). Extensive experiments are conducted on five
datasets across eight different low-resource languages. The results show that
HateMAML outperforms the state-of-the-art baselines by more than 3% in the
cross-domain multilingual transfer setting. We also conduct ablation studies to
analyze the characteristics of HateMAML.",2023-03-04,"Md Rabiul Awal, Roy Ka-Wei Lee, Eshaan Tanwar, Tanmay Garg, Tanmoy Chakraborty"
"Social Media COVID-19 Contact Tracing Using Mobile Social Payments and
  Facebook Data","Many in the US were reluctant to report their COVID-19 cases at the height of
the pandemic (e.g., for fear of missing work or other obligations due to
quarantine mandates). Other methods such as using public social media data can
therefore help augment current approaches to surveilling pandemics. This study
evaluated the effectiveness of using social media data as a data source for
tracking public health pandemics. There have been several attempts at using
social media data from platforms like Twitter for analyzing the COVID-19
pandemic. While these provide a multitude of useful insights, new platforms
like Venmo, a popular U.S. mobile social payment app often used during
in-person activities, remain understudied. We developed unique computational
methods (combining Venmo- and Facebook- derived data) to classify post content,
including the location where the content was likely posted. This approach
enabled geotemporal COVID-19-related infoveillance. By examining 135M publicly
available Venmo transactions from 22.1M unique users, we found significant
spikes in the use of COVID-19 related keywords in March 2020. Using
Facebook-based geotags for 9K users along with transaction geo-parsing (i.e.,
parsing text to detect place names), we identified 38K location-based clusters.
Within these groups, we found a strong correlation (0.81) between the use of
COVID-19 keywords in a region and the number of reported COVID-19 cases as well
as an aggregate decrease in transactions during lockdowns and an increase when
lockdowns are lifted. Surprisingly, we saw a weak negative correlation between
the number of transactions and reported cases over time (-0.49). Our results
indicate that using non-Twitter social media trace data can aid pandemic- and
other health-related infoveillance.",2023-03-04,"Shrivu Shankar, Dhiraj Murthy, Hassan Dashtian"
"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a
  Context Synergized Hyperbolic Network","The tremendous growth of social media users interacting in online
conversations has led to significant growth in hate speech, affecting people
from various demographics. Most of the prior works focus on detecting explicit
hate speech, which is overt and leverages hateful phrases, with very little
work focusing on detecting hate speech that is implicit or denotes hatred
through indirect or coded language. In this paper, we present CoSyn, a
context-synergized neural network that explicitly incorporates user- and
conversational context for detecting implicit hate speech in online
conversations. CoSyn introduces novel ways to encode these external contexts
and employs a novel context interaction mechanism that clearly captures the
interplay between them, making independent assessments of the amounts of
information to be retrieved from these noisy contexts. Additionally, it carries
out all these operations in the hyperbolic space to account for the scale-free
dynamics of social media. We demonstrate the effectiveness of CoSyn on 6 hate
speech datasets and show that CoSyn outperforms all our baselines in detecting
implicit hate speech with absolute improvements in the range of 1.24% - 57.8%.",2023-03-02,"Sreyan Ghosh, Manan Suri, Purva Chiniya, Utkarsh Tyagi, Sonal Kumar, Dinesh Manocha"
Hyperlink communities in higher-order networks,"Many networks can be characterised by the presence of communities, which are
groups of units that are closely linked. Identifying these communities can be
crucial for understanding the system's overall function. Recently, hypergraphs
have emerged as a fundamental tool for modelling systems where interactions are
not limited to pairs but may involve an arbitrary number of nodes. In this
study, we adopt a dual approach to community detection and extend the concept
of link communities to hypergraphs. This extension allows us to extract
informative clusters of highly related hyperedges. We analyze the dendrograms
obtained by applying hierarchical clustering to distance matrices among
hyperedges across a variety of real-world data, showing that hyperlink
communities naturally highlight the hierarchical and multiscale structure of
higher-order networks. Moreover, hyperlink communities enable us to extract
overlapping memberships from nodes, overcoming limitations of traditional hard
clustering methods. Finally, we introduce higher-order network cartography as a
practical tool for categorizing nodes into different structural roles based on
their interaction patterns and community participation. This approach aids in
identifying different types of individuals in a variety of real-world social
systems. Our work contributes to a better understanding of the structural
organization of real-world higher-order systems.",2023-03-02,"Quintino Francesco Lotito, Federico Musciotto, Alberto Montresor, Federico Battiston"
Specformer: Spectral Graph Neural Networks Meet Transformers,"Spectral graph neural networks (GNNs) learn graph representations via
spectral-domain graph convolutions. However, most existing spectral graph
filters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a
single filtered value, thus ignoring the global pattern of the spectrum.
Furthermore, these filters are often constructed based on some fixed-order
polynomials, which have limited expressiveness and flexibility. To tackle these
issues, we introduce Specformer, which effectively encodes the set of all
eigenvalues and performs self-attention in the spectral domain, leading to a
learnable set-to-set spectral filter. We also design a decoder with learnable
bases to enable non-local graph convolution. Importantly, Specformer is
equivariant to permutation. By stacking multiple Specformer layers, one can
build a powerful spectral GNN. On synthetic datasets, we show that our
Specformer can better recover ground-truth spectral filters than other spectral
GNNs. Extensive experiments of both node-level and graph-level tasks on
real-world graph datasets show that our Specformer outperforms state-of-the-art
GNNs and learns meaningful spectrum patterns. Code and data are available at
https://github.com/bdy9527/Specformer.",2023-03-02,"Deyu Bo, Chuan Shi, Lele Wang, Renjie Liao"
"QuickCent: a fast and frugal heuristic for harmonic centrality
  estimation on scale-free networks","We present a simple and quick method to approximate network centrality
indexes. Our approach, called QuickCent, is inspired by so-called fast and
frugal heuristics, which are heuristics initially proposed to model some human
decision and inference processes. The centrality index that we estimate is the
harmonic centrality, which is a measure based on shortest-path distances, so
infeasible to compute on large networks. We compare QuickCent with known
machine learning algorithms on synthetic data generated with preferential
attachment, and some empirical networks. Our experiments show that QuickCent is
able to make estimates that are competitive in accuracy with the best
alternative methods tested, either on synthetic scale-free networks or
empirical networks. QuickCent has the feature of achieving low error variance
estimates, even with a small training set. Moreover, QuickCent is comparable in
efficiency -- accuracy and time cost -- to those produced by more complex
methods. We discuss and provide some insight into how QuickCent exploits the
fact that in some networks, such as those generated by preferential attachment,
local density measures such as the in-degree, can be a proxy for the size of
the network region to which a node has access, opening up the possibility of
approximating centrality indices based on size such as the harmonic centrality.
Our initial results show that simple heuristics and biologically inspired
computational methods are a promising line of research in the context of
network measure estimations.",2023-03-02,"Francisco Plana, Andrés Abeliuk, Jorge Pérez"
"Guided Graph Generation: Evaluation of Graph Generators in Terms of
  Network Statistics, and a New Algorithm","We consider the problem of graph generation guided by network statistics,
i.e., the generation of graphs which have given values of various numerical
measures that characterize networks, such as the clustering coefficient and the
number of cycles of given lengths. Algorithms for the generation of synthetic
graphs are often based on graph growth models, i.e., rules of adding (and
sometimes removing) nodes and edges to a graph that mimic the processes present
in real-world networks. While such graph generators are desirable from a
theoretical point of view, they are often only able to reproduce a narrow set
of properties of real-world networks, resulting in graphs with otherwise
unrealistic properties. In this article, we instead evaluate common graph
generation algorithms at the task of reproducing the numerical statistics of
real-world networks, such as the clustering coefficient, the degree
assortativity, and the connectivity. We also propose an iterative algorithm,
the Guided Graph Generator, based on a greedy-like procedure that recovers
realistic values over a large number of commonly used graph statistics, while
at the same time allowing an efficient implementation based on incremental
updating of only a small number of subgraph counts. We show that the proposed
algorithm outperforms previous graph generation algorithms in terms of the
error in the reconstructed graphs for a large number of graph statistics such
as the clustering coefficient, the assortativity, the mean node distance, and
also evaluate the algorithm in terms of precision, speed of convergence and
scalability, and compare it to previous graph generators and models. We also
show that the proposed algorithm generates graphs with realistic degree
distributions, graph spectra, clustering coefficient distributions, and
distance distributions.",2023-03-01,"Jérôme Kunegis, Jun Sun, Eiko Yoneki"
"Heuristic Modularity Maximization Algorithms for Community Detection
  Rarely Return an Optimal Partition or Anything Similar","Community detection is a fundamental problem in computational sciences with
extensive applications in various fields. The most commonly used methods are
the algorithms designed to maximize modularity over different partitions of the
network nodes. Using 80 real and random networks from a wide range of contexts,
we investigate the extent to which current heuristic modularity maximization
algorithms succeed in returning maximum-modularity (optimal) partitions. We
evaluate (1) the ratio of the algorithms' output modularity to the maximum
modularity for each input graph, and (2) the maximum similarity between their
output partition and any optimal partition of that graph. We compare eight
existing heuristic algorithms against an exact integer programming method that
globally maximizes modularity. The average modularity-based heuristic algorithm
returns optimal partitions for only 19.4% of the 80 graphs considered.
Additionally, results on adjusted mutual information reveal substantial
dissimilarity between the sub-optimal partitions and any optimal partition of
the networks in our experiments. More importantly, our results show that
near-optimal partitions are often disproportionately dissimilar to any optimal
partition. Taken together, our analysis points to a crucial limitation of
commonly used modularity-based heuristics for discovering communities: they
rarely produce an optimal partition or a partition resembling an optimal
partition. If modularity is to be used for detecting communities, exact or
approximate optimization algorithms are recommendable for a more
methodologically sound usage of modularity within its applicability limits.",2023-02-28,"Samin Aref, Mahdi Mostajabdaveh, Hriday Chheda"
"Exploring 3D community inconsistency in human chromosome contact
  networks","Researchers developed chromosome capture methods such as Hi-C to better
understand DNA's 3D folding in nuclei. The Hi-C method captures contact
frequencies between DNA segment pairs across the genome. When analyzing Hi-C
data sets, it is common to group these pairs using standard bioinformatics
methods (e.g., PCA). Other approaches handle Hi-C data as weighted networks,
where connected node represent DNA segments in 3D proximity. In this
representation, one can leverage community detection techniques developed in
complex network theory to group nodes into mesoscale communities containing
similar connection patterns. While there are several successful attempts to
analyze Hi-C data in this way, it is common to report and study the most
typical community structure. But in reality, there are often several valid
candidates. Therefore, depending on algorithm design, different community
detection methods focusing on slightly different connectivity features may have
differing views on the ideal node groupings. In fact, even the same community
detection method may yield different results if using a stochastic algorithm.
This ambiguity is fundamental to community detection and shared by most complex
networks whenever interactions span all scales in the network. This is known as
community inconsistency. This paper explores this inconsistency of 3D
communities in Hi-C data for all human chromosomes. We base our analysis on two
inconsistency metrics, one local and one global, and quantify the network
scales where the community separation is most variable. For example, we find
that TADs are less reliable than A/B compartments and that nodes with highly
variable node-community memberships are associated with open chromatin.
Overall, our study provides a helpful framework for data-driven researchers and
increases awareness of some inherent challenges when clustering Hi-C data into
3D communities.",2023-02-28,"Dolores Bernenko, Sang Hoon Lee, Ludvig Lizana"
"Moral intuitions behind deepfake-related discussions in Reddit
  communities","Deepfakes are AI-synthesized content that are becoming popular on many social
media platforms, meaning the use of deepfakes is increasing in society,
regardless of its societal implications. Its implications are harmful if the
moral intuitions behind deepfakes are problematic; thus, it is important to
explore how the moral intuitions behind deepfakes unfold in communities at
scale. However, understanding perceived moral viewpoints unfolding in digital
contexts is challenging, due to the complexities in conversations. In this
research, we demonstrate how Moral Foundations Theory (MFT) can be used as a
lens through which to operationalize moral viewpoints in discussions about
deepfakes on Reddit communities. Using the extended Moral Foundations
Dictionary (eMFD), we measured the strengths of moral intuition (moral loading)
behind 101,869 Reddit posts. We present the discussions that unfolded on Reddit
in 2018 to 2022 wherein intuitions behind some posts were found to be morally
questionable to society. Our results may help platforms detect and take action
against immoral activities related to deepfakes.",2023-02-27,"Dilrukshi Gamage, Hariharan Ravinthran, Kazutoshi Sasahara"
"Tweets Under the Rubble: Detection of Messages Calling for Help in
  Earthquake Disaster","The importance of social media is again exposed in the recent tragedy of the
2023 Turkey and Syria earthquake. Many victims who were trapped under the
rubble called for help by posting messages in Twitter. We present an
interactive tool to provide situational awareness for missing and trapped
people, and disaster relief for rescue and donation efforts. The system (i)
collects tweets, (ii) classifies the ones calling for help, (iii) extracts
important entity tags, and (iv) visualizes them in an interactive map screen.
Our initial experiments show that the performance in terms of the F1 score is
up to 98.30 for tweet classification, and 84.32 for entity extraction. The
demonstration, dataset, and other related files can be accessed at
https://github.com/avaapm/deprem",2023-02-26,"Cagri Toraman, Izzet Emre Kucukkaya, Oguzhan Ozcelik, Umitcan Sahin"
Discovering Top-k Structural Hole Spanners in Dynamic Networks,"Structural Hole (SH) theory states that the node which acts as a connecting
link among otherwise disconnected communities gets positional advantages in the
network. These nodes are called Structural Hole Spanners (SHS). Numerous
solutions are proposed to discover SHSs; however, most of the solutions are
only applicable to static networks. Since real-world networks are dynamic
networks; consequently, in this study, we aim to discover SHSs in dynamic
networks. Discovering SHSs is an NP-hard problem, due to which, instead of
discovering exact k SHSs, we adopt a greedy approach to discover Top-k SHSs. We
first propose an efficient Tracking-SHS algorithm for updating SHSs in dynamic
networks. Our algorithm reuses the information obtained during the initial runs
of the static algorithm and avoids the recomputations for the nodes unaffected
by the updates. Besides, motivated from the success of Graph Neural Networks
(GNNs) on various graph mining problems, we also design a Graph Neural
Network-based model, GNN-SHS, to discover SHSs in dynamic networks, aiming to
reduce the computational cost while achieving high accuracy. We provide a
theoretical analysis of the Tracking-SHS algorithm, and our theoretical results
prove that for a particular type of graphs, such as Preferential Attachment
graphs [1], Tracking-SHS algorithm achieves 1.6 times of speedup compared with
the static algorithm. We perform extensive experiments, and our results
demonstrate that the Tracking-SHS algorithm attains a minimum of 3.24 times
speedup over the static algorithm. Also, the proposed second model GNN-SHS is
on an average 671.6 times faster than the Tracking-SHS algorithm.",2023-02-26,"Diksha Goel, Hong Shen, Hui Tian, Mingyu Guo"
Interruptions detection in video conferences,"In recent years, video conferencing (VC) popularity has skyrocketed for a
wide range of activities. As a result, the number of VC users surged sharply.
The sharp increase in VC usage has been accompanied by various newly emerging
privacy and security challenges. VC meetings became a target for various
security attacks, such as Zoombombing. Other VC-related challenges also
emerged. For example, during COVID lockdowns, educators had to teach in online
environments struggling with keeping students engaged for extended periods. In
parallel, the amount of available VC videos has grown exponentially. Thus,
users and companies are limited in finding abnormal segments in VC meetings
within the converging volumes of data. Such abnormal events that affect most
meeting participants may be indicators of interesting points in time, including
security attacks or other changes in meeting climate, like someone joining a
meeting or sharing a dramatic content. Here, we present a novel algorithm for
detecting abnormal events in VC data. We curated VC publicly available
recordings, including meetings with interruptions. We analyzed the videos using
our algorithm, extracting time windows where abnormal occurrences were
detected. Our algorithm is a pipeline that combines multiple methods in several
steps to detect users' faces in each video frame, track face locations during
the meeting and generate vector representations of a facial expression for each
face in each frame. Vector representations are used to monitor changes in
facial expressions throughout the meeting for each participant. The overall
change in meeting climate is quantified using those parameters across all
participants, and translating them into event anomaly detection. This is the
first open pipeline for automatically detecting anomaly events in VC meetings.
Our model detects abnormal events with 92.3% precision over the collected
dataset.",2023-02-25,"Shmuel Horowitz, Dima Kagan, Galit Fuhrmann Alpert, Michael Fire"
Improving Fairness in Information Exposure by Adding Links,"Fairness in influence maximization has been a very active research topic
recently. Most works in this context study the question of how to find seeding
strategies (deterministic or probabilistic) such that nodes or communities in
the network get their fair share of coverage. Different fairness criteria have
been used in this context. All these works assume that the entity that is
spreading the information has an inherent interest in spreading the information
fairly, otherwise why would they want to use the developed fair algorithms?
This assumption may however be flawed in reality -- the spreading entity may be
purely \emph{efficiency-oriented}. In this paper we propose to study two
optimization problems with the goal to modify the network structure by adding
links in such a way that efficiency-oriented information spreading becomes
\emph{automatically fair}. We study the proposed optimization problems both
from a theoretical and experimental perspective, that is, we give several
hardness and hardness of approximation results, provide efficient algorithms
for some special cases, and more importantly provide heuristics for solving one
of the problems in practice. In our experimental study we then first compare
the proposed heuristics against each other and establish the most successful
one. In a second experiment, we then show that our approach can be very
successful in practice. That is, we show that already after adding a few edges
to the networks the greedy algorithm that purely maximizes spread surpasses all
fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly,
we even show that our approach achieves ex-post fairness values that are
comparable or even better than the ex-ante fairness values of the currently
most efficient algorithms that optimize ex-ante fairness.",2023-02-25,"Ruben Becker, Gianlorenzo D'Angelo, Sajjad Ghobadi"
On the Cost of Demographic Parity in Influence Maximization,"Modeling and shaping how information spreads through a network is a major
research topic in network analysis. While initially the focus has been mostly
on efficiency, recently fairness criteria have been taken into account in this
setting. Most work has focused on the maximin criteria however, and thus still
different groups can receive very different shares of information. In this work
we propose to consider fairness as a notion to be guaranteed by an algorithm
rather than as a criterion to be maximized. To this end, we propose three
optimization problems that aim at maximizing the overall spread while enforcing
strict levels of demographic parity fairness via constraints (either ex-post or
ex-ante). The level of fairness hence becomes a user choice rather than a
property to be observed upon output. We study this setting from various
perspectives. First, we prove that the cost of introducing demographic parity
can be high in terms of both overall spread and computational complexity, i.e.,
the price of fairness may be unbounded for all three problems and optimal
solutions are hard to compute, in some case even approximately or when fairness
constraints may be violated. For one of our problems, we still design an
algorithm with both constant approximation factor and fairness violation. We
also give two heuristics that allow the user to choose the tolerated fairness
violation. By means of an extensive experimental study, we show that our
algorithms perform well in practice, that is, they achieve the best demographic
parity fairness values. For certain instances we additionally even obtain an
overall spread comparable to the most efficient algorithms that come without
any fairness guarantee, indicating that the empirical price of fairness may
actually be small when using our algorithms.",2023-02-25,"Ruben Becker, Gianlorenzo D'Angelo, Sajjad Ghobadi"
"Morality in the mundane: Categorizing moral reasoning in real-life
  social situations","Moral reasoning reflects how people acquire and apply moral rules in
particular situations. With increasingly social interactions happening online,
social media data provides an unprecedented opportunity to assess in-the-wild
moral reasoning. We investigate the commonsense aspects of morality in ordinary
matters empirically. To this end, we examine data from a Reddit subcommunity
(i.e., a subreddit) where an author may describe their behavior in a situation
to seek comments about whether that behavior was appropriate. Other users
comment to provide judgments and reasoning. We focus on the novel problem of
understanding the moral reasoning implicit in user comments about the propriety
of an author's behavior. Especially, we explore associations between the common
elements of the indicated reasoning and the extractable social factors. Our
results suggest the reasoning depends on the author's gender and the topic of a
post, such as when expressing anger emotion and using sensible words (e.g.,
f-ck, hell, and damn) in work-related situations. Moreover, we find that the
commonly expressed semantics also depends on commenters' interests.",2023-02-24,"Ruijie Xi, Munindar P. Singh"
"Modularity-based approach for tracking communities in dynamic social
  networks","Community detection is a crucial task to unravel the intricate dynamics of
online social networks. The emergence of these networks has dramatically
increased the volume and speed of interactions among users, presenting
researchers with unprecedented opportunities to explore and analyze the
underlying structure of social communities. Despite a growing interest in
tracking the evolution of groups of users in real-world social networks, the
predominant focus of community detection efforts has been on communities within
static networks. In this paper, we introduce a novel framework for tracking
communities over time in a dynamic network, where a series of significant
events is identified for each community. Our framework adopts a
modularity-based strategy and does not require a predefined threshold, leading
to a more accurate and robust tracking of dynamic communities. We validated the
efficacy of our framework through extensive experiments on synthetic networks
featuring embedded events. The results indicate that our framework can
outperform the state-of-the-art methods. Furthermore, we utilized the proposed
approach on a Twitter network comprising over 60,000 users and 5 million tweets
throughout 2020, showcasing its potential in identifying dynamic communities in
real-world scenarios. The proposed framework can be applied to different social
networks and provides a valuable tool to gain deeper insights into the
evolution of communities in dynamic social networks.",2023-02-24,"Michele Mazza, Guglielmo Cola, Maurizio Tesconi"
"Effective Graph-Neural-Network based Models for Discovering Structural
  Hole Spanners in Large-Scale and Diverse Networks","A Structural Hole Spanner (SHS) is a set of nodes in a network that act as a
bridge among different otherwise disconnected communities. Numerous solutions
have been proposed to discover SHSs that generally require high run time on
large-scale networks. Another challenge is discovering SHSs across different
types of networks for which the traditional one-model-fit-all approach fails to
capture the inter-graph difference, particularly in the case of diverse
networks. Therefore, there is an urgent need of developing effective solutions
for discovering SHSs in large-scale and diverse networks. Inspired by the
recent advancement of graph neural network approaches on various graph
problems, we propose graph neural network-based models to discover SHS nodes in
large scale networks and diverse networks. We transform the problem into a
learning problem and propose an efficient model GraphSHS, that exploits both
the network structure and node features to discover SHS nodes in large scale
networks, endeavouring to lessen the computational cost while maintaining high
accuracy. To effectively discover SHSs across diverse networks, we propose
another model Meta-GraphSHS based on meta-learning that learns generalizable
knowledge from diverse training graphs (instead of directly learning the model)
and utilizes the learned knowledge to create a customized model to identify
SHSs in each new graph. We theoretically show that the depth of the proposed
graph neural network model should be at least $\Omega(\sqrt{n}/\log n)$ to
accurately calculate the SHSs discovery problem. We evaluate the performance of
the proposed models through extensive experiments on synthetic and real-world
datasets. Our experimental results show that GraphSHS discovers SHSs with high
accuracy and is at least 167.1 times faster than the comparative methods on
large-scale real-world datasets.",2023-02-24,"Diksha Goel, Hong Shen, Hui Tian, Mingyu Guo"
Auto-HeG: Automated Graph Neural Network on Heterophilic Graphs,"Graph neural architecture search (NAS) has gained popularity in automatically
designing powerful graph neural networks (GNNs) with relieving human efforts.
However, existing graph NAS methods mainly work under the homophily assumption
and overlook another important graph property, i.e., heterophily, which exists
widely in various real-world applications. To date, automated heterophilic
graph learning with NAS is still a research blank to be filled in. Due to the
complexity and variety of heterophilic graphs, the critical challenge of
heterophilic graph NAS mainly lies in developing the heterophily-specific
search space and strategy. Therefore, in this paper, we propose a novel
automated graph neural network on heterophilic graphs, namely Auto-HeG, to
automatically build heterophilic GNN models with expressive learning abilities.
Specifically, Auto-HeG incorporates heterophily into all stages of automatic
heterophilic graph learning, including search space design, supernet training,
and architecture selection. Through the diverse message-passing scheme with
joint micro-level and macro-level designs, we first build a comprehensive
heterophilic GNN search space, enabling Auto-HeG to integrate complex and
various heterophily of graphs. With a progressive supernet training strategy,
we dynamically shrink the initial search space according to layer-wise
variation of heterophily, resulting in a compact and efficient supernet. Taking
a heterophily-aware distance criterion as the guidance, we conduct heterophilic
architecture selection in the leave-one-out pattern, so that specialized and
expressive heterophilic GNN architectures can be derived. Extensive experiments
illustrate the superiority of Auto-HeG in developing excellent heterophilic
GNNs to human-designed models and graph NAS models.",2023-02-23,"Xin Zheng, Miao Zhang, Chunyang Chen, Qin Zhang, Chuan Zhou, Shirui Pan"
"Exploring celebrity influence on public attitude towards the COVID-19
  pandemic: social media shared sentiment analysis","The COVID-19 pandemic has introduced new opportunities for health
communication, including an increase in the public use of online outlets for
health-related emotions. People have turned to social media networks to share
sentiments related to the impacts of the COVID-19 pandemic. In this paper we
examine the role of social messaging shared by Persons in the Public Eye (i.e.
athletes, politicians, news personnel) in determining overall public discourse
direction. We harvested approximately 13 million tweets ranging from 1 January
2020 to 1 March 2022. The sentiment was calculated for each tweet using a
fine-tuned DistilRoBERTa model, which was used to compare COVID-19
vaccine-related Twitter posts (tweets) that co-occurred with mentions of People
in the Public Eye. Our findings suggest the presence of consistent patterns of
emotional content co-occurring with messaging shared by Persons in the Public
Eye for the first two years of the COVID-19 pandemic influenced public opinion
and largely stimulated online public discourse. We demonstrate that as the
pandemic progressed, public sentiment shared on social networks was shaped by
risk perceptions, political ideologies and health-protective behaviours shared
by Persons in the Public Eye, often in a negative light.",2023-02-23,"Brianna M White, Chad A Melton, Parya Zareie, Robert L Davis, Robert A Bednarczyk, Arash Shaban-Nejad"
"MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for
  Real-Time Fake News Mitigation in Social Media","The widespread availability of internet access and handheld devices confers
to social media a power similar to the one newspapers used to have. People seek
affordable information on social media and can reach it within seconds. Yet
this convenience comes with dangers; any user may freely post whatever they
please and the content can stay online for a long period, regardless of its
truthfulness. A need to detect untruthful information, also known as fake news,
arises. In this paper, we present an end-to-end solution that accurately
detects fake news and immunizes network nodes that spread them in real-time. To
detect fake news, we propose two new stack deep learning architectures that
utilize convolutional and bidirectional LSTM layers. To mitigate the spread of
fake news, we propose a real-time network-aware strategy that (1) constructs a
minimum-cost weighted directed spanning tree for a detected node, and (2)
immunizes nodes in that tree by scoring their harmfulness using a novel ranking
function. We demonstrate the effectiveness of our solution on five real-world
datasets.",2023-02-23,"Ciprian-Octavian Truică, Elena-Simona Apostol, Radu-Cătălin Nicolescu, Panagiotis Karras"
"A Symmetry and Graph Regularized Nonnegative Matrix Factorization Model
  for Community Detection","Community is a fundamental and critical characteristic of a Large-scale
Undirected Network (LUN) like a social network, making community detection a
vital yet thorny issue in LUN representation learning. Owing to its good
scalability and interpretability, a Symmetric and Nonnegative Matrix
Factorization (SNMF) model is commonly used to tackle this issue. However, it
adopts a unique Latent Factor (LF) matrix for precisely representing an LUN's
symmetry, which leads to a reduced LF space that impairs its representational
learning ability. Motivated by this discovery, this study proposes a Symmetry
and Graph-regularized Nonnegative Matrix Factorization (SGNMF) method that
adopts three-fold ideas: a) leveraging multiple LF matrices to represent an
LUN, thereby enhancing its representation learning ability; b) introducing a
symmetry regularization term that implies the equality constraint between its
multiple LF matrices, thereby illustrating an LUN's symmetry; and c)
incorporating graph regularization into its learning objective, thereby
illustrating an LUN's intrinsic geometry. A theoretical proof is provided to
ensure SGNMF's convergence on an LUN. Extensive experiment results on ten LUNs
from real applications demonstrate that our proposed SGNMF-based community
detector significantly outperforms several baseline and state-of-the-art models
in achieving highly-accurate results for community detection.",2023-02-23,"Zhigang Liu, Xin Luo"
"Heterogeneous Social Event Detection via Hyperbolic Graph
  Representations","Social events reflect the dynamics of society and, here, natural disasters
and emergencies receive significant attention. The timely detection of these
events can provide organisations and individuals with valuable information to
reduce or avoid losses. However, due to the complex heterogeneities of the
content and structure of social media, existing models can only learn limited
information; large amounts of semantic and structural information are ignored.
In addition, due to high labour costs, it is rare for social media datasets to
include high-quality labels, which also makes it challenging for models to
learn information from social media. In this study, we propose two hyperbolic
graph representation-based methods for detecting social events from
heterogeneous social media environments. For cases where a dataset has labels,
we designed a Hyperbolic Social Event Detection (HSED) model that converts
complex social information into a unified social message graph. This model
addresses the heterogeneity of social media, and, with this graph, the
information in social media can be used to capture structural information based
on the properties of hyperbolic space. For cases where the dataset is
unlabelled, we designed an Unsupervised Hyperbolic Social Event Detection
(UHSED). This model is based on the HSED model but includes graph contrastive
learning to make it work in unlabelled scenarios. Extensive experiments
demonstrate the superiority of the proposed approaches.",2023-02-20,"Zitai Qiu, Jia Wu, Jian Yang, Xing Su, Charu C. Aggarwal"
"Mental Health Coping Stories on Social Media: A Causal-Inference Study
  of Papageno Effect","The Papageno effect concerns how media can play a positive role in preventing
and mitigating suicidal ideation and behaviors. With the increasing ubiquity
and widespread use of social media, individuals often express and share lived
experiences and struggles with mental health. However, there is a gap in our
understanding about the existence and effectiveness of the Papageno effect in
social media, which we study in this paper. In particular, we adopt a
causal-inference framework to examine the impact of exposure to mental health
coping stories on individuals on Twitter. We obtain a Twitter dataset with
$\sim$2M posts by $\sim$10K individuals. We consider engaging with coping
stories as the Treatment intervention, and adopt a stratified propensity score
approach to find matched cohorts of Treatment and Control individuals. We
measure the psychosocial shifts in affective, behavioral, and cognitive
outcomes in longitudinal Twitter data before and after engaging with the coping
stories. Our findings reveal that, engaging with coping stories leads to
decreased stress and depression, and improved expressive writing, diversity,
and interactivity. Our work discusses the practical and platform design
implications in supporting mental wellbeing.",2023-02-20,"Yunhao Yuan, Koustuv Saha, Barbara Keller, Erkki Tapio Isometsä, Talayeh Aledavood"
"Persian topic detection based on Human Word association and graph
  embedding","In this paper, we propose a framework to detect topics in social media based
on Human Word Association. Identifying topics discussed in these media has
become a critical and significant challenge. Most of the work done in this area
is in English, but much has been done in the Persian language, especially
microblogs written in Persian. Also, the existing works focused more on
exploring frequent patterns or semantic relationships and ignored the
structural methods of language. In this paper, a topic detection framework
using HWA, a method for Human Word Association, is proposed. This method uses
the concept of imitation of mental ability for word association. This method
also calculates the Associative Gravity Force that shows how words are related.
Using this parameter, a graph can be generated. The topics can be extracted by
embedding this graph and using clustering methods. This approach has been
applied to a Persian language dataset collected from Telegram. Several
experimental studies have been performed to evaluate the proposed framework's
performance. Experimental results show that this approach works better than
other topic detection methods.",2023-02-20,"Mehrdad Ranjbar-Khadivi, Shahin Akbarpour, Mohammad-Reza Feizi-Derakhshi, Babak Anari"
"Upvotes? Downvotes? No Votes? Understanding the relationship between
  reaction mechanisms and political discourse on Reddit","A significant share of political discourse occurs online on social media
platforms. Policymakers and researchers try to understand the role of social
media design in shaping the quality of political discourse around the globe. In
the past decades, scholarship on political discourse theory has produced
distinct characteristics of different types of prominent political rhetoric
such as deliberative, civic, or demagogic discourse. This study investigates
the relationship between social media reaction mechanisms (i.e., upvotes,
downvotes) and political rhetoric in user discussions by engaging in an
in-depth conceptual analysis of political discourse theory. First, we analyze
155 million user comments in 55 political subforums on Reddit between 2010 and
2018 to explore whether users' style of political discussion aligns with the
essential components of deliberative, civic, and demagogic discourse. Second,
we perform a quantitative study that combines confirmatory factor analysis with
difference in differences models to explore whether different reaction
mechanism schemes (e.g., upvotes only, upvotes and downvotes, no reaction
mechanisms) correspond with political user discussion that is more or less
characteristic of deliberative, civic, or demagogic discourse. We produce three
main takeaways. First, despite being ""ideal constructs of political rhetoric,""
we find that political discourse theories describe political discussions on
Reddit to a large extent. Second, we find that discussions in subforums with
only upvotes, or both up- and downvotes are associated with user discourse that
is more deliberate and civic. Third, social media discussions are most
demagogic in subreddits with no reaction mechanisms at all. These findings
offer valuable contributions for ongoing policy discussions on the relationship
between social media interface design and respectful political discussion among
users.",2023-02-19,"Orestis Papakyriakopoulos, Severin Engelmann, Amy Winecoff"
Geometric description of clustering in directed networks,"First principle network models are crucial to make sense of the intricate
topology of real complex networks. While modeling efforts have been quite
successful in undirected networks, generative models for networks with
asymmetric interactions are still not well developed and are unable to
reproduce several basic topological properties. This is particularly
disconcerting considering that real directed networks are the norm rather than
the exception in many natural and human-made complex systems. In this paper, we
fill this gap and show how the network geometry paradigm can be elegantly
extended to the case of directed networks. We define a maximum entropy ensemble
of geometric (directed) random graphs with a given sequence of in- and
out-degrees. Beyond these local properties, the ensemble requires only two
additional parameters to fix the level of reciprocity and the seven possible
types of 3-node cycles in directed networks. A systematic comparison with
several representative empirical datasets shows that fixing the level of
reciprocity alongside the coupling with an underlying geometry is able to
reproduce the wide diversity of clustering patterns observed in real complex
directed networks.",2023-02-17,"Antoine Allard, M. Ángeles Serrano, Marián Boguñá"
Temporal Graph Neural Networks for Irregular Data,"This paper proposes a temporal graph neural network model for forecasting of
graph-structured irregularly observed time series. Our TGNN4I model is designed
to handle both irregular time steps and partial observations of the graph. This
is achieved by introducing a time-continuous latent state in each node,
following a linear Ordinary Differential Equation (ODE) defined by the output
of a Gated Recurrent Unit (GRU). The ODE has an explicit solution as a
combination of exponential decay and periodic dynamics. Observations in the
graph neighborhood are taken into account by integrating graph neural network
layers in both the GRU state update and predictive model. The time-continuous
dynamics additionally enable the model to make predictions at arbitrary time
steps. We propose a loss function that leverages this and allows for training
the model for forecasting over different time horizons. Experiments on
simulated data and real-world data from traffic and climate modeling validate
the usefulness of both the graph structure and time-continuous dynamics in
settings with irregular observations.",2023-02-16,"Joel Oskarsson, Per Sidén, Fredrik Lindsten"
Predicting Gender and Political Affiliation Using Mobile Payment Data,"We explore the understudied area of social payments to evaluate whether or
not we can predict the gender and political affiliation of Venmo users based on
the content of their Venmo transactions. Latent attribute detection has been
successfully applied in the domain of studying social media. However, there
remains a dearth of previous work using data other than Twitter. There is also
a continued need for studies which explore mobile payments spaces like Venmo,
which remain understudied due to the lack of data access. We hypothesize that
using methods similar to latent attribute analysis with Twitter data, machine
learning algorithms will be able to predict gender and political affiliation of
Venmo users with a moderate degree of accuracy. We collected crowdsourced
training data that correlates participants' political views with their public
Venmo transaction history through the paid Prolific service. Additionally, we
collected 21 million public Venmo transactions from recently active users to
use for gender classification. We then ran the collected data through a TF-IDF
vectorizer and used that to train a support vector machine (SVM). After
hyperparameter training and additional feature engineering, we were able to
predict user's gender with a high level of accuracy (.91) and had modest
success predicting user's political orientation (.63).",2023-02-16,"Ben Stobaugh, Dhiraj Murthy"
"Analyzing the Engagement of Social Relationships During Life Event
  Shocks in Social Media","Individuals experiencing unexpected distressing events, shocks, often rely on
their social network for support. While prior work has shown how social
networks respond to shocks, these studies usually treat all ties equally,
despite differences in the support provided by different social relationships.
Here, we conduct a computational analysis on Twitter that examines how
responses to online shocks differ by the relationship type of a user dyad. We
introduce a new dataset of over 13K instances of individuals' self-reporting
shock events on Twitter and construct networks of relationship-labeled dyadic
interactions around these events. By examining behaviors across 110K replies to
shocked users in a pseudo-causal analysis, we demonstrate relationship-specific
patterns in response levels and topic shifts. We also show that while
well-established social dimensions of closeness such as tie strength and
structural embeddedness contribute to shock responsiveness, the degree of
impact is highly dependent on relationship and shock types. Our findings
indicate that social relationships contain highly distinctive characteristics
in network interactions and that relationship-specific behaviors in online
shock responses are unique from those of offline settings.",2023-02-15,"Minje Choi, David Jurgens, Daniel M. Romero"
"SynGraphy: Succinct Summarisation of Large Networks via Small Synthetic
  Representative Graphs","We describe SynGraphy, a method for visually summarising the structure of
large network datasets that works by drawing smaller graphs generated to have
similar structural properties to the input graphs. Visualising complex networks
is crucial to understand and make sense of networked data and the relationships
it represents. Due to the large size of many networks, visualisation is
extremely difficult; the simple method of drawing large networks like those of
Facebook or Twitter leads to graphics that convey little or no information.
While modern graph layout algorithms can scale computationally to large
networks, their output tends to a common ""hairball"" look, which makes it
difficult to even distinguish different graphs from each other. Graph sampling
and graph coarsening techniques partially address these limitations but they
are only able to preserve a subset of the properties of the original graphs. In
this paper we take the problem of visualising large graphs from a novel
perspective: we leave the original graph's nodes and edges behind, and instead
summarise its properties such as the clustering coefficient and bipartivity by
generating a completely new graph whose structural properties match that of the
original graph. To verify the utility of this approach as compared to other
graph visualisation algorithms, we perform an experimental evaluation in which
we repeatedly asked experimental subjects (professionals in graph mining and
related areas) to determine which of two given graphs has a given structural
property and then assess which visualisation algorithm helped in identifying
the correct answer. Our summarisation approach SynGraphy compares favourably to
other techniques on a variety of networks.",2023-02-15,"Jérôme Kunegis, Pawan Kumar, Jun Sun, Anna Samoilenko, Giuseppe Pirró"
"Evidence of Demographic rather than Ideological Segregation in News
  Discussion on Reddit","We evaluate homophily and heterophily among ideological and demographic
groups in a typical opinion formation context: online discussions of current
news. We analyze user interactions across five years in the r/news community on
Reddit, one of the most visited websites in the United States. Then, we
estimate demographic and ideological attributes of these users. Thanks to a
comparison with a carefully-crafted network null model, we establish which
pairs of attributes foster interactions and which ones inhibit them.
  Individuals prefer to engage with the opposite ideological side, which
contradicts the echo chamber narrative. Instead, demographic groups are
homophilic, as individuals tend to interact within their own group - even in an
online setting where such attributes are not directly observable. In
particular, we observe age and income segregation consistently across years:
users tend to avoid interactions when belonging to different groups. These
results persist after controlling for the degree of interest by each
demographic group in different news topics. Our findings align with the theory
that affective polarization - the difficulty in socializing across political
boundaries-is more connected with an increasingly divided society, rather than
ideological echo chambers on social media.
  We publicly release our anonymized data set and all the code to reproduce our
results: https://github.com/corradomonti/demographic-homophily",2023-02-15,"Corrado Monti, Jacopo D'Ignazi, Michele Starnini, Gianmarco De Francisci Morales"
Attacking Fake News Detectors via Manipulating News Social Engagement,"Social media is one of the main sources for news consumption, especially
among the younger generation. With the increasing popularity of news
consumption on various social media platforms, there has been a surge of
misinformation which includes false information or unfounded claims. As various
text- and social context-based fake news detectors are proposed to detect
misinformation on social media, recent works start to focus on the
vulnerabilities of fake news detectors. In this paper, we present the first
adversarial attack framework against Graph Neural Network (GNN)-based fake news
detectors to probe their robustness. Specifically, we leverage a multi-agent
reinforcement learning (MARL) framework to simulate the adversarial behavior of
fraudsters on social media. Research has shown that in real-world settings,
fraudsters coordinate with each other to share different news in order to evade
the detection of fake news detectors. Therefore, we modeled our MARL framework
as a Markov Game with bot, cyborg, and crowd worker agents, which have their
own distinctive cost, budget, and influence. We then use deep Q-learning to
search for the optimal policy that maximizes the rewards. Extensive
experimental results on two real-world fake news propagation datasets
demonstrate that our proposed framework can effectively sabotage the GNN-based
fake news detector performance. We hope this paper can provide insights for
future research on fake news detection.",2023-02-14,"Haoran Wang, Yingtong Dou, Canyu Chen, Lichao Sun, Philip S. Yu, Kai Shu"
SHEEP: Signed Hamiltonian Eigenvector Embedding for Proximity,"We introduce a spectral embedding algorithm for finding proximal
relationships between nodes in signed graphs, where edges can take either
positive or negative weights. Adopting a physical perspective, we construct a
Hamiltonian which is dependent on the distance between nodes, such that
relative embedding distance results in a similarity metric between nodes. The
Hamiltonian admits a global minimum energy configuration, which can be
reconfigured as an eigenvector problem, and therefore is computationally
efficient to compute. We use matrix perturbation theory to show that the
embedding generates a ground state energy, which can be used as a statistical
test for the presence of strong balance, and to develop an energy-based
approach for locating the optimal embedding dimension. Finally, we show through
a series of experiments on synthetic and empirical networks, that the resulting
position in the embedding can be used to recover certain continuous node
attributes, and that the distance to the origin in the optimal embedding gives
a measure of node extremism.",2023-02-14,"Shazia'Ayn Babul, Renaud Lambiotte"
"Random Majority Opinion Diffusion: Stabilization Time, Absorbing States,
  and Influential Nodes","Consider a graph G with n nodes and m edges, which represents a social
network, and assume that initially each node is blue or white. In each round,
all nodes simultaneously update their color to the most frequent color in their
neighborhood. This is called the Majority Model (MM) if a node keeps its color
in case of a tie and the Random Majority Model (RMM) if it chooses blue with
probability 1/2 and white otherwise.
  We prove that there are graphs for which RMM needs exponentially many rounds
to reach a stable configuration in expectation, and such a configuration can
have exponentially many states (i.e., colorings). This is in contrast to MM,
which is known to always reach a stable configuration with one or two states in
$O(m)$ rounds. For the special case of a cycle graph C_n, we prove the stronger
and tight bounds of $\lceil n/2\rceil-1$ and $O(n^2)$ in MM and RMM,
respectively. Furthermore, we show that the number of stable colorings in MM on
C_n is equal to $\Theta(\Phi^n)$, where $\Phi = (1+\sqrt{5})/2$ is the golden
ratio, while it is equal to 2 for RMM.
  We also study the minimum size of a winning set, which is a set of nodes
whose agreement on a color in the initial coloring enforces the process to end
in a coloring where all nodes share that color. We present tight bounds on the
minimum size of a winning set for both MM and RMM.
  Furthermore, we analyze our models for a random initial coloring, where each
node is colored blue independently with some probability $p$ and white
otherwise. Using some martingale analysis and counting arguments, we prove that
the expected final number of blue nodes is respectively equal to
$(2p^2-p^3)n/(1-p+p^2)$ and pn in MM and RMM on a cycle graph C_n.
  Finally, we conduct some experiments which complement our theoretical
findings and also lead to the proposal of some intriguing open problems and
conjectures to be tackled in future work.",2023-02-14,Ahad N. Zehmakan
Homophily-oriented Heterogeneous Graph Rewiring,"With the rapid development of the World Wide Web (WWW), heterogeneous graphs
(HG) have explosive growth. Recently, heterogeneous graph neural network (HGNN)
has shown great potential in learning on HG. Current studies of HGNN mainly
focus on some HGs with strong homophily properties (nodes connected by
meta-path tend to have the same labels), while few discussions are made in
those that are less homophilous. Recently, there have been many works on
homogeneous graphs with heterophily. However, due to heterogeneity, it is
non-trivial to extend their approach to deal with HGs with heterophily. In this
work, based on empirical observations, we propose a meta-path-induced metric to
measure the homophily degree of a HG. We also find that current HGNNs may have
degenerated performance when handling HGs with less homophilous properties.
Thus it is essential to increase the generalization ability of HGNNs on
non-homophilous HGs. To this end, we propose HDHGR, a homophily-oriented deep
heterogeneous graph rewiring approach that modifies the HG structure to
increase the performance of HGNN. We theoretically verify HDHGR. In addition,
experiments on real-world HGs demonstrate the effectiveness of HDHGR, which
brings at most more than 10% relative gain.",2023-02-13,"Jiayan Guo, Lun Du, Wendong Bi, Qiang Fu, Xiaojun Ma, Xu Chen, Shi Han, Dongmei Zhang, Yan Zhang"
"Towards Lightweight and Automated Representation Learning System for
  Networks","We propose LIGHTNE 2.0, a cost-effective, scalable, automated, and
high-quality network embedding system that scales to graphs with hundreds of
billions of edges on a single machine. In contrast to the mainstream belief
that distributed architecture and GPUs are needed for large-scale network
embedding with good quality, we prove that we can achieve higher quality,
better scalability, lower cost, and faster runtime with shared-memory, CPU-only
architecture. LIGHTNE 2.0 combines two theoretically grounded embedding methods
NetSMF and ProNE. We introduce the following techniques to network embedding
for the first time: (1) a newly proposed downsampling method to reduce the
sample complexity of NetSMF while preserving its theoretical advantages; (2) a
high-performance parallel graph processing stack GBBS to achieve high memory
efficiency and scalability; (3) sparse parallel hash table to aggregate and
maintain the matrix sparsifier in memory; (4) a fast randomized singular value
decomposition (SVD) enhanced by power iteration and fast orthonormalization to
improve vanilla randomized SVD in terms of both efficiency and effectiveness;
(5) Intel MKL for proposed fast randomized SVD and spectral propagation; and
(6) a fast and lightweight AutoML library FLAML for automated hyperparameter
tuning. Experimental results show that LIGHTNE 2.0 can be up to 84X faster than
GraphVite, 30X faster than PBG and 9X faster than NetSMF while delivering
better performance. LIGHTNE 2.0 can embed very large graph with 1.7 billion
nodes and 124 billion edges in half an hour on a CPU server, while other
baselines cannot handle very large graphs of this scale.",2023-02-13,"Yuyang Xie, Jiezhong Qiu, Laxman Dhulipala, Wenjian Yu, Jie Tang, Richard Peng, Chi Wang"
"PDSum: Prototype-driven Continuous Summarization of Evolving
  Multi-document Sets Stream","Summarizing text-rich documents has been long studied in the literature, but
most of the existing efforts have been made to summarize a static and
predefined multi-document set. With the rapid development of online platforms
for generating and distributing text-rich documents, there arises an urgent
need for continuously summarizing dynamically evolving multi-document sets
where the composition of documents and sets is changing over time. This is
especially challenging as the summarization should be not only effective in
incorporating relevant, novel, and distinctive information from each concurrent
multi-document set, but also efficient in serving online applications. In this
work, we propose a new summarization problem, Evolving Multi-Document sets
stream Summarization (EMDS), and introduce a novel unsupervised algorithm PDSum
with the idea of prototype-driven continuous summarization. PDSum builds a
lightweight prototype of each multi-document set and exploits it to adapt to
new documents while preserving accumulated knowledge from previous documents.
To update new summaries, the most representative sentences for each
multi-document set are extracted by measuring their similarities to the
prototypes. A thorough evaluation with real multi-document sets streams
demonstrates that PDSum outperforms state-of-the-art unsupervised
multi-document summarization algorithms in EMDS in terms of relevance, novelty,
and distinctiveness and is also robust to various evaluation settings.",2023-02-10,"Susik Yoon, Hou Pong Chan, Jiawei Han"
Fair Notification Optimization: An Auction Approach,"Notifications are important for the user experience in mobile apps and can
influence their engagement. However, too many notifications can be disruptive
for users. A typical mobile app usually has several types of notification,
managed by distinct teams with objectives that are possibly conflicting with
each other, or even with the overall platform objective. Therefore, there is a
need for careful curation of notifications sent to users of these different
types. In this work, we study a novel centralized approach for notification
optimization, where we view the opportunities to send user notifications as
items and types of notifications as buyers in an auction market. Furthermore,
the auction setup is unique, and the platform has the ability to subsidize the
bids from the notification types.
  Using tools from fair division, we study the application of competitive
equilibrium for addressing this problem. We show that an Eisenberg-Gale-style
convex program allows us to find an allocation that is fair to all notification
types in hindsight. Using the dual of the formulation, we present an online
algorithm that allocates notifications via first-price auctions using a
pacing-multiplier approach. Secondly, we introduce an approach based on
second-price auctions and pacing, which has the benefit of working well with
existing advertising systems built for second-price auctions.
  Through an A/B test in production, we show that the second price-based
auction system improves over a decentralized notification optimization system,
leading to its launch in production for some Instagram notifications. Further,
through simulations on Instagram notification data and a subsequent production
A/B test, we compare the outcomes of first-price and second-price auctions and
show that the former has more stable pacing multipliers.",2023-02-09,"Christian Kroer, Deeksha Sinha, Xuan Zhang, Shiwen Cheng, Ziyu Zhou"
"NeuKron: Constant-Size Lossy Compression of Sparse Reorderable Matrices
  and Tensors","Many real-world data are naturally represented as a sparse reorderable
matrix, whose rows and columns can be arbitrarily ordered (e.g., the adjacency
matrix of a bipartite graph). Storing a sparse matrix in conventional ways
requires an amount of space linear in the number of non-zeros, and lossy
compression of sparse matrices (e.g., Truncated SVD) typically requires an
amount of space linear in the number of rows and columns. In this work, we
propose NeuKron for compressing a sparse reorderable matrix into a
constant-size space. NeuKron generalizes Kronecker products using a recurrent
neural network with a constant number of parameters. NeuKron updates the
parameters so that a given matrix is approximated by the product and reorders
the rows and columns of the matrix to facilitate the approximation. The updates
take time linear in the number of non-zeros in the input matrix, and the
approximation of each entry can be retrieved in logarithmic time. We also
extend NeuKron to compress sparse reorderable tensors (e.g. multi-layer
graphs), which generalize matrices. Through experiments on ten real-world
datasets, we show that NeuKron is (a) Compact: requiring up to five orders of
magnitude less space than its best competitor with similar approximation
errors, (b) Accurate: giving up to 10x smaller approximation error than its
best competitors with similar size outputs, and (c) Scalable: successfully
compressing a matrix with over 230 million non-zero entries.",2023-02-09,"Taehyung Kwon, Jihoon Ko, Jinhong Jung, Kijung Shin"
"Auditing Recommender Systems -- Putting the DSA into practice with a
  risk-scenario-based approach","Today's online platforms rely heavily on recommendation systems to serve
content to their users; social media is a prime example. In turn,
recommendation systems largely depend on artificial intelligence algorithms to
decide who gets to see what. While the content social media platforms deliver
is as varied as the users who engage with them, it has been shown that
platforms can contribute to serious harm to individuals, groups and societies.
Studies have suggested that these negative impacts range from worsening an
individual's mental health to driving society-wide polarisation capable of
putting democracies at risk. To better safeguard people from these harms, the
European Union's Digital Services Act (DSA) requires platforms, especially
those with large numbers of users, to make their algorithmic systems more
transparent and follow due diligence obligations. These requirements constitute
an important legislative step towards mitigating the systemic risks posed by
online platforms. However, the DSA lacks concrete guidelines to operationalise
a viable audit process that would allow auditors to hold these platforms
accountable. This void could foster the spread of 'audit-washing', that is,
platforms exploiting audits to legitimise their practices and neglect
responsibility.
  To fill this gap, we propose a risk-scenario-based audit process. We explain
in detail what audits and assessments of recommender systems according to the
DSA should look like. Our approach also considers the evolving nature of
platforms and emphasises the observability of their recommender systems'
components. The resulting audit facilitates internal (among audits of the same
system at different moments in time) and external comparability (among audits
of different platforms) while also affording the evaluation of mitigation
measures implemented by the platforms themselves.",2023-02-09,"Anna-Katharina Meßmer, Martin Degeling"
On Generalized Degree Fairness in Graph Neural Networks,"Conventional graph neural networks (GNNs) are often confronted with fairness
issues that may stem from their input, including node attributes and neighbors
surrounding a node. While several recent approaches have been proposed to
eliminate the bias rooted in sensitive attributes, they ignore the other key
input of GNNs, namely the neighbors of a node, which can introduce bias since
GNNs hinge on neighborhood structures to generate node representations. In
particular, the varying neighborhood structures across nodes, manifesting
themselves in drastically different node degrees, give rise to the diverse
behaviors of nodes and biased outcomes. In this paper, we first define and
generalize the degree bias using a generalized definition of node degree as a
manifestation and quantification of different multi-hop structures around
different nodes. To address the bias in the context of node classification, we
propose a novel GNN framework called Generalized Degree Fairness-centric Graph
Neural Network (Deg-FairGNN). Specifically, in each GNN layer, we employ a
learnable debiasing function to generate debiasing contexts, which modulate the
layer-wise neighborhood aggregation to eliminate the degree bias originating
from the diverse degrees among nodes. Extensive experiments on three benchmark
datasets demonstrate the effectiveness of our model on both accuracy and
fairness metrics.",2023-02-08,"Zemin Liu, Trung-Kien Nguyen, Yuan Fang"
"Does AI-Assisted Fact-Checking Disproportionately Benefit Majority
  Groups Online?","In recent years, algorithms have been incorporated into fact-checking
pipelines. They are used not only to flag previously fact-checked
misinformation, but also to provide suggestions about which trending claims
should be prioritized for fact-checking - a paradigm called `check-worthiness.'
While several studies have examined the accuracy of these algorithms, none have
investigated how the benefits from these algorithms (via reduction in exposure
to misinformation) are distributed amongst various online communities. In this
paper, we investigate how diverse representation across multiple stages of the
AI development pipeline affects the distribution of benefits from AI-assisted
fact-checking for different online communities. We simulate information
propagation through the network using our novel Topic-Aware, Community-Impacted
Twitter (TACIT) simulator on a large Twitter followers network, tuned to
produce realistic cascades of true and false information across multiple
topics. Finally, using simulated data as a test bed, we implement numerous
algorithmic fact-checking interventions that explicitly account for notions of
diversity. We find that both representative and egalitarian methods for
sampling and labeling check-worthiness model training data can lead to
network-wide benefit concentrated in majority communities, while incorporating
diversity into how fact-checkers use algorithmic recommendations can actively
reduce inequalities in benefits between majority and minority communities.
These findings contribute to an important conversation around the responsible
implementation of AI-assisted fact-checking by social media platforms and
fact-checking organizations.",2023-02-07,"Terrence Neumann, Nicholas Wolczynski"
"What Do We Mean When We Talk about Trust in Social Media? A Systematic
  Review","Do people trust social media? If so, why, in what contexts, and how does that
trust impact their lives? Researchers, companies, and journalists alike have
increasingly investigated these questions, which are fundamental to
understanding social media interactions and their implications for society.
However, trust in social media is a complex concept, and there is conflicting
evidence about the antecedents and implications of trusting social media
content, users, and platforms. More problematic is that we lack basic agreement
as to what trust means in the context of social media. Addressing these
challenges, we conducted a systematic review to identify themes and challenges
in this field. Through our analysis of 70 papers, we contribute a synthesis of
how trust in social media is defined, conceptualized, and measured, a summary
of trust antecedents in social media, an understanding of how trust in social
media impacts behaviors and attitudes, and directions for future work.",2023-02-07,"Yixuan Zhang, Joseph D Gaggiano, Nutchanon Yongsatianchot, Nurul M Suhaimi, Miso Kim, Yifan Sun, Jacqueline Griffin, Andrea G Parker"
"Understanding the Loss in Community Resilience due to Hurricanes using
  Facebook Data","Significant negative impacts are observed in productivity, economy, and
social wellbeing because of the reduced human activity due to extreme events.
Community resilience is an important and widely used concept to understand the
impacts of an extreme event to population activity. Resilience is generally
defined as the ability of a system to manage shocks and return to a steady
state in response to an extreme event. In this study, aggregate location data
from Facebook in response to Hurricane Ida are analyzed. Using changes in the
number of Facebook users before, during, and after the disaster, community
resilience is quantified as a function of the magnitude of impact and the time
to recover from the extreme situation. Based on the resilience function, the
transient loss of resilience in population activity is measured for the
affected communities in Louisiana. The loss in resilience of the affected
communities are explained by three types of factors, including disruption in
physical infrastructures, disaster conditions due to hurricanes, and
socio-economic characteristics. A greater loss in community resilience is
associated with factors such as disruptions in power and transportation
services and disaster conditions. Socioeconomic disparities in loss of
resilience are found with respect to median income of a community.
Understanding community resilience using decreased population activity levels
due to a disaster and the factors associated with losses in resilience will
enable us improve hazard preparedness, enhance disaster management practices,
and create better recovery policies towards strengthening infrastructure and
community resilience.",2023-02-07,"Tasnuba Binte Jamal, Samiul Hasan"
Calibrated Recommendations for Users with Decaying Attention,"Recommendation systems capable of providing diverse sets of results are a
focus of increasing importance, with motivations ranging from fairness to
novelty and other aspects of optimizing user experience. One form of diversity
of recent interest is calibration, the notion that personalized recommendations
should reflect the full distribution of a user's interests, rather than a
single predominant category -- for instance, a user who mainly reads
entertainment news but also wants to keep up with news on the environment and
the economy would prefer to see a mixture of these genres, not solely
entertainment news. Existing work has formulated calibration as a subset
selection problem; this line of work observes that the formulation requires the
unrealistic assumption that all recommended items receive equal consideration
from the user, but leaves as an open question the more realistic setting in
which user attention decays as they move down the list of results.
  In this paper, we consider calibration with decaying user attention under two
different models. In both models, there is a set of underlying genres that
items can belong to. In the first setting, where items are represented by
fine-grained mixtures of genre percentages, we provide a
$(1-1/e)$-approximation algorithm by extending techniques for constrained
submodular optimization. In the second setting, where items are coarsely binned
into a single genre each, we surpass the $(1-1/e)$ barrier imposed by
submodular maximization and give a $2/3$-approximate greedy algorithm. Our work
thus addresses the problem of capturing ordering effects due to decaying
attention, allowing for the extension of near-optimal calibration from
recommendation sets to recommendation lists.",2023-02-07,"Jon Kleinberg, Emily Ryu, Éva Tardos"
Generative models for two-ground-truth partitions in networks,"A myriad of approaches have been proposed to characterise the mesoscale
structure of networks - most often as a partition based on patterns variously
called communities, blocks, or clusters. Clearly, distinct methods designed to
detect different types of patterns may provide a variety of answers to the
network's mesoscale structure. Yet, even multiple runs of a given method can
sometimes yield diverse and conflicting results, producing entire landscapes of
partitions which potentially include multiple (locally optimal) mesoscale
explanations of the network. Such ambiguity motivates a closer look at the
ability of these methods to find multiple qualitatively different 'ground
truth' partitions in a network. Here, we propose the stochastic cross-block
model (SCBM), a generative model which allows for two distinct partitions to be
built into the mesoscale structure of a single benchmark network. We
demonstrate a use case of the benchmark model by appraising the power of
stochastic block models (SBMs) to detect implicitly planted coexisting
bi-community and core-periphery structures of different strengths. Given our
model design and experimental set-up, we find that the ability to detect the
two partitions individually varies by SBM variant and that coexistence of both
partitions is recovered only in a very limited number of cases. Our findings
suggest that in most instances only one - in some way dominating - structure
can be detected, even in the presence of other partitions. They underline the
need for considering entire landscapes of partitions when different competing
explanations exist and motivate future research to advance partition
coexistence detection methods. Our model also contributes to the field of
benchmark networks more generally by enabling further exploration of the
ability of new and existing methods to detect ambiguity in the mesoscale
structure of networks.",2023-02-06,"Lena Mangold, Camille Roth"
Hatemongers ride on echo chambers to escalate hate speech diffusion,"Recent years have witnessed a swelling rise of hateful and abusive content
over online social networks. While detection and moderation of hate speech have
been the early go-to countermeasures, the solution requires a deeper
exploration of the dynamics of hate generation and propagation. We analyze more
than 32 million posts from over 6.8 million users across three popular online
social networks to investigate the interrelations between hateful behavior,
information dissemination, and polarised organization mediated by echo
chambers. We find that hatemongers play a more crucial role in governing the
spread of information compared to singled-out hateful content. This observation
holds for both the growth of information cascades as well as the conglomeration
of hateful actors. Dissection of the core-wise distribution of these networks
points towards the fact that hateful users acquire a more well-connected
position in the social network and often flock together to build up information
cascades. We observe that this cohesion is far from mere organized behavior;
instead, in these networks, hatemongers dominate the echo chambers -- groups of
users actively align themselves to specific ideological positions. The observed
dominance of hateful users to inflate information cascades is primarily via
user interactions amplified within these echo chambers. We conclude our study
with a cautionary note that popularity-based recommendation of content is
susceptible to be exploited by hatemongers given their potential to escalate
content popularity via echo-chambered interactions.",2023-02-05,"Vasu Goel, Dhruv Sahnan, Subhabrata Dutta, Anil Bandhakavi, Tanmoy Chakraborty"
"Quantifying the uneven efficiency benefits of ridesharing market
  integration","Ridesharing is recognized as one of the key pathways to sustainable urban
mobility. With the emergence of Transportation Network Companies (TNCs) such as
Uber and Lyft, the ridesharing market has become increasingly fragmented in
many cities around the world, leading to efficiency loss and increased traffic
congestion. While an integrated ridesharing market (allowing sharing across
TNCs) can improve the overall efficiency, how such benefits may vary across
TNCs based on actual market characteristics is still not well understood. In
this study, we extend a shareability network framework to quantify and explain
the efficiency benefits of ridesharing market integration using available TNC
trip records. Through a case study in Manhattan, New York City, the proposed
framework is applied to analyze a real-world ridesharing market with 3
TNCs$-$Uber, Lyft, and Via. It is estimated that a perfectly integrated market
in Manhattan would improve ridesharing efficiency by 13.3%, or 5% of daily TNC
vehicle hours traveled. Further analysis reveals that (1) the efficiency
improvement is negatively correlated with the overall demand density and
inter-TNC spatiotemporal unevenness (measured by network modularity), (2)
market integration would generate a larger efficiency improvement in a
competitive market, and (3) the TNC with a higher intra-TNC demand
concentration (measured by clustering coefficient) would benefit less from
market integration. As the uneven benefits may deter TNCs from collaboration,
we also illustrate how to quantify each TNC's marginal contribution based on
the Shapley value, which can be used to ensure equitable profit allocation.
These results can help market regulators and business alliances to evaluate and
monitor market efficiency and dynamically adjust their strategies, incentives,
and profit allocation schemes to promote market integration and collaboration.",2023-02-05,"Xiaohan Wang, Zhan Zhao, Hongmou Zhang, Xiaotong Guo, Jinhua Zhao"
"Structural Robustness of Complex Networks: A Survey of A Posteriori
  Measures","Network robustness is critical for various industrial and social networks
against malicious attacks, which has various meanings in different research
contexts and here it refers to the ability of a network to sustain its
functionality when a fraction of the network fail to work due to attacks. The
rapid development of complex networks research indicates special interest and
great concern about the network robustness, which is essential for further
analyzing and optimizing network structures towards engineering applications.
This comprehensive survey distills the important findings and developments of
network robustness research, focusing on the a posteriori structural robustness
measures for single-layer static networks. Specifically, the a posteriori
robustness measures are reviewed from four perspectives: 1) network
functionality, including connectivity, controllability and communication
ability, as well as their extensions; 2) malicious attacks, including
conventional and computation-based attack strategies; 3) robustness estimation
methods using either analytical approximation or machine learning-based
prediction; 4) network robustness optimization. Based on the existing measures,
a practical threshold of network destruction is introduced, with the suggestion
that network robustness should be measured only before reaching the threshold
of destruction. Then, a posteriori and a priori measures are compared
experimentally, revealing the advantages of the a posteriori measures. Finally,
prospective research directions with respect to a posteriori robustness
measures are recommended.",2023-02-03,"Yang Lou, Lin Wang, Guanrong Chen"
"Identification of an influence network using ensemble-based filtering
  for Hawkes processes driven by count data","Many networks have event-driven dynamics (such as communication, social media
and criminal networks), where the mean rate of the events occurring at a node
in the network changes according to the occurrence of other events in the
network. In particular, events associated with a node of the network could
increase the rate of events at other nodes, depending on their influence
relationship. Thus, it is of interest to use temporal data to uncover the
directional, time-dependent, influence structure of a given network while also
quantifying uncertainty even when knowledge of a physical network is lacking.
Typically, methods for inferring the influence structure in networks require
knowledge of a physical network or are only able to infer small network
structures. In this paper, we model event-driven dynamics on a network by a
multidimensional Hawkes process. We then develop a novel ensemble-based
filtering approach for a time-series of count data (i.e., data that provides
the number of events per unit time for each node in the network) that not only
tracks the influence network structure over time but also approximates the
uncertainty via ensemble spread. The method overcomes several deficiencies in
existing methods such as existing methods for inferring multidimensional Hawkes
processes are too slow to be practical for any network over ~50 nodes, can only
deal with timestamp data (i.e. data on just when events occur not the number of
events at each node), and that we do not need a physical network to start with.
Our method is massively parallelizable, allowing for its use to infer the
influence structure of large networks (~10,000 nodes). We demonstrate our
method for large networks using both synthetic and real-world email
communication data.",2023-02-01,"Santitissadeekorn N., Delahaies S., Lloyd D. J. B"
"Anomaly, reciprocity, and community detection in networks","Anomaly detection algorithms are a valuable tool in network science for
identifying unusual patterns in a network. These algorithms have numerous
practical applications, including detecting fraud, identifying network security
threats, and uncovering significant interactions within a dataset. In this
project, we propose a probabilistic generative approach that incorporates
community membership and reciprocity as key factors driving regular behavior in
a network, which can be used to identify potential anomalies that deviate from
expected patterns. We model pairs of edges in a network with exact two-edge
joint distributions. As a result, our approach captures the exact relationship
between pairs of edges and provides a more comprehensive view of social
networks. Additionally, our study highlights the role of reciprocity in network
analysis and can inform the design of future models and algorithms. We also
develop an efficient algorithmic implementation that takes advantage of the
sparsity of the network.",2023-02-01,"Hadiseh Safdari, Martina Contisciani, Caterina De Bacco"
"Affinity Uncertainty-based Hard Negative Mining in Graph Contrastive
  Learning","Hard negative mining has shown effective in enhancing self-supervised
contrastive learning (CL) on diverse data types, including graph CL (GCL). The
existing hardness-aware CL methods typically treat negative instances that are
most similar to the anchor instance as hard negatives, which helps improve the
CL performance, especially on image data. However, this approach often fails to
identify the hard negatives but leads to many false negatives on graph data.
This is mainly due to that the learned graph representations are not
sufficiently discriminative due to oversmooth representations and/or
non-independent and identically distributed (non-i.i.d.) issues in graph data.
To tackle this problem, this article proposes a novel approach that builds a
discriminative model on collective affinity information (i.e., two sets of
pairwise affinities between the negative instances and the anchor instance) to
mine hard negatives in GCL. In particular, the proposed approach evaluates how
confident/uncertain the discriminative model is about the affinity of each
negative instance to an anchor instance to determine its hardness weight
relative to the anchor instance. This uncertainty information is then
incorporated into the existing GCL loss functions via a weighting term to
enhance their performance. The enhanced GCL is theoretically grounded that the
resulting GCL loss is equivalent to a triplet loss with an adaptive margin
being exponentially proportional to the learned uncertainty of each negative
instance. Extensive experiments on ten graph datasets show that our approach
does the following: 1) consistently enhances different state-of-the-art (SOTA)
GCL methods in both graph and node classification tasks and 2) significantly
improves their robustness against adversarial attacks. Code is available at
https://github.com/mala-lab/AUGCL.",2023-01-31,"Chaoxi Niu, Guansong Pang, Ling Chen"
"Enhancing Efficiency in Parallel Louvain Algorithm for Community
  Detection","Community detection is a key aspect of network analysis, as it allows for the
identification of groups and patterns within a network. With the
ever-increasing size of networks, it is crucial to have fast algorithms to
analyze them efficiently. It is a modularity-based greedy algorithm that
divides a network into disconnected communities better over several iterations.
Even in big, dense networks, it is renowned for establishing high-quality
communities. However it can be at least a factor of ten slower than community
discovery techniques that rely on label-propagation, which are generally
extremely fast but obtain communities of lower quality. The researchers have
suggested a number of methods for parallelizing and improving the Louvain
algorithm. To decide which strategy is generally the best fit and which
parameter values produce the highest performance without compromising community
quality, it is critical to assess the performance and accuracy of these
existing approaches. As we implement the single-threaded and multi-threaded
versions of the static Louvain algorithm in this report, we carefully examine
the method's specifics, make the required tweaks and optimizations, and
determine the right parameter values. The tolerance between each pass can be
changed to adjust the method's performance. With an initial tolerance of 0.01
and a tolerance decline factor of 10, an asynchronous version of the algorithm
produced the best results. Generally speaking, according to our findings, the
approach is not well suited for shared-memory parallelism; however, one
potential workaround is to break the graph into manageable chunks that can be
independently executed and then merged back together.",2023-01-29,Subhajit Sahu
"Encoding Node Diffusion Competence and Role Significance for Network
  Dismantling","Percolation theory shows that removing a small fraction of critical nodes can
lead to the disintegration of a large network into many disconnected tiny
subnetworks. The network dismantling task focuses on how to efficiently select
the least such critical nodes. Most existing approaches focus on measuring
nodes' importance from either functional or topological viewpoint. Different
from theirs, we argue that nodes' importance can be measured from both of the
two complementary aspects: The functional importance can be based on the nodes'
competence in relaying network information; While the topological importance
can be measured from nodes' regional structural patterns. In this paper, we
propose an unsupervised learning framework for network dismantling, called
DCRS, which encodes and fuses both node diffusion competence and role
significance. Specifically, we propose a graph diffusion neural network which
emulates information diffusion for competence encoding; We divide nodes with
similar egonet structural patterns into a few roles, and construct a role graph
on which to encode node role significance. The DCRS converts and fuses the two
encodings to output a final ranking score for selecting critical nodes.
Experiments on both real-world networks and synthetic networks demonstrate that
our scheme significantly outperforms the state-of-the-art competitors for its
mostly requiring much fewer nodes to dismantle a network.",2023-01-29,"Jiazheng Zhang, Bang Wang"
"Neural Temporal Point Processes for Forecasting Directional Relations in
  Evolving Hypergraphs","Forecasting relations between entities is paramount in the current era of
data and AI. However, it is often overlooked that real-world relationships are
inherently directional, involve more than two entities, and can change with
time. In this paper, we provide a comprehensive solution to the problem of
forecasting directional relations in a general setting, where relations are
higher-order, i.e., directed hyperedges in a hypergraph. This problem has not
been previously explored in the existing literature. The primary challenge in
solving this problem is that the number of possible hyperedges is exponential
in the number of nodes at each event time. To overcome this, we propose a
sequential generative approach that segments the forecasting process into
multiple stages, each contingent upon the preceding stages, thereby reducing
the search space involved in predictions of hyperedges. The first stage
involves a temporal point process-based node event forecasting module that
identifies the subset of nodes involved in an event. The second stage is a
candidate generation module that predicts hyperedge sizes and adjacency vectors
for nodes observing events. The final stage is a directed hyperedge predictor
that identifies the truth by searching over the set of candidate hyperedges. To
validate the effectiveness of our model, we compiled five datasets and
conducted an extensive empirical study to assess each downstream task. Our
proposed method achieves a performance gain of 32\% and 41\% compared to the
state-of-the-art pairwise and hyperedge event forecasting models, respectively,
for the event type prediction.",2023-01-28,"Tony Gracious, Arman Gupta, Ambedkar Dukkipati"
"Resource Allocation of Federated Learning Assisted Mobile Augmented
  Reality System in the Metaverse","Metaverse has become a buzzword recently. Mobile augmented reality (MAR) is a
promising approach to providing users with an immersive experience in the
Metaverse. However, due to limitations of bandwidth, latency and computational
resources, MAR cannot be applied on a large scale in the Metaverse yet.
Moreover, federated learning, with its privacy-preserving characteristics, has
emerged as a prospective distributed learning framework in the future Metaverse
world. In this paper, we propose a federated learning assisted MAR system via
non-orthogonal multiple access for the Metaverse. Additionally, to optimize a
weighted sum of energy, latency and model accuracy, a resource allocation
algorithm is devised by setting appropriate transmission power, CPU frequency
and video frame resolution for each user. Experimental results demonstrate that
our proposed algorithm achieves an overall good performance compared to a
random algorithm and greedy algorithm.",2023-01-28,"Xinyu Zhou, Yang Li, Jun Zhao"
Gender and Prestige Bias in Coronavirus News Reporting,"Journalists play a vital role in surfacing issues of societal importance, but
their choices of what to highlight and who to interview are influenced by
societal biases. In this work, we use natural language processing tools to
measure these biases in a large corpus of news articles about the Covid-19
pandemic. Specifically, we identify when experts are quoted in news and extract
their names and institutional affiliations. We enrich the data by classifying
each expert's gender, the type of organization they belong to, and for academic
institutions, their ranking. Our analysis reveals disparities in the
representation of experts in news. We find a substantial gender gap, where men
are quoted three times more than women. The gender gap varies by partisanship
of the news source, with conservative media exhibiting greater gender bias. We
also identify academic prestige bias, where journalists turn to experts from
highly-ranked academic institutions more than experts from less prestigious
institutions, even if the latter group has more public health expertise.
Liberal news sources exhibit slightly more prestige bias than conservative
sources. Equality of representation is essential to enable voices from all
groups to be heard. By auditing bias, our methods help identify blind spots in
news coverage.",2023-01-27,"Rebecca Dorn, Yiwen Ma, Fred Morstatter, Kristina Lerman"
"Creative beyond TikToks: Investigating Adolescents' Social Privacy
  Management on TikTok","TikTok has been criticized for its low privacy standards, but little is known
about how its adolescent users protect their privacy. Based on interviews with
54 adolescents in Switzerland, this study provides a comprehensive
understanding of young TikTok users' privacy management practices related to
the creation of videos. The data were explored using the COM-B model, an
established behavioral analysis framework adapted for sociotechnical privacy
research. Our overall findings are in line with previous research on other
social networks: adolescents are aware of privacy related to their online
social connections (social privacy) and perform conscious privacy management.
However, we also identified new patterns related to the central role of
algorithmic recommendations potentially relevant for other social networks.
Adolescents are aware that TikTok's special algorithm, combined with the app's
high prevalence among their peers, could easily put them in the spotlight. Some
adolescents also reduce TikTok, which was originally conceived as a social
network, to its extensive audio-visual capabilities and share TikToks via more
private channels (e.g., Snapchat) to manage audiences and avoid identification
by peers. Young users also find other creative ways to protect their privacy
such as identifying stalkers or maintaining multiple user accounts with
different privacy settings to establish granular audience management. Based on
our findings, we propose various concrete measures to develop interventions
that protect the privacy of adolescents on TikTok.",2023-01-27,"Nico Ebert, Tim Geppert, Joanna Strycharz, Melanie Knieps, Michael Hönig, Elke Brucker-Kley"
"Down the Rabbit Hole: Detecting Online Extremism, Radicalisation, and
  Politicised Hate Speech","Social media is a modern person's digital voice to project and engage with
new ideas and mobilise communities $\unicode{x2013}$ a power shared with
extremists. Given the societal risks of unvetted content-moderating algorithms
for Extremism, Radicalisation, and Hate speech (ERH) detection, responsible
software engineering must understand the who, what, when, where, and why such
models are necessary to protect user safety and free expression. Hence, we
propose and examine the unique research field of ERH context mining to unify
disjoint studies. Specifically, we evaluate the start-to-finish design process
from socio-technical definition-building and dataset collection strategies to
technical algorithm design and performance. Our 2015-2021 51-study Systematic
Literature Review (SLR) provides the first cross-examination of textual,
network, and visual approaches to detecting extremist affiliation, hateful
content, and radicalisation towards groups and movements. We identify
consensus-driven ERH definitions and propose solutions to existing ideological
and geographic biases, particularly due to the lack of research in
Oceania/Australasia. Our hybridised investigation on Natural Language
Processing, Community Detection, and visual-text models demonstrates the
dominating performance of textual transformer-based algorithms. We conclude
with vital recommendations for ERH context mining researchers and propose an
uptake roadmap with guidelines for researchers, industries, and governments to
enable a safer cyberspace.",2023-01-27,"Jarod Govers, Philip Feldman, Aaron Dant, Panos Patros"
Opinion-aware Influence Maximization in Online Social Networks,"Influence maximization (IM) aims to find seed users on an online social
network to maximize the spread of information about a target product through
word-of-mouth propagation among all users. Prior IM methods mostly focus on
maximizing the overall influence spread, which assumes that all users are
potential customers of the product and that more exposure leads to higher
benefits. However, in real-world scenarios, some users who dislike the product
may express and spread negative opinions, damaging the product's reputation and
lowering its profit. This paper investigates the opinion-aware influence
maximization (OIM) problem, which finds a set of seed users to maximize the
positive opinions toward the product while minimizing the negative opinions. We
propose a novel algorithm for the OIM problem. Specifically, after obtaining
the users with positive and negative opinions towards the product from
historical data, we design a reverse reachable set-based method for
opinion-aware influence estimation and a sandwich approximation algorithm for
seed set selection. Despite the NP-hardness and non-submodularity of OIM, our
algorithm achieves a data-dependent approximation factor for OIM. Experimental
results on three real-world datasets demonstrate that our algorithm improves
the spread of positive opinions while reducing the spread of negative opinions
compared to existing methods.",2023-01-27,"Ying Wang, Yanhao Wang"
uHelp: intelligent volunteer search for mutual help communities,"When people need help with their day-to-day activities, they turn to family,
friends or neighbours. But despite an increasingly networked world, technology
falls short in finding suitable volunteers. In this paper, we propose uHelp, a
platform for building a community of helpful people and supporting community
members find the appropriate help within their social network. Lately,
applications that focus on finding volunteers have started to appear, such as
Helpin or Facebook's Community Help. However, what distinguishes uHelp from
existing applications is its trust-based intelligent search for volunteers.
Although trust is crucial to these innovative social applications, none of them
have seriously achieved yet a trust-building solution such as that of uHelp.
uHelp's intelligent search for volunteers is based on a number of AI
technologies: (1) a novel trust-based flooding algorithm that navigates one's
social network looking for appropriate trustworthy volunteers; (2) a novel
trust model that maintains the trustworthiness of peers by learning from their
similar past experiences; and (3) a semantic similarity model that assesses the
similarity of experiences. This article presents the uHelp application,
describes the underlying AI technologies that allow uHelp find trustworthy
volunteers efficiently, and illustrates the implementation details. uHelp's
initial prototype has been tested with a community of single parents in
Barcelona, and the app is available online at both Apple Store and Google Play.",2023-01-26,"Nardine Osman, Bruno Rosell, Carles Sierra, Marco Schorlemmer, Jordi Sabater-Mir, Lissette Lemus"
"Constrained Expectation-Maximisation for inference of social graphs
  explaining online user-user interactions","Current network inference algorithms fail to generate graphs with edges that
can explain whole sequences of node interactions in a given dataset or trace.
To quantify how well an inferred graph can explain a trace, we introduce
feasibility, a novel quality criterion, and suggest that it is linked to the
result's accuracy. In addition, we propose CEM-*, a network inference method
that guarantees 100% feasibility given online social media traces, which is a
non-trivial extension of the Expectation-Maximization algorithm developed by
Newman (2018). We propose a set of linear optimization updates that incorporate
a set of auxiliary variables and a set of feasibility constraints; the latter
takes into consideration all the hidden paths that are possible between users
based on their timestamps of interaction and guide the inference toward
feasibility. We provide two CEM-* variations, that assume either an Erdos Renyi
(ER) or a Stochastic Block Model (SBM) prior for the underlying graph's unknown
distribution. Extensive experiments on one synthetic and one real-world Twitter
dataset show that for both priors CEM-* can generate a posterior distribution
of graphs that explains the whole trace while being closer to the ground truth.
As an additional benefit, the use of the SBM prior infers and clusters users
simultaneously during optimization. CEM-* outperforms baseline and
state-of-the-art methods in terms of feasibility, run-time, and precision of
the inferred graph and communities. Finally, we propose a heuristic to adapt
the inference to lower feasibility requirements and show how it can affect the
precision of the result.",2023-01-25,"Effrosyni Papanastasiou, Anastasios Giovanidis"
"Characterizing Polarization in Social Networks using the Signed
  Relational Latent Distance Model","Graph representation learning has become a prominent tool for the
characterization and understanding of the structure of networks in general and
social networks in particular. Typically, these representation learning
approaches embed the networks into a low-dimensional space in which the role of
each individual can be characterized in terms of their latent position. A major
current concern in social networks is the emergence of polarization and filter
bubbles promoting a mindset of ""us-versus-them"" that may be defined by extreme
positions believed to ultimately lead to political violence and the erosion of
democracy. Such polarized networks are typically characterized in terms of
signed links reflecting likes and dislikes. We propose the latent Signed
relational Latent dIstance Model (SLIM) utilizing for the first time the
Skellam distribution as a likelihood function for signed networks and extend
the modeling to the characterization of distinct extreme positions by
constraining the embedding space to polytopes. On four real social signed
networks of polarization, we demonstrate that the model extracts
low-dimensional characterizations that well predict friendships and animosity
while providing interpretable visualizations defined by extreme positions when
endowing the model with an embedding space restricted to polytopes.",2023-01-23,"Nikolaos Nakis, Abdulkadir Çelikkanat, Louis Boucherie, Christian Djurhuus, Felix Burmester, Daniel Mathias Holmelund, Monika Frolcová, Morten Mørup"
"Selecting a suitable Parallel Label-propagation based algorithm for
  Disjoint Community Detection","Community detection is an essential task in network analysis as it helps
identify groups and patterns within a network. High-speed community detection
algorithms are necessary to analyze large-scale networks in a reasonable amount
of time. Researchers have made significant contributions in the development of
high-speed community detection algorithms, particularly in the area of
label-propagation based disjoint community detection. These algorithms have
been proven to be highly effective in analyzing large-scale networks in a
reasonable amount of time. However, it is important to evaluate the performance
and accuracy of these existing methods to determine which algorithm is best
suited for a particular type of network and specific research problem. In this
report, we investigate the RAK, COPRA, and SLPA, three label-propagation-based
static community discovery techniques. We pay close attention to each
algorithm's minute details as we implement both its single-threaded and
multi-threaded OpenMP-based variants, making any necessary adjustments or
optimizations and obtaining the right parameter values. The RAK algorithm is
found to perform well with a tolerance of 0.05 and OpenMP-based strict RAK with
12 threads was 6.75x faster than the sequential non-strict RAK. The COPRA
algorithm works well with a single label for road networks and max labels of
4-16 for other classes of graphs. The SLPA algorithm performs well with
increasing memory size, but overall doesn't offer a favourable return on
investment. The RAK algorithm is recommended for label-propagation based
disjoint community detection.",2023-01-22,Subhajit Sahu
"Using deterministic tourist walk as a small-world metric on
  Watts-Strogatz networks","The Watts-Strogatz model (WS) has been demonstrated to effectively describe
real-world networks due to its ability to reproduce the small-world properties
commonly observed in a variety of systems, including social networks, computer
networks, biochemical reactions, and neural networks. As the presence of
small-world properties is a prevalent characteristic in many real-world
networks, the measurement of ""small-worldness"" has become a crucial metric in
the field of network science, leading to the development of various methods for
its assessment over the past two decades. In contrast, the deterministic
tourist walk (DTW) method has emerged as a prominent technique for texture
analysis and network classification. In this paper, we propose the use of a
modified version of the DTW method to classify networks into three categories:
regular networks, random networks, and small-world networks. Additionally, we
construct a small-world metric, denoted by the coefficient $\chi$, from the DTW
method. Results indicate that the proposed method demonstrates excellent
performance in the task of network classification, achieving over $90\%$
accuracy. Furthermore, the results obtained using the coefficient $\chi$ on
real-world networks provide evidence that the proposed method effectively
serves as a satisfactory small-world metric.",2023-01-21,"Joao V. Merenda, Odemir M. Bruno"
"Same Words, Different Meanings: Semantic Polarization in Broadcast Media
  Language Forecasts Polarization on Social Media Discourse","With the growth of online news over the past decade, empirical studies on
political discourse and news consumption have focused on the phenomenon of
filter bubbles and echo chambers. Yet recently, scholars have revealed limited
evidence around the impact of such phenomenon, leading some to argue that
partisan segregation across news audiences cannot be fully explained by online
news consumption alone and that the role of traditional legacy media may be as
salient in polarizing public discourse around current events. In this work, we
expand the scope of analysis to include both online and more traditional media
by investigating the relationship between broadcast news media language and
social media discourse. By analyzing a decade's worth of closed captions (2
million speaker turns) from CNN and Fox News along with topically corresponding
discourse from Twitter, we provide a novel framework for measuring semantic
polarization between America's two major broadcast networks to demonstrate how
semantic polarization between these outlets has evolved (Study 1), peaked
(Study 2) and influenced partisan discussions on Twitter (Study 3) across the
last decade. Our results demonstrate a sharp increase in polarization in how
topically important keywords are discussed between the two channels, especially
after 2016, with overall highest peaks occurring in 2020. The two stations
discuss identical topics in drastically distinct contexts in 2020, to the
extent that there is barely any linguistic overlap in how identical keywords
are contextually discussed. Further, we demonstrate at scale, how such partisan
division in broadcast media language significantly shapes semantic polarity
trends on Twitter (and vice-versa), empirically linking for the first time, how
online discussions are influenced by televised media.",2023-01-20,"Xiaohan Ding, Mike Horning, Eugenia H. Rho"
"Hypercore Decomposition for Non-Fragile Hyperedges: Concepts,
  Algorithms, Observations, and Applications","Hypergraphs are a powerful abstraction for modeling high-order relations,
which are ubiquitous in many fields. A hypergraph consists of nodes and
hyperedges (i.e., subsets of nodes); and there have been a number of attempts
to extend the notion of $k$-cores, which proved useful with numerous
applications for pairwise graphs, to hypergraphs. However, the previous
extensions are based on an unrealistic assumption that hyperedges are fragile,
i.e., a high-order relation becomes obsolete as soon as a single member leaves
it.
  In this work, we propose a new substructure model, called ($k$,
$t$)-hypercore, based on the assumption that high-order relations remain as
long as at least $t$ fraction of the members remain. Specifically, it is
defined as the maximal subhypergraph where (1) every node is contained in at
least $k$ hyperedges in it and (2) at least $t$ fraction of the nodes remain in
every hyperedge. We first prove that, given $t$ (or $k$), finding the ($k$,
$t$)-hypercore for every possible $k$ (or $t$) can be computed in time linear
w.r.t the sum of the sizes of hyperedges. Then, we demonstrate that real-world
hypergraphs from the same domain share similar ($k$, $t$)-hypercore structures,
which capture different perspectives depending on $t$. Lastly, we show the
successful applications of our model in identifying influential nodes, dense
substructures, and vulnerability in hypergraphs.",2023-01-20,"Fanchen Bu, Geon Lee, Kijung Shin"
"Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and
  Venmo Platforms","Understanding the dynamics of financial transactions among people is
critically important for various applications such as fraud detection. One
important aspect of financial transaction networks is temporality. The order
and repetition of transactions can offer new insights when considered within
the graph structure. Temporal motifs, defined as a set of nodes that interact
with each other in a short time period, are a promising tool in this context.
In this work, we study three unique temporal financial networks: transactions
in Mercari, an online marketplace, payments in a synthetic network generated by
J.P. Morgan Chase, and payments and friendships among Venmo users. We consider
the fraud detection problem on the Mercari and J.P. Morgan Chase networks, for
which the ground truth is available. We show that temporal motifs offer
superior performance than a previous method that considers simple graph
features. For the Venmo network, we investigate the interplay between financial
and social relations on three tasks: friendship prediction, vendor
identification, and analysis of temporal cycles. For friendship prediction,
temporal motifs yield better results than general heuristics, such as Jaccard
and Adamic-Adar measures. We are also able to identify vendors with high
accuracy and observe interesting patterns in rare motifs, like temporal cycles.
We believe that the analysis, datasets, and lessons from this work will be
beneficial for future research on financial transaction networks.",2023-01-18,"Penghang Liu, Rupam Acharyya, Robert E. Tillman, Shunya Kimura, Naoki Masuda, Ahmet Erdem Sarıyüce"
"Follow Us and Become Famous! Insights and Guidelines From Instagram
  Engagement Mechanisms","With 1.3 billion users, Instagram (IG) has also become a business tool. IG
influencer marketing, expected to generate $33.25 billion in 2022, encourages
companies and influencers to create trending content. Various methods have been
proposed for predicting a post's popularity, i.e., how much engagement (e.g.,
Likes) it will generate. However, these methods are limited: first, they focus
on forecasting the likes, ignoring the number of comments, which became crucial
in 2021. Secondly, studies often use biased or limited data. Third, researchers
focused on Deep Learning models to increase predictive performance, which are
difficult to interpret. As a result, end-users can only estimate engagement
after a post is created, which is inefficient and expensive. A better approach
is to generate a post based on what people and IG like, e.g., by following
guidelines.
  In this work, we uncover part of the underlying mechanisms driving IG
engagement. To achieve this goal, we rely on statistical analysis and
interpretable models rather than Deep Learning (black-box) approaches. We
conduct extensive experiments using a worldwide dataset of 10 million posts
created by 34K global influencers in nine different categories. With our simple
yet powerful algorithms, we can predict engagement up to 94% of F1-Score,
making us comparable and even superior to Deep Learning-based method.
Furthermore, we propose a novel unsupervised algorithm for finding highly
engaging topics on IG. Thanks to our interpretable approaches, we conclude by
outlining guidelines for creating successful posts.",2023-01-17,"Pier Paolo Tricomi, Marco Chilese, Mauro Conti, Ahmad-Reza Sadeghi"
Subgraph Centralization: A Necessary Step for Graph Anomaly Detection,"Graph anomaly detection has attracted a lot of interest recently. Despite
their successes, existing detectors have at least two of the three weaknesses:
(a) high computational cost which limits them to small-scale networks only; (b)
existing treatment of subgraphs produces suboptimal detection accuracy; and (c)
unable to provide an explanation as to why a node is anomalous, once it is
identified. We identify that the root cause of these weaknesses is a lack of a
proper treatment for subgraphs. A treatment called Subgraph Centralization for
graph anomaly detection is proposed to address all the above weaknesses. Its
importance is shown in two ways. First, we present a simple yet effective new
framework called Graph-Centric Anomaly Detection (GCAD). The key advantages of
GCAD over existing detectors including deep-learning detectors are: (i) better
anomaly detection accuracy; (ii) linear time complexity with respect to the
number of nodes; and (iii) it is a generic framework that admits an existing
point anomaly detector to be used to detect node anomalies in a network.
Second, we show that Subgraph Centralization can be incorporated into two
existing detectors to overcome the above-mentioned weaknesses.",2023-01-17,"Zhong Zhuang, Kai Ming Ting, Guansong Pang, Shuaibin Song"
"Temporal Dynamics of Coordinated Online Behavior: Stability, Archetypes,
  and Influence","Large-scale online campaigns, malicious or otherwise, require a significant
degree of coordination among participants, which sparked interest in the study
of coordinated online behavior. State-of-the-art methods for detecting
coordinated behavior perform static analyses, disregarding the temporal
dynamics of coordination. Here, we carry out the first dynamic analysis of
coordinated behavior. To reach our goal we build a multiplex temporal network
and we perform dynamic community detection to identify groups of users that
exhibited coordinated behaviors in time. Thanks to our novel approach we find
that: (i) coordinated communities feature variable degrees of temporal
instability; (ii) dynamic analyses are needed to account for such instability,
and results of static analyses can be unreliable and scarcely representative of
unstable communities; (iii) some users exhibit distinct archetypal behaviors
that have important practical implications; (iv) content and network
characteristics contribute to explaining why users leave and join coordinated
communities. Our results demonstrate the advantages of dynamic analyses and
open up new directions of research on the unfolding of online debates, on the
strategies of coordinated communities, and on the patterns of online influence.",2023-01-17,"Serena Tardelli, Leonardo Nizzoli, Maurizio Tesconi, Mauro Conti, Preslav Nakov, Giovanni Da San Martino, Stefano Cresci"
"ClassBases at CASE-2022 Multilingual Protest Event Detection Tasks:
  Multilingual Protest News Detection and Automatically Replicating Manually
  Created Event Datasets","In this report, we describe our ClassBases submissions to a shared task on
multilingual protest event detection. For the multilingual protest news
detection, we participated in subtask-1, subtask-2, and subtask-4, which are
document classification, sentence classification, and token classification. In
subtask-1, we compare XLM-RoBERTa-base, mLUKE-base, and XLM-RoBERTa-large on
finetuning in a sequential classification setting. We always use a combination
of the training data from every language provided to train our multilingual
models. We found that larger models seem to work better and entity knowledge
helps but at a non-negligible cost. For subtask-2, we only submitted an
mLUKE-base system for sentence classification. For subtask-4, we only submitted
an XLM-RoBERTa-base for token classification system for sequence labeling. For
automatically replicating manually created event datasets, we participated in
COVID-related protest events from the New York Times news corpus. We created a
system to process the crawled data into a dataset of protest events.",2023-01-16,Peratham Wiriyathammabhum
"PromptShots at the FinNLP-2022 ERAI Tasks: Pairwise Comparison and
  Unsupervised Ranking","This report describes our PromptShots submissions to a shared task on
Evaluating the Rationales of Amateur Investors (ERAI). We participated in both
pairwise comparison and unsupervised ranking tasks. For pairwise comparison, we
employed instruction-based models based on T5-small and OpenAI InstructGPT
language models. Surprisingly, we observed OpenAI InstructGPT language model
few-shot trained on Chinese data works best in our submissions, ranking 3rd on
the maximal loss (ML) pairwise accuracy. This model works better than training
on the Google translated English data by a large margin, where the English
few-shot trained InstructGPT model even performs worse than an
instruction-based T5-small model finetuned on the English data. However, all
instruction-based submissions do not perform well on the maximal potential
profit (MPP) pairwise accuracy where there are more data and learning signals.
The Chinese few-shot trained InstructGPT model still performs best in our
setting. For unsupervised ranking, we utilized many language models, including
many financial-specific ones, and Bayesian lexicons unsupervised-learned on
both Chinese and English words using a method-of-moments estimator. All our
submissions rank best in the MPP ranking, from 1st to 3rd. However, they all do
not perform well for ML scoring. Therefore, both MPP and ML scores need
different treatments since we treated MPP and ML using the same formula. Our
only difference is the treatment of market sentiment lexicons.",2023-01-16,Peratham Wiriyathammabhum
"Network analysis on political election; populist vs social emergent
  behaviour","Social networks play an important role in people's daily socialization,
particularly through social media platforms, which have become key channels for
communication and information dissemination. The digital ecosystem does not
only evolve communication on multi-network (like TV, social media, and online
newspapers) but also provides the social researcher with useful data to explain
social-complex dynamics. Our work focus on cultural dynamics-reactions that
occurred during the 2020 Emilia-Romagna elections'' in Italy, where a
stronghold culture felt in danger of losing against the strong populism and
Euro-scepticism present in digital ecosystems. We would like to show how the
interaction between parts of the society, during cultural and/or political
shifting, can lead to or induce emerging behaviour from society, creating
groups that react against or improve the status quo. We developed a word-entry
network based on three different levels of participation: pro, con, and
neutral. We have analyzed the tweets collected (as text) with the word
embedding tools, to see, the most used words (which may suggest the main
topics) and the most related words among the various groups. We show how a
careful analysis of groups through networks, can give important information
about the current event.",2023-01-13,"Andrea Russo, Vincenzo Miracula, Antonio Picone"
"Emergence of Urban Heat Traps from the Intersection of Human Mobility
  and Heat Hazard Exposure in Cities","Understanding the relationship between spatial structures of cities and
environmental hazard exposures (such as urban heat) is essential for urban
health and sustainability planning. However, a critical knowledge gap exists in
terms of the extent to which socio-spatial networks shaped by human mobility
exacerbate or alleviate urban heat exposures of populations in cities. In this
study, we utilize location-based data to construct human mobility networks in
twenty metropolitan areas in the U.S. The human mobility networks are analyzed
in conjunction with the urban heat characteristics of spatial areas. We
identify areas with high and low urban heat exposure and evaluate visitation
patterns of populations residing in high and low urban heat areas to other
spatial areas with similar and dissimilar urban heat exposure. The results
reveal the presence of urban heat traps in the majority of the studied
metropolitan areas in which populations residing in high heat exposure areas
primarily visit areas with high heat exposure. The results also show a small
percentage of human mobility to produce urban heat escalate (visitations from
low heat areas to high heat areas) and heat escapes (movements from high heat
areas to low heat areas). The findings from this study provide a better
understanding of urban heat exposure in cities based on patterns of human
mobility. These finding contribute to a broader understanding of the
intersection of human network dynamics and environmental hazard exposures in
cities to inform more integrated urban design and planning to promote health
and sustainability.",2023-01-13,"Xinke Huang, Yuqin Jiang, Ali Mostafavi"
"ITA-ELECTION-2022: A multi-platform dataset of social media
  conversations around the 2022 Italian general election","Online social media play a major role in shaping public discourse and
opinion, especially during political events. We present the first public
multi-platform dataset of Italian-language political conversations, focused on
the 2022 Italian general election taking place on September 25th. Leveraging
public APIs and a keyword-based search, we collected millions of posts
published by users, pages and groups on Facebook, Instagram and Twitter, along
with metadata of TikTok and YouTube videos shared on these platforms, over a
period of four months. We augmented the dataset with a collection of political
ads sponsored on Meta platforms, and a list of social media handles associated
with political representatives. Our data resource will allow researchers and
academics to further our understanding of the role of social media in the
democratic process.",2023-01-12,"Francesco Pierri, Geng Liu, Stefano Ceri"
"Fair and skill-diverse student group formation via constrained k-way
  graph partitioning","Forming the right combination of students in a group promises to enable a
powerful and effective environment for learning and collaboration. However,
defining a group of students is a complex task which has to satisfy multiple
constraints. This work introduces an unsupervised algorithm for fair and
skill-diverse student group formation. This is achieved by taking account of
student course marks and sensitive attributes provided by the education office.
The skill sets of students are determined using unsupervised dimensionality
reduction of course mark data via the Laplacian eigenmap. The problem is
formulated as a constrained graph partitioning problem, whereby the diversity
of skill sets in each group are maximised, group sizes are upper and lower
bounded according to available resources, and `balance' of a sensitive
attribute is lower bounded to enforce fairness in group formation. This
optimisation problem is solved using integer programming and its effectiveness
is demonstrated on a dataset of student course marks from Imperial College
London.",2023-01-12,"Alexander Jenkins, Imad Jaimoukha, Ljubisa Stankovic, Danilo Mandic"
Dirac signal processing of higher-order topological signals,"Higher-order networks can sustain topological signals which are variables
associated not only to the nodes, but also to the links, to the triangles and
in general to the higher dimensional simplices of simplicial complexes. These
topological signals can describe a large variety of real systems including
currents in the ocean, synaptic currents between neurons and biological
transportation networks. In real scenarios topological signal data might be
noisy and an important task is to process these signals by improving their
signal to noise ratio. So far topological signals are typically processed
independently of each other. For instance, node signals are processed
independently of link signals, and algorithms that can enforce a consistent
processing of topological signals across different dimensions are largely
lacking. Here we propose Dirac signal processing, an adaptive, unsupervised
signal processing algorithm that learns to jointly filter topological signals
supported on nodes, links and triangles of simplicial complexes in a consistent
way. The proposed Dirac signal processing algorithm is formulated in terms of
the discrete Dirac operator which can be interpreted as ""square root"" of a
higher-order Hodge Laplacian. We discuss in detail the properties of the Dirac
operator including its spectrum and the chirality of its eigenvectors and we
adopt this operator to formulate Dirac signal processing that can filter noisy
signals defined on nodes, links and triangles of simplicial complexes. We test
our algorithms on noisy synthetic data and noisy data of drifters in the ocean
and find that the algorithm can learn to efficiently reconstruct the true
signals outperforming algorithms based exclusively on the Hodge Laplacian.",2023-01-12,"Lucille Calmon, Michael T. Schaub, Ginestra Bianconi"
Is Facebook regionally a small world network?,"The analysis of social networks, can lead to important discoveries concerning
society and trends. Can in fact imply the discovery of several new aspects of
social behavior, as well as understanding the interest behind certain topics.
Facebook, is now used worldwide, by approximately 3 billions of users, and has
become one of the main sources of information. For analyzing facebook data, not
only worldwide scales are important, but it is crucial to interpret local data
behavior. In this paper we address and analyse Facebook at a regional
dimensionality of Facebook, and evaluate the properties of regional Facebook as
a small world network. To do this, we propose a novel approach a novel
experimental setup, to simulate worldwide known Milgram six degrees of
separation experiment. The novel repeated sampling random procedure proposed to
reproduce the Milgram experiment showed promising and interesting results,
allowing to evaluate the regional Facebook scale.",2023-01-12,Giovanna Maria Dimitri
Stretched and measured neural predictions of complex network dynamics,"Differential equations are a ubiquitous tool to study dynamics, ranging from
physical systems to complex systems, where a large number of agents interact
through a graph with non-trivial topological features. Data-driven
approximations of differential equations present a promising alternative to
traditional methods for uncovering a model of dynamical systems, especially in
complex systems that lack explicit first principles. A recently employed
machine learning tool for studying dynamics is neural networks, which can be
used for data-driven solution finding or discovery of differential equations.
Specifically for the latter task, however, deploying deep learning models in
unfamiliar settings - such as predicting dynamics in unobserved state space
regions or on novel graphs - can lead to spurious results. Focusing on complex
systems whose dynamics are described with a system of first-order differential
equations coupled through a graph, we show that extending the model's
generalizability beyond traditional statistical learning theory limits is
feasible. However, achieving this advanced level of generalization requires
neural network models to conform to fundamental assumptions about the dynamical
model. Additionally, we propose a statistical significance test to assess
prediction quality during inference, enabling the identification of a neural
network's confidence level in its predictions.",2023-01-12,"Vaiva Vasiliauskaite, Nino Antulov-Fantulin"
"Grassroots Systems: Concept, Examples, Implementation and Applications","Informally, a grassroots system is a distributed system that can have
multiple instances, independent of each other and of any global resources, that
can interoperate once interconnected. Grassroots applications are potentially
important as they may allow people to conduct their social, economic, civic,
and political lives in the digital realm solely using the networked computing
devices they own and operate (e.g., smartphones), free of third-party control,
surveillance, manipulation, coercion, or rent seeking (e.g., by global digital
platforms such as Facebook or Bitcoin).
  Here, we formalize the notion of grassroots systems and grassroots
implementations; specify an abstract grassroots dissemination protocol;
describe and prove an implementation of grassroots dissemination for the model
of asynchrony; extend the implementation to mobile (address-changing) devices
that communicate via an unreliable network (e.g. smartphones using UDP); and
discuss how grassroots dissemination can realize applications that support
digital sovereignty -- grassroots social networking and grassroots currencies.
The mathematical construction employs distributed multiagent transition systems
to define the notions of grassroots protocols and grassroots implementations,
to specify grassroots dissemination protocols and their implementation, and to
prove their correctness. The implementation uses the blocklace -- a
generalization of the blockchain that functions as a fault-tolerant,
conflict-free replicated data type.",2023-01-11,Ehud Shapiro
"Hyper-cores promote localization and efficient seeding in higher-order
  processes","Going beyond networks, to include higher-order interactions of arbitrary
sizes, is a major step to better describe complex systems. In the resulting
hypergraph representation, tools to identify structures and central nodes are
scarce. We consider the decomposition of a hypergraph in hyper-cores, subsets
of nodes connected by at least a certain number of hyperedges of at least a
certain size. We show that this provides a fingerprint for data described by
hypergraphs and suggests a novel notion of centrality, the hyper-coreness. We
assess the role of hyper-cores and nodes with large hyper-coreness in
higher-order dynamical processes: such nodes have large spreading power and
spreading processes are localized in central hyper-cores. Additionally, in the
emergence of social conventions very few committed individuals with high
hyper-coreness can rapidly overturn a majority convention. Our work opens
multiple research avenues, from comparing empirical data to model validation
and study of temporally varying hypergraphs.",2023-01-10,"Marco Mancastroppa, Iacopo Iacopini, Giovanni Petri, Alain Barrat"
"Time-aware Hyperbolic Graph Attention Network for Session-based
  Recommendation","Session-based Recommendation (SBR) is to predict users' next interested items
based on their previous browsing sessions. Existing methods model sessions as
graphs or sequences to estimate user interests based on their interacted items
to make recommendations. In recent years, graph-based methods have achieved
outstanding performance on SBR. However, none of these methods consider
temporal information, which is a crucial feature in SBR as it indicates
timeliness or currency. Besides, the session graphs exhibit a hierarchical
structure and are demonstrated to be suitable in hyperbolic geometry. But few
papers design the models in hyperbolic spaces and this direction is still under
exploration. In this paper, we propose Time-aware Hyperbolic Graph Attention
Network (TA-HGAT) - a novel hyperbolic graph neural network framework to build
a session-based recommendation model considering temporal information. More
specifically, there are three components in TA-HGAT. First, a hyperbolic
projection module transforms the item features into hyperbolic space. Second,
the time-aware graph attention module models time intervals between items and
the users' current interests. Third, an evolutionary loss at the end of the
model provides an accurate prediction of the recommended item based on the
given timestamp. TA-HGAT is built in a hyperbolic space to learn the
hierarchical structure of session graphs. Experimental results show that the
proposed TA-HGAT has the best performance compared to ten baseline models on
two real-world datasets.",2023-01-10,"Xiaohan Li, Yuqing Liu, Zheng Liu, Philip S. Yu"
"Modelling exposure between populations using networks of mobility during
  Covid-19","The use of mobile phone call detail records and device location data for the
calling patterns, movements, and social contacts of individuals, has proven to
be valuable for devising models and understanding of their mobility and
behaviour patterns. In this study we investigate weighted exposure-networks of
human daily activities in the capital region of Finland as a proxy for contacts
between postal code areas during the pre-pandemic year 2019 and pandemic years
2020, 2021 and early 2022. We investigate the suitability of gravity and
radiation type models for reconstructing the exposure-networks based on
geo-spatial and population mobility information. For this we use a mobile phone
dataset of aggregated daily visits from a postal code area to cellphone grid
locations, and treat it as a bipartite network to create weighted one mode
projections using a weighted co-occurrence function. We fit a gravitation model
and a radiation model to the averaged weekly and yearly projection networks
with geo-spatial and socioeconomic variables of the postal code areas and their
populations. We also consider an extended gravity type model comprising of
additional postal area information such as distance via public transportation
and population density. The results show that the co-occurrence of human
activities, or exposure, between postal code areas follows both the gravity and
radiation type interactions, once fitted to the empirical network. The effects
of the pandemic beginning in 2020 can be observed as a decrease of the overall
activity as well as of the exposure of the projected networks. In general, the
results show that the postal code level networks changed to be more proximity
weighted after the pandemic began, following the government imposed
non-pharmaceutical interventions, with differences based on the geo-spatial and
socioeconomic structure of the areas.",2023-01-09,"Tuomas Takko, Kunal Bhattacharya, Kimmo Kaski"
Hierarchical core-periphery structure in networks,"We study core-periphery structure in networks using inference methods based
on a flexible network model that allows for traditional onion-like cores within
cores, but also for hierarchical tree-like structures and more general
non-nested types of structure. We propose an efficient Monte Carlo scheme for
fitting the model to observed networks and report results for a selection of
real-world data sets. Among other things, we observe an empirical distinction
between networks showing traditional core-periphery structure with a dense core
weakly connected to a sparse periphery, and an alternative structure in which
the core is strongly connected both within itself and to the periphery.
Networks vary in whether they are better represented by one type of structure
or the other. We also observe structures that are a hybrid between
core-periphery structure and community structure, in which networks have a set
of non-overlapping cores that correspond roughly to communities, surrounded by
a single undifferentiated periphery. Computer code implementing our methods is
available.",2023-01-09,"Austin Polanco, M. E. J. Newman"
"Understanding the (In)Effectiveness of Content Moderation: A Case Study
  of Facebook in the Context of the U.S. Capitol Riot","Social media networks commonly employ content moderation as a tool to limit
the spread of harmful content. However, the efficacy of this strategy in
limiting the delivery of harmful content to users is not well understood. In
this paper, we create a framework to quantify the efficacy of content
moderation and use our metrics to analyze content removal on Facebook within
the U.S. news ecosystem. In a data set of over 2M posts with 1.6B user
engagements collected from 2,551 U.S. news sources before and during the
Capitol Riot on January 6, 2021, we identify 10,811 removed posts. We find that
the active engagement life cycle of Facebook posts is very short, with 90% of
all engagement occurring within the first 30 hours after posting. Thus, even
relatively quick intervention allowed significant accrual of engagement before
removal, and prevented only 21% of the predicted engagement potential during a
baseline period before the U.S. Capitol attack. Nearly a week after the attack,
Facebook began removing older content, but these removals occurred so late in
these posts' engagement life cycles that they disrupted less than 1% of
predicted future engagement, highlighting the limited impact of this
intervention. Content moderation likely has limits in its ability to prevent
engagement, especially in a crisis, and we recommend that other approaches such
as slowing down the rate of content diffusion be investigated.",2023-01-06,"Ian Goldstein, Laura Edelson, Minh-Kha Nguyen, Oana Goga, Damon McCoy, Tobias Lauinger"
"Emergence of simple and complex contagion dynamics from weighted belief
  networks","Social contagion is a ubiquitous and fundamental process that drives
individual and social changes. Although social contagion arises as a result of
cognitive processes and biases, the integration of cognitive mechanisms with
the theory of social contagion remains an open challenge. In particular,
studies on social phenomena usually assume contagion dynamics to be either
simple or complex, rather than allowing it to emerge from cognitive mechanisms,
despite empirical evidence indicating that a social system can exhibit a
spectrum of contagion dynamics -- from simple to complex -- simultaneously.
Here, we propose a model of interacting beliefs, from which both simple and
complex contagion dynamics can organically arise. Our model also elucidates how
a fundamental mechanism of complex contagion -- resistance -- can come about
from cognitive mechanisms.",2023-01-06,"Rachith Aiyappa, Alessandro Flammini, Yong-Yeol Ahn"
"M-Centrality: identifying key nodes based on global position and local
  degree variation","Identifying influential nodes in a network is a major issue due to the great
deal of applications concerned, such as disease spreading and rumor dynamics.
That is why, a plethora of centrality measures has emerged over the years in
order to rank nodes according to their topological importance in the network.
Local metrics such as degree centrality make use of a very limited information
and are easy to compute. Global metrics such as betweenness centrality exploit
the information of the whole network structure at the cost of a very high
computational complexity. Recent works have shown that combining multiple
metrics is a promising strategy to quantify the node's influential ability. Our
work is in this line. In this paper, we introduce a multi-attributes centrality
measure called M-Centrality that combines the information on the position of
the node in the network with the local information on its nearest neighborhood.
The position is measured by the K-shell decomposition, and the degree variation
in the neighborhood of the node quantifies the influence of the local context.
In order to examine the performances of the proposed measure, we conduct
experiments on small and large scale real-world networks from the perspectives
of transmission dynamics and network connectivity. According to the empirical
results, the M-Centrality outperforms its alternatives in identifying both
influential spreaders and nodes essential to maintain the network connectivity.
In addition, its low computational complexity makes it easily applied to large
scale networks.",2023-01-03,"Ahmed Ibnoulouafi, Mohamed El Haziti, Hocine Cherifi"
"Impact of random and targeted disruptions on information diffusion
  during outbreaks","Outbreaks are complex multi-scale processes that are impacted not only by
cellular dynamics and the ability of pathogens to effectively reproduce and
spread, but also by population-level dynamics and the effectiveness of
mitigation measures. A timely exchange of information related to the spread of
novel pathogens, stay-at-home orders, and other containment measures can be
effective at containing an infectious disease, particularly during in the early
stages when testing infrastructure, vaccines, and other medical interventions
may not be available at scale. Using a multiplex epidemic model that consists
of an information layer (modeling information exchange between individuals) and
a spatially embedded epidemic layer (representing a human contact network), we
study how random and targeted disruptions in the information layer (\eg, errors
and intentional attacks on communication infrastructure) impact outbreak
dynamics. We calibrate our model to the early outbreak stages of the SARS-CoV-2
pandemic in 2020. Mitigation campaign can still be effective under random
disruptions, such as failure of information channels between a few individuals.
However, targeted disruptions or sabotage of hub nodes that exchange
information with a large number of individuals can abruptly change outbreak
characteristics such as the time to reach the peak infection. Our results
emphasize the importance of using a robust communication infrastructure that
can withstand both random and targeted disruptions.",2023-01-02,"Hosein Masoomy, Tom Chou, Lucas Böttcher"
"Investigating the Dynamics of Social Norm Emergence within Online
  Communities","Although the effects of the social norm on mitigating misinformation are
identified, scant knowledge exists about the patterns of social norm emergence,
such as the patterns and variations of social tipping in online communities
with diverse characteristics. Accordingly, this study investigates the features
of social tipping in online communities and examines the correlations between
the tipping features and characteristics of online communities. Taking the side
effects of COVID-19 vaccination as the case topic, we first track the patterns
of tipping features in 100 online communities, which are detected using Louvain
Algorithm from the aggregated communication network on Twitter between May 2020
and April 2021. Then, we use multi-variant linear regression to explore the
correlations between tipping features and community characteristics. We find
that social tipping in online communities can sustain for two to four months
and lead to a 50% increase in populations who accept the normative belief in
online communities. The regression indicates that the duration of social
tipping is positively related to the community populations and original
acceptance of social norms, while the correlation between the tipping duration
and the degrees among community members is negative. Additionally, the network
modularity and original acceptance of social norms have negative relationships
with the extent of social tipping, while the degree and betweenness centrality
can have significant positive relationships with the extent of tipping. Our
findings shed light on more precise normative interventions on misinformation
in digital environments as it offers preliminary evidence about the timing and
mechanism of social norm emergence.",2023-01-01,"Shangde Gao, Yan Wang, My T. Thai"
"RiskProp: Account Risk Rating on Ethereum via De-anonymous Score and
  Network Propagation","As one of the most popular blockchain platforms supporting smart contracts,
Ethereum has caught the interest of both investors and criminals. Differently
from traditional financial scenarios, executing Know Your Customer verification
on Ethereum is rather difficult due to the pseudonymous nature of the
blockchain. Fortunately, as the transaction records stored in the Ethereum
blockchain are publicly accessible, we can understand the behavior of accounts
or detect illicit activities via transaction mining. Existing risk control
techniques have primarily been developed from the perspectives of
de-anonymizing address clustering and illicit account classification. However,
these techniques cannot be used to ascertain the potential risks for all
accounts and are limited by specific heuristic strategies or insufficient label
information. These constraints motivate us to seek an effective rating method
for quantifying the spread of risk in a transaction network. To the best of our
knowledge, we are the first to address the problem of account risk rating on
Ethereum by proposing a novel model called RiskProp, which includes a
de-anonymous score to measure transaction anonymity and a network propagation
mechanism to formulate the relationships between accounts and transactions. We
demonstrate the effectiveness of RiskProp in overcoming the limitations of
existing models by conducting experiments on real-world datasets from Ethereum.
Through case studies on the detected high-risk accounts, we demonstrate that
the risk assessment by RiskProp can be used to provide warnings for investors
and protect them from possible financial losses, and the superior performance
of risk score-based account classification experiments further verifies the
effectiveness of our rating method.",2023-01-01,"Dan Lin, Jiajing Wu, Qishuang Fu, Zibin Zheng, Ting Chen"
"Assessment of creditworthiness models privacy-preserving training with
  synthetic data","Credit scoring models are the primary instrument used by financial
institutions to manage credit risk. The scarcity of research on behavioral
scoring is due to the difficult data access. Financial institutions have to
maintain the privacy and security of borrowers' information refrain them from
collaborating in research initiatives. In this work, we present a methodology
that allows us to evaluate the performance of models trained with synthetic
data when they are applied to real-world data. Our results show that synthetic
data quality is increasingly poor when the number of attributes increases.
However, creditworthiness assessment models trained with synthetic data show a
reduction of 3\% of AUC and 6\% of KS when compared with models trained with
real data. These results have a significant impact since they encourage credit
risk investigation from synthetic data, making it possible to maintain
borrowers' privacy and to address problems that until now have been hampered by
the availability of information.",2022-12-31,"Ricardo Muñoz-Cancino, Cristián Bravo, Sebastián A. Ríos, Manuel Graña"
NetEffect: Discovery and Exploitation of Generalized Network Effects,"Given a large graph with few node labels, how can we (a) identify whether
there is generalized network-effects (GNE) or not, (b) estimate GNE to explain
the interrelations among node classes, and (c) exploit GNE efficiently to
improve the performance on downstream tasks? The knowledge of GNE is valuable
for various tasks like node classification, and targeted advertising. However,
identifying GNE such as homophily, heterophily or their combination is
challenging in real-world graphs due to limited availability of node labels and
noisy edges. We propose NetEffect, a graph mining approach to address the above
issues, enjoying the following properties: (i) Principled: a statistical test
to determine the presence of GNE in a graph with few node labels; (ii) General
and Explainable: a closed-form solution to estimate the specific type of GNE
observed; and (iii) Accurate and Scalable: the integration of GNE for accurate
and fast node classification. Applied on real-world graphs, NetEffect discovers
the unexpected absence of GNE in numerous graphs, which were recognized to
exhibit heterophily. Further, we show that incorporating GNE is effective on
node classification. On a million-scale real-world graph, NetEffect achieves
over 7 times speedup (14 minutes vs. 2 hours) compared to most competitors.",2022-12-31,"Meng-Chieh Lee, Shubhranshu Shekhar, Jaemin Yoo, Christos Faloutsos"
"Modeling social resilience: Questions, answers, open problems","Resilience denotes the capacity of a system to withstand shocks and its
ability to recover from them. We develop a framework to quantify the resilience
of highly volatile, non-equilibrium social organizations, such as collectives
or collaborating teams. It consists of four steps: (i) \emph{delimitation},
i.e., narrowing down the target systems, (ii) \emph{conceptualization}, .e.,
identifying how to approach social organizations, (iii) formal
\emph{representation} using a combination of agent-based and network models,
(iv) \emph{operationalization}, i.e. specifying measures and demonstrating how
they enter the calculation of resilience. Our framework quantifies two
dimensions of resilience, the \emph{robustness} of social organizations and
their \emph{adaptivity}, and combines them in a novel resilience measure. It
allows monitoring resilience instantaneously using longitudinal data instead of
an ex-post evaluation.",2022-12-31,"Frank Schweitzer, Georges Andres, Giona Casiraghi, Christoph Gote, Ramona Roller, Ingo Scholtes, Giacomo Vaccario, Christian Zingg"
"Targeted k-node Collapse Problem: Towards Understanding the Robustness
  of Local k-core Structure","The concept of k-core, which indicates the largest induced subgraph where
each node has k or more neighbors, plays a significant role in measuring the
cohesiveness and the engagement of a network, and it is exploited in diverse
applications, e.g., network analysis, anomaly detection, community detection,
etc. Recent works have demonstrated the vulnerability of k-core under malicious
perturbations which focuses on removing the minimal number of edges to make a
whole k-core structure collapse. However, to the best of our knowledge, there
is no existing research concentrating on how many edges should be removed at
least to make an arbitrary node in k-core collapse. Therefore, in this paper,
we make the first attempt to study the Targeted k-node Collapse Problem (TNCP)
with four novel contributions. Firstly, we offer the general definition of TNCP
problem with the proof of its NP-hardness. Secondly, in order to address the
TNCP problem, we propose a heuristic algorithm named TNC and its improved
version named ATNC for implementations on large-scale networks. After that, the
experiments on 16 real-world networks across various domains verify the
superiority of our proposed algorithms over 4 baseline methods along with
detailed comparisons and analyses. Finally, the significance of TNCP problem
for precisely evaluating the resilience of k-core structures in networks is
validated.",2022-12-31,"Yuqian Lv, Bo Zhou, Jinhuan Wang, Qi Xuan"
"Asynchronous Hybrid Reinforcement Learning for Latency and Reliability
  Optimization in the Metaverse over Wireless Communications","Technology advancements in wireless communications and high-performance
Extended Reality (XR) have empowered the developments of the Metaverse. The
demand for the Metaverse applications and hence, real-time digital twinning of
real-world scenes is increasing. Nevertheless, the replication of 2D physical
world images into 3D virtual objects is computationally intensive and requires
computation offloading. The disparity in transmitted object dimension (2D as
opposed to 3D) leads to asymmetric data sizes in uplink (UL) and downlink (DL).
To ensure the reliability and low latency of the system, we consider an
asynchronous joint UL-DL scenario where in the UL stage, the smaller data size
of the physical world images captured by multiple extended reality users (XUs)
will be uploaded to the Metaverse Console (MC) to be construed and rendered. In
the DL stage, the larger-size 3D virtual objects need to be transmitted back to
the XUs. We design a novel multi-agent reinforcement learning algorithm
structure, namely Asynchronous Actors Hybrid Critic (AAHC), to optimize the
decisions pertaining to computation offloading and channel assignment in the UL
stage and optimize the DL transmission power in the DL stage. Extensive
experiments demonstrate that compared to proposed baselines, AAHC obtains
better solutions with satisfactory training time.",2022-12-30,"Wenhan Yu, Terence Jie Chua, Jun Zhao"
"RevealED: Uncovering Pro-Eating Disorder Content on Twitter Using Deep
  Learning","The Covid-19 pandemic induced a vast increase in adolescents diagnosed with
eating disorders and hospitalized due to eating disorders. This immense growth
stemmed partially from the stress of the pandemic but also from increased
exposure to content that promotes eating disorders via social media, which,
within the last decade, has become plagued by pro-eating disorder content. This
study aimed to create a deep learning model capable of determining whether a
given social media post promotes eating disorders based solely on image data.
Tweets from hashtags that have been documented to promote eating disorders
along with Tweets from unrelated hashtags were collected. After prepossessing,
these images were labeled as either pro-eating disorder or not based on which
Twitter hashtag they were scraped from. Several deep-learning models were
trained on the scraped dataset and were evaluated based on their accuracy, F1
score, precision, and recall. Ultimately, the Vision Transformer model was
determined to be the most accurate, attaining an F1 score of 0.877 and an
accuracy of 86.7% on the test set. The model, which was applied to unlabeled
Twitter image data scraped from ""#selfie"", uncovered seasonal fluctuations in
the relative abundance of pro-eating disorder content, which reached its peak
in the summertime. These fluctuations correspond not only to the seasons, but
also to stressors, such as the Covid-19 pandemic. Moreover, the Twitter image
data indicated that the relative amount of pro-eating disorder content has been
steadily rising over the last five years and is likely to continue increasing
in the future.",2022-12-28,Jonathan Feldman
"Cyber Security and Online Safety Education for Schools in the UK:
  Looking through the Lens of Twitter Data","In recent years, digital technologies have grown in many ways. As a result,
many school-aged children have been exposed to the digital world a lot.
Children are using more digital technologies, so schools need to teach kids
more about cyber security and online safety. Because of this, there are now
more school programmes and projects that teach students about cyber security
and online safety and help them learn and improve their skills. Still, despite
many programmes and projects, there is not much proof of how many schools have
taken part and helped spread the word about them. This work shows how we can
learn about the size and scope of cyber security and online safety education in
schools in the UK, a country with a very active and advanced cyber security
education profile, using nearly 200k public tweets from over 15k schools. By
using simple techniques like descriptive statistics and visualisation as well
as advanced natural language processing (NLP) techniques like sentiment
analysis and topic modelling, we show some new findings and insights about how
UK schools as a sector have been doing on Twitter with their cyber security and
online safety education activities. Our work has led to a range of large-scale
and real-world evidence that can help inform people and organisations
interested in cyber security and teaching online safety in schools.",2022-12-28,"Jamie Knott, Haiyue Yuan, Matthew Boakes, Shujun Li"
PersonaSAGE: A Multi-Persona Graph Neural Network,"Graph Neural Networks (GNNs) have become increasingly important in recent
years due to their state-of-the-art performance on many important downstream
applications. Existing GNNs have mostly focused on learning a single node
representation, despite that a node often exhibits polysemous behavior in
different contexts. In this work, we develop a persona-based graph neural
network framework called PersonaSAGE that learns multiple persona-based
embeddings for each node in the graph. Such disentangled representations are
more interpretable and useful than a single embedding. Furthermore, PersonaSAGE
learns the appropriate set of persona embeddings for each node in the graph,
and every node can have a different number of assigned persona embeddings. The
framework is flexible enough and the general design helps in the wide
applicability of the learned embeddings to suit the domain. We utilize publicly
available benchmark datasets to evaluate our approach and against a variety of
baselines. The experiments demonstrate the effectiveness of PersonaSAGE for a
variety of important tasks including link prediction where we achieve an
average gain of 15% while remaining competitive for node classification.
Finally, we also demonstrate the utility of PersonaSAGE with a case study for
personalized recommendation of different entity types in a data management
platform.",2022-12-28,"Gautam Choudhary, Iftikhar Ahamath Burhanuddin, Eunyee Koh, Fan Du, Ryan A. Rossi"
"Battling the Coronavirus Infodemic Among Social Media Users in Kenya and
  Nigeria","How can we induce social media users to be discerning when sharing
information during a pandemic? An experiment on Facebook Messenger with users
from Kenya (n = 7,498) and Nigeria (n = 7,794) tested interventions designed to
decrease intentions to share COVID-19 misinformation without decreasing
intentions to share factual posts. The initial stage of the study incorporated:
(i) a factorial design with 40 intervention combinations; and (ii) a contextual
adaptive design, increasing the probability of assignment to treatments that
worked better for previous subjects with similar characteristics. The second
stage evaluated the best-performing treatments and a targeted treatment
assignment policy estimated from the data. We precisely estimate null effects
from warning flags and related article suggestions, tactics used by social
media platforms. However, nudges to consider information's accuracy reduced
misinformation sharing relative to control by 4.9% (estimate = -2.3 pp, s.e. =
1.0 , Z = -2.31, p = 0.021, 95% CI = [-4.2 , -0.35]). Such low-cost scalable
interventions may improve the quality of information circulating online.",2022-12-27,"Molly Offer-Westort, Leah R. Rosenzweig, Susan Athey"
"Countering Malicious Content Moderation Evasion in Online Social
  Networks: Simulation and Detection of Word Camouflage","Content moderation is the process of screening and monitoring user-generated
content online. It plays a crucial role in stopping content resulting from
unacceptable behaviors such as hate speech, harassment, violence against
specific groups, terrorism, racism, xenophobia, homophobia, or misogyny, to
mention some few, in Online Social Platforms. These platforms make use of a
plethora of tools to detect and manage malicious information; however,
malicious actors also improve their skills, developing strategies to surpass
these barriers and continuing to spread misleading information. Twisting and
camouflaging keywords are among the most used techniques to evade platform
content moderation systems. In response to this recent ongoing issue, this
paper presents an innovative approach to address this linguistic trend in
social networks through the simulation of different content evasion techniques
and a multilingual Transformer model for content evasion detection. In this
way, we share with the rest of the scientific community a multilingual public
tool, named ""pyleetspeak"" to generate/simulate in a customizable way the
phenomenon of content evasion through automatic word camouflage and a
multilingual Named-Entity Recognition (NER) Transformer-based model tuned for
its recognition and detection. The multilingual NER model is evaluated in
different textual scenarios, detecting different types and mixtures of
camouflage techniques, achieving an overall weighted F1 score of 0.8795. This
article contributes significantly to countering malicious information by
developing multilingual tools to simulate and detect new methods of evasion of
content on social networks, making the fight against information disorders more
effective.",2022-12-27,"Álvaro Huertas-García, Alejandro Martín, Javier Huertas Tato, David Camacho"
A Combined Synchronization Index for Grassroots Activism on Social Media,"Social media has provided a citizen voice, giving rise to grassroots
collective action, where users deploy a concerted effort to disseminate online
narratives and even carry out offline protests. Sometimes these collective
action are aided by inorganic synchronization, which arise from bot actors. It
is thus important to identify the synchronicity of emerging discourse on social
media and the indications of organic/inorganic activity within the
conversations. This provides a way of profiling an event for possibility of
offline protests and violence. In this study, we build on past definitions of
synchronous activity on social media -- simultaneous user action -- and develop
a Combined Synchronization Index (CSI) which adopts a hierarchical approach in
measuring user synchronicity. We apply this index on six political and social
activism events on Twitter and analyzed three action types: synchronicity by
hashtag, URL and @mentions.The CSI provides an overall quantification of
synchronization across all action types within an event, which allows ranking
of a spectrum of synchronicity across the six events. Human users have higher
synchronous scores than bot users in most events; and bots and humans exhibits
the most synchronized activities across all events as compared to other pairs
(i.e., bot-bot and human-human). We further rely on the harmony and dissonance
of CSI-Network scores with network centrality metrics to observe the presence
of organic/inorganic synchronization. We hope this work aids in investigating
synchronized action within social media in a collective manner.",2022-12-26,"Lynnette Hui Xian Ng, Kathleen M. Carley"
Escape times for subgraph detection and graph partitioning,"We provide a rearrangement based algorithm for fast detection of subgraphs of
$k$ vertices with long escape times for directed or undirected networks.
Complementing other notions of densest subgraphs and graph cuts, our method is
based on the mean hitting time required for a random walker to leave a
designated set and hit the complement. We provide a new relaxation of this
notion of hitting time on a given subgraph and use that relaxation to construct
a fast subgraph detection algorithm and a generalization to $K$-partitioning
schemes. Using a modification of the subgraph detector on each component, we
propose a graph partitioner that identifies regions where random walks live for
comparably large times. Importantly, our method implicitly respects the
directed nature of the data for directed graphs while also being applicable to
undirected graphs. We apply the partitioning method for community detection to
a large class of model and real-world data sets.",2022-12-25,"Zachary M. Boyd, Nicolas Fraiman, Jeremy L. Marzuola, Peter J. Mucha, Braxton Osting"
"Nothing Stands Alone: Relational Fake News Detection with Hypergraph
  Neural Networks","Nowadays, fake news easily propagates through online social networks and
becomes a grand threat to individuals and society. Assessing the authenticity
of news is challenging due to its elaborately fabricated contents, making it
difficult to obtain large-scale annotations for fake news data. Due to such
data scarcity issues, detecting fake news tends to fail and overfit in the
supervised setting. Recently, graph neural networks (GNNs) have been adopted to
leverage the richer relational information among both labeled and unlabeled
instances. Despite their promising results, they are inherently focused on
pairwise relations between news, which can limit the expressive power for
capturing fake news that spreads in a group-level. For example, detecting fake
news can be more effective when we better understand relations between news
pieces shared among susceptible users. To address those issues, we propose to
leverage a hypergraph to represent group-wise interaction among news, while
focusing on important news relations with its dual-level attention mechanism.
Experiments based on two benchmark datasets show that our approach yields
remarkable performance and maintains the high performance even with a small
subset of labeled news data.",2022-12-24,"Ujun Jeong, Kaize Ding, Lu Cheng, Ruocheng Guo, Kai Shu, Huan Liu"
"Analyzing Regrettable Communications on Twitter: Characterizing Deleted
  Tweets and Their Authors","Over 500 million tweets are posted in Twitter each day, out of which about
11% tweets are deleted by the users posting them. This phenomenon of widespread
deletion of tweets leads to a number of questions: what kind of content posted
by users makes them want to delete them later? %Are all users equally active in
deleting their tweets or Are users of certain predispositions more likely to
post regrettable tweets, deleting them later? In this paper we provide a
detailed characterization of tweets posted and then later deleted by their
authors. We collected tweets from over 200 thousand Twitter users during a
period of four weeks. Our characterization shows significant personality
differences between users who delete their tweets and those who do not. We find
that users who delete their tweets are more likely to be extroverted and
neurotic while being less conscientious. Also, we find that deleted tweets
while containing less information and being less conversational, contain
significant indications of regrettable content. Since users of online
communication do not have instant social cues (like listener's body language)
to gauge the impact of their words, they are often delayed in employing repair
strategies. Finally, we build a classifier which takes textual, contextual, as
well as user features to predict if a tweet will be deleted or not. The
classifier achieves a F1-score of 0.78 and the precision increases when we
consider response features of the tweets.",2022-12-23,"Parantapa Bhattacharya, Saptarshi Ghosh, Niloy Ganguly"
Multidimensional Tie Strength and Economic Development,"The strength of social relations has been shown to affect an individual's
access to opportunities. To date, however, the correspondence between tie
strength and population's economic prospects has not been quantified, largely
because of the inability to operationalise strength based on Granovetter's
classic theory. Our work departed from the premise that tie strength is a
unidimensional construct (typically operationalized with frequency or volume of
contact), and used instead a validated model of ten fundamental dimensions of
social relationships grounded in the literature of social psychology. We built
state-of-the-art NLP tools to infer the presence of these dimensions from
textual communication, and analyzed a large conversation network of 630K
geo-referenced Reddit users across the entire US connected by 12.8M social ties
created over the span of 7 years. We found that unidimensional tie strength is
only weakly correlated with economic opportunities (R2=0.30), while
multidimensional constructs are highly correlated (R2=0.62). In particular,
economic opportunities are associated to the combination of: i) knowledge ties,
which bridge geographically distant groups, facilitating the knowledge
dissemination across communities; and ii) social support ties, which knit
geographically close communities together, and represent dependable sources of
social and emotional support. These results point to the importance of
developing high-quality measures of tie strength in network theory.",2022-12-22,"Luca Maria Aiello, Sagar Joglekar, Daniele Quercia"
"Maximising Influence Spread in Complex Networks by Utilising
  Community-based Driver Nodes as Seeds","Finding a small subset of influential nodes to maximise influence spread in a
complex network is an active area of research. Different methods have been
proposed in the past to identify a set of seed nodes that can help achieve a
faster spread of influence in the network. This paper combines driver node
selection methods from the field of network control, with the
divide-and-conquer approach of using community structure to guide the selection
of candidate seed nodes from the driver nodes of the communities.
  The use of driver nodes in communities as seed nodes is a comparatively new
idea. We identify communities of synthetic (i.e., Random, Small-World and
Scale-Free) networks as well as twenty-two real-world social networks. Driver
nodes from those communities are then ranked according to a range of common
centrality measures. We compare the influence spreading power of these seed
sets to the results of selecting driver nodes at a global level. We show that
in both synthetic and real networks, exploiting community structure enhances
the power of the resulting seed sets.",2022-12-22,"Abida Sadaf, Luke Mathieson, Piotr Bródka, Katarzyna Musial"
"Self-supervised Hypergraph Representation Learning for Sociological
  Analysis","Modern sociology has profoundly uncovered many convincing social criteria for
behavioural analysis. Unfortunately, many of them are too subjective to be
measured and presented in online social networks. On the other hand, data
mining techniques can better find data patterns but many of them leave behind
unnatural understanding. In this paper, we propose a fundamental methodology to
support the further fusion of data mining techniques and sociological
behavioral criteria. Our highlights are three-fold: First, we propose an
effective hypergraph awareness and a fast line graph construction framework.
The hypergraph can more profoundly indicate the interactions between
individuals and their environments because each edge in the hypergraph (a.k.a
hyperedge) contains more than two nodes, which is perfect to describe social
environments. A line graph treats each social environment as a super node with
the underlying influence between different environments. In this way, we go
beyond traditional pair-wise relations and explore richer patterns under
various sociological criteria; Second, we propose a novel hypergraph-based
neural network to learn social influence flowing from users to users, users to
environments, environment to users, and environments to environments. The
neural network can be learned via a task-free method, making our model very
flexible to support various data mining tasks and sociological analysis; Third,
we propose both qualitative and quantitive solutions to effectively evaluate
the most common sociological criteria like social conformity, social
equivalence, environmental evolving and social polarization. Our extensive
experiments show that our framework can better support both data mining tasks
for online user behaviours and sociological analysis.",2022-12-22,"Xiangguo Sun, Hong Cheng, Bo Liu, Jia Li, Hongyang Chen, Guandong Xu, Hongzhi Yin"
"The Ties that matter: From the perspective of Similarity Measure in
  Online Social Networks","Online Social Networks have embarked on the importance of connection strength
measures which has a broad array of applications such as, analyzing diffusion
behaviors, community detection, link predictions, recommender systems. Though
there are some existing connection strength measures, the density that a
connection shares with it's neighbors and the directionality aspect has not
received much attention. In this paper, we have proposed an asymmetric edge
similarity measure namely, Neighborhood Density-based Edge Similarity (NDES)
which provides a fundamental support to derive the strength of connection. The
time complexity of NDES is $O(nk^2)$. An application of NDES for community
detection in social network is shown. We have considered a similarity based
community detection technique and substituted its similarity measure with NDES.
The performance of NDES is evaluated on several small real-world datasets in
terms of the effectiveness in detecting communities and compared with three
widely used similarity measures. Empirical results show NDES enables detecting
comparatively better communities both in terms of accuracy and quality.",2022-12-21,"Soumita Das, Anupam Biswas"
"Beyond Information Exchange: An Approach to Deploy Network Properties
  for Information Diffusion","Information diffusion in Online Social Networks is a new and crucial problem
in social network analysis field and requires significant research attention.
Efficient diffusion of information are of critical importance in diverse
situations such as; pandemic prevention, advertising, marketing etc. Although
several mathematical models have been developed till date, but previous works
lacked systematic analysis and exploration of the influence of neighborhood for
information diffusion. In this paper, we have proposed Common Neighborhood
Strategy (CNS) algorithm for information diffusion that demonstrates the role
of common neighborhood in information propagation throughout the network. The
performance of CNS algorithm is evaluated on several real-world datasets in
terms of diffusion speed and diffusion outspread and compared with several
widely used information diffusion models. Empirical results show CNS algorithm
enables better information diffusion both in terms of diffusion speed and
diffusion outspread.",2022-12-21,"Soumita Das, Anupam Biswas, Ravi Kishore Devarapalli"
"Mining User-aware Multi-relations for Fake News Detection in Large Scale
  Online Social Networks","Users' involvement in creating and propagating news is a vital aspect of fake
news detection in online social networks. Intuitively, credible users are more
likely to share trustworthy news, while untrusted users have a higher
probability of spreading untrustworthy news. In this paper, we construct a
dual-layer graph (i.e., the news layer and the user layer) to extract multiple
relations of news and users in social networks to derive rich information for
detecting fake news. Based on the dual-layer graph, we propose a fake news
detection model named Us-DeFake. It learns the propagation features of news in
the news layer and the interaction features of users in the user layer. Through
the inter-layer in the graph, Us-DeFake fuses the user signals that contain
credibility information into the news features, to provide distinctive
user-aware embeddings of news for fake news detection. The training process
conducts on multiple dual-layer subgraphs obtained by a graph sampler to scale
Us-DeFake in large scale social networks. Extensive experiments on real-world
datasets illustrate the superiority of Us-DeFake which outperforms all
baselines, and the users' credibility signals learned by interaction relation
can notably improve the performance of our model.",2022-12-21,"Xing Su, Jian Yang, Jia Wu, Yuchen Zhang"
"ECoHeN: A Hypothesis Testing Framework for Extracting Communities from
  Heterogeneous Networks","Community discovery is the general process of attaining assortative
communities from a network: collections of nodes that are densely connected
within yet sparsely connected to the rest of the network. While community
discovery has been well studied, few such techniques exist for heterogeneous
networks, which contain different types of nodes and possibly different
connectivity patterns between the node types. In this paper, we introduce a
framework called ECoHeN, which \textbf{e}xtracts \textbf{co}mmunities from a
\textbf{he}terogeneous \textbf{n}etwork in a statistically meaningful way.
Using a heterogeneous configuration model as a reference distribution, ECoHeN
identifies communities that are significantly more densely connected than
expected given the node types and connectivity of its membership. Specifically,
the ECoHeN algorithm extracts communities one at a time through a dynamic set
of iterative updating rules, is guaranteed to converge, and imposes no
constraints on the type composition of extracted communities. To our knowledge
this is the first discovery method that distinguishes and identifies both
homogeneous and heterogeneous, possibly overlapping, community structure in a
network. We demonstrate the performance of ECoHeN through simulation and in
application to a political blogs network to identify collections of blogs which
reference one another more than expected considering the ideology of its'
members.",2022-12-20,"Connor P. Gibbs, Bailey K. Fosdick, James D. Wilson"
"Task Preferences across Languages on Community Question Answering
  Platforms","With the steady emergence of community question answering (CQA) platforms
like Quora, StackExchange, and WikiHow, users now have an unprecedented access
to information on various kind of queries and tasks. Moreover, the rapid
proliferation and localization of these platforms spanning geographic and
linguistic boundaries offer a unique opportunity to study the task requirements
and preferences of users in different socio-linguistic groups. In this study,
we implement an entity-embedding model trained on a large longitudinal dataset
of multi-lingual and task-oriented question-answer pairs to uncover and
quantify the (i) prevalence and distribution of various online tasks across
linguistic communities, and (ii) emerging and receding trends in task
popularity over time in these communities. Our results show that there exists
substantial variance in task preference as well as popularity trends across
linguistic communities on the platform. Findings from this study will help Q&A
platforms better curate and personalize content for non-English users, while
also offering valuable insights to businesses looking to target non-English
speaking communities online.",2022-12-18,"Sebastin Santy, Prasanta Bhattacharya, Rishabh Mehrotra"
"Translating Social Media Crisis Narratives into Road Network Utilization
  Metrics: The Case of 2020 Oklahoma Ice Storm","Risk communication in times of disasters is complex, involving rapid and
diverse communication in social networks (i.e., public and/or private agencies;
local residents) as well as limited mobilization capacity and operational
constraints of physical infrastructure networks. Despite a growing literature
on infrastructure interdependencies and co-dependent social-physical systems,
an in-depth understanding of how risk communication in online social networks
weighs into physical infrastructure networks during a major disaster remains
limited, let alone in compounding risk events. This study analyzes large-scale
datasets of crisis mobility and activity-related social interactions and
concerns available through social media (Twitter) for communities that were
impacted by an ice storm (Oct. 2020) in Oklahoma. Compounded by the COVID-19
pandemic, Oklahoma residents faced this historic ice storm (Oct. 26, 2020-Oct.
29, 2020) that caused devastating traffic impacts (among others) due to
excessive ice accumulation. By using the recently released academic Application
Programming Interface (API) by Twitter that provides complete and unbiased
data, geotagged tweets (approx. 210K) were collected covering the entire state
of Oklahoma, and ice storm-related tweets (approx. 14.2K) were considered.
First, the study uses natural language processing and text quantification
techniques to translate crisis narratives (i.e., tweets). Next, geo-tagged
tweets are mapped into co-located road networks using traditional GIS
techniques. Finally, insights are generated using network science theories and
quantified social narratives to interpret different elements of road networks
(e.g., local roads, freeways, etc.) for the Oklahoma communities that were
impacted by the ice storm event during the pandemic.",2022-12-16,"H M Imran Kays, Khondhaker Al Momin, Menziwokuhle Bandise Thwala, K. K. ""Muralee"" Muraleetharan, Arif Mohaimin Sadri"
A framework to generate hypergraphs with community structure,"In recent years hypergraphs have emerged as a powerful tool to study systems
with multi-body interactions which cannot be trivially reduced to pairs. While
highly structured methods to generate synthetic data have proved fundamental
for the standardized evaluation of algorithms and the statistical study of
real-world networked data, these are scarcely available in the context of
hypergraphs. Here we propose a flexible and efficient framework for the
generation of hypergraphs with many nodes and large hyperedges, which allows
specifying general community structures and tune different local statistics. We
illustrate how to use our model to sample synthetic data with desired features
(assortative or disassortative communities, mixed or hard community
assignments, etc.), analyze community detection algorithms, and generate
hypergraphs structurally similar to real-world data. Overcoming previous
limitations on the generation of synthetic hypergraphs, our work constitutes a
substantial advancement in the statistical modeling of higher-order systems.",2022-12-16,"Nicolò Ruggeri, Federico Battiston, Caterina De Bacco"
"Discovering Structural Hole Spanners in Dynamic Networks via Graph
  Neural Networks","Structural Hole (SH) theory states that the node which acts as a connecting
link among otherwise disconnected communities gets positional advantages in the
network. These nodes are called Structural Hole Spanners (SHS). SHSs have many
applications, including viral marketing, information dissemination, community
detection, etc. Numerous solutions are proposed to discover SHSs; however, most
of the solutions are only applicable to static networks. Since real-world
networks are dynamic networks; consequently, in this study, we aim to discover
SHSs in dynamic networks. Discovering SHSs is an NP-hard problem, due to which,
instead of discovering exact k SHSs, we adopt a greedy approach to discover
top-k SHSs. Motivated from the success of Graph Neural Networks (GNNs) on
various graph mining problems, we design a Graph Neural Network-based model,
GNN-SHS, to discover SHSs in dynamic networks, aiming to reduce the
computational cost while achieving high accuracy. We analyze the efficiency of
the proposed model through exhaustive experiments, and our results show that
the proposed GNN-SHS model is at least 31.8 times faster and, on an average
671.6 times faster than the comparative method, providing a considerable
efficiency advantage.",2022-12-16,"Diksha Goel, Hong Shen, Hui Tian, Mingyu Guo"
"The Russian invasion of Ukraine selectively depolarized the Finnish NATO
  discussion","The Russian invasion of Ukraine in 2022 dramatically reshaped the European
security landscape. In Finland, public opinion on NATO had long been polarized
along the left-right partisan axis, but the invasion led to a rapid convergence
of the opinion toward joining NATO. We investigate whether and how this
depolarization took place among polarized actors on Finnish Twitter. By
analyzing retweeting patterns, we find three separated user groups before the
invasion: a pro-NATO, a left-wing anti-NATO, and a conspiracy-charged anti-NATO
group. After the invasion, the left-wing anti-NATO group members broke out of
their retweeting bubble and connected with the pro-NATO group despite their
difference in partisanship, while the conspiracy-charged anti-NATO group mostly
remained a separate cluster. Our content analysis reveals that the left-wing
anti-NATO group and the pro-NATO group were bridged by a shared condemnation of
Russia's actions and shared democratic norms, while the other anti-NATO group,
mainly built around conspiracy theories and disinformation, consistently
demonstrated a clear anti-NATO attitude. We show that an external threat can
bridge partisan divides in issues linked to the threat, but bubbles upheld by
conspiracy theories and disinformation may persist even under dramatic external
threats.",2022-12-15,"Yan Xia, Antti Gronow, Arttu Malkamäki, Tuomas Ylä-Anttila, Barbara Keller, Mikko Kivelä"
"AI-enabled exploration of Instagram profiles predicts soft skills and
  personality traits to empower hiring decisions","It does not matter whether it is a job interview with Tech Giants, Wall
Street firms, or a small startup; all candidates want to demonstrate their best
selves or even present themselves better than they really are. Meanwhile,
recruiters want to know the candidates' authentic selves and detect soft skills
that prove an expert candidate would be a great fit in any company. Recruiters
worldwide usually struggle to find employees with the highest level of these
skills. Digital footprints can assist recruiters in this process by providing
candidates' unique set of online activities, while social media delivers one of
the largest digital footprints to track people. In this study, for the first
time, we show that a wide range of behavioral competencies consisting of 16
in-demand soft skills can be automatically predicted from Instagram profiles
based on the following lists and other quantitative features using machine
learning algorithms. We also provide predictions on Big Five personality
traits. Models were built based on a sample of 400 Iranian volunteer users who
answered an online questionnaire and provided their Instagram usernames which
allowed us to crawl the public profiles. We applied several machine learning
algorithms to the uniformed data. Deep learning models mostly outperformed by
demonstrating 70% and 69% average Accuracy in two-level and three-level
classifications respectively. Creating a large pool of people with the highest
level of soft skills, and making more accurate evaluations of job candidates is
possible with the application of AI on social media user-generated data.",2022-12-14,"Mercedeh Harirchian, Fereshteh Amin, Saeed Rouhani, Aref Aligholipour, Vahid Amiri Lord"
"A Generic Reinforced Explainable Framework with Knowledge Graph for
  Session-based Recommendation","Session-based recommendation (SR) has gained increasing attention in recent
years. Quite a great amount of studies have been devoted to designing complex
algorithms to improve recommendation performance, where deep learning methods
account for the majority. However, most of these methods are black-box ones and
ignore to provide moderate explanations to facilitate users' understanding,
which thus might lead to lowered user satisfaction and reduced system revenues.
Therefore, in our study, we propose a generic Reinforced Explainable framework
with Knowledge graph for Session-based recommendation (i.e., REKS), which
strives to improve the existing black-box SR models (denoted as non-explainable
ones) with Markov decision process. In particular, we construct a knowledge
graph with session behaviors and treat SR models as part of the policy network
of Markov decision process. Based on our particularly designed state vector,
reward strategy, and loss function, the reinforcement learning (RL)-based
framework not only achieves improved recommendation accuracy, but also provides
appropriate explanations at the same time. Finally, we instantiate the REKS in
five representative, state-of-the-art SR models (i.e., GRU4REC, NARM, SR-GNN,
GCSAN, BERT4REC), whereby extensive experiments towards these methods on four
datasets demonstrate the effectiveness of our framework on both recommendation
and explanation tasks.",2022-12-14,"Huizi Wu, Hui Fang, Zhu Sun, Cong Geng, Xinyu Kong, Yew-Soon Ong"
"On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive
  Learning","The dissemination of hateful memes online has adverse effects on social media
platforms and the real world. Detecting hateful memes is challenging, one of
the reasons being the evolutionary nature of memes; new hateful memes can
emerge by fusing hateful connotations with other cultural ideas or symbols. In
this paper, we propose a framework that leverages multimodal contrastive
learning models, in particular OpenAI's CLIP, to identify targets of hateful
content and systematically investigate the evolution of hateful memes. We find
that semantic regularities exist in CLIP-generated embeddings that describe
semantic relationships within the same modality (images) or across modalities
(images and text). Leveraging this property, we study how hateful memes are
created by combining visual elements from multiple images or fusing textual
information with a hateful image. We demonstrate the capabilities of our
framework for analyzing the evolution of hateful memes by focusing on
antisemitic memes, particularly the Happy Merchant meme. Using our framework on
a dataset extracted from 4chan, we find 3.3K variants of the Happy Merchant
meme, with some linked to specific countries, persons, or organizations. We
envision that our framework can be used to aid human moderators by flagging new
variants of hateful memes so that moderators can manually verify them and
mitigate the problem of hateful content online.",2022-12-13,"Yiting Qu, Xinlei He, Shannon Pierson, Michael Backes, Yang Zhang, Savvas Zannettou"
"Estimating Geographic Spillover Effects of COVID-19 Policies From
  Large-Scale Mobility Networks","Many policies in the US are determined locally, e.g., at the county-level.
Local policy regimes provide flexibility between regions, but may become less
effective in the presence of geographic spillovers, where populations
circumvent local restrictions by traveling to less restricted regions nearby.
Due to the endogenous nature of policymaking, there have been few opportunities
to reliably estimate causal spillover effects or evaluate their impact on local
policies. In this work, we identify a novel setting and develop a suitable
methodology that allow us to make unconfounded estimates of spillover effects
of local policies. Focusing on California's Blueprint for a Safer Economy, we
leverage how county-level mobility restrictions were deterministically set by
public COVID-19 severity statistics, enabling a regression discontinuity design
framework to estimate spillovers between counties. We estimate these effects
using a mobility network with billions of timestamped edges and find
significant spillover movement, with larger effects in retail, eating places,
and gyms. Contrasting local and global policy regimes, our spillover estimates
suggest that county-level restrictions are only 54% as effective as statewide
restrictions at reducing mobility. However, an intermediate strategy of
macro-county restrictions -- where we optimize county partitions by solving a
minimum k-cut problem on a graph weighted by our spillover estimates -- can
recover over 90% of statewide mobility reductions, while maintaining
substantial flexibility between counties.",2022-12-12,"Serina Chang, Damir Vrabac, Jure Leskovec, Johan Ugander"
Multivariate Powered Dirichlet Hawkes Process,"The publication time of a document carries a relevant information about its
semantic content. The Dirichlet-Hawkes process has been proposed to jointly
model textual information and publication dynamics. This approach has been used
with success in several recent works, and extended to tackle specific
challenging problems --typically for short texts or entangled publication
dynamics. However, the prior in its current form does not allow for complex
publication dynamics. In particular, inferred topics are independent from each
other --a publication about finance is assumed to have no influence on
publications about politics, for instance.
  In this work, we develop the Multivariate Powered Dirichlet-Hawkes Process
(MPDHP), that alleviates this assumption. Publications about various topics can
now influence each other. We detail and overcome the technical challenges that
arise from considering interacting topics. We conduct a systematic evaluation
of MPDHP on a range of synthetic datasets to define its application domain and
limitations. Finally, we develop a use case of the MPDHP on Reddit data. At the
end of this article, the interested reader will know how and when to use MPDHP,
and when not to.",2022-12-12,"Gaël Poux-Médard, Julien Velcin, Sabine Loudcher"
Blockchain Network Analysis: A Comparative Study of Decentralized Banks,"Decentralized finance (DeFi) is known for its unique mechanism design, which
applies smart contracts to facilitate peer-to-peer transactions. The
decentralized bank is a typical DeFi application. Ideally, a decentralized bank
should be decentralized in the transaction. However, many recent studies have
found that decentralized banks have not achieved a significant degree of
decentralization. This research conducts a comparative study among mainstream
decentralized banks. We apply core-periphery network features analysis using
the transaction data from four decentralized banks, Liquity, Aave, MakerDao,
and Compound. We extract six features and compare the banks' levels of
decentralization cross-sectionally. According to the analysis results, we find
that: 1) MakerDao and Compound are more decentralized in the transactions than
Aave and Liquity. 2) Although decentralized banking transactions are supposed
to be decentralized, the data show that four banks have primary external
transaction core addresses such as Huobi, Coinbase, and Binance, etc. We also
discuss four design features that might affect network decentralization. Our
research contributes to the literature at the interface of decentralized
finance, financial technology (Fintech), and social network analysis and
inspires future protocol designs to live up to the promise of decentralized
finance for a truly peer-to-peer transaction network.",2022-12-11,"Yufan Zhang, Zichao Chen, Yutong Sun, Yulin Liu, Luyao Zhang"
"Religion and Spirituality on Social Media in the Aftermath of the Global
  Pandemic","During the COVID-19 pandemic, the Church closed its physical doors for the
first time in about 800 years, which is, arguably, a cataclysmic event. Other
religions have found themselves in a similar situation, and they were
practically forced to move online, which is an unprecedented occasion. In this
paper, we analyse this sudden change in religious activities twofold: we create
and deliver a questionnaire, as well as analyse Twitter data, to understand
people's perceptions and activities related to religious activities online.
Importantly, we also analyse the temporal variations in this process by
analysing a period of 3 months: July-September 2020. Additionally to the
separate analysis of the two data sources, we also discuss the implications
from triangulating the results.",2022-12-11,"Olanrewaju Tahir Aduragba, Alexandra I. Cristea, Pete Phillips, Jonas Kurlberg, Jialin Yu"
"Optimal Influencer Marketing Campaign Under Budget Constraints Using
  Frank-Wolfe","Influencer marketing has become a thriving industry with a global market
value expected to reach 15 billion dollars by 2022. The advertising problem
that such agencies face is the following: given a monetary budget find a set of
appropriate influencers that can create and publish posts of various types
(e.g. text, image, video) for the promotion of a target product. The campaign's
objective is to maximize across one or multiple online social platforms some
impact metric of interest, e.g. number of impressions, sales (ROI), or audience
reach. In this work, we present an original continuous formulation of the
budgeted influencer marketing problem as a convex program. We further propose
an efficient iterative algorithm based on the Frank-Wolfe method, that
converges to the global optimum and has low computational complexity. We also
suggest a simpler near-optimal rule of thumb, which can perform well in many
practical scenarios. We test our algorithm and the heuristic against several
alternatives from the optimization literature as well as standard seed
selection methods and validate the superior performance of Frank-Wolfe in
execution time and memory, as well as its capability to scale well for problems
with very large number (millions) of social users.",2022-12-10,"Ricardo Lopez-Dawn, Anastasios Giovanidis"
A Survey of Graph Neural Networks for Social Recommender Systems,"Social recommender systems (SocialRS) simultaneously leverage the
user-to-item interactions as well as the user-to-user social relations for the
task of generating item recommendations to users. Additionally exploiting
social relations is clearly effective in understanding users' tastes due to the
effects of homophily and social influence. For this reason, SocialRS has
increasingly attracted attention. In particular, with the advance of graph
neural networks (GNN), many GNN-based SocialRS methods have been developed
recently. Therefore, we conduct a comprehensive and systematic review of the
literature on GNN-based SocialRS. In this survey, we first identify 84 papers
on GNN-based SocialRS after annotating 2151 papers by following the PRISMA
framework (preferred reporting items for systematic reviews and meta-analyses).
Then, we comprehensively review them in terms of their inputs and architectures
to propose a novel taxonomy: (1) input taxonomy includes 5 groups of input type
notations and 7 groups of input representation notations; (2) architecture
taxonomy includes 8 groups of GNN encoder notations, 2 groups of decoder
notations, and 12 groups of loss function notations. We classify the GNN-based
SocialRS methods into several categories as per the taxonomy and describe their
details. Furthermore, we summarize benchmark datasets and metrics widely used
to evaluate the GNN-based SocialRS methods. Finally, we conclude this survey by
presenting some future research directions. GitHub repository with the curated
list of papers are available at
https://github.com/claws-lab/awesome-GNN-social-recsys.",2022-12-08,"Kartik Sharma, Yeon-Chang Lee, Sivagami Nambi, Aditya Salian, Shlok Shah, Sang-Wook Kim, Srijan Kumar"
"A Modality-level Explainable Framework for Misinformation Checking in
  Social Networks","The widespread of false information is a rising concern worldwide with
critical social impact, inspiring the emergence of fact-checking organizations
to mitigate misinformation dissemination. However, human-driven verification
leads to a time-consuming task and a bottleneck to have checked trustworthy
information at the same pace they emerge. Since misinformation relates not only
to the content itself but also to other social features, this paper addresses
automatic misinformation checking in social networks from a multimodal
perspective. Moreover, as simply naming a piece of news as incorrect may not
convince the citizen and, even worse, strengthen confirmation bias, the
proposal is a modality-level explainable-prone misinformation classifier
framework. Our framework comprises a misinformation classifier assisted by
explainable methods to generate modality-oriented explainable inferences.
Preliminary findings show that the misinformation classifier does benefit from
multimodal information encoding and the modality-oriented explainable mechanism
increases both inferences' interpretability and completeness.",2022-12-08,"Vítor Lourenço, Aline Paes"
The Ordered Matrix Dirichlet for State-Space Models,"Many dynamical systems in the real world are naturally described by latent
states with intrinsic orderings, such as ""ally"", ""neutral"", and ""enemy""
relationships in international relations. These latent states manifest through
countries' cooperative versus conflictual interactions over time. State-space
models (SSMs) explicitly relate the dynamics of observed measurements to
transitions in latent states. For discrete data, SSMs commonly do so through a
state-to-action emission matrix and a state-to-state transition matrix. This
paper introduces the Ordered Matrix Dirichlet (OMD) as a prior distribution
over ordered stochastic matrices wherein the discrete distribution in the kth
row stochastically dominates the (k+1)th, such that probability mass is shifted
to the right when moving down rows. We illustrate the OMD prior within two
SSMs: a hidden Markov model, and a novel dynamic Poisson Tucker decomposition
model tailored to international relations data. We find that models built on
the OMD recover interpretable ordered latent structure without forfeiting
predictive performance. We suggest future applications to other domains where
models with stochastic matrices are popular (e.g., topic modeling), and publish
user-friendly code.",2022-12-08,"Niklas Stoehr, Benjamin J. Radford, Ryan Cotterell, Aaron Schein"
A Frequency-Structure Approach for Link Stream Analysis,"A link stream is a set of triplets $(t, u, v)$ indicating that $u$ and $v$
interacted at time $t$. Link streams model numerous datasets and their proper
study is crucial in many applications. In practice, raw link streams are often
aggregated or transformed into time series or graphs where decisions are made.
Yet, it remains unclear how the dynamical and structural information of a raw
link stream carries into the transformed object. This work shows that it is
possible to shed light into this question by studying link streams via
algebraically linear graph and signal operators, for which we introduce a novel
linear matrix framework for the analysis of link streams. We show that, due to
their linearity, most methods in signal processing can be easily adopted by our
framework to analyze the time/frequency information of link streams. However,
the availability of linear graph methods to analyze relational/structural
information is limited. We address this limitation by developing (i) a new
basis for graphs that allow us to decompose them into structures at different
resolution levels; and (ii) filters for graphs that allow us to change their
structural information in a controlled manner. By plugging-in these
developments and their time-domain counterpart into our framework, we are able
to (i) obtain a new basis for link streams that allow us to represent them in a
frequency-structure domain; and (ii) show that many interesting transformations
to link streams, like the aggregation of interactions or their embedding into a
euclidean space, can be seen as simple filters in our frequency-structure
domain.",2022-12-07,"Esteban Bautista, Matthieu Latapy"
"Exact Phase Transitions for Stochastic Block Models and Reconstruction
  on Trees","In this paper we continue to rigorously establish the predictions in ground
breaking work in statistical physics by Decelle, Krzakala, Moore, Zdeborov\'a
(2011) regarding the block model, in particular in the case of $q=3$ and $q=4$
communities.
  We prove that for $q=3$ and $q=4$ there is no computational-statistical gap
if the average degree is above some constant by showing it is information
theoretically impossible to detect below the Kesten-Stigum bound. The proof is
based on showing that for the broadcast process on Galton-Watson trees,
reconstruction is impossible for $q=3$ and $q=4$ if the average degree is
sufficiently large. This improves on the result of Sly (2009), who proved
similar results for regular trees for $q=3$. Our analysis of the critical case
$q=4$ provides a detailed picture showing that the tightness of the
Kesten-Stigum bound in the antiferromagnetic case depends on the average degree
of the tree. We also prove that for $q\geq 5$, the Kestin-Stigum bound is not
sharp.
  Our results prove conjectures of Decelle, Krzakala, Moore, Zdeborov\'a
(2011), Moore (2017), Abbe and Sandon (2018) and Ricci-Tersenghi, Semerjian,
and Zdeborov{\'a} (2019). Our proofs are based on a new general coupling of the
tree and graph processes and on a refined analysis of the broadcast process on
the tree.",2022-12-06,"Elchanan Mossel, Allan Sly, Youngtak Sohn"
"Trajectory Flow Map: Graph-based Approach to Analysing Temporal
  Evolution of Aggregated Traffic Flows in Large-scale Urban Networks","This paper proposes a graph-based approach to representing spatio-temporal
trajectory data that allows an effective visualization and characterization of
city-wide traffic dynamics. With the advance of sensor, mobile, and Internet of
Things (IoT) technologies, vehicle and passenger trajectories are being
increasingly collected on a massive scale and are becoming a critical source of
insight into traffic pattern and traveller behaviour. To leverage such
trajectory data to better understand traffic dynamics in a large-scale urban
network, this study develops a trajectory-based network traffic analysis method
that converts individual trajectory data into a sequence of graphs that evolve
over time (known as dynamic graphs or time-evolving graphs) and analyses
network-wide traffic patterns in terms of a compact and informative
graph-representation of aggregated traffic flows. First, we partition the
entire network into a set of cells based on the spatial distribution of data
points in individual trajectories, where the cells represent spatial regions
between which aggregated traffic flows can be measured. Next, dynamic flows of
moving objects are represented as a time-evolving graph, where regions are
graph vertices and flows between them are treated as weighted directed edges.
Given a fixed set of vertices, edges can be inserted or removed at every time
step depending on the presence of traffic flows between two regions at a given
time window. Once a dynamic graph is built, we apply graph mining algorithms to
detect change-points in time, which represent time points where the graph
exhibits significant changes in its overall structure and, thus, correspond to
change-points in city-wide mobility pattern throughout the day (e.g., global
transition points between peak and off-peak periods).",2022-12-06,"Jiwon Kim, Kai Zheng, Jonathan Corcoran, Sanghyung Ahn, Marty Papamanolis"
"A machine learning approach to support decision in insider trading
  detection","Identifying market abuse activity from data on investors' trading activity is
very challenging both for the data volume and for the low signal to noise
ratio. Here we propose two complementary unsupervised machine learning methods
to support market surveillance aimed at identifying potential insider trading
activities. The first one uses clustering to identify, in the vicinity of a
price sensitive event such as a takeover bid, discontinuities in the trading
activity of an investor with respect to his/her own past trading history and on
the present trading activity of his/her peers. The second unsupervised approach
aims at identifying (small) groups of investors that act coherently around
price sensitive events, pointing to potential insider rings, i.e. a group of
synchronised traders displaying strong directional trading in rewarding
position in a period before the price sensitive event. As a case study, we
apply our methods to investor resolved data of Italian stocks around takeover
bids.",2022-12-06,"Piero Mazzarisi, Adele Ravagnani, Paola Deriu, Fabrizio Lillo, Francesca Medda, Antonio Russo"
"Political Honeymoon Effect on Social Media: Characterizing Social Media
  Reaction to the Changes of Prime Minister in Japan","New leaders in democratic countries typically enjoy high approval ratings
immediately after taking office. This phenomenon is called the honeymoon effect
and is regarded as a significant political phenomenon; however, its mechanism
remains underexplored. Therefore, this study examines how social media users
respond to changes in political leadership in order to better understand the
honeymoon effect in politics. In particular, we constructed a 15-year Twitter
dataset on eight change timings of Japanese prime ministers consisting of 6.6M
tweets and analyzed them in terms of sentiments, topics, and users. We found
that, while not always, social media tend to show a honeymoon effect at the
change timings of prime minister. The study also revealed that sentiment about
prime ministers differed by topic, indicating that public expectations vary
from one prime minister to another. Furthermore, the user base was largely
replaced before and after the change in the prime minister, and their sentiment
was also significantly different. The implications of this study would be
beneficial for administrative management.",2022-12-06,"Kunihiro Miyazaki, Taichi Murayama, Akira Matsui, Masaru Nishikawa, Takayuki Uchiba, Haewoon Kwak, Jisun An"
"A Mobility-Aware Deep Learning Model for Long-Term COVID-19 Pandemic
  Prediction and Policy Impact Analysis","Pandemic(epidemic) modeling, aiming at disease spreading analysis, has always
been a popular research topic especially following the outbreak of COVID-19 in
2019. Some representative models including SIR-based deep learning prediction
models have shown satisfactory performance. However, one major drawback for
them is that they fall short in their long-term predictive ability. Although
graph convolutional networks (GCN) also perform well, their edge
representations do not contain complete information and it can lead to biases.
Another drawback is that they usually use input features which they are unable
to predict. Hence, those models are unable to predict further future. We
propose a model that can propagate predictions further into the future and it
has better edge representations. In particular, we model the pandemic as a
spatial-temporal graph whose edges represent the transition of infections and
are learned by our model. We use a two-stream framework that contains GCN and
recursive structures (GRU) with an attention mechanism. Our model enables
mobility analysis that provides an effective toolbox for public health
researchers and policy makers to predict how different lock-down strategies
that actively control mobility can influence the spread of pandemics.
Experiments show that our model outperforms others in its long-term predictive
power. Moreover, we simulate the effects of certain policies and predict their
impacts on infection control.",2022-12-05,"Danfeng Guo, Zijie Huang, Junheng Hao, Yizhou Sun, Wei Wang, Demetri Terzopoulos"
"GraphGDP: Generative Diffusion Processes for Permutation Invariant Graph
  Generation","Graph generative models have broad applications in biology, chemistry and
social science. However, modelling and understanding the generative process of
graphs is challenging due to the discrete and high-dimensional nature of
graphs, as well as permutation invariance to node orderings in underlying graph
distributions. Current leading autoregressive models fail to capture the
permutation invariance nature of graphs for the reliance on generation ordering
and have high time complexity. Here, we propose a continuous-time generative
diffusion process for permutation invariant graph generation to mitigate these
issues. Specifically, we first construct a forward diffusion process defined by
a stochastic differential equation (SDE), which smoothly converts graphs within
the complex distribution to random graphs that follow a known edge probability.
Solving the corresponding reverse-time SDE, graphs can be generated from newly
sampled random graphs. To facilitate the reverse-time SDE, we newly design a
position-enhanced graph score network, capturing the evolving structure and
position information from perturbed graphs for permutation equivariant score
estimation. Under the evaluation of comprehensive metrics, our proposed
generative diffusion process achieves competitive performance in graph
distribution learning. Experimental results also show that GraphGDP can
generate high-quality graphs in only 24 function evaluations, much faster than
previous autoregressive models.",2022-12-04,"Han Huang, Leilei Sun, Bowen Du, Yanjie Fu, Weifeng Lv"
Interpretable Node Representation with Attribute Decoding,"Variational Graph Autoencoders (VGAEs) are powerful models for unsupervised
learning of node representations from graph data. In this work, we
systematically analyze modeling node attributes in VGAEs and show that
attribute decoding is important for node representation learning. We further
propose a new learning model, interpretable NOde Representation with Attribute
Decoding (NORAD). The model encodes node representations in an interpretable
approach: node representations capture community structures in the graph and
the relationship between communities and node attributes. We further propose a
rectifying procedure to refine node representations of isolated notes,
improving the quality of these nodes' representations. Our empirical results
demonstrate the advantage of the proposed model when learning graph data in an
interpretable approach.",2022-12-03,"Xiaohui Chen, Xi Chen, Liping Liu"
Node and Edge Centrality based Failures in Multi-layer Complex Networks,"Multi-layer complex networks (MLCN) appears in various domains, such as,
transportation, supply chains, etc. Failures in MLCN can lead to major
disruptions in systems. Several research have focussed on different kinds of
failures, such as, cascades, their reasons and ways to avoid them. This paper
considers failures in a specific type of MLCN where the lower layer provides
services to the higher layer without cross layer interaction, typical of a
computer network. A three layer MLCN is constructed with the same set of nodes
where each layer has different characteristics, the bottom most layer is
Erdos-Renyi (ER) random graph with shortest path hop count among the nodes as
gaussian, the middle layer is ER graph with higher number of edges from the
previous, and the top most layer is scale free graph with even higher number of
edges. Both edge and node failures are considered. Failures happen with
decreasing order of centralities of edges and nodes in static batch mode and
when the centralities change dynamically with progressive failures. Emergent
pattern of three key parameters, namely, average shortest path length (ASPL),
total shortest path count (TSPC) and total number of edges (TNE) for all the
three layers after node or edge failures are studied. Extensive simulations
show that all but one parameters show definite degrading patterns. Surprising,
ASPL for the middle layer starts showing a chaotic behavior beyond a certain
point for all types of failures.",2022-12-03,"Dibakar Das, Jyotsna Bapat, Debabrata Das"
"Resource Allocation for Augmented Reality Empowered Vehicular Edge
  Metaverse","Metaverse is considered to be the evolution of the next-generation networks,
providing users with experience sharing at the intersection between physical
and digital. Augmented reality (AR) is one of the primary supporting
technologies in the Metaverse, which can seamlessly integrate real-world
information with virtual world information to provide users with an immersive
interactive experience. Extraordinarily, AR has brought new opportunities for
assisting safe driving. Nevertheless, achieving efficient execution of AR tasks
and increasing system revenue are the main challenges faced by the Metaverse's
AR in-vehicle applications. In this paper, we are the first to propose an
efficient resource allocation framework for AR-empowered vehicular edge
Metaverse to improve system utility. We formulate an optimization problem
featuring multidimensional control to concurrently maximize data utility at the
Metaverse operator side and minimize energy consumption at the vehicles' side,
which jointly considers the computational resource allocation on the Metaverse
server, and AR vehicles' CPU frequency, transmit power, and computation model
size. Notwithstanding, the major impediment is how to design an efficient
algorithm to obtain the solutions of the optimization. Wherefore, we do this by
decoupling the optimization variables. We first derive the optimal computation
model size by the binary search, followed by obtaining the optimal power
allocation by the bisection method and finding a closed-form solution to the
optimal CPU frequency of AR vehicles, and finally, attain the optimal
allocation of computational resource on the server by the Lagrangian dual
method. To estimate the performance of our proposed scheme, we establish three
baseline schemes as a comparison, and simulation manifests that our proposed
scheme balances the operator's reward and the energy consumption of vehicles.",2022-12-02,"Jie Feng, Jun Zhao"
"Olive Branch Learning: A Topology-Aware Federated Learning Framework for
  Space-Air-Ground Integrated Network","The space-air-ground integrated network (SAGIN), one of the key technologies
for next-generation mobile communication systems, can facilitate data
transmission for users all over the world, especially in some remote areas
where vast amounts of informative data are collected by Internet of remote
things (IoRT) devices to support various data-driven artificial intelligence
(AI) services. However, training AI models centrally with the assistance of
SAGIN faces the challenges of highly constrained network topology, inefficient
data transmission, and privacy issues. To tackle these challenges, we first
propose a novel topology-aware federated learning framework for the SAGIN,
namely Olive Branch Learning (OBL). Specifically, the IoRT devices in the
ground layer leverage their private data to perform model training locally,
while the air nodes in the air layer and the ring-structured low earth orbit
(LEO) satellite constellation in the space layer are in charge of model
aggregation (synchronization) at different scales.To further enhance
communication efficiency and inference performance of OBL, an efficient
Communication and Non-IID-aware Air node-Satellite Assignment (CNASA) algorithm
is designed by taking the data class distribution of the air nodes as well as
their geographic locations into account. Furthermore, we extend our OBL
framework and CNASA algorithm to adapt to more complex multi-orbit satellite
networks. We analyze the convergence of our OBL framework and conclude that the
CNASA algorithm contributes to the fast convergence of the global model.
Extensive experiments based on realistic datasets corroborate the superior
performance of our algorithm over the benchmark policies.",2022-12-02,"Qingze Fang, Zhiwei Zhai, Shuai Yu, Qiong Wu, Xiaowen Gong, Xu Chen"
"Data analytics on key indicators for the city's urban services and
  dashboards for leadership and decision-making","Cities are continuously evolving human settlements. Our cities are under
strain in an increasingly urbanized world, and planners, decision-makers, and
communities must be ready to adapt. Data is an important resource for municipal
administration. Some technologies aid in the collection, processing, and
visualization of urban data, assisting in the interpretation and comprehension
of how urban systems operate. The relationship between data analytics and smart
cities has come to light in recent years as interest in both has grown. A
sophisticated network of interconnected systems, including planners and
inhabitants, is what is known as a smart city. Data analysis has the potential
to support data-driven decision-making in the context of smart cities. Both
urban managers and residents are becoming more interested in city dashboards.
Dashboards may collect, display, analyze, and provide information on regional
performance to help smart cities development have sustainability. In order to
assist decision-making processes and enhance the performance of cities, we
examine how dashboards might be used to acquire accurate and representative
information regarding urban challenges. This chapter culminates Data Analytics
on key indicators for the city's urban services and dashboards for leadership
and decision-making. A single web page with consolidated information, real-time
data streams pertinent to planners and decision-makers as well as residents'
everyday lives, and site analytics as a method to assess user interactions and
preferences are among the proposals for urban dashboards.
  Keywords: -Dashboard, data analytics, smart city, sustainability, Smart
cities, City dashboards, Urban services, Decision-making, Interconnected
systems, Real-time data streams, Key indicators, and Urban challenges.",2022-12-01,"Md Aminul Islam, Md Abu Sufian"
Identifying Different Layers of Online Misogyny,"Social media has become an everyday means of interaction and information
sharing on the Internet. However, posts on social networks are often aggressive
and toxic, especially when the topic is controversial or politically charged.
Radicalization, extreme speech, and in particular online misogyny against women
in the public eye have become alarmingly negative features of online
discussions. The present study proposes a methodological approach to contribute
to ongoing discussions about the multiple ways in which women, their
experiences, and their choices are attacked in polarized social media
responses. Based on a review of theories on and detection methods for misogyny,
we present a classification scheme that incorporates eleven different explicit
as well as implicit layers of online misogyny. We also apply our classes to a
case study related to online aggression against Amber Heard in the context of
her allegations of domestic violence against Johnny Depp. We finally evaluate
the reliability of Google's Perspective API -- a standard for detecting toxic
language -- for determining gender discrimination as toxicity. We show that a
large part of online misogyny, especially when verbalized without expletive
terms but instead more implicitly is not captured automatically.",2022-12-01,"Wienke Strathern, Juergen Pfeffer"
"Identification of the Breach of Short-term Rental Regulations in Irish
  Rent Pressure Zones","The housing crisis in Ireland has rapidly grown in recent years. To make a
more significant profit, many landlords are no longer renting out their houses
under long-term tenancies but under short-term tenancies. The shift from
long-term to short-term rentals has harmed the supply of private housing
rentals. Regulating rentals in Rent Pressure Zones with the highest and rising
rents is becoming a tricky issue.
  In this paper, we develop a breach identifier to check short-term rentals
located in Rent Pressure Zones with potential breaches only using publicly
available data from Airbnb (an online marketplace focused on short-term
home-stays). First, we use a Residual Neural Network to filter out outdoor
landscape photos that negatively impact identifying whether an owner has
multiple rentals in a Rent Pressure Zone. Second, a Siamese Neural Network is
used to compare the similarity of indoor photos to determine if multiple rental
posts correspond to the same residence. Next, we use the Haversine algorithm to
locate short-term rentals within a circle centered on the coordinate of a
permit. Short-term rentals with a permit will not be restricted. Finally, we
improve the occupancy estimation model combined with sentiment analysis, which
may provide higher accuracy.
  Because Airbnb does not disclose accurate house coordinates and occupancy
data, it is impossible to verify the accuracy of our breach identifier. The
accuracy of the occupancy estimator cannot be verified either. It only provides
an estimate within a reasonable range. Users should be skeptical of short-term
rentals that are flagged as possible breaches.",2022-11-29,"Guowen Liu, Inmaculada Arnedillo-Sanchez, Zhenshuo Chen"
"Is Twitter Enough? Investigating Situational Awareness in Social and
  Print Media during the Second COVID-19 Wave in India","The pandemic required efficient allocation of public resources and
transforming existing ways of societal functions. To manage any crisis,
governments and public health researchers exploit the information available to
them in order to make informed decisions, also defined as situational
awareness. Gathering situational awareness using social media has been
functional to manage epidemics. Previous research focused on using discussions
during periods of epidemic crises on social media platforms like Twitter,
Reddit, or Facebook and developing NLP techniques to filter out relevant
discussions from a huge corpus of messages and posts. Social media usage varies
with internet penetration and other socioeconomic factors, which might induce
disparity in analyzing discussions across different geographies. However, print
media is a ubiquitous information source, irrespective of geography. Further,
topics discussed in news articles are already newsworthy, while on social media
newsworthiness is a product of techno-social processes. Developing this
fundamental difference, we study Twitter data during the second wave in India
focused on six high-population cities with varied macroeconomic factors.
Through a mixture of qualitative and quantitative methods, we further analyze
two Indian newspapers during the same period and compare topics from both
Twitter and the newspapers to evaluate situational awareness around the second
phase of COVID on each of these platforms. We conclude that factors like
internet penetration and GDP in a specific city influence the discourse
surrounding situational updates on social media. Thus, augmenting information
from newspapers with information extracted from social media would provide a
more comprehensive perspective in resource deficit cities.",2022-11-29,"Ishita Vohra, Meher Shashwat Nigam, Aryan Sakaria, Amey Kudari, Nimmi Rangaswamy"
"How Many Tweets DoWe Need?: Efficient Mining of Short-Term Polarized
  Topics on Twitter: A Case Study From Japan","In recent years, social media has been criticized for yielding polarization.
Identifying emerging disagreements and growing polarization is important for
journalists to create alerts and provide more balanced coverage. While recent
studies have shown the existence of polarization on social media, they
primarily focused on limited topics such as politics with a large volume of
data collected in the long term, especially over months or years. While these
findings are helpful, they are too late to create an alert immediately. To
address this gap, we develop a domain-agnostic mining method to identify
polarized topics on Twitter in a short-term period, namely 12 hours. As a
result, we find that daily Japanese news-related topics in early 2022 were
polarized by 31.6\% within a 12-hour range. We also analyzed that they tend to
construct information diffusion networks with a relatively high average degree,
and half of the tweets are created by a relatively small number of people.
However, it is very costly and impractical to collect a large volume of tweets
daily on many topics and monitor the polarization due to the limitations of the
Twitter API. To make it more cost-efficient, we also develop a prediction
method using machine learning techniques to estimate the polarization level
using randomly collected tweets leveraging the network information. Extensive
experiments show a significant saving in collection costs compared to baseline
methods. In particular, our approach achieves F-score of 0.85, requiring 4,000
tweets, 4x savings than the baseline. To the best of our knowledge, our work is
the first to predict the polarization level of the topics with low-resource
tweets. Our findings have profound implications for the news media, allowing
journalists to detect and disseminate polarizing information quickly and
efficiently.",2022-11-29,"Tomoki Fukuma, Koki Noda, Hiroki Kumagai, Hiroki Yamamoto, Yoshiharu Ichikawa, Kyosuke Kambe, Yu Maubuchi, Fujio Toriumi"
Triadic Temporal Exponential Random Graph Models (TTERGM),"Temporal exponential random graph models (TERGM) are powerful statistical
models that can be used to infer the temporal pattern of edge formation and
elimination in complex networks (e.g., social networks). TERGMs can also be
used in a generative capacity to predict longitudinal time series data in these
evolving graphs. However, parameter estimation within this framework fails to
capture many real-world properties of social networks, including: triadic
relationships, small world characteristics, and social learning theories which
could be used to constrain the probabilistic estimation of dyadic covariates.
Here, we propose triadic temporal exponential random graph models (TTERGM) to
fill this void, which includes these hierarchical network relationships within
the graph model. We represent social network learning theory as an additional
probability distribution that optimizes Markov chains in the graph vector
space. The new parameters are then approximated via Monte Carlo maximum
likelihood estimation. We show that our TTERGM model achieves improved fidelity
and more accurate predictions compared to several benchmark methods on GitHub
network data.",2022-11-29,"Yifan Huang, Clayton Barham, Eric Page, PK Douglas"
"Entropy-rate as prediction method for newspapers and information
  diffusion","This paper aims to show how some popular topics on social networks can be
used to predict online newspaper views, related to the topics. Newspapers site
and many social networks, become a good source of data to analyse and explain
complex phenomena. Understanding the entropy of a topic, could help all
organizations that need to share information like government, institution,
newspaper or company, to expect an higher activity over their channels, and in
some cases predict what the receiver expect from the senders or what is wrong
about the communication. For some organization such political party, leaders,
company and many others, the reputation and the communication are (for most of
them) the key part of a more and complex huge system. To reach our goal, we use
gathering tools and information theory to detect and analyse trends topic on
social networks, with the purpose of proved a method that helps organization,
newspapers to predict how many articles or communication they will have to do
on a topic, and how much flow of views they will have in a given period,
starting with the entropy-article ratio. Our work address the issue to explore
in which entropy-rate, and through which dynamics, a suitable information
diffusion performance is expected on social network and then on newspaper. We
have identified some cross-cutting dynamics that, associated with the contexts,
might explain how people discuss about a topic, can move on to argue and
informs on newspapers sites.",2022-11-29,"Andrea Russo, Antonio Picone, Vincenzo Miracula, Giovanni Giuffrida, Francesco Mazzeo Rinaldi"
FakeEdge: Alleviate Dataset Shift in Link Prediction,"Link prediction is a crucial problem in graph-structured data. Due to the
recent success of graph neural networks (GNNs), a variety of GNN-based models
were proposed to tackle the link prediction task. Specifically, GNNs leverage
the message passing paradigm to obtain node representation, which relies on
link connectivity. However, in a link prediction task, links in the training
set are always present while ones in the testing set are not yet formed,
resulting in a discrepancy of the connectivity pattern and bias of the learned
representation. It leads to a problem of dataset shift which degrades the model
performance. In this paper, we first identify the dataset shift problem in the
link prediction task and provide theoretical analyses on how existing link
prediction methods are vulnerable to it. We then propose FakeEdge, a
model-agnostic technique, to address the problem by mitigating the graph
topological gap between training and testing sets. Extensive experiments
demonstrate the applicability and superiority of FakeEdge on multiple datasets
across various domains.",2022-11-29,"Kaiwen Dong, Yijun Tian, Zhichun Guo, Yang Yang, Nitesh V. Chawla"
"A Bayesian Approach to Reconstructing Interdependent Infrastructure
  Networks from Cascading Failures","Analyzing the behavior of complex interdependent networks requires complete
information about the network topology and the interdependent links across
networks. For many applications such as critical infrastructure systems,
understanding network interdependencies is crucial to anticipate cascading
failures and plan for disruptions. However, data on the topology of individual
networks are often publicly unavailable due to privacy and security concerns.
Additionally, interdependent links are often only revealed in the aftermath of
a disruption as a result of cascading failures. We propose a scalable
nonparametric Bayesian approach to reconstruct the topology of interdependent
infrastructure networks from observations of cascading failures.
Metropolis-Hastings algorithm coupled with the infrastructure-dependent
proposal are employed to increase the efficiency of sampling possible graphs.
Results of reconstructing a synthetic system of interdependent infrastructure
networks demonstrate that the proposed approach outperforms existing methods in
both accuracy and computational time. We further apply this approach to
reconstruct the topology of one synthetic and two real-world systems of
interdependent infrastructure networks, including gas-power-water networks in
Shelby County, TN, USA, and an interdependent system of power-water networks in
Italy, to demonstrate the general applicability of the approach.",2022-11-28,"Yu Wang, Jin-Zhu Yu, Hiba Baroud"
FLOWViZ: Framework for Phylogenetic Processing,"The increasing risk of epidemics and a fast-growing world population has
contributed to a great investment in phylogenetic analysis, in order to track
numerous diseases and conceive effective medication and treatments.
  Phylogenetic analysis requires large quantities of information to be analyzed
and processed for knowledge extraction, using suitable techniques and,
nowadays, specific software and algorithms, to deliver results as efficiently
and fast as possible. These algorithms and techniques are already provided by
several free and available frameworks and tools. Usually, the process of
phylogenetic analysis consists of several processing steps, which define a
pipeline. Some phylogenetic frameworks have available more than one processing
step, such as inferring phylogenetic trees, data integration, and
visualization, but due to the continuous growth in involved data amounts, each
step may last several hours or days.
  Scientific workflow systems may use high performance computing facilities, if
available, for processing large volumes of data, concurrently. But most of
these scientific workflow systems cannot be easily installed and configured,
are available as centralized services, and, usually, it is not easy to
integrate tools and processing steps available in phylogenetic frameworks.
  This paper summarizes the thesis document of the FLOWViZ framework, which
main goal is to provide a software integration framework between a phylogenetic
framework and a scientific workflow system. This framework makes it possible to
build a customized integration with much fewer lines of code, while providing
existing phylogenetic frameworks with workflow building and execution, to
manage the processing of great amounts of data.
  The project was supported by funds, for a student grant of FCT - NGPHYLO
PTDC/CCI-BIO/29676/2017 and an IPL project - IPL/2021/DIVA.",2022-11-28,"Miguel Luis, Catia Vaz"
Maximizing the Probability of Fixation in the Positional Voter Model,"The Voter model is a well-studied stochastic process that models the invasion
of a novel trait $A$ (e.g., a new opinion, social meme, genetic mutation,
magnetic spin) in a network of individuals (agents, people, genes, particles)
carrying an existing resident trait $B$. Individuals change traits by
occasionally sampling the trait of a neighbor, while an invasion bias
$\delta\geq 0$ expresses the stochastic preference to adopt the novel trait $A$
over the resident trait $B$. The strength of an invasion is measured by the
probability that eventually the whole population adopts trait $A$, i.e., the
fixation probability. In more realistic settings, however, the invasion bias is
not ubiquitous, but rather manifested only in parts of the network. For
instance, when modeling the spread of a social trait, the invasion bias
represents localized incentives. In this paper, we generalize the standard
biased Voter model to the positional Voter model, in which the invasion bias is
effectuated only on an arbitrary subset of the network nodes, called biased
nodes. We study the ensuing optimization problem, which is, given a budget $k$,
to choose $k$ biased nodes so as to maximize the fixation probability of a
randomly occurring invasion. We show that the problem is NP-hard both for
finite $\delta$ and when $\delta \rightarrow \infty$ (strong bias), while the
objective function is not submodular in either setting, indicating strong
computational hardness. On the other hand, we show that, when
$\delta\rightarrow 0$ (weak bias), we can obtain a tight approximation in
$O(n^{2\omega})$ time, where $\omega$ is the matrix-multiplication exponent. We
complement our theoretical results with an experimental evaluation of some
proposed heuristics.",2022-11-26,"Petros Petsinis, Andreas Pavlogiannis, Panagiotis Karras"
"A Contextual Master-Slave Framework on Urban Region Graph for Urban
  Village Detection","Urban villages (UVs) refer to the underdeveloped informal settlement falling
behind the rapid urbanization in a city. Since there are high levels of social
inequality and social risks in these UVs, it is critical for city managers to
discover all UVs for making appropriate renovation policies. Existing
approaches to detecting UVs are labor-intensive or have not fully addressed the
unique challenges in UV detection such as the scarcity of labeled UVs and the
diverse urban patterns in different regions. To this end, we first build an
urban region graph (URG) to model the urban area in a hierarchically structured
way. Then, we design a novel contextual master-slave framework to effectively
detect the urban village from the URG. The core idea of such a framework is to
firstly pre-train a basis (or master) model over the URG, and then to
adaptively derive specific (or slave) models from the basis model for different
regions. The proposed framework can learn to balance the generality and
specificity for UV detection in an urban area. Finally, we conduct extensive
experiments in three cities to demonstrate the effectiveness of our approach.",2022-11-26,"Congxi Xiao, Jingbo Zhou, Jizhou Huang, Hengshu Zhu, Tong Xu, Dejing Dou, Hui Xiong"
"VR-GNN: Variational Relation Vector Graph Neural Network for Modeling
  both Homophily and Heterophily","Graph Neural Networks (GNNs) have achieved remarkable success in diverse
real-world applications. Traditional GNNs are designed based on homophily,
which leads to poor performance under heterophily scenarios. Current solutions
deal with heterophily mainly by mixing high-order neighbors or passing signed
messages. However, mixing high-order neighbors destroys the original graph
structure and passing signed messages utilizes an inflexible message-passing
mechanism, which is prone to producing unsatisfactory effects. To overcome the
above problems, we propose a novel GNN model based on relation vector
translation named Variational Relation Vector Graph Neural Network (VR-GNN).
VR-GNN models relation generation and graph aggregation into an end-to-end
model based on Variational Auto-Encoder. The encoder utilizes the structure,
feature and label to generate a proper relation vector. The decoder achieves
superior node representation by incorporating the relation translation into the
message-passing framework. VR-GNN can fully capture the homophily and
heterophily between nodes due to the great flexibility of relation translation
in modeling neighbor relationships. We conduct extensive experiments on eight
real-world datasets with different homophily-heterophily properties to verify
the effectiveness of our model. The experimental results show that VR-GNN gains
consistent and significant improvements against state-of-the-art GNN methods
under heterophily, and competitive performance under homophily.",2022-11-26,"Fengzhao Shi, Ren Li, Yanan Cao, Yanmin Shang, Lanxue Zhang, Chuan Zhou, Jia Wu, Shirui Pan"
"Resampling community detection to maximize propagation in complex
  network","Identifying important nodes in complex networks is essential in theoretical
and applied fields. A small number of such nodes have deterministic power to
decide information spreading, so it is of importance to find a set of nodes
that maximize the propagation in networks. Based on baseline ranking methods,
various improved methods were proposed, but there does not exist one enhanced
method that covers all the base methods. In this paper, we propose a penalized
method called RCD-Map, which is short for resampling community detection to
maximize propagation, on five baseline ranking methods(Degree centrality,
Closeness centrality, Betweennees centrality, K-shell and PageRank) with nodes'
local community information. We perturbed the original graph by resampling to
decrease the biases and randomness brought by community detection methods-both
overlapping and non-overlapping methods. To assess the performance of our
identifying method, SIR(susceptible-infected-recovered) model is applied to
simulate the information propagation process. The result shows that methods
with penalties perform better with a vaster propagation range in general.",2022-11-26,"Xintong Zhai, Zhonghao Xu"
Link Prediction with Non-Contrastive Learning,"A recent focal area in the space of graph neural networks (GNNs) is graph
self-supervised learning (SSL), which aims to derive useful node
representations without labeled data. Notably, many state-of-the-art graph SSL
methods are contrastive methods, which use a combination of positive and
negative samples to learn node representations. Owing to challenges in negative
sampling (slowness and model sensitivity), recent literature introduced
non-contrastive methods, which instead only use positive samples. Though such
methods have shown promising performance in node-level tasks, their suitability
for link prediction tasks, which are concerned with predicting link existence
between pairs of nodes (and have broad applicability to recommendation systems
contexts) is yet unexplored. In this work, we extensively evaluate the
performance of existing non-contrastive methods for link prediction in both
transductive and inductive settings. While most existing non-contrastive
methods perform poorly overall, we find that, surprisingly, BGRL generally
performs well in transductive settings. However, it performs poorly in the more
realistic inductive settings where the model has to generalize to links to/from
unseen nodes. We find that non-contrastive models tend to overfit to the
training graph and use this analysis to propose T-BGRL, a novel non-contrastive
framework that incorporates cheap corruptions to improve the generalization
ability of the model. This simple modification strongly improves inductive
performance in 5/6 of our datasets, with up to a 120% improvement in
Hits@50--all with comparable speed to other non-contrastive baselines and up to
14x faster than the best-performing contrastive baseline. Our work imparts
interesting findings about non-contrastive learning for link prediction and
paves the way for future researchers to further expand upon this area.",2022-11-25,"William Shiao, Zhichun Guo, Tong Zhao, Evangelos E. Papalexakis, Yozen Liu, Neil Shah"
Detrimental role of fluctuations in the resource dependency networks,"Individual components of many real-world complex networks produce and
exchange resources among themselves. However, because the resource production
in such networks is almost always stochastic, fluctuations in the production
are unavoidable. In this paper, we study the effect of fluctuations on the
resource dependencies in complex networks. To this end, we consider a
modification of a threshold model of resource dependencies in networks that was
recently proposed, where each vertex has a fitness that depends on the total
amount of resource it has produced, the amount it has procured from its
neighbours, and the fitness threshold. We study how the ``network fitness'',
defined as the average fitness of vertices in the network, is affected as the
fluctuation size is varied. We show that the fluctuations worsen the network
fitness even when average production on vertices is kept fixed. This is true
independent of whether more than required amount is produced in the network or
not. However, this effect saturates for large fluctuations, and hence very
large fluctuations cannot worsen the network fitness beyond a limit. We further
show that the networks with a homogeneous degree distribution, such as the
Erdos-Renyi network, are less affected by fluctuations and also produce lower
wastage than the networks with a heterogeneous degree distribution like the
Scale-Free network. Our work shows that fluctuations in the resource production
should be avoided in resource dependency networks.",2022-11-25,"Saumitra Kulkarni, Snehal M. Shekatkar"
"Batching of Tasks by Users of Pseudonymous Forums: Anonymity Compromise
  and Protection","There are a number of forums where people participate under pseudonyms. One
example is peer review, where the identity of reviewers for any paper is
confidential. When participating in these forums, people frequently engage in
""batching"": executing multiple related tasks (e.g., commenting on multiple
papers) at nearly the same time. Our empirical analysis shows that batching is
common in two applications we consider $\unicode{x2013}$ peer review and
Wikipedia edits. In this paper, we identify and address the risk of
deanonymization arising from linking batched tasks. To protect against linkage
attacks, we take the approach of adding delay to the posting time of batched
tasks. We first show that under some natural assumptions, no delay mechanism
can provide a meaningful differential privacy guarantee. We therefore propose a
""one-sided"" formulation of differential privacy for protecting against linkage
attacks. We design a mechanism that adds zero-inflated uniform delay to events
and show it can preserve privacy. We prove that this noise distribution is in
fact optimal in minimizing expected delay among mechanisms adding independent
noise to each event, thereby establishing the Pareto frontier of the trade-off
between the expected delay for batched and unbatched events. Finally, we
conduct a series of experiments on Wikipedia and Bitcoin data that corroborate
the practical utility of our algorithm in obfuscating batching without
introducing onerous delay to a system.",2022-11-23,"Alexander Goldberg, Giulia Fanti, Nihar B. Shah"
"A Mixed-Method Approach to Determining Contact Matrices in the Cox's
  Bazar Refugee Settlement","Contact matrices are an important ingredient in age-structured epidemic
models to inform the simulated spread of the disease between sub-groups of the
population. These matrices are generally derived using resource-intensive
diary-based surveys and few exist in the Global South or tailored to vulnerable
populations. In particular, no contact matrices exist for refugee settlements -
locations under-served by epidemic models in general. In this paper we present
a novel, mixed-method approach, for deriving contact matrices in populations
which combines a lightweight, rapidly deployable, survey with an agent-based
model of the population informed by census and behavioural data. We use this
method to derive the first set of contact matrices for the Cox's Bazar refugee
settlement in Bangladesh. The matrices from the refugee settlement show strong
banding effects due to different age cut-offs in attendance at certain venues,
such as distribution centres and religious sites, as well as the important
contribution of the demographic profile of the settlement which was encoded in
the model. These can have significant implications to the modelled disease
dynamics. To validate our approach, we also apply our method to the population
of the UK and compare our derived matrices against well-known contact matrices
previously collected using traditional approaches. Overall, our findings
demonstrate that our mixed-method approach can address some of the challenges
of both the traditional and previously proposed agent-based approaches to
deriving contact matrices, and has the potential to be rolled-out in other
resource-constrained environments. This work therefore contributes to a broader
aim of developing new methods and mechanisms of data collection for modelling
disease spread in refugee and IDP settlements and better serving these
vulnerable communities.",2022-11-22,"Joseph Walker, Joseph Aylett-Bullock, Difu Shi, Allen Gidraf Kahindo Maina, Egmond Samir Evers, Sandra Harlass, Frank Krauss"
"""Coherent Mode"" for the World's Public Square","Systems for large scale deliberation have resolved polarized issues and
shifted agenda setting into the public's hands. These systems integrate
bridging-based ranking algorithms - including group informed consensus
implemented in Polis and the continuous matrix factorization approach
implemented by Twitter Birdwatch - making it possible to highlight statements
which enjoy broad support from a diversity of opinion groups.
  Polis has been productively employed to foster more constructive political
deliberation at nation scale in law making exercises. Twitter Birdwatch is
implemented with the intention of addressing misinformation in the global
public square. From one perspective, Twitter Birdwatch can be viewed as an
anti-misinformation system which has deliberative aspects. But it can also be
viewed as a first step towards a generalized deliberative system, using
Twitter's misinformation problem as a proving ground.
  In this paper, we propose that Twitter could adapt Birdwatch to produce maps
of public opinion. We describe a system in five parts for generalizing
Birdwatch: activation of a deliberative system and topic selection, population
sampling and the role of expert networks, deliberation, reporting interpretable
results and finally distribution of the results to the public and those in
power.",2022-11-22,"Colin Megill, Elizabeth Barry, Christopher Small"
"Predicting the Type and Target of Offensive Social Media Posts in
  Marathi","The presence of offensive language on social media is very common motivating
platforms to invest in strategies to make communities safer. This includes
developing robust machine learning systems capable of recognizing offensive
content online. Apart from a few notable exceptions, most research on automatic
offensive language identification has dealt with English and a few other high
resource languages such as French, German, and Spanish. In this paper we
address this gap by tackling offensive language identification in Marathi, a
low-resource Indo-Aryan language spoken in India. We introduce the Marathi
Offensive Language Dataset v.2.0 or MOLD 2.0 and present multiple experiments
on this dataset. MOLD 2.0 is a much larger version of MOLD with expanded
annotation to the levels B (type) and C (target) of the popular OLID taxonomy.
MOLD 2.0 is the first hierarchical offensive language dataset compiled for
Marathi, thus opening new avenues for research in low-resource Indo-Aryan
languages. Finally, we also introduce SeMOLD, a larger dataset annotated
following the semi-supervised methods presented in SOLID.",2022-11-22,"Marcos Zampieri, Tharindu Ranasinghe, Mrinal Chaudhari, Saurabh Gaikwad, Prajwal Krishna, Mayuresh Nene, Shrunali Paygude"
"Efficient Sampling Algorithms for Approximate Motif Counting in Temporal
  Graph Streams","A great variety of complex systems, from user interactions in communication
networks to transactions in financial markets, can be modeled as temporal
graphs consisting of a set of vertices and a series of timestamped and directed
edges. Temporal motifs are generalized from subgraph patterns in static graphs
which consider edge orderings and durations in addition to topologies. Counting
the number of occurrences of temporal motifs is a fundamental problem for
temporal network analysis. However, existing methods either cannot support
temporal motifs or suffer from performance issues. Moreover, they cannot work
in the streaming model where edges are observed incrementally over time. In
this paper, we focus on approximate temporal motif counting via random
sampling. We first propose two sampling algorithms for temporal motif counting
in the offline setting. The first is an edge sampling (ES) algorithm for
estimating the number of instances of any temporal motif. The second is an
improved edge-wedge sampling (EWS) algorithm that hybridizes edge sampling with
wedge sampling for counting temporal motifs with $3$ vertices and $3$ edges.
Furthermore, we propose two algorithms to count temporal motifs incrementally
in temporal graph streams by extending the ES and EWS algorithms referred to as
SES and SEWS. We provide comprehensive analyses of the theoretical bounds and
complexities of our proposed algorithms. Finally, we perform extensive
experimental evaluations of our proposed algorithms on several real-world
temporal graphs. The results show that ES and EWS have higher efficiency,
better accuracy, and greater scalability than state-of-the-art sampling methods
for temporal motif counting in the offline setting. Moreover, SES and SEWS
achieve up to three orders of magnitude speedups over ES and EWS while having
comparable estimation errors for temporal motif counting in the streaming
setting.",2022-11-22,"Jingjing Wang, Yanhao Wang, Wenjun Jiang, Yuchen Li, Kian-Lee Tan"
Fast Multiplex Graph Association Rules for Link Prediction,"Multiplex networks allow us to study a variety of complex systems where nodes
connect to each other in multiple ways, for example friend, family, and
co-worker relations in social networks. Link prediction is the branch of
network analysis allowing us to forecast the future status of a network: which
new connections are the most likely to appear in the future? In multiplex link
prediction we also ask: of which type? Because this last question is
unanswerable with classical link prediction, here we investigate the use of
graph association rules to inform multiplex link prediction. We derive such
rules by identifying all frequent patterns in a network via multiplex graph
mining, and then score each unobserved link's likelihood by finding the
occurrences of each rule in the original network. Association rules add new
abilities to multiplex link prediction: to predict new node arrivals, to
consider higher order structures with four or more nodes, and to be memory
efficient. We improve over previous work by creating a framework that is also
efficient in terms of runtime, which enables an increase in prediction
performance. This increase in efficiency allows us to improve a case study on a
signed multiplex network, showing how graph association rules can provide
valuable insights to extend social balance theory.",2022-11-22,"Michele Coscia, Christian Borgelt, Michael Szell"
Measuring Belief Dynamics on Twitter,"There is growing concern about misinformation and the role online media plays
in social polarization. Analyzing belief dynamics is one way to enhance our
understanding of these problems. Existing analytical tools, such as survey
research or stance detection, lack the power to correlate contextual factors
with population-level changes in belief dynamics. In this exploratory study, I
present the Belief Landscape Framework, which uses data about people's
professed beliefs in an online setting to measure belief dynamics with high
resolution. I provide initial validation of the approach by comparing the
method's output to a set of hypotheses drawn from the literature and by
inspecting the ""belief landscape"" generated by the method. My analysis
indicates that the method is relatively robust to different parameter settings,
and results suggest that 1) there are many stable configurations of belief, or
attractors, on the polarizing issue of climate change and 2) that people move
in predictable ways around these attractors. The method paves the way for more
powerful tools that can be used to understand how the modern digital media
ecosystem impacts collective belief dynamics and what role misinformation plays
in that process.",2022-11-22,Joshua Introne
Asymptotically Normal Estimation of Local Latent Network Curvature,"Network data, commonly used throughout the physical, social, and biological
sciences, consist of nodes (individuals) and the edges (interactions) between
them. One way to represent network data's complex, high-dimensional structure
is to embed the graph into a low-dimensional geometric space. The curvature of
this space, in particular, provides insights about the structure in the graph,
such as the propensity to form triangles or present tree-like structures. We
derive an estimating function for curvature based on triangle side lengths and
the length of the midpoint of a side to the opposing corner. We construct an
estimator where the only input is a distance matrix and also establish
asymptotic normality. We next introduce a novel latent distance matrix
estimator for networks and an efficient algorithm to compute the estimate via
solving iterative quadratic programs. We apply this method to the Los Alamos
National Laboratory Unified Network and Host dataset and show how curvature
estimates can be used to detect a red-team attack faster than naive methods, as
well as discover non-constant latent curvature in co-authorship networks in
physics. The code for this paper is available at
https://github.com/SteveJWR/netcurve, and the methods are implemented in the R
package https://github.com/SteveJWR/lolaR.",2022-11-21,"Steven Wilkins-Reeves, Tyler McCormick"
"Data-driven Tracking of the Bounce-back Path after Disasters: Critical
  Milestones of Population Activity Recovery and Their Spatial Inequality","The ability to measure and track the speed and trajectory of a community's
post-disaster recovery is essential to inform resource allocation and
prioritization. The current survey-based approaches to examining community
recovery, however, have significant lags and put the burden of data collection
on affected people. Also, the existing literature lacks quantitative measures
for important milestones to inform the assessment of recovery trajectory.
Recognizing these gaps, this study uses location-based data related to
visitation patterns and credit card transactions to specify critical recovery
milestones related to population activity recovery. Using data from 2017
Hurricane Harvey in Harris County (Texas), the study specifies four critical
post-disaster recovery milestones and calculates quantitative measurements of
the length of time between the end of a hazard event and when the spatial areas
(census tracts) reached these milestones based on fluctuations in visits to
essential and non-essential facilities, and essential and non-essential credit
card transactions. Accordingly, an integrated recovery metric is created for an
overall measurement of each spatial area's recovery progression. Exploratory
statistical analyses were conducted to examine whether variations in community
recovery progression in achieving the critical milestones is correlated to its
flood status, socioeconomic characteristics, and demographic composition.
Finally, the extent of spatial inequality is examined. The results show the
presence of moderate spatial inequality in population activity recovery in
Hurricane Harvey, based upon which the inequality of recovery is measured.
Results of this study can benefit post-disaster recovery resource allocation as
well as improve community resilience towards future natural hazards.",2022-11-20,"Yuqin Jiang, Faxi Yuan, Hamed Farahmand, Kushal Acharya, Jingdi Zhang, Ali Mostafavi"
Understanding the Bystander Effect on Toxic Twitter Conversations,"In this study, we explore the power of group dynamics to shape the toxicity
of Twitter conversations. First, we examine how the presence of others in a
conversation can potentially diffuse Twitter users' responsibility to address a
toxic direct reply. Second, we examine whether the toxicity of the first direct
reply to a toxic tweet in conversations establishes the group norms for
subsequent replies. By doing so, we outline how bystanders and the tone of
initial responses to a toxic reply are explanatory factors which affect whether
others feel uninhibited to post their own abusive or derogatory replies. We
test this premise by analyzing a random sample of more than 156k tweets
belonging to ~9k conversations. Central to this work is the social
psychological research on the ""bystander effect"" documenting that the presence
of bystanders has the power to alter the dynamics of a social situation. If the
first direct reply reaffirms the divisive tone, other replies may follow suit.
We find evidence of a bystander effect, with our results showing that an
increased number of users participating in the conversation before receiving a
toxic tweet is negatively associated with the number of Twitter users who
responded to the toxic reply in a non-toxic way. We also find that the initial
responses to toxic tweets within conversations is of great importance. Posting
a toxic reply immediately after a toxic comment is negatively associated with
users posting non-toxic replies and Twitter conversations becoming increasingly
toxic.",2022-11-19,"Ana Aleksandric, Mohit Singhal, Anne Groggel, Shirin Nilizadeh"
"Asymptotically Tight Bounds on the Time Complexity of Broadcast and its
  Variants in Dynamic Networks","Data dissemination is a fundamental task in distributed computing. This paper
studies broadcast problems in various innovative models where the communication
network connecting $n$ processes is dynamic (e.g., due to mobility or failures)
and controlled by an adversary.
  In the first model, the processes transitively communicate their ids in
synchronous rounds along a rooted tree given in each round by the adversary
whose goal is to maximize the number of rounds until at least one id is known
by all processes.
  Previous research has shown a $\lceil{\frac{3n-1}{2}}\rceil-2$ lower bound
and an $O(n\log\log n)$ upper bound. We show the first linear upper bound for
this problem, namely $\lceil{(1 + \sqrt 2) n-1}\rceil \approx 2.4n$.
  We extend these results to the setting where the adversary gives in each
round $k$-disjoint forests and their goal is to maximize the number of rounds
until there is a set of $k$ ids such that each process knows of at least one of
them. We give a $\left\lceil{\frac{3(n-k)}{2}}\right\rceil-1$ lower bound and a
$\frac{\pi^2+6}{6}n+1 \approx 2.6n$ upper bound for this problem.
  Finally, we study the setting where the adversary gives in each round a
directed graph with $k$ roots and their goal is to maximize the number of
rounds until there exist $k$ ids that are known by all processes. We give a
$\left\lceil{\frac{3(n-3k)}{2}}\right\rceil+2$ lower bound and a $\lceil {
(1+\sqrt{2})n}\rceil+k-1 \approx 2.4n+k$ upper bound for this problem.
  For the two latter problems no upper or lower bounds were previously known.",2022-11-18,"Antoine El-Hayek, Monika Henzinger, Stefan Schmid"
"Influence Maximization in Social Networks using Discretized Harris Hawks
  Optimization Algorithm and Neighbour Scout Strategy","Influence Maximization (IM) is the task of determining k optimal influential
nodes in a social network to maximize the influence spread using a propagation
model. IM is a prominent problem for viral marketing, and helps significantly
in social media advertising. However, developing effective algorithms with
minimal time complexity for real-world social networks still remains a
challenge. While traditional heuristic approaches have been applied for IM,
they often result in minimal performance gains over the computationally
expensive Greedy-based and Reverse Influence Sampling-based approaches. In this
paper, we propose the discretization of the nature-inspired Harris Hawks
Optimisation meta-heuristic algorithm using community structures for optimal
selection of seed nodes for influence spread. In addition to Harris Hawks
intelligence, we employ a neighbour scout strategy algorithm to avoid blindness
and enhance the searching ability of the hawks. Further, we use a candidate
nodes-based random population initialization approach, and these candidate
nodes aid in accelerating the convergence process for the entire populace. We
evaluate the efficacy of our proposed DHHO approach on six social networks
using the Independent Cascade model for information diffusion. We observe that
DHHO is comparable or better than competing meta-heuristic approaches for
Influence Maximization across five metrics, and performs noticeably better than
competing heuristic approaches.",2022-11-17,"Inder Khatri, Arjun Choudhry, Aryaman Rao, Aryan Tyagi, Dinesh Kumar Vishwakarma, Mukesh Prasad"
"A Spreader Ranking Algorithm for Extremely Low-budget Influence
  Maximization in Social Networks using Community Bridge Nodes","In recent years, social networking platforms have gained significant
popularity among the masses like connecting with people and propagating ones
thoughts and opinions. This has opened the door to user-specific advertisements
and recommendations on these platforms, bringing along a significant focus on
Influence Maximisation (IM) on social networks due to its wide applicability in
target advertising, viral marketing, and personalized recommendations. The aim
of IM is to identify certain nodes in the network which can help maximize the
spread of certain information through a diffusion cascade. While several works
have been proposed for IM, most were inefficient in exploiting community
structures to their full extent. In this work, we propose a community
structures-based approach, which employs a K-Shell algorithm in order to
generate a score for the connections between seed nodes and communities for
low-budget scenarios. Further, our approach employs entropy within communities
to ensure the proper spread of information within the communities. We choose
the Independent Cascade (IC) model to simulate information spread and evaluate
it on four evaluation metrics. We validate our proposed approach on eight
publicly available networks and find that it significantly outperforms the
baseline approaches on these metrics, while still being relatively efficient.",2022-11-17,"Aaryan Gupta, Inder Khatri, Arjun Choudhry, Pranav Chandhok, Dinesh Kumar Vishwakarma, Mukesh Prasad"
Few-shot Learning for Multi-modal Social Media Event Filtering,"Social media has become an important data source for event analysis. When
collecting this type of data, most contain no useful information to a target
event. Thus, it is essential to filter out those noisy data at the earliest
opportunity for a human expert to perform further inspection. Most existing
solutions for event filtering rely on fully supervised methods for training.
However, in many real-world scenarios, having access to large number of labeled
samples is not possible. To deal with a few labeled sample training problem for
event filtering, we propose a graph-based few-shot learning pipeline. We also
release the Brazilian Protest Dataset to test our method. To the best of our
knowledge, this dataset is the first of its kind in event filtering that
focuses on protests in multi-modal social media data, with most of the text in
Portuguese. Our experimental results show that our proposed pipeline has
comparable performance with only a few labeled samples (60) compared with a
fully labeled dataset (3100). To facilitate the research community, we make our
dataset and code available at https://github.com/jdnascim/7Set-AL.",2022-11-16,"José Nascimento, João Phillipe Cardenuto, Jing Yang, Anderson Rocha"
"Resource Allocation of Federated Learning for the Metaverse with Mobile
  Augmented Reality","The Metaverse has received much attention recently. Metaverse applications
via mobile augmented reality (MAR) require rapid and accurate object detection
to mix digital data with the real world. Federated learning (FL) is an
intriguing distributed machine learning approach due to its privacy-preserving
characteristics. Due to privacy concerns and the limited computation resources
on mobile devices, we incorporate FL into MAR systems of the Metaverse to train
a model cooperatively. Besides, to balance the trade-off between energy,
execution latency and model accuracy, thereby accommodating different demands
and application scenarios, we formulate an optimization problem to minimize a
weighted combination of total energy consumption, completion time and model
accuracy. Through decomposing the non-convex optimization problem into two
subproblems, we devise a resource allocation algorithm to determine the
bandwidth allocation, transmission power, CPU frequency and video frame
resolution for each participating device. We further present the convergence
analysis and computational complexity of the proposed algorithm. Numerical
results show that our proposed algorithm has better performance (in terms of
energy consumption, completion time and model accuracy) under different weight
parameters compared to existing benchmarks.",2022-11-16,"Xinyu Zhou, Chang Liu, Jun Zhao"
"Coronavirus statistics causes emotional bias: a social media text mining
  perspective","While COVID-19 has impacted humans for a long time, people search the web for
pandemic-related information, causing anxiety. From a theoretic perspective,
previous studies have confirmed that the number of COVID-19 cases can cause
negative emotions, but how statistics of different dimensions, such as the
number of imported cases, the number of local cases, and the number of
government-designated lockdown zones, stimulate people's emotions requires
detailed understanding. In order to obtain the views of people on COVID-19,
this paper first proposes a deep learning model which classifies texts related
to the pandemic from text data with place labels. Next, it conducts a sentiment
analysis based on multi-task learning. Finally, it carries out a fixed-effect
panel regression with outputs of the sentiment analysis. The performance of the
algorithm shows a promising result. The empirical study demonstrates while the
number of local cases is positively associated with risk perception, the number
of imported cases is negatively associated with confidence levels, which
explains why citizens tend to ascribe the protracted pandemic to foreign
factors. Besides, this study finds that previous pandemic hits cities recover
slowly from the suffering, while local governments' spending on healthcare can
improve the situation. Our study illustrates the reasons for risk perception
and confidence based on different sources of statistical information due to
cognitive bias. It complements the knowledge related to epidemic information.
It also contributes to a framework that combines sentiment analysis using
advanced deep learning technology with the empirical regression method.",2022-11-16,"Linjiang Guo, Zijian Feng, Yuxue Chi, Mingzhu Wang, Yijun Liu"
"SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic
  Specialisation for Chinese Sexism Detection in Social Media","The goal of sexism detection is to mitigate negative online content targeting
certain gender groups of people. However, the limited availability of labeled
sexism-related datasets makes it problematic to identify online sexism for
low-resource languages. In this paper, we address the task of automatic sexism
detection in social media for one low-resource language -- Chinese. Rather than
collecting new sexism data or building cross-lingual transfer learning models,
we develop a cross-lingual domain-aware semantic specialisation system in order
to make the most of existing data. Semantic specialisation is a technique for
retrofitting pre-trained distributional word vectors by integrating external
linguistic knowledge (such as lexico-semantic relations) into the specialised
feature space. To do this, we leverage semantic resources for sexism from a
high-resource language (English) to specialise pre-trained word vectors in the
target language (Chinese) to inject domain knowledge. We demonstrate the
benefit of our sexist word embeddings (SexWEs) specialised by our framework via
intrinsic evaluation of word similarity and extrinsic evaluation of sexism
detection. Compared with other specialisation approaches and Chinese baseline
word vectors, our SexWEs shows an average score improvement of 0.033 and 0.064
in both intrinsic and extrinsic evaluations, respectively. The ablative results
and visualisation of SexWEs also prove the effectiveness of our framework on
retrofitting word vectors in low-resource languages.",2022-11-15,"Aiqi Jiang, Arkaitz Zubiaga"
"Anomaly Detection in Multiplex Dynamic Networks: from Blockchain
  Security to Brain Disease Prediction","The problem of identifying anomalies in dynamic networks is a fundamental
task with a wide range of applications. However, it raises critical challenges
due to the complex nature of anomalies, lack of ground truth knowledge, and
complex and dynamic interactions in the network. Most existing approaches
usually study networks with a single type of connection between vertices, while
in many applications interactions between objects vary, yielding multiplex
networks. We propose ANOMULY, a general, unsupervised edge anomaly detection
framework for multiplex dynamic networks. In each relation type, ANOMULY sees
node embeddings at different GNN layers as hierarchical node states and employs
a GRU cell to capture temporal properties of the network and update node
embeddings over time. We then add an attention mechanism that incorporates
information across different types of relations. Our case study on brain
networks shows how this approach could be employed as a new tool to understand
abnormal brain activity that might reveal a brain disease or disorder.
Extensive experiments on nine real-world datasets demonstrate that ANOMULY
achieves state-of-the-art performance.",2022-11-15,"Ali Behrouz, Margo Seltzer"
"Methodological proposal to identify the nationality of Twitter users
  through Random-Forests","We disclose a methodology to determine the participants in discussions and
their contributions in social networks with a local relationship (e.g.,
nationality), providing certain levels of trust and efficiency in the process.
The dynamic is a challenge that has demanded studies and some approximations to
recent solutions. The study addressed the problem of identifying the
nationality of users in the Twitter social network before an opinion request
(of a political nature and social participation). The employed methodology
classifies, via machine learning, the Twitter users' nationality to carry out
opinion studies in three Central American countries. The Random Forests
algorithm is used to generate classification models with small training
samples, using exclusively numerical characteristics based on the number of
times that different interactions among users occur. When averaging the
proportions achieved by inferences of the ratio of nationals of each country,
in the initial data, an average of 77.40% was calculated, compared to 91.60%
averaged after applying the automatic classification model, an average increase
of 14.20%. In conclusion, it can be seen that the suggested set of method
provides a reasonable approach and efficiency in the face of opinion problems.",2022-11-15,"Damián Quijano, Richard Gil-Herrera"
"Adaptive Multi-Neighborhood Attention based Transformer for Graph
  Representation Learning","By incorporating the graph structural information into Transformers, graph
Transformers have exhibited promising performance for graph representation
learning in recent years. Existing graph Transformers leverage specific
strategies, such as Laplacian eigenvectors and shortest paths of the node
pairs, to preserve the structural features of nodes and feed them into the
vanilla Transformer to learn the representations of nodes. It is hard for such
predefined rules to extract informative graph structural features for arbitrary
graphs whose topology structure varies greatly, limiting the learning capacity
of the models. To this end, we propose an adaptive graph Transformer, termed
Multi-Neighborhood Attention based Graph Transformer (MNA-GT), which captures
the graph structural information for each node from the multi-neighborhood
attention mechanism adaptively. By defining the input to perform scaled-dot
product as an attention kernel, MNA-GT constructs multiple attention kernels
based on different hops of neighborhoods such that each attention kernel can
capture specific graph structural information of the corresponding neighborhood
for each node pair. In this way, MNA-GT can preserve the graph structural
information efficiently by incorporating node representations learned by
different attention kernels. MNA-GT further employs an attention layer to learn
the importance of different attention kernels to enable the model to adaptively
capture the graph structural information for different nodes. Extensive
experiments are conducted on a variety of graph benchmarks, and the empirical
results show that MNA-GT outperforms many strong baselines.",2022-11-15,"Gaichao Li, Jinsong Chen, Kun He"
"Neighborhood Convolutional Network: A New Paradigm of Graph Neural
  Networks for Node Classification","The decoupled Graph Convolutional Network (GCN), a recent development of GCN
that decouples the neighborhood aggregation and feature transformation in each
convolutional layer, has shown promising performance for graph representation
learning. Existing decoupled GCNs first utilize a simple neural network (e.g.,
MLP) to learn the hidden features of the nodes, then propagate the learned
features on the graph with fixed steps to aggregate the information of
multi-hop neighborhoods. Despite effectiveness, the aggregation operation,
which requires the whole adjacency matrix as the input, is involved in the
model training, causing high training cost that hinders its potential on larger
graphs. On the other hand, due to the independence of node attributes as the
input, the neural networks used in decoupled GCNs are very simple, and advanced
techniques cannot be applied to the modeling. To this end, we further liberate
the aggregation operation from the decoupled GCN and propose a new paradigm of
GCN, termed Neighborhood Convolutional Network (NCN), that utilizes the
neighborhood aggregation result as the input, followed by a special
convolutional neural network tailored for extracting expressive node
representations from the aggregation input. In this way, the model could
inherit the merit of decoupled GCN for aggregating neighborhood information, at
the same time, develop much more powerful feature learning modules. A training
strategy called mask training is incorporated to further boost the model
performance. Extensive results demonstrate the effectiveness of our model for
the node classification task on diverse homophilic graphs and heterophilic
graphs.",2022-11-15,"Jinsong Chen, Boyu Li, Kun He"
"Between News and History: Identifying Networked Topics of Collective
  Attention on Wikipedia","The digital information landscape has introduced a new dimension to
understanding how we collectively react to new information and preserve it at
the societal level. This, together with the emergence of platforms such as
Wikipedia, has challenged traditional views on the relationship between current
events and historical accounts of events, with an ever-shrinking divide between
""news"" and ""history"". Wikipedia's place as the Internet's primary reference
work thus poses the question of how it represents both traditional
encyclopaedic knowledge and evolving important news stories. In other words,
how is information on and attention towards current events integrated into the
existing topical structures of Wikipedia? To address this we develop a temporal
community detection approach towards topic detection that takes into account
both short term dynamics of attention as well as long term article network
structures. We apply this method to a dataset of one year of current events on
Wikipedia to identify clusters distinct from those that would be found solely
from page view time series correlations or static network structure. We are
able to resolve the topics that more strongly reflect unfolding current events
vs more established knowledge by the relative importance of collective
attention dynamics vs link structures. We also offer important developments by
identifying and describing the emergent topics on Wikipedia. This work provides
a means of distinguishing how these information and attention clusters are
related to Wikipedia's twin faces of encyclopaedic knowledge and current events
-- crucial to understanding the production and consumption of knowledge in the
digital age.",2022-11-14,"Patrick Gildersleve, Renaud Lambiotte, Taha Yasseri"
Dollar-Yuan Battle in the World Trade Network,"From the Bretton Woods agreement in 1944 till the present day, the US dollar
has been the dominant currency in the world trade. However, the rise of the
Chinese economy led recently to the emergence of trade transactions in Chinese
yuan. Here, we analyze mathematically how the structure of the international
trade flows would favor a country to trade whether in US dollar or in Chinese
yuan. The computation of the trade currency preference is based on the world
trade network built from the 2010-2020 UN Comtrade data. The preference of a
country to trade in US dollar or Chinese yuan is determined by two
multiplicative factors: the relative weight of trade volume exchanged by the
country with its direct trade partners, and the relative weight of its trade
partners in the global international trade. The performed analysis, based on
Ising spin interactions on the world trade network, shows that, from 2010 to
present, a transition took place, and the majority of the world countries would
have now a preference to trade in Chinese yuan if one only consider the world
trade network structure.",2022-11-14,"Célestin Coquidé, José Lages, Dima L. Shepelyansky"
"How Much Hate with #china? A Preliminary Analysis on China-related
  Hateful Tweets Two Years After the Covid Pandemic Began","Following the outbreak of a global pandemic, online content is filled with
hate speech. Donald Trump's ''Chinese Virus'' tweet shifted the blame for the
spread of the Covid-19 virus to China and the Chinese people, which triggered a
new round of anti-China hate both online and offline. This research intends to
examine China-related hate speech on Twitter during the two years following the
burst of the pandemic (2020 and 2021). Through Twitter's API, in total
2,172,333 tweets hashtagged #china posted during the time were collected. By
employing multiple state-of-the-art pretrained language models for hate speech
detection, we identify a wide range of hate of various types, resulting in an
automatically labeled anti-China hate speech dataset. We identify a hateful
rate in #china tweets of 2.5% in 2020 and 1.9% in 2021. This is well above the
average rate of online hate speech on Twitter at 0.6% identified in Gao et al.,
2017. We further analyzed the longitudinal development of #china tweets and
those identified as hateful in 2020 and 2021 through visualizing the daily
number and hate rate over the two years. Our keyword analysis of hate speech in
#china tweets reveals the most frequently mentioned terms in the hateful #china
tweets, which can be used for further social science studies.",2022-11-11,"Jinghua Xu, Zarah Weiss"
MGTCOM: Community Detection in Multimodal Graphs,"Community detection is the task of discovering groups of nodes sharing
similar patterns within a network. With recent advancements in deep learning,
methods utilizing graph representation learning and deep clustering have shown
great results in community detection. However, these methods often rely on the
topology of networks (i) ignoring important features such as network
heterogeneity, temporality, multimodality, and other possibly relevant
features. Besides, (ii) the number of communities is not known a priori and is
often left to model selection. In addition, (iii) in multimodal networks all
nodes are assumed to be symmetrical in their features; while true for
homogeneous networks, most of the real-world networks are heterogeneous where
feature availability often varies. In this paper, we propose a novel framework
(named MGTCOM) that overcomes the above challenges (i)--(iii). MGTCOM
identifies communities through multimodal feature learning by leveraging a new
sampling technique for unsupervised learning of temporal embeddings.
Importantly, MGTCOM is an end-to-end framework optimizing network embeddings,
communities, and the number of communities in tandem. In order to assess its
performance, we carried out an extensive evaluation on a number of multimodal
networks. We found out that our method is competitive against state-of-the-art
and performs well in inductive inference.",2022-11-10,"E. Dmitriev, M. W. Chekol, S. Wang"
"Biomedical Multi-hop Question Answering Using Knowledge Graph Embeddings
  and Language Models","Biomedical knowledge graphs (KG) are heterogenous networks consisting of
biological entities as nodes and relations between them as edges. These
entities and relations are extracted from millions of research papers and
unified in a single resource. The goal of biomedical multi-hop
question-answering over knowledge graph (KGQA) is to help biologist and
scientist to get valuable insights by asking questions in natural language.
Relevant answers can be found by first understanding the question and then
querying the KG for right set of nodes and relationships to arrive at an
answer. To model the question, language models such as RoBERTa and BioBERT are
used to understand context from natural language question. One of the
challenges in KGQA is missing links in the KG. Knowledge graph embeddings (KGE)
help to overcome this problem by encoding nodes and edges in a dense and more
efficient way. In this paper, we use a publicly available KG called Hetionet
which is an integrative network of biomedical knowledge assembled from 29
different databases of genes, compounds, diseases, and more. We have enriched
this KG dataset by creating a multi-hop biomedical question-answering dataset
in natural language for testing the biomedical multi-hop question-answering
system and this dataset will be made available to the research community. The
major contribution of this research is an integrated system that combines
language models with KG embeddings to give highly relevant answers to free-form
questions asked by biologists in an intuitive interface. Biomedical multi-hop
question-answering system is tested on this data and results are highly
encouraging.",2022-11-10,"Dattaraj J. Rao, Shraddha S. Mane, Mukta A. Paliwal"
The Friendship Paradox and Social Network Participation,"The friendship paradox implies that a person will, on average, have fewer
friends than their friends do. Prior work has shown how the friendship paradox
can lead to perception biases regarding behaviors that correlate with the
number of friends: for example, people tend to perceive their friends as being
more socially engaged than they are. Here, we investigate the consequences of
this type of social comparison in the conceptual setting of content creation
(""sharing"") in an online social network. Suppose people compare the amount of
feedback that their content receives to the amount of feedback that their
friends' content receives, and suppose they modify their sharing behavior as a
result of that comparison. How does that impact overall sharing on the social
network over time? We run simulations over model-generated synthetic networks,
assuming initially uniform sharing and feedback rates. Thus, people's initial
modifications of their sharing behavior in response to social comparisons are
entirely driven by the friendship paradox. These modifications induce
inhomogeneities in sharing rates that can further alter perception biases. If
people's responses to social comparisons are monotonic (i.e., the larger the
disparity, the larger the modification in sharing behavior), our simulations
suggest that overall sharing in the network gradually declines. Meanwhile,
convex responses can sustain or grow overall sharing in the network. We focus
entirely on synthetic graphs in the present work and have not yet extended our
simulations to real-world network topologies. Nevertheless, we do discuss
practical implications, such as how interventions can be tailored to sustain
long-term sharing, even in the presence of adverse social-comparison effects.",2022-11-10,"Ahmed Medhat, Shankar Iyer"
Countering Misinformation on Social Networks Using Graph Alterations,"We restrict the propagation of misinformation in a social-media-like
environment while preserving the spread of correct information. We model the
environment as a random network of users in which each news item propagates in
the network in consecutive cascades. Existing studies suggest that the cascade
behaviors of misinformation and correct information are affected differently by
user polarization and reflexivity. We show that this difference can be used to
alter network dynamics in a way that selectively hinders the spread of
misinformation content. To implement these alterations, we introduce an
optimization-based probabilistic dropout method that randomly removes
connections between users to achieve minimal propagation of misinformation. We
use disciplined convex programming to optimize these removal probabilities over
a reduced space of possible network alterations. We test the algorithm's
effectiveness using simulated social networks. In our tests, we use both
synthetic network structures based on stochastic block models, and natural
network structures that are generated using random sampling of a dataset
collected from Twitter. The results show that on average the algorithm
decreases the cascade size of misinformation content by up to $70\%$ in
synthetic network tests and up to $45\%$ in natural network tests while
maintaining a branching ratio of at least $1.5$ for correct information.",2022-11-09,"Yigit E. Bayiz, Ufuk Topcu"
"GENIUS: A Novel Solution for Subteam Replacement with Clustering-based
  Graph Neural Network","Subteam replacement is defined as finding the optimal candidate set of people
who can best function as an unavailable subset of members (i.e., subteam) for
certain reasons (e.g., conflicts of interests, employee churn), given a team of
people embedded in a social network working on the same task. Prior
investigations on this problem incorporate graph kernel as the optimal criteria
for measuring the similarity between the new optimized team and the original
team. However, the increasingly abundant social networks reveal fundamental
limitations of existing methods, including (1) the graph kernel-based
approaches are powerless to capture the key intrinsic correlations among node
features, (2) they generally search over the entire network for every member to
be replaced, making it extremely inefficient as the network grows, and (3) the
requirement of equal-sized replacement for the unavailable subteam can be
inapplicable due to limited hiring budget. In this work, we address the
limitations in the state-of-the-art for subteam replacement by (1) proposing
GENIUS, a novel clustering-based graph neural network (GNN) framework that can
capture team network knowledge for flexible subteam replacement, and (2)
equipping the proposed GENIUS with self-supervised positive team contrasting
training scheme to improve the team-level representation learning and
unsupervised node clusters to prune candidates for fast computation. Through
extensive empirical evaluations, we demonstrate the efficacy of the proposed
method (1) effectiveness: being able to select better candidate members that
significantly increase the similarity between the optimized and original teams,
and (2) efficiency: achieving more than 600 times speed-up in average running
time.",2022-11-08,"Chuxuan Hu, Qinghai Zhou, Hanghang Tong"
User Engagement and the Toxicity of Tweets,"Twitter is one of the most popular online micro-blogging and social
networking platforms. This platform allows individuals to freely express
opinions and interact with others regardless of geographic barriers. However,
with the good that online platforms offer, also comes the bad. Twitter and
other social networking platforms have created new spaces for incivility. With
the growing interest on the consequences of uncivil behavior online,
understanding how a toxic comment impacts online interactions is imperative. We
analyze a random sample of more than 85,300 Twitter conversations to examine
differences between toxic and non-toxic conversations and the relationship
between toxicity and user engagement. We find that toxic conversations, those
with at least one toxic tweet, are longer but have fewer individual users
contributing to the dialogue compared to the non-toxic conversations. However,
within toxic conversations, toxicity is positively associated with more
individual Twitter users participating in conversations. This suggests that
overall, more visible conversations are more likely to include toxic replies.
  Additionally, we examine the sequencing of toxic tweets and its impact on
conversations. Toxic tweets often occur as the main tweet or as the first
reply, and lead to greater overall conversation toxicity. We also find a
relationship between the toxicity of the first reply to a toxic tweet and the
toxicity of the conversation, such that whether the first reply is toxic or
non-toxic sets the stage for the overall toxicity of the conversation,
following the idea that hate can beget hate.",2022-11-07,"Nazanin Salehabadi, Anne Groggel, Mohit Singhal, Sayak Saha Roy, Shirin Nilizadeh"
"Network Diffusion Model Reveals Recovery Multipliers and Heterogeneous
  Spatial Effects in Post-Disaster Community Recovery","Community recovery from hazards and crises occurs through various diffusion
processes within social and spatial networks of communities. Existing knowledge
regarding the diffusion of recovery in community socio-spatial networks,
however, is rather limited. To bridge this gap, in this study, we created a
network diffusion model to characterize the unfolding of population activity
recovery in spatial networks of communities. Using data related to population
activity recovery durations calculated from location-based data in the context
of 2017 Hurricane Harvey in the Houston area, we parameterized the
threshold-based network diffusion model and evaluated the extent of homogeneity
in spatial effects. Then we implemented the network diffusion model along with
the genetic algorithm to simulate and identify recovery multipliers. The
results show that the spatial effects of recovery are rather heterogeneous
across spatial areas; some spatial areas demonstrate a greater spatial effect
(spatial interdependence) in their recovery compared with others. Also, the
results show that low-income areas demonstrate a greater spatial effect in
their recovery. The greater spatial effects in recovery of low-income areas
imply more reliance on resources and facilities of neighboring areas and also
explain the existence of slow recovery hotspots in areas where socially
vulnerable populations reside. Also, the results show that low-income and
minority areas are community recovery multipliers; the faster the recovery of
these recovery multipliers; the faster the recovery of the entire community.
Hence, prioritizing these areas for recovery resource allocation could expedite
the recovery of the overall community and promote recovery equality and equity.",2022-11-07,"Chia-Fu Liu, Ali Mostafavi"
On a Network Centrality Maximization Game,"We study a network formation game where $n$ players, identified with the
nodes of a directed graph to be formed, choose where to wire their outgoing
links in order to maximize their PageRank centrality. Specifically, the action
of every player $i$ consists in the wiring of a predetermined number $d_i$ of
directed out-links, and her utility is her own PageRank centrality in the
network resulting from the actions of all players. We show that this is a
potential game and that the best response correspondence always exhibits a
local structure in that it is never convenient for a node $i$ to link to other
nodes that are at incoming distance more than $d_i $ from her. We then study
the equilibria of this game determining necessary conditions for a graph to be
a (strict, recurrent) Nash equilibrium. Moreover, in the homogeneous case,
where players all have the same number $d$ of out-links, we characterize the
structure of the potential maximizing equilibria and, in the special cases $
d=1 $ and $ d=2 $, we provide a complete classification of the set of (strict,
recurrent) Nash equilibria. Our analysis shows in particular that the
considered formation mechanism leads to the emergence of undirected and
disconnected or loosely connected networks.",2022-11-07,"Costanza Catalano, Maria Castaldo, Giacomo Como, Fabio Fagnani"
The Value Chain of Education Metaverse,"Since the end of 2021, the Metaverse has been booming. Many unknown
possibilities are gradually being realized, but many people only determined
that they use Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality
(MR) in the Metaverse. It is even considered that as long as the above
realities (VR, AR, MR) are used, it is equal to the Metaverse. However, this is
not true, for Reality-based display tools are only one of the presentation
methods of the Metaverse. If we cannot return to the three main characteristics
of the Metaverse: ""digital avatars,"" a decentralized ""consensus value system,""
and ""Immersive experience,"" the practice and imagination of the Metaverse will
become very narrow. Since 2022, the concept of Metaverse has also been widely
used in classroom teaching to integrate into teaching activities. Therefore, to
prevent teachers and students from understanding the Metaverse not only in the
""Using VR, AR, MR is equivalent to Metaverse"" but also pay more attention to
the other two characteristics of the Metaverse: ""digital avatars"" and a
decentralized ""consensus value system.""",2022-11-07,Yun-Cheng Tsai
Stochastic Solutions for Dense Subgraph Discovery in Multilayer Networks,"Network analysis has played a key role in knowledge discovery and data
mining. In many real-world applications in recent years, we are interested in
mining multilayer networks, where we have a number of edge sets called layers,
which encode different types of connections and/or time-dependent connections
over the same set of vertices. Among many network analysis techniques, dense
subgraph discovery, aiming to find a dense component in a network, is an
essential primitive with a variety of applications in diverse domains. In this
paper, we introduce a novel optimization model for dense subgraph discovery in
multilayer networks. Our model aims to find a stochastic solution, i.e., a
probability distribution over the family of vertex subsets, rather than a
single vertex subset, whereas it can also be used for obtaining a single vertex
subset. For our model, we design an LP-based polynomial-time exact algorithm.
Moreover, to handle large-scale networks, we also devise a simple, scalable
preprocessing algorithm, which often reduces the size of the input networks
significantly and results in a substantial speed-up. Computational experiments
demonstrate the validity of our model and the effectiveness of our algorithms.",2022-11-07,"Yasushi Kawase, Atsushi Miyauchi, Hanna Sumita"
BEKG: A Built Environment Knowledge Graph,"Practices in the built environment have become more digitalized with the
rapid development of modern design and construction technologies. However, the
requirement of practitioners or scholars to gather complicated professional
knowledge in the built environment has not been satisfied yet. In this paper,
more than 80,000 paper abstracts in the built environment field were obtained
to build a knowledge graph, a knowledge base storing entities and their
connective relations in a graph-structured data model. To ensure the retrieval
accuracy of the entities and relations in the knowledge graph, two
well-annotated datasets have been created, containing 2,000 instances and 1,450
instances each in 29 relations for the named entity recognition task and
relation extraction task respectively. These two tasks were solved by two
BERT-based models trained on the proposed dataset. Both models attained an
accuracy above 85% on these two tasks. More than 200,000 high-quality relations
and entities were obtained using these models to extract all abstract data.
Finally, this knowledge graph is presented as a self-developed visualization
system to reveal relations between various entities in the domain. Both the
source code and the annotated dataset can be found here:
https://github.com/HKUST-KnowComp/BEKG.",2022-11-05,"Xiaojun Yang, Haoyu Zhong, Penglin Du, Keyi Zhou, Xingjin Lai, Zhengdong Wang, Yik Lun Lau, Yangqiu Song, Liyaning Tang"
"BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19
  Tweets","The free flow of information has been accelerated by the rapid development of
social media technology. There has been a significant social and psychological
impact on the population due to the outbreak of Coronavirus disease (COVID-19).
The COVID-19 pandemic is one of the current events being discussed on social
media platforms. In order to safeguard societies from this pandemic, studying
people's emotions on social media is crucial. As a result of their particular
characteristics, sentiment analysis of texts like tweets remains challenging.
Sentiment analysis is a powerful text analysis tool. It automatically detects
and analyzes opinions and emotions from unstructured data. Texts from a wide
range of sources are examined by a sentiment analysis tool, which extracts
meaning from them, including emails, surveys, reviews, social media posts, and
web articles. To evaluate sentiments, natural language processing (NLP) and
machine learning techniques are used, which assign weights to entities, topics,
themes, and categories in sentences or phrases. Machine learning tools learn
how to detect sentiment without human intervention by examining examples of
emotions in text. In a pandemic situation, analyzing social media texts to
uncover sentimental trends can be very helpful in gaining a better
understanding of society's needs and predicting future trends. We intend to
study society's perception of the COVID-19 pandemic through social media using
state-of-the-art BERT and Deep CNN models. The superiority of BERT models over
other deep models in sentiment analysis is evident and can be concluded from
the comparison of the various research studies mentioned in this article.",2022-11-04,"Javad Hassannataj Joloudari, Sadiq Hussain, Mohammad Ali Nematollahi, Rouhollah Bagheri, Fatemeh Fazl, Roohallah Alizadehsani, Reza Lashgari, Ashis Talukder"
"Rethinking the positive role of cluster structure in complex networks
  for link prediction tasks","Clustering is a fundamental problem in network analysis that finds closely
connected groups of nodes and separates them from other nodes in the graph,
while link prediction is to predict whether two nodes in a network are likely
to have a link. The definition of both naturally determines that clustering
must play a positive role in obtaining accurate link prediction tasks. Yet
researchers have long ignored or used inappropriate ways to undermine this
positive relationship. In this article, We construct a simple but efficient
clustering-driven link prediction framework(ClusterLP), with the goal of
directly exploiting the cluster structures to obtain connections between nodes
as accurately as possible in both undirected graphs and directed graphs.
Specifically, we propose that it is easier to establish links between nodes
with similar representation vectors and cluster tendencies in undirected
graphs, while nodes in a directed graphs can more easily point to nodes similar
to their representation vectors and have greater influence in their own
cluster. We customized the implementation of ClusterLP for undirected and
directed graphs, respectively, and the experimental results using multiple
real-world networks on the link prediction task showed that our models is
highly competitive with existing baseline models. The code implementation of
ClusterLP and baselines we use are available at
https://github.com/ZINUX1998/ClusterLP.",2022-11-04,"Shanfan Zhang, Wenjiao Zhang, Zhan Bu"
Learning Hypergraphs From Signals With Dual Smoothness Prior,"Hypergraph structure learning, which aims to learn the hypergraph structures
from the observed signals to capture the intrinsic high-order relationships
among the entities, becomes crucial when a hypergraph topology is not readily
available in the datasets. There are two challenges that lie at the heart of
this problem: 1) how to handle the huge search space of potential hyperedges,
and 2) how to define meaningful criteria to measure the relationship between
the signals observed on nodes and the hypergraph structure. In this paper, for
the first challenge, we adopt the assumption that the ideal hypergraph
structure can be derived from a learnable graph structure that captures the
pairwise relations within signals. Further, we propose a hypergraph structure
learning framework HGSL with a novel dual smoothness prior that reveals a
mapping between the observed node signals and the hypergraph structure, whereby
each hyperedge corresponds to a subgraph with both node signal smoothness and
edge signal smoothness in the learnable graph structure. Finally, we conduct
extensive experiments to evaluate HGSL on both synthetic and real world
datasets. Experiments show that HGSL can efficiently infer meaningful
hypergraph topologies from observed signals.",2022-11-03,"Bohan Tang, Siheng Chen, Xiaowen Dong"
"Supporting the Task-driven Skill Identification in Open Source Project
  Issue Tracking Systems","Selecting an appropriate task is challenging for contributors to Open Source
Software (OSS), mainly for those who are contributing for the first time.
Therefore, researchers and OSS projects have proposed various strategies to aid
newcomers, including labeling tasks. We investigate the automatic labeling of
open issues strategy to help the contributors to pick a task to contribute. We
label the issues with API-domains--categories of APIs parsed from the source
code used to solve the issues. We plan to add social network analysis metrics
from the issues conversations as new predictors. By identifying the skills, we
claim the contributor candidates should pick a task more suitable. We analyzed
interview transcripts and the survey's open-ended questions to comprehend the
strategies used to assist in onboarding contributors and used to pick up an
issue. We applied quantitative studies to analyze the relevance of the labels
in an experiment and compare the strategies' relative importance. We also mined
issue data from OSS repositories to predict the API-domain labels with
comparable precision, recall, and F-measure with the state-of-art. We plan to
use a skill ontology to assist the matching process between contributors and
tasks. By analyzing the confidence level of the matching instances in
ontologies describing contributors' skills and tasks, we might recommend issues
for contribution. So far, the results showed that organizing the issues--which
includes assigning labels is seen as an essential strategy for diverse roles in
OSS communities. The API-domain labels are relevant for experienced
practitioners. The predictions have an average precision of 75.5%. Labeling the
issues indicates the skills involved in an issue. The labels represent possible
skills in the source code related to an issue. By investigating this research
topic, we expect to assist the new contributors in finding a task.",2022-11-02,Fabio Santos
"DeepTrace: Learning to Optimize Contact Tracing in Epidemic Networks
  with Graph Neural Networks","Digital contact tracing aims to curb epidemics by identifying and mitigating
public health emergencies through technology. Backward contact tracing, which
tracks the sources of infection, proved crucial in places like Japan for
identifying COVID-19 infections from superspreading events. This paper presents
a novel perspective of digital contact tracing as online graph exploration and
addresses the forward and backward contact tracing problem as a
maximum-likelihood (ML) estimation problem using iterative epidemic network
data sampling. The challenge lies in the combinatorial complexity and rapid
spread of infections. We introduce DeepTrace, an algorithm based on a Graph
Neural Network (GNN) that iteratively updates its estimations as new contact
tracing data is collected, learning to optimize the maximum likelihood
estimation by utilizing topological features to accelerate learning and improve
convergence. The contact tracing process combines either BFS or DFS to expand
the network and trace the infection source, ensuring comprehensive and
efficient exploration. Additionally, the GNN model is fine-tuned through a
two-phase approach: pre-training with synthetic networks to approximate
likelihood probabilities and fine-tuning with high-quality data to refine the
model. Using COVID-19 variant data, we illustrate that DeepTrace surpasses
current methods in identifying superspreaders, providing a robust basis for a
scalable digital contact tracing strategy.",2022-11-02,"Chee Wei Tan, Pei-Duo Yu, Siya Chen, H. Vincent Poor"
A General Language for Modeling Social Media Account Behavior,"Malicious actors exploit social media to inflate stock prices, sway
elections, spread misinformation, and sow discord. To these ends, they employ
tactics that include the use of inauthentic accounts and campaigns. Methods to
detect these abuses currently rely on features specifically designed to target
suspicious behaviors. However, the effectiveness of these methods decays as
malicious behaviors evolve. To address this challenge, we propose a general
language for modeling social media account behavior. Words in this language,
called BLOC, consist of symbols drawn from distinct alphabets representing user
actions and content. The language is highly flexible and can be applied to
model a broad spectrum of legitimate and suspicious online behaviors without
extensive fine-tuning. Using BLOC to represent the behaviors of Twitter
accounts, we achieve performance comparable to or better than state-of-the-art
methods in the detection of social bots and coordinated inauthentic behavior.",2022-11-01,"Alexander C. Nwala, Alessandro Flammini, Filippo Menczer"
Learning to Navigate Wikipedia by Taking Random Walks,"A fundamental ability of an intelligent web-based agent is seeking out and
acquiring new information. Internet search engines reliably find the correct
vicinity but the top results may be a few links away from the desired target. A
complementary approach is navigation via hyperlinks, employing a policy that
comprehends local content and selects a link that moves it closer to the
target. In this paper, we show that behavioral cloning of randomly sampled
trajectories is sufficient to learn an effective link selection policy. We
demonstrate the approach on a graph version of Wikipedia with 38M nodes and
387M edges. The model is able to efficiently navigate between nodes 5 and 20
steps apart 96% and 92% of the time, respectively. We then use the resulting
embeddings and policy in downstream fact verification and question answering
tasks where, in combination with basic TF-IDF search and ranking methods, they
are competitive results to the state-of-the-art methods.",2022-10-31,"Manzil Zaheer, Kenneth Marino, Will Grathwohl, John Schultz, Wendy Shang, Sheila Babayan, Arun Ahuja, Ishita Dasgupta, Christine Kaeser-Chen, Rob Fergus"
Random Walk-based Community Key-members Search over Large Graphs,"Given a graph $G$, a query node $q$, and an integer $k$, community search
(CS) seeks a cohesive subgraph (measured by community models such as $k$-core
or $k$-truss) from $G$ that contains $q$. It is difficult for ordinary users
with less knowledge of graphs' complexity to set an appropriate $k$. Even if we
define quite a large $k$, the community size returned by CS is often too large
for users to gain much insight about it. Compared against the entire community,
key-members in the community appear more valuable than others. To contend with
this, we focus on Community Key-members Search problem (CKS). We turn our
perspective to the key-members in the community containing $q$ instead of the
entire community. To solve CKS problem, we first propose an exact algorithm
based on truss decomposition as a baseline. Then, we present four random
walk-based optimized algorithms to achieve a trade-off between effectiveness
and efficiency, by carefully considering three important cohesiveness features
in the design of transition matrix. As a result, we return key-members
according to the stationary distribution when random walk converges. We
theoretically analyze the rationality of designing the cohesiveness-aware
transition matrix for random walk, through Bayesian theory based on Gaussian
Mixture Model with Box-Cox Transformation and Copula Function Fitting.
Moreover, we propose a lightweight refinement method following an
``expand-replace"" manner to further optimize the result with little overhead,
and we extend our method for CKS with multiple query nodes. Comprehensive
experimental studies on various real-world datasets demonstrate our method's
superiority.",2022-10-31,"Yuxiang Wang, Yuyang Zhao, Xiaoliang Xu, Yue Wu, Tianxing Wu, Xiangyu Ke"
PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks,"Aside from graph neural networks (GNNs) attracting significant attention as a
powerful framework revolutionizing graph representation learning, there has
been an increasing demand for explaining GNN models. Although various
explanation methods for GNNs have been developed, most studies have focused on
instance-level explanations, which produce explanations tailored to a given
graph instance. In our study, we propose Prototype-bAsed GNN-Explainer (PAGE),
a novel model-level GNN explanation method that explains what the underlying
GNN model has learned for graph classification by discovering
human-interpretable prototype graphs. Our method produces explanations for a
given class, thus being capable of offering more concise and comprehensive
explanations than those of instance-level explanations. First, PAGE selects
embeddings of class-discriminative input graphs on the graph-level embedding
space after clustering them. Then, PAGE discovers a common subgraph pattern by
iteratively searching for high matching node tuples using node-level embeddings
via a prototype scoring function, thereby yielding a prototype graph as our
explanation. Using six graph classification datasets, we demonstrate that PAGE
qualitatively and quantitatively outperforms the state-of-the-art model-level
explanation method. We also carry out systematic experimental studies by
demonstrating the relationship between PAGE and instance-level explanation
methods, the robustness of PAGE to input data scarce environments, and the
computational efficiency of the proposed prototype scoring function in PAGE.",2022-10-31,"Yong-Min Shin, Sun-Woo Kim, Won-Yong Shin"
Solidago: A Modular Collaborative Scoring Pipeline,"This paper presents Solidago, an end-to-end modular pipeline to allow any
community of users to collaboratively score any number of entities. Solidago
proposes a six-module decomposition. First, it uses pretrust and peer-to-peer
vouches to assign trust scores to users. Second, based on participation, trust
scores are turned into voting rights per user per entity. Third, for each user,
a preference model is learned from the user's evaluation data. Fourth, users'
models are put on a similar scale. Fifth, these models are securely aggregated.
Sixth, models are post-processed to yield human-readable global scores. We also
propose default implementations of the six modules, including a novel trust
propagation algorithm, and adaptations of state-of-the-art scaling and
aggregation solutions. Our pipeline has been successfully deployed on the
open-source platform tournesol.app. We thereby lay an appealing foundation for
the collaborative, effective, scalable, fair, interpretable and secure scoring
of any set of entities.",2022-10-30,"Lê Nguyên Hoang, Romain Beylerian, Bérangère Colbois, Julien Fageot, Louis Faucon, Aidan Jungo, Alain Le Noac'h, Adrien Matissart, Oscar Villemaud"
MiCRO: Multi-interest Candidate Retrieval Online,"Providing personalized recommendations in an environment where items exhibit
ephemerality and temporal relevancy (e.g. in social media) presents a few
unique challenges: (1) inductively understanding ephemeral appeal for items in
a setting where new items are created frequently, (2) adapting to trends within
engagement patterns where items may undergo temporal shifts in relevance, (3)
accurately modeling user preferences over this item space where users may
express multiple interests. In this work we introduce MiCRO, a generative
statistical framework that models multi-interest user preferences and temporal
multi-interest item representations. Our framework is specifically formulated
to adapt to both new items and temporal patterns of engagement. MiCRO
demonstrates strong empirical performance on candidate retrieval experiments
performed on two large scale user-item datasets: (1) an open-source temporal
dataset of (User, User) follow interactions and (2) a temporal dataset of
(User, Tweet) favorite interactions which we will open-source as an additional
contribution to the community.",2022-10-28,"Frank Portman, Stephen Ragain, Ahmed El-Kishky"
Centralization Problem for Opinion Convergence in Decentralized Networks,"This paper aims to provide a new perspective on the interplay between
decentralization -- a prevalent character of multi-agent systems -- and
centralization, i.e., the task of imposing central control to meet system-level
goals. In particular, in the context of networked opinion dynamic model, the
paper proposes and discusses a framework for centralization. More precisely, a
decentralized network consists of autonomous agents and their social structure
that is unknown and dynamic. Centralization is a process of appointing agents
in the network to act as access units who provide information and exert
influence over their local surroundings. We discuss centralization for the
DeGroot model of opinion dynamics, aiming to enforce opinion convergence using
the minimum number of access units. We show that the key to the centralization
process lies in selecting access units so that they form a dominating set. We
then propose algorithms under a new local algorithmic framework, namely
prowling, to accomplish this task. To validate our algorithm, we perform
systematic experiments over both real-world and synthetic networks and verify
that our algorithm outperforms benchmarks.",2022-10-28,"Yiping Liu, Jiamou Liu, Bakhadyr Khoussaino, Miao Qiao, Bo Yan"
"Interplay between exogenous triggers and endogenous behavioral changes
  in contagion processes on social networks","In recent years, statistical physics' methodologies have proven extremely
successful in offering insights into the mechanisms that govern social
interactions. However, the question of whether these models are able to capture
trends observed in real-world datasets is hardly addressed in the current
literature. With this work we aim at bridging the gap between theoretical
modeling and validation with data. In particular, we propose a model for
opinion dynamics on a social network in the presence of external triggers,
framing the interpretation of the model in the context of misbehavior
spreading. We divide our population in aware, unaware and zealot/educated
agents. Individuals change their status according to two competing dynamics,
referred to as behavioral dynamics and broadcasting. The former accounts for
information spreading through contact among individuals whereas broadcasting
plays the role of an external agent, modeling the effect of mainstream media
outlets. Through both simulations and analytical computations we find that the
stationary distribution of the fraction of unaware agents in the system
undergoes a phase transition when an all-to-all approximation is considered.
Surprisingly, such a phase transition disappears in the presence of a minimum
fraction of educated agents. Finally, we validate our model using data
collected from the public discussion on Twitter, including millions of posts,
about the potential adverse effects of the AstraZeneca vaccine against
COVID-19. We show that the intervention of external agents, as accounted for in
our model, is able to reproduce some key features that are found in this
real-world dataset.",2022-10-27,"Clara Eminente, Oriol Artime, Manlio De Domenico"
"Trust and Believe -- Should We? Evaluating the Trustworthiness of
  Twitter Users","Social networking and micro-blogging services, such as Twitter, play an
important role in sharing digital information. Despite the popularity and
usefulness of social media, they are regularly abused by corrupt users. One of
these nefarious activities is so-called fake news -- a ""virus"" that has been
spreading rapidly thanks to the hospitable environment provided by social media
platforms. The extensive spread of fake news is now becoming a major problem
with far-reaching negative repercussions on both individuals and society.
Hence, the identification of fake news on social media is a problem of utmost
importance that has attracted the interest not only of the research community
but most of the big players on both sides - such as Facebook, on the industry
side, and political parties on the societal one. In this work, we create a
model through which we hope to be able to offer a solution that will instill
trust in social network communities. Our model analyses the behaviour of 50,000
politicians on Twitter and assigns an influence score for each evaluated user
based on several collected and analysed features and attributes. Next, we
classify political Twitter users as either trustworthy or untrustworthy using
random forest and support vector machine classifiers. An active learning model
has been used to classify any unlabeled ambiguous records from our dataset.
Finally, to measure the performance of the proposed model, we used accuracy as
the main evaluation metric.",2022-10-27,"Tanveer Khan, Antonis Michalas"
"Identifying Diversity, Equity, Inclusion, and Accessibility (DEIA)
  Indicators for Transportation Systems using Social Media Data: The Case of
  New York City during Covid-19 Pandemic","The adoption of transportation policies that prioritized highway expansion
over public transportation has disproportionately impacted minorities and
low-income people by restricting their access to social and economic
opportunities and thus resulting in residential segregation. Policymakers,
transportation researchers, planners, and practitioners have started
acknowledging the need to build a diverse, equitable, inclusive, and accessible
(DEIA) transportation system. Traditionally, this has been done through
survey-based approaches that are time-consuming and expensive. While there is
recent attention on leveraging social media data in transportation, the
literature is inconclusive regarding the use of social media data as a viable
alternative to traditional sources to identify the latent DEIA indicators based
on public reactions and perspectives on social media. This study utilized
large-scale Twitter data covering eight counties around the New York City (NYC)
area during the initial phase of the Covid-19 lockdown to address this research
gap. Natural language processing techniques were used to identify
transportation-related major DEIA issues for residents living around NYC by
analyzing their relevant tweet conversations. The study revealed that citizens,
who had negative sentiments toward the DEIA of their local transportation
system, broadly discussed racism, income, unemployment, gender, ride
dependency, transportation modes, and dependent groups. Analyzing the
socio-demographic information based on census tracts, the study also observed
that areas with a higher percentage of low-income, female, Hispanic, and Latino
populations share more concerns about transportation DEIA on Twitter.",2022-10-26,"Fariha Nazneen Rista, Khondhaker Al Momin, Arif Mohaimin Sadri"
Finding Early Adopters of Innovation in Social Network,"Social networks play a fundamental role in the diffusion of innovation
through peers' influence on adoption. Thus, network position including a wide
range of network centrality measures have been used to describe individuals'
affinity to adopt an innovation and their ability to propagate diffusion. Yet,
social networks are assortative in terms of susceptibility and influence and in
terms of network centralities as well. This makes the identification of
influencers difficult especially since susceptibility and centrality does not
always go hand in hand. Here we propose the Top Candidate algorithm, an expert
recommendation method, to rank individuals based on their perceived expertise,
which resonates well with the assortative nature of innovators and early
adopters. Leveraging adoption data from two online social networks that are
assortative in terms of adoption but represent different levels of
assortativity of network centralities, we demonstrate that the Top Candidate
ranking is more efficient in capturing early adopters than other widely used
indices. Top Candidate nodes adopt earlier and have higher reach among
innovators, early adopters and early majority than nodes highlighted by other
methods. These results suggest that the Top Candidate method can identify good
seeds for influence maximization campaigns on social networks.",2022-10-25,"Balázs R. Sziklai, Balázs Lengyel"
"Datavoidant: An AI System for Addressing Political Data Voids on Social
  Media","The limited information (data voids) on political topics relevant to
underrepresented communities has facilitated the spread of disinformation.
Independent journalists who combat disinformation in underrepresented
communities have reported feeling overwhelmed because they lack the tools
necessary to make sense of the information they monitor and address the data
voids. In this paper, we present a system to identify and address political
data voids within underrepresented communities. Armed with an interview study,
indicating that the independent news media has the potential to address them,
we designed an intelligent collaborative system, called Datavoidant.
Datavoidant uses state-of-the-art machine learning models and introduces a
novel design space to provide independent journalists with a collective
understanding of data voids to facilitate generating content to cover the
voids. We performed a user interface evaluation with independent news media
journalists (N=22). These journalists reported that Datavoidant's features
allowed them to more rapidly while easily having a sense of what was taking
place in the information ecosystem to address the data voids. They also
reported feeling more confident about the content they created and the unique
perspectives they had proposed to cover the voids. We conclude by discussing
how Datavoidant enables a new design space wherein individuals can collaborate
to make sense of their information ecosystem and actively devise strategies to
prevent disinformation.",2022-10-24,"Claudia Flores-Saviaga, Shangbin Feng, Saiph Savage"
"Causal Analysis on the Anchor Store Effect in a Location-based Social
  Network","A particular phenomenon of interest in Retail Economics is the spillover
effect of anchor stores (specific stores with a reputable brand) to non-anchor
stores in terms of customer traffic. Prior works in this area rely on small and
survey-based datasets that are often confidential or expensive to collect on a
large scale. Also, very few works study the underlying causal mechanisms
between factors that underpin the spillover effect. In this work, we analyse
the causal relationship between anchor stores and customer traffic to
non-anchor stores and employ a propensity score matching framework to
investigate this effect more efficiently. First of all, to demonstrate the
effect, we leverage open and mobile data from London Datastore and
Location-Based Social Networks (LBSNs) such as Foursquare. We then perform a
large-scale empirical analysis on customer visit patterns from anchor stores to
non-anchor stores(e.g., non-chain restaurants) located in the Greater London
area as a case study. By studying over 600 neighbourhoods in the GreaterLondon
Area, we find that anchor stores cause a 14.2-26.5% increase in customer
traffic for the non-anchor stores reinforcing the established economic theory.
Moreover, we evaluate the efficiency of our methodology by studying the
confounder balance, dose difference and performance of matching framework on
synthetic data. Through this work, we point decision-makers in the retail
industry to a more systematic approach to estimate the anchor store effect and
pave the way for further research to discover more complex causal relationships
underlying this effect with open data.",2022-10-24,"Anish K. Vallapuram, Young D. Kwon, Lik-Hang Lee, Fengli Xu, Pan Hui"
Twitter Users' Behavioral Response to Toxic Replies,"Online toxic attacks, such as harassment, trolling, and hate speech have been
linked to an increase in offline violence and negative psychological effects on
victims. In this paper, we studied the impact of toxicity on users' online
behavior. We collected a sample of 79.8k Twitter conversations. Then, through a
longitudinal study, for nine weeks, we tracked and compared the behavioral
reactions of authors, who were toxicity victims, with those who were not. We
found that toxicity victims show a combination of the following behavioral
reactions: avoidance, revenge, countermeasures, and negotiation. We performed
statistical tests to understand the significance of the contribution of toxic
replies toward user behaviors while considering confounding factors, such as
the structure of conversations and the user accounts' visibility,
identifiability, and activity level. Interestingly, we found that compared to
other random authors, victims are more likely to engage in conversations, reply
in a toxic way, and unfollow toxicity instigators. Even if the toxicity is
directed at other participants, the root authors are more likely to engage in
the conversations and reply in a toxic way. However, victims who have verified
accounts are less likely to participate in conversations or respond by posting
toxic comments. In addition, replies are more likely to be removed in
conversations with a larger percentage of toxic nested replies and toxic
replies directed at other users. Our results can assist further studies in
developing more effective detection and intervention methods for reducing the
negative consequences of toxicity on social media.",2022-10-24,"Ana Aleksandric, Sayak Saha Roy, Shirin Nilizadeh"
"Identifying Crisis Response Communities in Online Social Networks for
  Compound Disasters: The Case of Hurricane Laura and Covid-19","Online social networks allow different agencies and the public to interact
and share the underlying risks and protective actions during major disasters.
This study revealed such crisis communication patterns during hurricane Laura
compounded by the COVID-19 pandemic. Laura was one of the strongest (Category
4) hurricanes on record to make landfall in Cameron, Louisiana. Using the
Application Programming Interface (API), this study utilizes large-scale social
media data obtained from Twitter through the recently released academic track
that provides complete and unbiased observations. The data captured publicly
available tweets shared by active Twitter users from the vulnerable areas
threatened by Laura. Online social networks were based on user influence
feature ( mentions or tags) that allows notifying other users while posting a
tweet. Using network science theories and advanced community detection
algorithms, the study split these networks into twenty-one components of
various sizes, the largest of which contained eight well-defined communities.
Several natural language processing techniques (i.e., word clouds, bigrams,
topic modeling) were applied to the tweets shared by the users in these
communities to observe their risk-taking or risk-averse behavior during a major
compounding crisis. Social media accounts of local news media, radio,
universities, and popular sports pages were among those who involved heavily
and interacted closely with local residents. In contrast, emergency management
and planning units in the area engaged less with the public. The findings of
this study provide novel insights into the design of efficient social media
communication guidelines to respond better in future disasters.",2022-10-23,"Khondhaker Al Momin, H M Imran Kays, Arif Mohaimin Sadri"
"Statistical Comparison among Brain Networks with Popular Network
  Measurement Algorithms","In this research, a number of popular network measurement algorithms have
been applied to several brain networks (based on applicability of algorithms)
for finding out statistical correlation among these popular network
measurements which will help scientists to understand these popular network
measurement algorithms and their applicability to brain networks. By analysing
the results of correlations among these network measurement algorithms,
statistical comparison among selected brain networks has also been summarized.
Besides that, to understand each brain network, the visualization of each brain
network and each brain network degree distribution histogram have been
extrapolated. Six network measurement algorithms have been chosen to apply time
to time on sixteen brain networks based on applicability of these network
measurement algorithms and the results of these network measurements are put
into a correlation method to show the relationship among these six network
measurement algorithms for each brain network. At the end, the results of the
correlations have been summarized to show the statistical comparison among
these sixteen brain networks.",2022-10-22,Rakib Hassan Pran
"Why Do You Feel This Way? Summarizing Triggers of Emotions in Social
  Media Posts","Crises such as the COVID-19 pandemic continuously threaten our world and
emotionally affect billions of people worldwide in distinct ways. Understanding
the triggers leading to people's emotions is of crucial importance. Social
media posts can be a good source of such analysis, yet these texts tend to be
charged with multiple emotions, with triggers scattering across multiple
sentences. This paper takes a novel angle, namely, emotion detection and
trigger summarization, aiming to both detect perceived emotions in text, and
summarize events and their appraisals that trigger each emotion. To support
this goal, we introduce CovidET (Emotions and their Triggers during Covid-19),
a dataset of ~1,900 English Reddit posts related to COVID-19, which contains
manual annotations of perceived emotions and abstractive summaries of their
triggers described in the post. We develop strong baselines to jointly detect
emotions and summarize emotion triggers. Our analyses show that CovidET
presents new challenges in emotion-specific summarization, as well as
multi-emotion detection in long social media posts.",2022-10-22,"Hongli Zhan, Tiberiu Sosea, Cornelia Caragea, Junyi Jessy Li"
"Spontaneous emergence of groups and signaling diversity in dynamic
  networks","We study the coevolution of network structure and signaling behavior. We
model agents who can preferentially associate with others in a dynamic network
while they also learn to play a simple sender-receiver game. We have four major
findings. First, signaling interactions in dynamic networks are sufficient to
cause the endogenous formation of distinct signaling groups, even in an
initially homogeneous population. Second, dynamic networks allow the emergence
of novel {\em hybrid} signaling groups that do not converge on a single common
signaling system but are instead composed of different yet complementary
signaling strategies. We show that the presence of these hybrid groups promotes
stable diversity in signaling among other groups in the population. Third, we
find important distinctions in information processing capacity of different
groups: hybrid groups diffuse information more quickly initially but at the
cost of taking longer to reach all group members. Fourth, our findings pertain
to all common interest signaling games, are robust across many parameters, and
mitigate known problems of inefficient communication.",2022-10-22,"Zachary Fulker, Patrick Forber, Rory Smead, Christoph Riedl"
GLCC: A General Framework for Graph-Level Clustering,"This paper studies the problem of graph-level clustering, which is a novel
yet challenging task. This problem is critical in a variety of real-world
applications such as protein clustering and genome analysis in bioinformatics.
Recent years have witnessed the success of deep clustering coupled with graph
neural networks (GNNs). However, existing methods focus on clustering among
nodes given a single graph, while exploring clustering on multiple graphs is
still under-explored. In this paper, we propose a general graph-level
clustering framework named Graph-Level Contrastive Clustering (GLCC) given
multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph
to explore instance- and cluster-level contrastive learning (CL).
Instance-level CL leverages graph Laplacian based contrastive loss to learn
clustering-friendly representations while cluster-level CL captures
discriminative cluster representations incorporating neighbor information of
each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the
optimization of representation learning. The two steps can be alternatively
trained to collaborate and benefit each other. Experiments on a range of
well-known datasets demonstrate the superiority of our proposed GLCC over
competitive baselines.",2022-10-21,"Wei Ju, Yiyang Gu, Binqi Chen, Gongbo Sun, Yifang Qin, Xingyuming Liu, Xiao Luo, Ming Zhang"
"DyTed: Disentangled Representation Learning for Discrete-time Dynamic
  Graph","Unsupervised representation learning for dynamic graphs has attracted a lot
of research attention in recent years. Compared with static graph, the dynamic
graph is a comprehensive embodiment of both the intrinsic stable
characteristics of nodes and the time-related dynamic preference. However,
existing methods generally mix these two types of information into a single
representation space, which may lead to poor explanation, less robustness, and
a limited ability when applied to different downstream tasks. To solve the
above problems, in this paper, we propose a novel disenTangled representation
learning framework for discrete-time Dynamic graphs, namely DyTed. We specially
design a temporal-clips contrastive learning task together with a structure
contrastive learning to effectively identify the time-invariant and
time-varying representations respectively. To further enhance the
disentanglement of these two types of representation, we propose a
disentanglement-aware discriminator under an adversarial learning framework
from the perspective of information theory. Extensive experiments on Tencent
and five commonly used public datasets demonstrate that DyTed, as a general
framework that can be applied to existing methods, achieves state-of-the-art
performance on various downstream tasks, as well as be more robust against
noise.",2022-10-19,"Kaike Zhang, Qi Cao, Gaolin Fang, Bingbing Xu, Hongjian Zou, Huawei Shen, Xueqi Cheng"
Dense subgraphs induced by edge labels,"Finding densely connected groups of nodes in networks is a widely used tool
for analysis in graph mining. A popular choice for finding such groups is to
find subgraphs with a high average degree. While useful, interpreting such
subgraphs may be difficult. On the other hand, many real-world networks have
additional information, and we are specifically interested in networks with
labels on edges. In this paper, we study finding sets of labels that induce
dense subgraphs. We consider two notions of density: average degree and the
number of edges minus the number of nodes weighted by a parameter $\alpha$.
There are many ways to induce a subgraph from a set of labels, and we study two
cases: First, we study conjunctive-induced dense subgraphs, where the subgraph
edges need to have all labels. Secondly, we study disjunctive-induced dense
subgraphs, where the subgraph edges need to have at least one label. We show
that both problems are NP-hard. Because of the hardness, we resort to greedy
heuristics. We show that we can implement the greedy search efficiently: the
respective running times for finding conjunctive-induced and
disjunctive-induced dense subgraphs are in $O(p \log k)$ and $O(p \log^2 k)$,
where $p$ is the number of edge-label pairs and $k$ is the number of labels.
Our experimental evaluation demonstrates that we can find the ground truth in
synthetic graphs and that we can find interpretable subgraphs from real-world
networks.",2022-10-19,"Iiro Kumpulainen, Nikolaj Tatti"
Discipline Reputation Evaluation Based on PhD Exchange Network,"When reputation evaluation indicators become targets, existing indicators
will lose the role of indicating the true quality; At present, the evaluation
of discipline reputation mostly focuses on subjective evaluation based on
objective data, and there is a dispute about reliability and validity; Due to
different indicators and weight settings, it is difficult to make horizontal
comparison among disciplines; The evaluation also has a certain time lag. In
order to solve the above four problems, this study explores a new method of
discipline reputation evaluation. Taking the business administration discipline
as an example, it collects data of 5848 doctoral graduates who first entered
teaching posts, establishes a directed adjacency matrix from the employment
unit to the doctoral degree awarding unit, and uses the theory and method of
social network analysis to conduct quantitative analysis on the doctoral mutual
employment network. The results show that: (1) PhD exchange network can explain
discipline reputation and is a new indicator to measure discipline reputation;
(2) From the perspective of employment behavior among colleges and
universities, there is horizontal flow and downward flow between the head
colleges and universities, and downward flow is mainly among the middle and
lower colleges. There is a time lag between college talent recruitment and
academic achievement output. Therefore, the mining of the structural
characteristics and network evolution trend of the PhD exchange network based
on the ""foot voting"" of doctoral graduates is faster than the discipline
ranking based on the follow-up achievement indicators to reflect the changes in
the discipline quality, which can be used to warn the changes in the discipline
quality.",2022-10-18,"Hua Jiang, Shudong Yang, Shuang Li, Shengbo Liu"
"Auditing YouTube's Recommendation Algorithm for Misinformation Filter
  Bubbles","In this paper, we present results of an auditing study performed over YouTube
aimed at investigating how fast a user can get into a misinformation filter
bubble, but also what it takes to ""burst the bubble"", i.e., revert the bubble
enclosure. We employ a sock puppet audit methodology, in which pre-programmed
agents (acting as YouTube users) delve into misinformation filter bubbles by
watching misinformation promoting content. Then they try to burst the bubbles
and reach more balanced recommendations by watching misinformation debunking
content. We record search results, home page results, and recommendations for
the watched videos. Overall, we recorded 17,405 unique videos, out of which we
manually annotated 2,914 for the presence of misinformation. The labeled data
was used to train a machine learning model classifying videos into three
classes (promoting, debunking, neutral) with the accuracy of 0.82. We use the
trained model to classify the remaining videos that would not be feasible to
annotate manually.
  Using both the manually and automatically annotated data, we observe the
misinformation bubble dynamics for a range of audited topics. Our key finding
is that even though filter bubbles do not appear in some situations, when they
do, it is possible to burst them by watching misinformation debunking content
(albeit it manifests differently from topic to topic). We also observe a sudden
decrease of misinformation filter bubble effect when misinformation debunking
videos are watched after misinformation promoting videos, suggesting a strong
contextuality of recommendations. Finally, when comparing our results with a
previous similar study, we do not observe significant improvements in the
overall quantity of recommended misinformation content.",2022-10-18,"Ivan Srba, Robert Moro, Matus Tomlein, Branislav Pecher, Jakub Simko, Elena Stefancova, Michal Kompan, Andrea Hrckova, Juraj Podrouzek, Adrian Gavornik, Maria Bielikova"
"Diverse Misinformation: Impacts of Human Biases on Detection of
  Deepfakes on Networks","Social media platforms often assume that users can self-correct against
misinformation. However, social media users are not equally susceptible to all
misinformation as their biases influence what types of misinformation might
thrive and who might be at risk. We call ""diverse misinformation"" the complex
relationships between human biases and demographics represented in
misinformation. To investigate how users' biases impact their susceptibility
and their ability to correct each other, we analyze classification of deepfakes
as a type of diverse misinformation. We chose deepfakes as a case study for
three reasons: 1) their classification as misinformation is more objective; 2)
we can control the demographics of the personas presented; 3) deepfakes are a
real-world concern with associated harms that must be better understood. Our
paper presents an observational survey (N=2,016) where participants are exposed
to videos and asked questions about their attributes, not knowing some might be
deepfakes. Our analysis investigates the extent to which different users are
duped and which perceived demographics of deepfake personas tend to mislead. We
find that accuracy varies by demographics, and participants are generally
better at classifying videos that match them. We extrapolate from these results
to understand the potential population-level impacts of these biases using a
mathematical model of the interplay between diverse misinformation and crowd
correction. Our model suggests that diverse contacts might provide ""herd
correction"" where friends can protect each other. Altogether, human biases and
the attributes of misinformation matter greatly, but having a diverse social
group may help reduce susceptibility to misinformation.",2022-10-18,"Juniper Lovato, Laurent Hébert-Dufresne, Jonathan St-Onge, Randall Harp, Gabriela Salazar Lopez, Sean P. Rogers, Ijaz Ul Haq, Jeremiah Onaolapo"
Graph Anomaly Detection with Unsupervised GNNs,"Graph-based anomaly detection finds numerous applications in the real-world.
Thus, there exists extensive literature on the topic that has recently shifted
toward deep detection models due to advances in deep learning and graph neural
networks (GNNs). A vast majority of prior work focuses on detecting
node/edge/subgraph anomalies within a single graph, with much less work on
graph-level anomaly detection in a graph database. This work aims to fill two
gaps in the literature: We (1) design GLAM, an end-to-end graph-level anomaly
detection model based on GNNs, and (2) focus on unsupervised model selection,
which is notoriously hard due to lack of any labels, yet especially critical
for deep NN based models with a long list of hyper-parameters. Further, we
propose a new pooling strategy for graph-level embedding, called MMD-pooling,
that is geared toward detecting distribution anomalies which has not been
considered before. Through extensive experiments on 15 real-world datasets, we
show that (i) GLAM outperforms node-level and two-stage (i.e. not end-to-end)
baselines, and (ii) model selection picks a significantly more effective model
than expectation (i.e. average) -- without using any labels -- among candidates
with otherwise large variation in performance.",2022-10-18,"Lingxiao Zhao, Saurabh Sawlani, Arvind Srinivasan, Leman Akoglu"
"Implicit models, latent compression, intrinsic biases, and cheap lunches
  in community detection","The task of community detection, which aims to partition a network into
clusters of nodes to summarize its large-scale structure, has spawned the
development of many competing algorithms with varying objectives. Some
community detection methods are inferential, explicitly deriving the clustering
objective through a probabilistic generative model, while other methods are
descriptive, dividing a network according to an objective motivated by a
particular application, making it challenging to compare these methods on the
same scale. Here we present a solution to this problem that associates any
community detection objective, inferential or descriptive, with its
corresponding implicit network generative model. This allows us to compute the
description length of a network and its partition under arbitrary objectives,
providing a principled measure to compare the performance of different
algorithms without the need for ""ground truth"" labels. Our approach also gives
access to instances of the community detection problem that are optimal to any
given algorithm, and in this way reveals intrinsic biases in popular
descriptive methods, explaining their tendency to overfit. Using our framework,
we compare a number of community detection methods on artificial networks, and
on a corpus of over 500 structurally diverse empirical networks. We find that
more expressive community detection methods exhibit consistently superior
compression performance on structured data instances, without having degraded
performance on a minority of situations where more specialized algorithms
perform optimally. Our results undermine the implications of the ""no free
lunch"" theorem for community detection, both conceptually and in practice,
since it is confined to unstructured data instances, unlike relevant community
detection problems which are structured by requirement.",2022-10-17,"Tiago P. Peixoto, Alec Kirkley"
"CS-MLGCN : Multiplex Graph Convolutional Networks for Community Search
  in Multiplex Networks","Community Search (CS) is one of the fundamental tasks in network science and
has attracted much attention due to its ability to discover personalized
communities with a wide range of applications. Given any query nodes, CS seeks
to find a densely connected subgraph containing query nodes. Most existing
approaches usually study networks with a single type of proximity between
nodes, which defines a single view of a network. However, in many applications
such as biological, social, and transportation networks, interactions between
objects span multiple aspects, yielding networks with multiple views, called
multiplex networks. Existing CS approaches in multiplex networks adopt
pre-defined subgraph patterns to model the communities, which cannot find
communities that do not have such pre-defined patterns in real-world networks.
In this paper, we propose a query-driven graph convolutional network in
multiplex networks, CS-MLGCN, that can capture flexible community structures by
learning from the ground-truth communities in a data-driven fashion. CS-MLGCN
first combines the local query-dependent structure and global graph embedding
in each type of proximity and then uses an attention mechanism to incorporate
information on different types of relations. Experiments on real-world graphs
with ground-truth communities validate the quality of the solutions we obtain
and the efficiency of our model.",2022-10-17,"Ali Behrouz, Farnoosh Hashemi"
"Exposing Influence Campaigns in the Age of LLMs: A Behavioral-Based AI
  Approach to Detecting State-Sponsored Trolls","The detection of state-sponsored trolls operating in influence campaigns on
social media is a critical and unsolved challenge for the research community,
which has significant implications beyond the online realm. To address this
challenge, we propose a new AI-based solution that identifies troll accounts
solely through behavioral cues associated with their sequences of sharing
activity, encompassing both their actions and the feedback they receive from
others. Our approach does not incorporate any textual content shared and
consists of two steps: First, we leverage an LSTM-based classifier to determine
whether account sequences belong to a state-sponsored troll or an organic,
legitimate user. Second, we employ the classified sequences to calculate a
metric named the ""Troll Score"", quantifying the degree to which an account
exhibits troll-like behavior. To assess the effectiveness of our method, we
examine its performance in the context of the 2016 Russian interference
campaign during the U.S. Presidential election. Our experiments yield
compelling results, demonstrating that our approach can identify account
sequences with an AUC close to 99% and accurately differentiate between Russian
trolls and organic users with an AUC of 91%. Notably, our behavioral-based
approach holds a significant advantage in the ever-evolving landscape, where
textual and linguistic properties can be easily mimicked by Large Language
Models (LLMs): In contrast to existing language-based techniques, it relies on
more challenging-to-replicate behavioral cues, ensuring greater resilience in
identifying influence campaigns, especially given the potential increase in the
usage of LLMs for generating inauthentic content. Finally, we assessed the
generalizability of our solution to various entities driving different
information operations and found promising results that will guide future
research.",2022-10-17,"Fatima Ezzeddine, Luca Luceri, Omran Ayoub, Ihab Sbeity, Gianluca Nogara, Emilio Ferrara, Silvia Giordano"
"Temporal Link Prediction: A Unified Framework, Taxonomy, and Review","Dynamic graphs serve as a generic abstraction and description of the
evolutionary behaviors of various complex systems (e.g., social networks and
communication networks). Temporal link prediction (TLP) is a classic yet
challenging inference task on dynamic graphs, which predicts possible future
linkage based on historical topology. The predicted future topology can be used
to support some advanced applications on real-world systems (e.g., resource
pre-allocation) for better system performance. This survey provides a
comprehensive review of existing TLP methods. Concretely, we first give the
formal problem statements and preliminaries regarding data models, task
settings, and learning paradigms that are commonly used in related research. A
hierarchical fine-grained taxonomy is further introduced to categorize existing
methods in terms of their data models, learning paradigms, and techniques. From
a generic perspective, we propose a unified encoder-decoder framework to
formulate all the methods reviewed, where different approaches only differ in
terms of some components of the framework. Moreover, we envision serving the
community with an open-source project OpenTLP that refactors or implements some
representative TLP methods using the proposed unified framework and summarizes
other public resources. As a conclusion, we finally discuss advanced topics in
recent research and highlight possible future directions.",2022-10-17,"Meng Qin, Dit-Yan Yeung"
CLARE: A Semi-supervised Community Detection Algorithm,"Community detection refers to the task of discovering closely related
subgraphs to understand the networks. However, traditional community detection
algorithms fail to pinpoint a particular kind of community. This limits its
applicability in real-world networks, e.g., distinguishing fraud groups from
normal ones in transaction networks. Recently, semi-supervised community
detection emerges as a solution. It aims to seek other similar communities in
the network with few labeled communities as training data. Existing works can
be regarded as seed-based: locate seed nodes and then develop communities
around seeds. However, these methods are quite sensitive to the quality of
selected seeds since communities generated around a mis-detected seed may be
irrelevant. Besides, they have individual issues, e.g., inflexibility and high
computational overhead. To address these issues, we propose CLARE, which
consists of two key components, Community Locator and Community Rewriter. Our
idea is that we can locate potential communities and then refine them.
Therefore, the community locator is proposed for quickly locating potential
communities by seeking subgraphs that are similar to training ones in the
network. To further adjust these located communities, we devise the community
rewriter. Enhanced by deep reinforcement learning, it suggests intelligent
decisions, such as adding or dropping nodes, to refine community structures
flexibly. Extensive experiments verify both the effectiveness and efficiency of
our work compared with prior state-of-the-art approaches on multiple real-world
datasets.",2022-10-15,"Xixi Wu, Yun Xiong, Yao Zhang, Yizhu Jiao, Caihua Shan, Yiheng Sun, Yangyong Zhu, Philip S. Yu"
Old can be Gold: Better Gradient Flow can Make Vanilla-GCNs Great Again,"Despite the enormous success of Graph Convolutional Networks (GCNs) in
modeling graph-structured data, most of the current GCNs are shallow due to the
notoriously challenging problems of over-smoothening and information squashing
along with conventional difficulty caused by vanishing gradients and
over-fitting. Previous works have been primarily focused on the study of
over-smoothening and over-squashing phenomena in training deep GCNs.
Surprisingly, in comparison with CNNs/RNNs, very limited attention has been
given to understanding how healthy gradient flow can benefit the trainability
of deep GCNs. In this paper, firstly, we provide a new perspective of gradient
flow to understand the substandard performance of deep GCNs and hypothesize
that by facilitating healthy gradient flow, we can significantly improve their
trainability, as well as achieve state-of-the-art (SOTA) level performance from
vanilla-GCNs. Next, we argue that blindly adopting the Glorot initialization
for GCNs is not optimal, and derive a topology-aware isometric initialization
scheme for vanilla-GCNs based on the principles of isometry. Additionally,
contrary to ad-hoc addition of skip-connections, we propose to use
gradient-guided dynamic rewiring of vanilla-GCNs} with skip connections. Our
dynamic rewiring method uses the gradient flow within each layer during
training to introduce on-demand skip-connections adaptively. We provide
extensive empirical evidence across multiple datasets that our methods improve
gradient flow in deep vanilla-GCNs and significantly boost their performance to
comfortably compete and outperform many fancy state-of-the-art methods. Codes
are available at: https://github.com/VITA-Group/GradientGCN.",2022-10-14,"Ajay Jaiswal, Peihao Wang, Tianlong Chen, Justin F. Rousseau, Ying Ding, Zhangyang Wang"
Empirical Network Structure of Malicious Programs,"A modern binary executable is a composition of various networks. Control flow
graphs are commonly used to represent an executable program in labeled datasets
used for classification tasks. Control flow and term representations are widely
adopted, but provide only a partial view of program semantics. This study is an
empirical analysis of the networks composing malicious binaries in order to
provide a complete representation of the structural properties of a program.
This is accomplished by the measurement of structural properties of program
networks in a malicious binary executable dataset. We demonstrate the presence
of Scale-Free properties of network structure for program data dependency and
control flow graphs, and show that data dependency graphs also have Small-World
structural properties. We show that program data dependency graphs have a
degree correlation that is structurally disassortative, and that control flow
graphs have a neutral degree assortativity, indicating the use of random graphs
to model the structural properties of program control flow graphs would show
increased accuracy. By providing an increase in feature resolution within
labeled datasets of executable programs we provide a quantitative basis to
interpret the results of classifiers trained on CFG graph features. An increase
in feature resolution allows for the structural properties of program classes
to be analyzed for patterns as well as their component parts. By capturing a
complete picture of program graphs we can enable theoretical solutions for the
mapping a program's operational semantics to its structure.",2022-10-14,"John Musgrave, Alina Campan, Temesguen Messay-Kebede, David Kapp, Anca Ralescu"
"Gender Animus Can Still Exist Under Favorable Disparate Impact: a
  Cautionary Tale from Online P2P Lending","This paper investigates gender discrimination and its underlying drivers on a
prominent Chinese online peer-to-peer (P2P) lending platform. While existing
studies on P2P lending focus on disparate treatment (DT), DT narrowly
recognizes direct discrimination and overlooks indirect and proxy
discrimination, providing an incomplete picture. In this work, we measure a
broadened discrimination notion called disparate impact (DI), which encompasses
any disparity in the loan's funding rate that does not commensurate with the
actual return rate. We develop a two-stage predictor substitution approach to
estimate DI from observational data. Our findings reveal (i) female borrowers,
given identical actual return rates, are 3.97% more likely to receive funding,
(ii) at least 37.1% of this DI favoring female is indirect or proxy
discrimination, and (iii) DT indeed underestimates the overall female
favoritism by 44.6%. However, we also identify the overall female favoritism
can be explained by one specific discrimination driver, rational statistical
discrimination, wherein investors accurately predict the expected return rate
from imperfect observations. Furthermore, female borrowers still require 2%
higher expected return rate to secure funding, indicating another driver
taste-based discrimination co-exists and is against female. These results
altogether tell a cautionary tale: on one hand, P2P lending provides a valuable
alternative credit market where the affirmative action to support female
naturally emerges from the rational crowd; on the other hand, while the overall
discrimination effect (both in terms of DI or DT) favors female, concerning
taste-based discrimination can persist and can be obscured by other co-existing
discrimination drivers, such as statistical discrimination.",2022-10-14,"Xudong Shen, Tianhui Tan, Tuan Q. Phan, Jussi Keppo"
Revisiting Heterophily For Graph Neural Networks,"Graph Neural Networks (GNNs) extend basic Neural Networks (NNs) by using
graph structures based on the relational inductive bias (homophily assumption).
While GNNs have been commonly believed to outperform NNs in real-world tasks,
recent work has identified a non-trivial set of datasets where their
performance compared to NNs is not satisfactory. Heterophily has been
considered the main cause of this empirical observation and numerous works have
been put forward to address it. In this paper, we first revisit the widely used
homophily metrics and point out that their consideration of only graph-label
consistency is a shortcoming. Then, we study heterophily from the perspective
of post-aggregation node similarity and define new homophily metrics, which are
potentially advantageous compared to existing ones. Based on this
investigation, we prove that some harmful cases of heterophily can be
effectively addressed by local diversification operation. Then, we propose the
Adaptive Channel Mixing (ACM), a framework to adaptively exploit aggregation,
diversification and identity channels node-wisely to extract richer localized
information for diverse node heterophily situations. ACM is more powerful than
the commonly used uni-channel framework for node classification tasks on
heterophilic graphs and is easy to be implemented in baseline GNN layers. When
evaluated on 10 benchmark node classification tasks, ACM-augmented baselines
consistently achieve significant performance gain, exceeding state-of-the-art
GNNs on most tasks without incurring significant computational burden.",2022-10-14,"Sitao Luan, Chenqing Hua, Qincheng Lu, Jiaqi Zhu, Mingde Zhao, Shuyuan Zhang, Xiao-Wen Chang, Doina Precup"
"ToupleGDD: A Fine-Designed Solution of Influence Maximization by Deep
  Reinforcement Learning","Aiming at selecting a small subset of nodes with maximum influence on
networks, the Influence Maximization (IM) problem has been extensively studied.
Since it is #P-hard to compute the influence spread given a seed set, the
state-of-the-art methods, including heuristic and approximation algorithms,
faced with great difficulties such as theoretical guarantee, time efficiency,
generalization, etc. This makes it unable to adapt to large-scale networks and
more complex applications. On the other side, with the latest achievements of
Deep Reinforcement Learning (DRL) in artificial intelligence and other fields,
lots of works have been focused on exploiting DRL to solve combinatorial
optimization problems. Inspired by this, we propose a novel end-to-end DRL
framework, ToupleGDD, to address the IM problem in this paper, which
incorporates three coupled graph neural networks for network embedding and
double deep Q-networks for parameters learning. Previous efforts to solve IM
problem with DRL trained their models on subgraphs of the whole network, and
then tested on the whole graph, which makes the performance of their models
unstable among different networks. However, our model is trained on several
small randomly generated graphs with a small budget, and tested on completely
different networks under various large budgets, which can obtain results very
close to IMM and better results than OPIM-C on several datasets, and shows
strong generalization ability. Finally, we conduct a large number of
experiments on synthetic and realistic datasets, and experimental results prove
the effectiveness and superiority of our model.",2022-10-14,"Tiantian Chen, Siwen Yan, Jianxiong Guo, Weili Wu"
G2A2: An Automated Graph Generator with Attributes and Anomalies,"Many data-mining applications use dynamic attributed graphs to represent
relational information; but due to security and privacy concerns, there is a
dearth of available datasets that can be represented as dynamic attributed
graphs. Even when such datasets are available, they do not have ground truth
that can be used to train deep-learning models. Thus, we present G2A2, an
automated graph generator with attributes and anomalies, which encompasses (1)
probabilistic models to generate a dynamic bipartite graph, representing
time-evolving connections between two independent sets of entities, (2)
realistic injection of anomalies using a novel algorithm that captures the
general properties of graph anomalies across domains, and (3) a deep generative
model to produce realistic attributes, learned from an existing real-world
dataset. Using the maximum mean discrepancy (MMD) metric to evaluate the
realism of a G2A2-generated graph against three real-world graphs, G2A2
outperforms Kronecker graph generation by reducing the MMD distance by up to
six-fold (6x).",2022-10-14,"Saikat Dey, Sonal Jha, Wu-chun Feng"
Human mobility networks reveal increased segregation in large cities,"A long-standing expectation is that large, dense, and cosmopolitan areas
support socioeconomic mixing and exposure between diverse individuals. It has
been difficult to assess this hypothesis because past approaches to measuring
socioeconomic mixing have relied on static residential housing data rather than
real-life exposures between people at work, in places of leisure, and in home
neighborhoods. Here we develop a new measure of exposure segregation (ES) that
captures the socioeconomic diversity of everyday encounters. Leveraging cell
phone mobility data to represent 1.6 billion exposures among 9.6 million people
in the United States, we measure exposure segregation across 382 Metropolitan
Statistical Areas (MSAs) and 2829 counties. We discover that exposure
segregation is 67% higher in the 10 largest Metropolitan Statistical Areas
(MSAs) than in small MSAs with fewer than 100,000 residents. This means that,
contrary to expectation, residents of large cosmopolitan areas have
significantly less exposure to diverse individuals. Second, we find evidence
that large cities offer a greater choice of differentiated spaces targeted to
specific socioeconomic groups, a dynamic that accounts for this increase in
everyday socioeconomic segregation. Third, we discover that this
segregation-increasing effect is countered when a city's hubs (e.g. shopping
malls) are positioned to bridge diverse neighborhoods and thus attract people
of all socioeconomic statuses. Overall, our findings challenge a long-standing
conjecture in human geography and urban design, and highlight how built
environment can both prevent and facilitate exposure between diverse
individuals.",2022-10-13,"Hamed Nilforoshan, Wenli Looi, Emma Pierson, Blanca Villanueva, Nic Fishman, Yiling Chen, John Sholar, Beth Redbird, David Grusky, Jure Leskovec"
Neighborhood Structure Configuration Models,"We develop a new method to efficiently sample synthetic networks that
preserve the d-hop neighborhood structure of a given network for any given d.
The proposed algorithm trades off the diversity in network samples against the
depth of the neighborhood structure that is preserved. Our key innovation is to
employ a colored Configuration Model with colors derived from iterations of the
so-called Color Refinement algorithm. We prove that with increasing iterations
the preserved structural information increases: the generated synthetic
networks and the original network become more and more similar, and are
eventually indistinguishable in terms of centrality measures such as PageRank,
HITS, Katz centrality and eigenvector centrality. Our work enables to
efficiently generate samples with a precisely controlled similarity to the
original network, especially for large networks.",2022-10-13,"Felix I. Stamm, Michael Scholkemper, Markus Strohmaier, Michael T. Schaub"
"Detecting Propagators of Disinformation on Twitter Using Quantitative
  Discursive Analysis","Efforts by foreign actors to influence public opinion have gained
considerable attention because of their potential to impact democratic
elections. Thus, the ability to identify and counter sources of disinformation
is increasingly becoming a top priority for government entities in order to
protect the integrity of democratic processes. This study presents a method of
identifying Russian disinformation bots on Twitter using centering resonance
analysis and Clauset-Newman-Moore community detection. The data reflect a
significant degree of discursive dissimilarity between known Russian
disinformation bots and a control set of Twitter users during the timeframe of
the 2016 U.S. Presidential Election. The data also demonstrate statistically
significant classification capabilities (MCC = 0.9070) based on community
clustering. The prediction algorithm is very effective at identifying true
positives (bots), but is not able to resolve true negatives (non-bots) because
of the lack of discursive similarity between control users. This leads to a
highly sensitive means of identifying propagators of disinformation with a high
degree of discursive similarity on Twitter, with implications for limiting the
spread of disinformation that could impact democratic processes.",2022-10-11,Mark M. Bailey
"Reciprocity in Directed Hypergraphs: Measures, Findings, and Generators","Group interactions are prevalent in a variety of areas. Many of them,
including email exchanges, chemical reactions, and bitcoin transactions, are
directional, and thus they are naturally modeled as directed hypergraphs, where
each hyperarc consists of the set of source nodes and the set of destination
nodes. For directed graphs, which are a special case of directed hypergraphs,
reciprocity has played a key role as a fundamental graph statistic in revealing
organizing principles of graphs and in solving graph learning tasks. For
general directed hypergraphs, however, even no systematic measure of
reciprocity has been developed. In this work, we investigate the reciprocity of
11 real-world hypergraphs. To this end, we first introduce eight axioms that
any reasonable measure of reciprocity should satisfy. Second, we propose
HyperRec, a family of principled measures of hypergraph reciprocity that
satisfies all the axioms. Third, we develop Ferret, a fast and exact algorithm
for computing the measure, whose search space is up to 10^{147}x smaller than
that of naive computation. Fourth, using them, we examine 11 real-world
hypergraphs and discover patterns that distinguish them from random
hypergraphs. Lastly, we propose ReDi, an intuitive generative model for
directed hypergraphs exhibiting the patterns.",2022-10-11,"Sunwoo Kim, Minyoung Choe, Jaemin Yoo, Kijung Shin"
Spreading Processes with Mutations over Multi-layer Networks,"A key scientific challenge during the outbreak of novel infectious diseases
is to predict how the course of the epidemic changes under different
countermeasures that limit interaction in the population. Most epidemiological
models do not consider the role of mutations and heterogeneity in the type of
contact events. However, pathogens have the capacity to mutate in response to
changing environments, especially caused by the increase in population immunity
to existing strains and the emergence of new pathogen strains poses a continued
threat to public health. Further, in light of differing transmission risks in
different congregate settings (e.g., schools and offices), different mitigation
strategies may need to be adopted to control the spread of infection. We
analyze a multi-layer multi-strain model by simultaneously accounting for i)
pathways for mutations in the pathogen leading to the emergence of new pathogen
strains, and ii) differing transmission risks in different congregate settings,
modeled as network-layers. Assuming complete cross-immunity among strains,
namely, recovery from any infection prevents infection with any other (an
assumption that will need to be relaxed to deal with COVID-19 or influenza), we
derive the key epidemiological parameters for the proposed multi-layer
multi-strain framework. We demonstrate that reductions to existing
network-based models that discount heterogeneity in either the strain or the
network layers can lead to incorrect predictions for the course of the
outbreak. In addition, our results highlight that the impact of
imposing/lifting mitigation measures concerning different contact network
layers (e.g., school closures or work-from-home policies) should be evaluated
in connection with their effect on the likelihood of the emergence of new
pathogen strains.",2022-10-10,"Mansi Sood, Anirudh Sridhar, Rashad Eletreby, Chai Wah Wu, Simon A. Levin, H. Vincent Poor, Osman Yagan"
CrowdChecked: Detecting Previously Fact-Checked Claims in Social Media,"While there has been substantial progress in developing systems to automate
fact-checking, they still lack credibility in the eyes of the users. Thus, an
interesting approach has emerged: to perform automatic fact-checking by
verifying whether an input claim has been previously fact-checked by
professional fact-checkers and to return back an article that explains their
decision. This is a sensible approach as people trust manual fact-checking, and
as many claims are repeated multiple times. Yet, a major issue when building
such systems is the small number of known tweet--verifying article pairs
available for training. Here, we aim to bridge this gap by making use of crowd
fact-checking, i.e., mining claims in social media for which users have
responded with a link to a fact-checking article. In particular, we mine a
large-scale collection of 330,000 tweets paired with a corresponding
fact-checking article. We further propose an end-to-end framework to learn from
this noisy data based on modified self-adaptive training, in a distant
supervision scenario. Our experiments on the CLEF'21 CheckThat! test set show
improvements over the state of the art by two points absolute. Our code and
datasets are available at https://github.com/mhardalov/crowdchecked-claims",2022-10-10,"Momchil Hardalov, Anton Chernyavskiy, Ivan Koychev, Dmitry Ilvovsky, Preslav Nakov"
"Measuring Network Resilience via Geospatial Knowledge Graph: a Case
  Study of the US Multi-Commodity Flow Network","Quantifying the resilience in the food system is important for food security
issues. In this work, we present a geospatial knowledge graph (GeoKG)-based
method for measuring the resilience of a multi-commodity flow network.
Specifically, we develop a CFS-GeoKG ontology to describe geospatial semantics
of a multi-commodity flow network comprehensively, and design resilience
metrics that measure the node-level and network-level dependence of
single-sourcing, distant, or non-adjacent suppliers/customers in food supply
chains. We conduct a case study of the US state-level agricultural
multi-commodity flow network with hierarchical commodity types. The results
indicate that, by leveraging GeoKG, our method supports measuring both
node-level and network-level resilience across space and over time and also
helps discover concentration patterns of agricultural resources in the spatial
network at different geographic scales.",2022-10-09,"Jinmeng Rao, Song Gao, Michelle Miller, Alfonso Morales"
"Less is More: SlimG for Accurate, Robust, and Interpretable Graph Mining","How can we solve semi-supervised node classification in various graphs
possibly with noisy features and structures? Graph neural networks (GNNs) have
succeeded in many graph mining tasks, but their generalizability to various
graph scenarios is limited due to the difficulty of training, hyperparameter
tuning, and the selection of a model itself. Einstein said that we should ""make
everything as simple as possible, but not simpler."" We rephrase it into the
careful simplicity principle: a carefully-designed simple model can surpass
sophisticated ones in real-world graphs. Based on the principle, we propose
SlimG for semi-supervised node classification, which exhibits four desirable
properties: It is (a) accurate, winning or tying on 10 out of 13 real-world
datasets; (b) robust, being the only one that handles all scenarios of graph
data (homophily, heterophily, random structure, noisy features, etc.); (c) fast
and scalable, showing up to 18 times faster training in million-scale graphs;
and (d) interpretable, thanks to the linearity and sparsity. We explain the
success of SlimG through a systematic study of the designs of existing GNNs,
sanity checks, and comprehensive ablation studies.",2022-10-08,"Jaemin Yoo, Meng-Chieh Lee, Shubhranshu Shekhar, Christos Faloutsos"
Kernel-based Substructure Exploration for Next POI Recommendation,"Point-of-Interest (POI) recommendation, which benefits from the proliferation
of GPS-enabled devices and location-based social networks (LBSNs), plays an
increasingly important role in recommender systems. It aims to provide users
with the convenience to discover their interested places to visit based on
previous visits and current status. Most existing methods usually merely
leverage recurrent neural networks (RNNs) to explore sequential influences for
recommendation. Despite the effectiveness, these methods not only neglect
topological geographical influences among POIs, but also fail to model
high-order sequential substructures. To tackle the above issues, we propose a
Kernel-Based Graph Neural Network (KBGNN) for next POI recommendation, which
combines the characteristics of both geographical and sequential influences in
a collaborative way. KBGNN consists of a geographical module and a sequential
module. On the one hand, we construct a geographical graph and leverage a
message passing neural network to capture the topological geographical
influences. On the other hand, we explore high-order sequential substructures
in the user-aware sequential graph using a graph kernel neural network to
capture user preferences. Finally, a consistency learning framework is
introduced to jointly incorporate geographical and sequential information
extracted from two separate graphs. In this way, the two modules effectively
exchange knowledge to mutually enhance each other. Extensive experiments
conducted on two real-world LBSN datasets demonstrate the superior performance
of our proposed method over the state-of-the-arts. Our codes are available at
https://github.com/Fang6ang/KBGNN.",2022-10-08,"Wei Ju, Yifang Qin, Ziyue Qiao, Xiao Luo, Yifan Wang, Yanjie Fu, Ming Zhang"
"CommsVAE: Learning the brain's macroscale communication dynamics using
  coupled sequential VAEs","Communication within or between complex systems is commonplace in the natural
sciences and fields such as graph neural networks. The brain is a perfect
example of such a complex system, where communication between brain regions is
constantly being orchestrated. To analyze communication, the brain is often
split up into anatomical regions that each perform certain computations. These
regions must interact and communicate with each other to perform tasks and
support higher-level cognition. On a macroscale, these regions communicate
through signal propagation along the cortex and along white matter tracts over
longer distances. When and what types of signals are communicated over time is
an unsolved problem and is often studied using either functional or structural
data. In this paper, we propose a non-linear generative approach to
communication from functional data. We address three issues with common
connectivity approaches by explicitly modeling the directionality of
communication, finding communication at each timestep, and encouraging
sparsity. To evaluate our model, we simulate temporal data that has sparse
communication between nodes embedded in it and show that our model can uncover
the expected communication dynamics. Subsequently, we apply our model to
temporal neural data from multiple tasks and show that our approach models
communication that is more specific to each task. The specificity of our method
means it can have an impact on the understanding of psychiatric disorders,
which are believed to be related to highly specific communication between brain
regions compared to controls. In sum, we propose a general model for dynamic
communication learning on graphs, and show its applicability to a subfield of
the natural sciences, with potential widespread scientific impact.",2022-10-07,"Eloy Geenjaar, Noah Lewis, Amrit Kashyap, Robyn Miller, Vince Calhoun"
The Power of Small Coalitions under Two-Tier Majority on Regular Graphs,"In this paper, we study the following problem. Consider a setting where a
proposal is offered to the vertices of a given network $G$, and the vertices
must conduct a vote and decide whether to accept the proposal or reject it.
Each vertex $v$ has its own valuation of the proposal; we say that $v$ is
``happy'' if its valuation is positive (i.e., it expects to gain from adopting
the proposal) and ``sad'' if its valuation is negative. However, vertices do
not base their vote merely on their own valuation. Rather, a vertex $v$ is a
\emph{proponent} of the proposal if the majority of its neighbors are happy
with it and an \emph{opponent} in the opposite case. At the end of the vote,
the network collectively accepts the proposal whenever the majority of its
vertices are proponents. We study this problem for regular graphs with loops.
Specifically, we consider the class $\mathcal{G}_{n|d|h}$ of $d$-regular graphs
of odd order $n$ with all $n$ loops and $h$ happy vertices. We are interested
in establishing necessary and sufficient conditions for the class
$\mathcal{G}_{n|d|h}$ to contain a labeled graph accepting the proposal, as
well as conditions to contain a graph rejecting the proposal. We also discuss
connections to the existing literature, including that on majority domination,
and investigate the properties of the obtained conditions.",2022-10-07,"Pavel Chebotarev, David Peleg"
Set2Box: Similarity Preserving Representation Learning of Sets,"Sets have been used for modeling various types of objects (e.g., a document
as the set of keywords in it and a customer as the set of the items that she
has purchased). Measuring similarity (e.g., Jaccard Index) between sets has
been a key building block of a wide range of applications, including,
plagiarism detection, recommendation, and graph compression. However, as sets
have grown in numbers and sizes, the computational cost and storage required
for set similarity computation have become substantial, and this has led to the
development of hashing and sketching based solutions. In this work, we propose
Set2Box, a learning-based approach for compressed representations of sets from
which various similarity measures can be estimated accurately in constant time.
The key idea is to represent sets as boxes to precisely capture overlaps of
sets. Additionally, based on the proposed box quantization scheme, we design
Set2Box+, which yields more concise but more accurate box representations of
sets. Through extensive experiments on 8 real-world datasets, we show that,
compared to baseline approaches, Set2Box+ is (a) Accurate: achieving up to
40.8X smaller estimation error while requiring 60% fewer bits to encode sets,
(b) Concise: yielding up to 96.8X more concise representations with similar
estimation error, and (c) Versatile: enabling the estimation of four
set-similarity measures from a single representation of each set.",2022-10-07,"Geon Lee, Chanyoung Park, Kijung Shin"
"Community as a Vague Operator: Epistemological Questions for a Critical
  Heuristics of Community Detection Algorithms","In this article, we aim to analyse the nature and epistemic consequences of
what figures in network science as patterns of nodes and edges called
'communities'. Tracing these patterns as multi-faceted and ambivalent, we
propose to describe the concept of community as a 'vague operator', a variant
of Susan Leigh Star's notion of the boundary object, and propose that the
ability to construct different modes of description that are both vague in some
registers and hyper-precise in others, is core both to digital politics and the
analysis of 'communities'. Engaging with these formations in terms drawn from
mathematics and software studies enables a wider mapping of their formation.
Disentangling different lineages in network science then allows us to
contextualise the founding account of 'community' popularised by Michelle
Girvan and Mark Newman in 2002. After studying one particular community
detection algorithm, the widely-used 'Louvain algorithm', we comment on
controversies arising with some of their more ambiguous applications. We argue
that 'community' can act as a real abstraction with the power to reshape social
relations such as producing echo chambers in social networking sites. To rework
the epistemological terms of community detection and propose a reconsideration
of vague operators, we draw on debates and propositions within the literature
of network science to imagine a 'critical heuristics' that embraces partiality,
epistemic humbleness, reflexivity and artificiality.",2022-10-06,"Dominik J. Schindler, Matthew Fuller"
"Addressing contingency in algorithmic (mis)information classification:
  Toward a responsible machine learning agenda","Machine learning (ML) enabled classification models are becoming increasingly
popular for tackling the sheer volume and speed of online misinformation and
other content that could be identified as harmful. In building these models,
data scientists need to take a stance on the legitimacy, authoritativeness and
objectivity of the sources of ``truth"" used for model training and testing.
This has political, ethical and epistemic implications which are rarely
addressed in technical papers. Despite (and due to) their reported high
accuracy and performance, ML-driven moderation systems have the potential to
shape online public debate and create downstream negative impacts such as undue
censorship and the reinforcing of false beliefs. Using collaborative
ethnography and theoretical insights from social studies of science and
expertise, we offer a critical analysis of the process of building ML models
for (mis)information classification: we identify a series of algorithmic
contingencies--key moments during model development that could lead to
different future outcomes, uncertainty and harmful effects as these tools are
deployed by social media platforms. We conclude by offering a tentative path
toward reflexive and responsible development of ML tools for moderating
misinformation and other harmful content online.",2022-10-05,"Andrés Domínguez Hernández, Richard Owen, Dan Saattrup Nielsen, Ryan McConville"
Social Balance on Networks: Local Minima and Best Edge Dynamics,"Structural balance theory is an established framework for studying social
relationships of friendship and enmity. These relationships are modeled by a
signed network whose energy potential measures the level of imbalance, while
stochastic dynamics drives the network towards a state of minimum energy that
captures social balance. It is known that this energy landscape has local
minima that can trap socially-aware dynamics, preventing it from reaching
balance. Here we first study the robustness and attractor properties of these
local minima. We show that a stochastic process can reach them from an
abundance of initial states, and that some local minima cannot be escaped by
mild perturbations of the network. Motivated by these anomalies, we introduce
Best Edge Dynamics (BED), a new plausible stochastic process. We prove that BED
always reaches balance, and that it does so fast in various interesting
settings.",2022-10-05,"Krishnendu Chatterjee, Jakub Svoboda, Ðorđe Žikelić, Andreas Pavlogiannis, Josef Tkadlec"
A Reputation System for Market Security and Equity,"We simulate a reputation system in a market to optimise the balance between
market security and market equity. We introduce a method of using a reputation
system that will stabilise the distribution of wealth in a market in a fair
manner. We also introduce metrics of a modified Gini that takes production
quality into account, a way to use a weighted Pearson as a tool to optimise
balance.",2022-10-05,"Anton Kolonin, Deborah Duong, Ben Goertzel, Cassio Pennachin, Matt Iklé, Nejc Znidar, Marco Argentieri"
"IGNiteR: News Recommendation in Microblogging Applications (Extended
  Version)","News recommendation is one of the most challenging tasks in recommender
systems, mainly due to the ephemeral relevance of news to users. As social
media, and particularly microblogging applications like Twitter or Weibo, gains
popularity as platforms for news dissemination, personalized news
recommendation in this context becomes a significant challenge. We revisit news
recommendation in the microblogging scenario, by taking into consideration
social interactions and observations tracing how the information that is up for
recommendation spreads in an underlying network. We propose a deep-learning
based approach that is diffusion and influence-aware, called Influence-Graph
News Recommender (IGNiteR). It is a content-based deep recommendation model
that jointly exploits all the data facets that may impact adoption decisions,
namely semantics, diffusion-related features pertaining to local and global
influence among users, temporal attractiveness, and timeliness, as well as
dynamic user preferences. To represent the news, a multi-level attention-based
encoder is used to reveal the different interests of users. This news encoder
relies on a CNN for the news content and on an attentive LSTM for the diffusion
traces. For the latter, by exploiting previously observed news diffusions
(cascades) in the microblogging medium, users are mapped to a latent space that
captures potential influence on others or susceptibility of being influenced
for news adoptions. Similarly, a time-sensitive user encoder enables us to
capture the dynamic preferences of users with an attention-based bidirectional
LSTM. We perform extensive experiments on two real-world datasets, showing that
IGNiteR outperforms the state-of-the-art deep-learning based news
recommendation methods.",2022-10-04,"Yuting Feng, Bogdan Cautis"
"Building a healthier feed: Private location trace intersection driven
  feed recommendations","The physical environment you navigate strongly determines which communities
and people matter most to individuals. These effects drive both personal access
to opportunities and the social capital of communities, and can often be
observed in the personal mobility traces of individuals. Traditional social
media feeds underutilize these mobility-based features, or do so in a privacy
exploitative manner. Here we propose a consent-first private information
sharing paradigm for driving social feeds from users' personal private data,
specifically using mobility traces. This approach designs the feed to
explicitly optimize for integrating the user into the local community and for
social capital building through leveraging mobility trace overlaps as a proxy
for existing or potential real-world social connections, creating
proportionality between whom a user sees in their feed, and whom the user is
likely to see in person. These claims are validated against existing
social-mobility data, and a reference implementation of the proposed algorithm
is built for demonstration. In total, this work presents a novel technique for
designing feeds that represent real offline social connections through private
set intersections requiring no third party, or public data exposure.",2022-10-04,"Tobin South, Nick Lothian, Alex ""Sandy"" Pentland"
When Infodemic Meets Epidemic: a Systematic Literature Review,"Epidemics and outbreaks present arduous challenges requiring both individual
and communal efforts. Social media offer significant amounts of data that can
be leveraged for bio-surveillance. They also provide a platform to quickly and
efficiently reach a sizeable percentage of the population, hence their
potential impact on various aspects of epidemic mitigation. The general
objective of this systematic literature review is to provide a methodical
overview of the integration of social media in different epidemic-related
contexts. Three research questions were conceptualized for this review,
resulting in over 10000 publications collected in the first PRISMA stage, 129
of which were selected for inclusion. A thematic method-oriented synthesis was
undertaken and identified 5 main themes related to social media enabled
epidemic surveillance, misinformation management, and mental health. Findings
uncover a need for more robust applications of the lessons learned from
epidemic post-mortem documentation. A vast gap exists between retrospective
analysis of epidemic management and result integration in prospective studies.
Harnessing the full potential of social media in epidemic related tasks
requires streamlining the results of epidemic forecasting, public opinion
understanding and misinformation propagation, all while keeping abreast of
potential mental health implications. Pro-active prevention has thus become
vital for epidemic curtailment and containment.",2022-10-03,"Chaimae Asaad, Imane Khaouja, Mounir Ghogho, Karim Baïna"
Deep Spatial Domain Generalization,"Spatial autocorrelation and spatial heterogeneity widely exist in spatial
data, which make the traditional machine learning model perform badly. Spatial
domain generalization is a spatial extension of domain generalization, which
can generalize to unseen spatial domains in continuous 2D space. Specifically,
it learns a model under varying data distributions that generalizes to unseen
domains. Although tremendous success has been achieved in domain
generalization, there exist very few works on spatial domain generalization.
The advancement of this area is challenged by: 1) Difficulty in characterizing
spatial heterogeneity, and 2) Difficulty in obtaining predictive models for
unseen locations without training data. To address these challenges, this paper
proposes a generic framework for spatial domain generalization. Specifically,
We develop the spatial interpolation graph neural network that handles spatial
data as a graph and learns the spatial embedding on each node and their
relationships. The spatial interpolation graph neural network infers the
spatial embedding of an unseen location during the test phase. Then the spatial
embedding of the target location is used to decode the parameters of the
downstream-task model directly on the target location. Finally, extensive
experiments on thirteen real-world datasets demonstrate the proposed method's
strength.",2022-10-03,"Dazhou Yu, Guangji Bai, Yun Li, Liang Zhao"
"Clustering Graphs -- Applying a Label Propagation Algorithm to Detect
  Communities in Graph Databases","In the last few decades, Database Management Systems (DBMSs) became powerful
tools for storing large amount of data and executing complex queries over them.
In the recent years, the growing amount of unstructured or semi-structured data
has seen a shift from representing data in the relational model towards
alternative data models. Graph Databases and Graph Database Management Systems
(GDBMSs) have seen an increase in use due to their ability to manage
highly-interconnected, continuously evolving data.
  This thesis is a documentation of the work done in implementing a system to
identify clusters in graph modeled data using a Label Propagation Community
Detection Algorithm. The graph was built using datasets of academic
publications in the field of Computer Science obtained from dblp.org . The
system developed is a FullStack WebApp consisting of a web-based user
interface, an API and the data (nodes, edges, graph) stored in a Graph Database
Management System (GDBMS).
  Described in this document are: - the process of manipulation pre-import and
import of the data in a Graph Database Management System (GDBMS) such as
ArangoDB, creation of nodes, relations (edges) between the nodes and a graph
composed of these nodes and edges; - the GraphQL API implemented in NodeJS to
request data from the Graph Database Management System (GDBMS); - the frontend
interface made with TypeScript and React consisting of the search
functionalities and ability to visualize results in Cytoscape Network Graphs; -
the Label Propagation Community Detection Algorithm execution on the graph, the
found clusters which are stored and visualized to the user whenever requested.
  This thesis hopes to contribute with a practical hands-on approach on the
graph representation, integration and analysis of interconnected data.",2022-10-02,Andi Ferhati
A Survey on Knowledge Graph-based Methods for Automated Driving,"Automated driving is one of the most active research areas in computer
science. Deep learning methods have made remarkable breakthroughs in machine
learning in general and in automated driving (AD)in particular. However, there
are still unsolved problems to guarantee reliability and safety of automated
systems, especially to effectively incorporate all available information and
knowledge in the driving task. Knowledge graphs (KG) have recently gained
significant attention from both industry and academia for applications that
benefit by exploiting structured, dynamic, and relational data. The complexity
of graph-structured data with complex relationships and inter-dependencies
between objects has posed significant challenges to existing machine learning
algorithms. However, recent progress in knowledge graph embeddings and graph
neural networks allows to applying machine learning to graph-structured data.
Therefore, we motivate and discuss the potential benefit of KGs applied to the
main tasks of AD including 1) ontologies 2) perception, 3) scene understanding,
4) motion planning, and 5) validation. Then, we survey, analyze and categorize
ontologies and KG-based approaches for AD. We discuss current research
challenges and propose promising future research directions for KG-based
solutions for AD.",2022-09-30,"Juergen Luettin, Sebastian Monka, Cory Henson, Lavdim Halilaj"
"Graph Anomaly Detection with Graph Neural Networks: Current Status and
  Challenges","Graphs are used widely to model complex systems, and detecting anomalies in a
graph is an important task in the analysis of complex systems. Graph anomalies
are patterns in a graph that do not conform to normal patterns expected of the
attributes and/or structures of the graph. In recent years, graph neural
networks (GNNs) have been studied extensively and have successfully performed
difficult machine learning tasks in node classification, link prediction, and
graph classification thanks to the highly expressive capability via message
passing in effectively learning graph representations. To solve the graph
anomaly detection problem, GNN-based methods leverage information about the
graph attributes (or features) and/or structures to learn to score anomalies
appropriately. In this survey, we review the recent advances made in detecting
graph anomalies using GNN models. Specifically, we summarize GNN-based methods
according to the graph type (i.e., static and dynamic), the anomaly type (i.e.,
node, edge, subgraph, and whole graph), and the network architecture (e.g.,
graph autoencoder, graph convolutional network). To the best of our knowledge,
this survey is the first comprehensive review of graph anomaly detection
methods based on GNNs.",2022-09-29,"Hwan Kim, Byung Suk Lee, Won-Yong Shin, Sungsu Lim"
OpenDSU: Digital Sovereignty in PharmaLedger,"Distributed ledger networks, chiefly those based on blockchain technologies,
currently are heralding a next generation of computer systems that aims to suit
modern users' demands. Over the recent years, several technologies for
blockchains, off-chaining strategies, as well as decentralised and respectively
self-sovereign identity systems have shot up so fast that standardisation of
the protocols is lagging behind, severely hampering the interoperability of
different approaches. Moreover, most of the currently available solutions for
distributed ledgers focus on either home users or enterprise use case
scenarios, failing to provide integrative solutions addressing the needs of
both.
  Herein we introduce the OpenDSU platform that allows to interoperate generic
blockchain technologies, organised - and possibly cascaded in a hierarchical
fashion - in domains. To achieve this flexibility, we seamlessly integrated a
set of well conceived OpenDSU components to orchestrate off-chain data with
granularly resolved and cryptographically secure access levels that are nested
with sovereign identities across the different domains.
  Employing our platform to PharmaLedger, an inter-European network for the
standardisation of data handling in the pharmaceutical industry and in
healthcare, we demonstrate that OpenDSU can cope with generic demands of
heterogeneous use cases in both, performance and handling substantially
different business policies. Importantly, whereas available solutions commonly
require a pre-defined and fixed set of components, no such vendor lock-in
restrictions on the blockchain technology or identity system exist in OpenDSU,
making systems built on it flexibly adaptable to new standards evolving in the
future.",2022-09-29,"Cosmin Ursache, Michael Sammeth, Sînică Alboaie"
Characterizing the Structure of Online Conversations Across Reddit,"The proliferation of social media platforms has afforded social scientists
unprecedented access to vast troves of data on human interactions, facilitating
the study of online behavior at an unparalleled scale. These platforms
typically structure conversations as threads, forming tree-like structures
known as ""discussion trees."" This paper examines the structural properties of
online discussions on Reddit by analyzing both global (community-level) and
local (post-level) attributes of these discussion trees. We conduct a
comprehensive statistical analysis of a year's worth of Reddit data,
encompassing a quarter of a million posts and several million comments. Our
primary objective is to disentangle the relative impacts of global and local
properties and evaluate how specific features shape discussion tree structures.
The results reveal that both local and global features contribute significantly
to explaining structural variation in discussion trees. However, local
features, such as post content and sentiment, collectively have a greater
impact, accounting for a larger proportion of variation in the width, depth,
and size of discussion trees. Our analysis also uncovers considerable
heterogeneity in the impact of various features on discussion structures.
Notably, certain global features play crucial roles in determining specific
discussion tree properties. These features include the subreddit's topic, age,
popularity, and content redundancy. For instance, posts in subreddits focused
on politics, sports, and current events tend to generate deeper and wider
discussion trees. This research enhances our understanding of online
conversation dynamics and offers valuable insights for both content creators
and platform designers. By elucidating the factors that shape online
discussions, our work contributes to ongoing efforts to improve the quality and
effectiveness of digital discourse.",2022-09-29,"Yulin Yu, Julie Jiang, Paramveer Dhillon"
Tourism's trend Ranking on Social Media Data Using Fuzzy-AHP vs. AHP,"Tourism is an exciting thing to be visited by people in the world. Search for
attractive and popular places can be done through social media. Data from
social media or websites can be used as a reference to find current travel
trends and get information about reviews, stories, likes, forums, blogs, and
feedback from a place. However, if the search is done manually one by one, it
takes a long time, and it becomes interesting to do research. So, searching
based on current trends will be easier and faster. For this reason, this study
uses a computer base to search by ranking tourist facilities from social media
data or websites using the multi-criteria decision-making (MCDM) method. The
implementation of the method used in finding the trend is the Fuzzy-AHP method
in comparison with the AHP. The data used is data reviews, stories, likes,
forums, blogs, and feedback from the web or social media. Because with these
components, tourism can be developed according to visitors\'' wishes. The
research aims to rank facilities\'' tourism attractions (trends) and
development priorities. The priority and ranking used the fuzzy-AHP and AHP
method to determine weight criteria and the ranking process. The highest
ranking is on the Parks/Picnic Spots attraction, and make it a priority to
develop. The methods have an average value MSE of all data is \approx 0.0002,
which can be used for this ranking.",2022-09-29,Shoffan Saifullah
"Doing data science with platforms crumbs: an investigation into fakes
  views on YouTube","This paper contributes to the ongoing discussions on the scholarly access to
social media data, discussing a case where this access is barred despite its
value for understanding and countering online disinformation and despite the
absence of privacy or copyright issues. Our study concerns YouTube's engagement
metrics and, more specifically, the way in which the platform removes ""fake
views"" (i.e., views considered as artificial or illegitimate by the platform).
Working with one and a half year of data extracted from a thousand French
YouTube channels, we show the massive extent of this phenomenon, which concerns
the large majority of the channels and more than half the videos in our corpus.
Our analysis indicates that most fakes news are corrected relatively late in
the life of the videos and that the final view counts of the videos are not
independent from the fake views they received. We discuss the potential harm
that delays in corrections could produce in content diffusion: by inflating
views counts, illegitimate views could make a video appear more popular than it
is and unwarrantedly encourage its human and algorithmic recommendation.
Unfortunately, we cannot offer a definitive assessment of this phenomenon,
because YouTube provides no information on fake views in its API or interface.
This paper is, therefore, also a call for greater transparency by YouTube and
other online platforms about information that can have crucial implications for
the quality of online public debate.",2022-09-28,"Maria Castaldo, Paolo Frasca, Tommaso Venturini, Floriana Gargiulo"
"Resource Allocation and Resolution Control in the Metaverse with Mobile
  Augmented Reality","With the development of blockchain and communication techniques, the
Metaverse is considered as a promising next-generation Internet paradigm, which
enables the connection between reality and the virtual world. The key to
rendering a virtual world is to provide users with immersive experiences and
virtual avatars, which is based on virtual reality (VR) technology and high
data transmission rate. However, current VR devices require intensive
computation and communication, and users suffer from high delay while using
wireless VR devices. To build the connection between reality and the virtual
world with current technologies, mobile augmented reality (MAR) is a feasible
alternative solution due to its cheaper communication and computation cost.
This paper proposes an MAR-based connection model for the Metaverse, and
proposes a communication resources allocation algorithm based on outer
approximation (OA) to achieve the best utility. Simulation results show that
our proposed algorithm is able to provide users with basic MAR services for the
Metaverse, and outperforms the benchmark greedy algorithm.",2022-09-28,"Peiyuan Si, Jun Zhao, Huimei Han, Kwok-Yan Lam, Yang Liu"
"Compressing network populations with modal networks reveals structural
  diversity","Analyzing relational data consisting of multiple samples or layers involves
critical challenges: How many networks are required to capture the variety of
structures in the data? And what are the structures of these representative
networks? We describe efficient nonparametric methods derived from the minimum
description length principle to construct the network representations
automatically. The methods input a population of networks or a multilayer
network measured on a fixed set of nodes and output a small set of
representative networks together with an assignment of each network sample or
layer to one of the representative networks. We identify the representative
networks and assign network samples to them with an efficient Monte Carlo
scheme that minimizes our description length objective. For temporally ordered
networks, we use a polynomial time dynamic programming approach that restricts
the clusters of network layers to be temporally contiguous. These methods
recover planted heterogeneity in synthetic network populations and identify
essential structural heterogeneities in global trade and fossil record
networks. Our methods are principled, scalable, parameter-free, and accommodate
a wide range of data, providing a unified lens for exploratory analyses and
preprocessing large sets of network samples.",2022-09-28,"Alec Kirkley, Alexis Rojas, Martin Rosvall, Jean-Gabriel Young"
A Review: Random Walk in Graph Sampling,"Graph sampling is a technique to pick a subset of vertices and/ or edges from
original graph. Among various graph sampling approaches, Traversal Based
Sampling (TBS) are widely used due to low cost and feasibility for many cases,
in which Simple Random Walk (SRW) and its variants share a large proportion in
TBS. We illustrate the foundation SRW and presents the problems of SRW. Based
on the problems, we provide a taxonomy of different Random Walk (RW) based
graph sampling methods and give an insight to the reason why and how they
revise SRW. our summary includes classical methods and state-of-art RW-based
methods. There are 3 ways to propose new algorithms based on SRW, including SRW
and its combinations, modified selection mechanisms, and the graph topology
modification. We explained the ideas behind those algorithms, and present
detailed pseudo codes. In addition, we add the mathematics behind random walk,
and the essence of random walk variants, which is not mentioned in detail in
many research papers and literature reviews. Apart from RW-based methods, SRW
also has related with the non-RW and non-TBS methods, we discuss the
relationships between SRW and non-RW methods, and the relationships between SRW
and non-TBS methods. The relations between these approaches are formally argued
and a general framework to bridge theoretical analysis and practical
implementation is provided.",2022-09-27,Xiao Qi
"Feedback Exchange and Online Affinity: A Case Study of Online Fanfiction
  Writers","Feedback is a critical piece of the creative process. Prior CSCW research has
invented peer-based and crowd-based systems that exchange feedback between
online strangers at scale. However, creators run into socio-psychological
challenges when engaging in online critique exchange with people they have
never met. In this study, we step back and take a different approach to
investigate online feedback by casting our attention to creators in online
affinity spaces, where feedback exchange happens naturally as part of the
interest-driven participatory culture. We present an interview study with 29
fanfiction writers that investigated how they seek feedback online, and how
they identified and built connections with feedback providers. We identify four
distinct feedback practices and unpack the social needs in feedback exchange.
Our findings surface the importance of affinity and trust in online feedback
exchange and illustrate how writers built relationships with feedback providers
in public and private online spaces. Inspired by the powerful stories we heard
about connection and feedback, we conclude with a series of design
considerations for future feedback systems\textemdash namely addressing a range
of social needs in feedback, helping feedback seekers signal interests and
identity, supporting authentic relationships in feedback exchange, and building
inclusive, safe community spaces for feedback.",2022-09-26,"Ruijia Cheng, Jenna Frens"
"Privacy-Preserving Online Content Moderation: A Federated Learning Use
  Case","Users are daily exposed to a large volume of harmful content on various
social network platforms. One solution is developing online moderation tools
using Machine Learning techniques. However, the processing of user data by
online platforms requires compliance with privacy policies. Federated Learning
(FL) is an ML paradigm where the training is performed locally on the users'
devices. Although the FL framework complies, in theory, with the GDPR policies,
privacy leaks can still occur. For instance, an attacker accessing the final
trained model can successfully perform unwanted inference of the data belonging
to the users who participated in the training process. In this paper, we
propose a privacy-preserving FL framework for online content moderation that
incorporates Differential Privacy (DP). To demonstrate the feasibility of our
approach, we focus on detecting harmful content on Twitter - but the overall
concept can be generalized to other types of misbehavior. We simulate a text
classifier - in FL fashion - which can detect tweets with harmful content. We
show that the performance of the proposed FL framework can be close to the
centralized approach - for both the DP and non-DP FL versions. Moreover, it has
a high performance even if a small number of clients (each with a small number
of data points) are available for the FL training. When reducing the number of
clients (from 50 to 10) or the data points per client (from 1K to 0.1K), the
classifier can still achieve ~81% AUC. Furthermore, we extend the evaluation to
four other Twitter datasets that capture different types of user misbehavior
and still obtain a promising performance (61% - 80% AUC). Finally, we explore
the overhead on the users' devices during the FL training phase and show that
the local training does not introduce excessive CPU utilization and memory
consumption overhead.",2022-09-23,"Pantelitsa Leonidou, Nicolas Kourtellis, Nikos Salamanos, Michael Sirivianos"
"The Impact of Social Media in Learning and Teaching: A
  Bibliometric-based Citation Analysis","This paper presents the results of a systematic review of the literature on
the impact of social media in learning and teaching through bibliometric based
Citation analysis. The objective of the review was to map the evolution of the
current literature and identify the leading sources of knowledge in terms of
the most influential journals, authors, and articles. From a total of 50 top
most relevant articles selected from the Scopus database, a detailed citation
analysis was conducted. The study explored the overall theoretical foundation
of social media research involving in learning and studying and identified the
leading sources of knowledge in terms of and papers and revealed research
trends over the last four years by citation analysis. The analysis of citation
data showed that International Journal of Management Education is the leading
journal in social media in learning and teaching research. Author Abdullah Z
was found to be the leading author in this field in terms of a total number of
publications, total citations, and h index, while the most cited article was
authored by Baaran S. and by Bapitha L. The contribution of this study is to
clearly outline the current state of knowledge regarding social media in
learning and teaching services in the literature.",2022-09-22,"Abdul Shaikh, Saqib Ali, Ramla Al-Maamari"
"Social-Inverse: Inverse Decision-making of Social Contagion Management
  with Task Migrations","Considering two decision-making tasks $A$ and $B$, each of which wishes to
compute an effective \textit{decision} $Y$ for a given \textit{query} $X$, {can
we solve task $B$ by using query-decision pairs $(X, Y)$ of $A$ without knowing
the latent decision-making model?} Such problems, called \textit{inverse
decision-making with task migrations}, are of interest in that the complex and
stochastic nature of real-world applications often prevents the agent from
completely knowing the underlying system. In this paper, we introduce such a
new problem with formal formulations and present a generic framework for
addressing decision-making tasks in social contagion management. On the theory
side, we present a generalization analysis for justifying the learning
performance of our framework. In empirical studies, we perform a sanity check
and compare the presented method with other possible learning-based and
graph-based methods. We have acquired promising experimental results,
confirming for the first time that it is possible to solve one decision-making
task by using the solutions associated with another one.",2022-09-21,Guangmo Tong
MulBot: Unsupervised Bot Detection Based on Multivariate Time Series,"Online social networks are actively involved in the removal of malicious
social bots due to their role in the spread of low quality information.
However, most of the existing bot detectors are supervised classifiers
incapable of capturing the evolving behavior of sophisticated bots. Here we
propose MulBot, an unsupervised bot detector based on multivariate time series
(MTS). For the first time, we exploit multidimensional temporal features
extracted from user timelines. We manage the multidimensionality with an LSTM
autoencoder, which projects the MTS in a suitable latent space. Then, we
perform a clustering step on this encoded representation to identify dense
groups of very similar users -- a known sign of automation. Finally, we perform
a binary classification task achieving f1-score $= 0.99$, outperforming
state-of-the-art methods (f1-score $\le 0.97$). Not only does MulBot achieve
excellent results in the binary classification task, but we also demonstrate
its strengths in a novel and practically-relevant task: detecting and
separating different botnets. In this multi-class classification task we
achieve f1-score $= 0.96$. We conclude by estimating the importance of the
different features used in our model and by evaluating MulBot's capability to
generalize to new unseen bots, thus proposing a solution to the generalization
deficiencies of supervised bot detectors.",2022-09-21,"Lorenzo Mannocci, Stefano Cresci, Anna Monreale, Athina Vakali, Maurizio Tesconi"
Influence Maximization in Real-World Closed Social Networks,"In the last few years, many closed social networks such as WhatsAPP and
WeChat have emerged to cater for people's growing demand of privacy and
independence. In a closed social network, the posted content is not available
to all users or senders can set limits on who can see the posted content. Under
such a constraint, we study the problem of influence maximization in a closed
social network. It aims to recommend users (not just the seed users) a limited
number of existing friends who will help propagate the information, such that
the seed users' influence spread can be maximized. We first prove that this
problem is NP-hard. Then, we propose a highly effective yet efficient method to
augment the diffusion network, which initially consists of seed users only. The
augmentation is done by iteratively and intelligently selecting and inserting a
limited number of edges from the original network. Through extensive
experiments on real-world social networks including deployment into a
real-world application, we demonstrate the effectiveness and efficiency of our
proposed method.",2022-09-21,"Shixun Huang, Wenqing Lin, Zhifeng Bao, Jiachen Sun"
Playing with Thresholds on the Forward Linear Threshold Rank,"Social networks are the natural space for the spreading of information and
influence and have become a media themselves. Several models capturing that
diffusion process have been proposed, most of them based on the Independent
Cascade (IC) model or on the Linear Threshold (LT) model. The IC model is
probabilistic while the LT model relies on the knowledge of an actor to be
convinced, reflected in an associated individual threshold.
  Although the LT-based models contemplate an individual threshold for each
actor in the network, the existing studies so far have always considered a
threshold of 0.5 equal in all actors (i.e., a simple majority activation
criterion).
  Our main objective in this work is to start the study on how the
dissemination of information on networks behaves when we consider other options
for setting those thresholds and how many network actors end up being
influenced by this dissemination. For doing so, we consider a recently
introduced centrality measure based on the LT model, the Forward Linear
Threshold Rank (FLTR). We analyze experimentally the ranking properties for
several networks in which the influence resistance threshold follows different
schemes. Here we consider three different schemes: (1) uniform, in which all
players have the same value; (2) random, where each player is assigned a
threshold u.a.r. in a prescribed interval; and (3) determined by the value of
another centrality measure on the actor. Our results show that the selection
has a clear impact on the ranking, even quite significant and abrupt in some
cases. We conclude that the social networks ranks that provide the best
assignments for the individual thresholds are PageRank and FLTR.",2022-09-21,"Maria J. Blesa, Maria Serna"
"Identifying Emerging Technologies and Leading Companies using Network
  Dynamics of Patent Clusters: a Cybersecurity Case Study","Strategic decisions rely heavily on non-scientific instrumentation to
forecast emerging technologies and leading companies. Instead, we build a fast
quantitative system with a small computational footprint to discover the most
important technologies and companies in a given field, using generalisable
methods applicable to any industry. With the help of patent data from the US
Patent and Trademark Office, we first assign a value to each patent thanks to
automated machine learning tools. We then apply network science to track the
interaction and evolution of companies and clusters of patents (i.e.
technologies) to create rankings for both sets that highlight important or
emerging network nodes thanks to five network centrality indices. Finally, we
illustrate our system with a case study based on the cybersecurity industry.
Our results produce useful insights, for instance by highlighting (i) emerging
technologies with a growing mean patent value and cluster size, (ii) the most
influential companies in the field and (iii) attractive startups with few but
impactful patents. Complementary analysis also provides evidence of decreasing
marginal returns of research and development in larger companies in the
cybersecurity industry.",2022-09-21,"Michael Tsesmelis, Ljiljana Dolamic, Marcus Matthias Keupp, Dimitri Percia David, Alain Mermoud"
Should we agree to disagree about Twitter's bot problem?,"Bots, simply defined as accounts controlled by automation, can be used as a
weapon for online manipulation and pose a threat to the health of platforms.
Researchers have studied online platforms to detect, estimate, and characterize
bot accounts. Concerns about the prevalence of bots were raised following Elon
Musk's bid to acquire Twitter. Twitter's recent estimate that 5\% of
monetizable daily active users being bot accounts raised questions about their
methodology. This estimate is based on a specific number of active users and
relies on Twitter's criteria for bot accounts. In this work, we want to stress
that crucial questions need to be answered in order to make a proper estimation
and compare different methodologies. We argue how assumptions on bot-likely
behavior, the detection approach, and the population inspected can affect the
estimation of the percentage of bots on Twitter. Finally, we emphasize the
responsibility of platforms to be vigilant, transparent, and unbiased in
dealing with threats that may affect their users.",2022-09-20,Onur Varol
Algorithms for Large-scale Network Analysis and the NetworKit Toolkit,"The abundance of massive network data in a plethora of applications makes
scalable analysis algorithms and software tools necessary to generate knowledge
from such data in reasonable time. Addressing scalability as well as other
requirements such as good usability and a rich feature set, the open-source
software NetworKit has established itself as a popular tool for large-scale
network analysis. This chapter provides a brief overview of the contributions
to NetworKit made by the DFG Priority Programme SPP 1736 Algorithms for Big
Data. Algorithmic contributions in the areas of centrality computations,
community detection, and sparsification are in the focus, but we also mention
several other aspects -- such as current software engineering principles of the
project and ways to visualize network data within a NetworKit-based workflow.",2022-09-20,"Eugenio Angriman, Alexander van der Grinten, Michael Hamann, Henning Meyerhenke, Manuel Penschuck"
"Identifying and Characterizing Behavioral Classes of Radicalization
  within the QAnon Conspiracy on Twitter","Social media provide a fertile ground where conspiracy theories and radical
ideas can flourish, reach broad audiences, and sometimes lead to hate or
violence beyond the online world itself. QAnon represents a notable example of
a political conspiracy that started out on social media but turned mainstream,
in part due to public endorsement by influential political figures. Nowadays,
QAnon conspiracies often appear in the news, are part of political rhetoric,
and are espoused by significant swaths of people in the United States. It is
therefore crucial to understand how such a conspiracy took root online, and
what led so many social media users to adopt its ideas. In this work, we
propose a framework that exploits both social interaction and content signals
to uncover evidence of user radicalization or support for QAnon. Leveraging a
large dataset of 240M tweets collected in the run-up to the 2020 US
Presidential election, we define and validate a multivariate metric of
radicalization. We use that to separate users in distinct, naturally-emerging,
classes of behaviors associated to radicalization processes, from self-declared
QAnon supporters to hyper-active conspiracy promoters. We also analyze the
impact of Twitter's moderation policies on the interactions among different
classes: we discover aspects of moderation that succeed, yielding a substantial
reduction in the endorsement received by hyper-active QAnon accounts. But we
also uncover where moderation fails, showing how QAnon content amplifiers are
not deterred or affected by Twitter intervention. Our findings refine our
understanding of online radicalization processes, reveal effective and
ineffective aspects of moderation, and call for the need to further investigate
the role social media play in the spread of conspiracies.",2022-09-19,"Emily L. Wang, Luca Luceri, Francesco Pierri, Emilio Ferrara"
Quantifying How Hateful Communities Radicalize Online Users,"While online social media offers a way for ignored or stifled voices to be
heard, it also allows users a platform to spread hateful speech. Such speech
usually originates in fringe communities, yet it can spill over into mainstream
channels. In this paper, we measure the impact of joining fringe hateful
communities in terms of hate speech propagated to the rest of the social
network. We leverage data from Reddit to assess the effect of joining one type
of echo chamber: a digital community of like-minded users exhibiting hateful
behavior. We measure members' usage of hate speech outside the studied
community before and after they become active participants. Using Interrupted
Time Series (ITS) analysis as a causal inference method, we gauge the spillover
effect, in which hateful language from within a certain community can spread
outside that community by using the level of out-of-community hate word usage
as a proxy for learned hate. We investigate four different Reddit
sub-communities (subreddits) covering three areas of hate speech: racism,
misogyny and fat-shaming. In all three cases we find an increase in hate speech
outside the originating community, implying that joining such community leads
to a spread of hate speech throughout the platform. Moreover, users are found
to pick up this new hateful speech for months after initially joining the
community. We show that the harmful speech does not remain contained within the
community. Our results provide new evidence of the harmful effects of echo
chambers and the potential benefit of moderating them to reduce adoption of
hateful speech.",2022-09-19,"Matheus Schmitz, Keith Burghardt, Goran Muric"
Detecting Political Biases of Named Entities and Hashtags on Twitter,"Ideological divisions in the United States have become increasingly prominent
in daily communication. Accordingly, there has been much research on political
polarization, including many recent efforts that take a computational
perspective. By detecting political biases in a corpus of text, one can attempt
to describe and discern the polarity of that text. Intuitively, the named
entities (i.e., the nouns and the phrases that act as nouns) and hashtags in
text often carry information about political views. For example, people who use
the term ""pro-choice"" are likely to be liberal, whereas people who use the term
""pro-life"" are likely to be conservative. In this paper, we seek to reveal
political polarities in social-media text data and to quantify these polarities
by explicitly assigning a polarity score to entities and hashtags. Although
this idea is straightforward, it is difficult to perform such inference in a
trustworthy quantitative way. Key challenges include the small number of known
labels, the continuous spectrum of political views, and the preservation of
both a polarity score and a polarity-neutral semantic meaning in an embedding
vector of words. To attempt to overcome these challenges, we propose the
Polarity-aware Embedding Multi-task learning (PEM) model. This model consists
of (1) a self-supervised context-preservation task, (2) an attention-based
tweet-level polarity-inference task, and (3) an adversarial learning task that
promotes independence between an embedding's polarity dimension and its
semantic dimensions. Our experimental results demonstrate that our PEM model
can successfully learn polarity-aware embeddings that perform well
classification tasks. We examine a variety of applications and we thereby
demonstrate the effectiveness of our PEM model. We also discuss important
limitations of our work and encourage caution when applying the it to
real-world scenarios.",2022-09-16,"Zhiping Xiao, Jeffrey Zhu, Yining Wang, Pei Zhou, Wen Hong Lam, Mason A. Porter, Yizhou Sun"
Interactions in Information Spread,"Since the development of writing 5000 years ago, human-generated data gets
produced at an ever-increasing pace. Classical archival methods aimed at easing
information retrieval. Nowadays, archiving is not enough anymore. The amount of
data that gets generated daily is beyond human comprehension, and appeals for
new information retrieval strategies. Instead of referencing every single data
piece as in traditional archival techniques, a more relevant approach consists
in understanding the overall ideas conveyed in data flows. To spot such general
tendencies, a precise comprehension of the underlying data generation
mechanisms is required. In the rich literature tackling this problem, the
question of information interaction remains nearly unexplored. First, we
investigate the frequency of such interactions. Building on recent advances
made in Stochastic Block Modelling, we explore the role of interactions in
several social networks. We find that interactions are rare in these datasets.
Then, we wonder how interactions evolve over time. Earlier data pieces should
not have an everlasting influence on ulterior data generation mechanisms. We
model this using dynamic network inference advances. We conclude that
interactions are brief. Finally, we design a framework that jointly models rare
and brief interactions based on Dirichlet-Hawkes Processes. We argue that this
new class of models fits brief and sparse interaction modelling. We conduct a
large-scale application on Reddit and find that interactions play a minor role
in this dataset. From a broader perspective, our work results in a collection
of highly flexible models and in a rethinking of core concepts of machine
learning. Consequently, we open a range of novel perspectives both in terms of
real-world applications and in terms of technical contributions to machine
learning.",2022-09-16,Gaël Poux-Médard
Understanding NFT Price Moves through Tweets Keywords Analysis,"Non-Fungible Token (NFT) is evolving with the rise of the cryptocurrency
market and the development of blockchain techniques, which leads to an emerging
NFT market that has become prosperous rapidly then followed by a cooldown.
Nevertheless, the overall rise procedure of the NFT market has not been well
understood. To this end, we consider that social media communities evolving
alongside the market growth, are worth exploring and reasoning about, as the
mineable information might unveil the market behaviors. We explore the
procedure from the perspective of NFT Twitter communities and its impact on the
NFT price moves with two experiments. We perform a Granger causality test on
the number of tweets and the NFT price time series and find that the number of
tweets has a positive impact on (Granger-causes) the price or reversely for
larger part of the 19 top authentic projects but seldom copycat projects.
Besides, to investigate the price moves predictability, we experiment on
predicting Markov normalized NFT price (representing the direction and
magnitude of price moves) given tweets-extracted word features and interpret
the feature importance to find insights. Our results show that social media
words as the predictors result in all 19 top projects having a testing accuracy
evidently above the baseline. Based on the feature importance analysis, we find
that both general market-related words and NFT event-related words have a
markedly positive contribution in predicting price moves. We summarize the
characteristics including categorization and sentiment for the words with the
top and least feature importance.",2022-09-16,"Junliang Luo, Yongzheng Jia, Xue Liu"
Reducing Access Disparities in Networks using Edge Augmentation,"In social networks, a node's position is a form of \it{social capital}.
Better-positioned members not only benefit from (faster) access to diverse
information, but innately have more potential influence on information spread.
Structural biases often arise from network formation, and can lead to
significant disparities in information access based on position. Further,
processes such as link recommendation can exacerbate this inequality by relying
on network structure to augment connectivity.
  We argue that one can understand and quantify this social capital through the
lens of information flow in the network. We consider the setting where all
nodes may be sources of distinct information, and a node's (dis)advantage deems
its ability to access all information available on the network. We introduce
three new measures of advantage (broadcast, influence, and control), which are
quantified in terms of position in the network using \it{access signatures} --
vectors that represent a node's ability to share information. We then consider
the problem of improving equity by making interventions to increase the access
of the least-advantaged nodes. We argue that edge augmentation is most
appropriate for mitigating bias in the network structure, and frame a budgeted
intervention problem for maximizing minimum pairwise access.
  Finally, we propose heuristic strategies for selecting edge augmentations and
empirically evaluate their performance on a corpus of real-world social
networks. We demonstrate that a small number of interventions significantly
increase the broadcast measure of access for the least-advantaged nodes (over 5
times more than random), and also improve the minimum influence. Additional
analysis shows that these interventions can also dramatically shrink the gap in
advantage between nodes (over \%82) and reduce disparities between their access
signatures.",2022-09-15,"Ashkan Bashardoust, Sorelle A. Friedler, Carlos E. Scheidegger, Blair D. Sullivan, Suresh Venkatasubramanian"
"Public Wisdom Matters! Discourse-Aware Hyperbolic Fourier Co-Attention
  for Social-Text Classification","Social media has become the fulcrum of all forms of communication.
Classifying social texts such as fake news, rumour, sarcasm, etc. has gained
significant attention. The surface-level signals expressed by a social-text
itself may not be adequate for such tasks; therefore, recent methods attempted
to incorporate other intrinsic signals such as user behavior and the underlying
graph structure. Oftentimes, the `public wisdom' expressed through the
comments/replies to a social-text acts as a surrogate of crowd-sourced view and
may provide us with complementary signals. State-of-the-art methods on
social-text classification tend to ignore such a rich hierarchical signal.
Here, we propose Hyphen, a discourse-aware hyperbolic spectral co-attention
network. Hyphen is a fusion of hyperbolic graph representation learning with a
novel Fourier co-attention mechanism in an attempt to generalise the
social-text classification tasks by incorporating public discourse. We parse
public discourse as an Abstract Meaning Representation (AMR) graph and use the
powerful hyperbolic geometric representation to model graphs with hierarchical
structure. Finally, we equip it with a novel Fourier co-attention mechanism to
capture the correlation between the source post and public discourse. Extensive
experiments on four different social-text classification tasks, namely
detecting fake news, hate speech, rumour, and sarcasm, show that Hyphen
generalises well, and achieves state-of-the-art results on ten benchmark
datasets. We also employ a sentence-level fact-checked and annotated dataset to
evaluate how Hyphen is capable of producing explanations as analogous evidence
to the final prediction.",2022-09-15,"Karish Grover, S. M. Phaneendra Angara, Md. Shad Akhtar, Tanmoy Chakraborty"
Complex hypergraphs,"Providing an abstract representation of natural and human complex structures
is a challenging problem. Accounting for the system heterogenous components
while allowing for analytical tractability is a difficult balance. Here I
introduce complex hypergraphs (chygraphs), bringing together concepts from
hypergraphs, multi-layer networks, simplicial complexes and hyperstructures. To
illustrate the applicability of this combinatorial structure I calculate the
component sizes statistics and identify the transition to a giant component. To
this end I introduce a vectorization technique that tackles the multi-level
nature of chygraphs. I conclude that chygraphs are a unifying representation of
complex systems allowing for analytical insight.",2022-09-15,Alexei Vazquez
Dizzy: Large-Scale Crawling and Analysis of Onion Services,"With nearly 2.5m users, onion services have become the prominent part of the
darkweb. Over the last five years alone, the number of onion domains has
increased 20x, reaching more than 700k unique domains in January 2022. As onion
services host various types of illicit content, they have become a valuable
resource for darkweb research and an integral part of e-crime investigation and
threat intelligence. However, this content is largely un-indexed by today's
search engines and researchers have to rely on outdated or manually-collected
datasets that are limited in scale, scope, or both.
  To tackle this problem, we built Dizzy: An open-source crawling and analysis
system for onion services. Dizzy implements novel techniques to explore,
update, check, and classify onion services at scale, without overwhelming the
Tor network. We deployed Dizzy in April 2021 and used it to analyze more than
63.3m crawled onion webpages, focusing on domain operations, web content,
cryptocurrency usage, and web graph. Our main findings show that onion services
are unreliable due to their high churn rate, have a relatively small number of
reachable domains that are often similar and illicit, enjoy a growing
underground cryptocurrency economy, and have a graph that is relatively
tightly-knit to, but topologically different from, the regular web's graph.",2022-09-15,"Yazan Boshmaf, Isuranga Perera, Udesh Kumarasinghe, Sajitha Liyanage, Husam Al Jawaheri"
Voting-based Opinion Maximization,"We investigate the novel problem of voting-based opinion maximization in a
social network: Find a given number of seed nodes for a target campaigner, in
the presence of other competing campaigns, so as to maximize a voting-based
score for the target campaigner at a given time horizon.
  The bulk of the influence maximization literature assumes that social network
users can switch between only two discrete states, inactive and active, and the
choice to switch is frozen upon one-time activation. In reality, even when
having a preferred opinion, a user may not completely despise the other
opinions, and the preference level may vary over time due to social influence.
To this end, we employ models rooted in opinion formation and diffusion, and
use several voting-based scores to determine a user's vote for each of the
multiple campaigners at a given time horizon.
  Our problem is NP-hard and non-submodular for various scores. We design
greedy seed selection algorithms with quality guarantees for our scoring
functions via sandwich approximation. To improve the efficiency, we develop
random walk and sketch-based opinion computation, with quality guarantees.
Empirical results validate our effectiveness, efficiency, and scalability.",2022-09-14,"Arkaprava Saha, Xiangyu Ke, Arijit Khan, Laks V. S. Lakshmanan"
"Targeting interventions for displacement minimization in opinion
  dynamics","Social influence is largely recognized as a key factor in opinion formation
processes. Recently, the role of external forces in inducing opinion
displacement and polarization in social networks has attracted significant
attention. This is in particular motivated by the necessity to understand and
possibly prevent interference phenomena during political campaigns and
elections. In this paper, we formulate and solve a targeted intervention
problem for opinion displacement minimization on a social network.
Specifically, we consider a min-max problem whereby a social planner (the
defender) aims at selecting the optimal network intervention within her given
budget constraint in order to minimize the opinion displacement in the system
that an adversary (the attacker) is instead trying to maximize. Our results
show that the optimal intervention of the defender has two regimes. For large
enough budget, the optimal intervention of the social planner acts on all nodes
proportionally to a new notion of network centrality. For lower budget values,
such optimal intervention has a more delicate structure and is rather
concentrated on a few target individuals.",2022-09-14,"Luca Damonte, Giacomo Como, Fabio Fagnani"
Mathematical Framework for Online Social Media Auditing,"Social media platforms (SMPs) leverage algorithmic filtering (AF) as a means
of selecting the content that constitutes a user's feed with the aim of
maximizing their rewards. Selectively choosing the contents to be shown on the
user's feed may yield a certain extent of influence, either minor or major, on
the user's decision-making, compared to what it would have been under a
natural/fair content selection. As we have witnessed over the past decade,
algorithmic filtering can cause detrimental side effects, ranging from biasing
individual decisions to shaping those of society as a whole, for example,
diverting users' attention from whether to get the COVID-19 vaccine or inducing
the public to choose a presidential candidate. The government's constant
attempts to regulate the adverse effects of AF are often complicated, due to
bureaucracy, legal affairs, and financial considerations. On the other hand
SMPs seek to monitor their own algorithmic activities to avoid being fined for
exceeding the allowable threshold. In this paper, we mathematically formalize
this framework and utilize it to construct a data-driven statistical auditing
procedure to regulate AF from deflecting users' beliefs over time, along with
sample complexity guarantees. This state-of-the-art algorithm can be used
either by authorities acting as external regulators or by SMPs for
self-auditing.",2022-09-12,"Wasim Huleihel, Yehonathan Refael"
"Detecting Network-based Internet Censorship via Latent Feature
  Representation Learning","Internet censorship is a phenomenon of societal importance and attracts
investigation from multiple disciplines. Several research groups, such as
Censored Planet, have deployed large scale Internet measurement platforms to
collect network reachability data. However, existing studies generally rely on
manually designed rules (i.e., using censorship fingerprints) to detect
network-based Internet censorship from the data. While this rule-based approach
yields a high true positive detection rate, it suffers from several challenges:
it requires human expertise, is laborious, and cannot detect any censorship not
captured by the rules. Seeking to overcome these challenges, we design and
evaluate a classification model based on latent feature representation learning
and an image-based classification model to detect network-based Internet
censorship.
  To infer latent feature representations fromnetwork reachability data, we
propose a sequence-to-sequence autoencoder to capture the structure and the
order of data elements in the data. To estimate the probability of censorship
events from the inferred latent features, we rely on a densely connected
multi-layer neural network model.
  Our image-based classification model encodes a network reachability data
record as a gray-scale image and classifies the image as censored or not using
a dense convolutional neural network. We compare and evaluate both approaches
using data sets from Censored Planet via a hold-out evaluation. Both
classification models are capable of detecting network-based Internet
censorship as we were able to identify instances of censorship not detected by
the known fingerprints. Latent feature representations likely encode more
nuances in the data since the latent feature learning approach discovers a
greater quantity, and a more diverse set, of new censorship instances.",2022-09-12,"Shawn P. Duncan, Hui Chen"
"Random Isn't Always Fair: Candidate Set Imbalance and Exposure
  Inequality in Recommender Systems","Traditionally, recommender systems operate by returning a user a set of
items, ranked in order of estimated relevance to that user. In recent years,
methods relying on stochastic ordering have been developed to create ""fairer""
rankings that reduce inequality in who or what is shown to users. Complete
randomization -- ordering candidate items randomly, independent of estimated
relevance -- is largely considered a baseline procedure that results in the
most equal distribution of exposure. In industry settings, recommender systems
often operate via a two-step process in which candidate items are first
produced using computationally inexpensive methods and then a full ranking
model is applied only to those candidates.
  In this paper, we consider the effects of inequality at the first step and
show that, paradoxically, complete randomization at the second step can result
in a higher degree of inequality relative to deterministic ordering of items by
estimated relevance scores. In light of this observation, we then propose a
simple post-processing algorithm in pursuit of reducing exposure inequality
that works both when candidate sets have a high level of imbalance and when
they do not. The efficacy of our method is illustrated on both simulated data
and a common benchmark data set used in studying fairness in recommender
systems.",2022-09-12,"Amanda Bower, Kristian Lum, Tomo Lazovich, Kyra Yee, Luca Belli"
A Complex Network based Graph Embedding Method for Link Prediction,"Graph embedding methods aim at finding useful graph representations by
mapping nodes to a low-dimensional vector space. It is a task with important
downstream applications, such as link prediction, graph reconstruction, data
visualization, node classification, and language modeling. In recent years, the
field of graph embedding has witnessed a shift from linear algebraic approaches
towards local, gradient-based optimization methods combined with random walks
and deep neural networks to tackle the problem of embedding large graphs.
However, despite this improvement in the optimization tools, graph embedding
methods are still generically designed in a way that is oblivious to the
particularities of real-life networks. Indeed, there has been significant
progress in understanding and modeling complex real-life networks in recent
years. However, the obtained results have had a minor influence on the
development of graph embedding algorithms. This paper aims to remedy this by
designing a graph embedding method that takes advantage of recent valuable
insights from the field of network science. More precisely, we present a novel
graph embedding approach based on the popularity-similarity and local
attraction paradigms. We evaluate the performance of the proposed approach on
the link prediction task on a large number of real-life networks. We show,
using extensive experimental analysis, that the proposed method outperforms
state-of-the-art graph embedding algorithms. We also demonstrate its robustness
to data scarcity and the choice of embedding dimensionality.",2022-09-11,"Said Kerrache, Hafida Benhidour"
"Doctors vs. Nurses: Understanding the Great Divide in Vaccine Hesitancy
  among Healthcare Workers","Healthcare workers such as doctors and nurses are expected to be trustworthy
and creditable sources of vaccine-related information. Their opinions toward
the COVID-19 vaccines may influence the vaccine uptake among the general
population. However, vaccine hesitancy is still an important issue even among
the healthcare workers. Therefore, it is critical to understand their opinions
to help reduce the level of vaccine hesitancy. There have been studies
examining healthcare workers' viewpoints on COVID-19 vaccines using
questionnaires. Reportedly, a considerably higher proportion of vaccine
hesitancy is observed among nurses, compared to doctors. We intend to verify
and study this phenomenon at a much larger scale and in fine grain using social
media data, which has been effectively and efficiently leveraged by researchers
to address real-world issues during the COVID-19 pandemic. More specifically,
we use a keyword search to identify healthcare workers and further classify
them into doctors and nurses from the profile descriptions of the corresponding
Twitter users. Moreover, we apply a transformer-based language model to remove
irrelevant tweets. Sentiment analysis and topic modeling are employed to
analyze and compare the sentiment and thematic differences in the tweets posted
by doctors and nurses. We find that doctors are overall more positive toward
the COVID-19 vaccines. The focuses of doctors and nurses when they discuss
vaccines in a negative way are in general different. Doctors are more concerned
with the effectiveness of the vaccines over newer variants while nurses pay
more attention to the potential side effects on children. Therefore, we suggest
that more customized strategies should be deployed when communicating with
different groups of healthcare workers.",2022-09-11,"Sajid Hussain Rafi Ahamed, Shahid Shakil, Hanjia Lyu, Xinping Zhang, Jiebo Luo"
MetaPriv: Acting in Favor of Privacy on Social Media Platforms,"Social networks such as Facebook (FB) and Instagram are known for tracking
user online behaviour for commercial gain. To this day, there is practically no
other way of achieving privacy in said platforms other than renouncing their
use. However, many users are reluctant in doing so because of convenience or
social and professional reasons. In this work, we propose a means of balancing
convenience and privacy on FB through obfuscation. We have created MetaPriv, a
tool based on simulating user interaction with FB. MetaPriv allows users to add
noise interactions to their account so as to lead FB's profiling algorithms
astray, and make them draw inaccurate profiles in relation to their interests
and habits. To prove our tool's effectiveness, we ran extensive experiments on
a dummy account and two existing user accounts. Our results showed that, by
using our tool, users can achieve a higher degree of privacy in just a couple
of weeks. We believe that MetaPriv can be further developed to accommodate
other social media platforms and help users regain their privacy, while
maintaining a reasonable level of convenience. To support open science and
reproducible research, our source code is publicly available online.",2022-09-08,"Robert Cantaragiu, Antonis Michalas, Eugene Frimpong, Alexandros Bakas"
IMAP: Individual huMAn mobility Patterns visualizing platform,"Understanding human mobility is essential for the development of smart cities
and social behavior research. Human mobility models may be used in numerous
applications, including pandemic control, urban planning, and traffic
management. The existing models' accuracy in predicting users' mobility
patterns is less than 25%. The low accuracy may be justified by the flexible
nature of the human movement. Indeed, humans are not rigid in their daily
movement. In addition, the rigid mobility models may result in missing the
hidden regularities in users' records. Thus, we propose a novel perspective to
study and analyze human mobility patterns and capture their flexibility.
Typically, the mobility patterns are represented by a sequence of locations. We
propose to define the mobility patterns by abstracting these locations into a
set of places. Labeling these locations will allow us to detect
close-to-reality hidden patterns. We present IMAP, an Individual huMAn mobility
Patterns visualizing platform. Our platform enables users to visualize a graph
of the places they visited based on their history records. In addition, our
platform displays the most frequent mobility patterns computed using a modified
PrefixSpan approach.",2022-09-08,"Yisheng Alison Zheng, Amani Abusafia, Abdallah Lakhdari, Shing Tai Tony Lui, Athman Bouguettaya"
"Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain
  Chatbots","Chatbots are used in many applications, e.g., automated agents, smart home
assistants, interactive characters in online games, etc. Therefore, it is
crucial to ensure they do not behave in undesired manners, providing offensive
or toxic responses to users. This is not a trivial task as state-of-the-art
chatbot models are trained on large, public datasets openly collected from the
Internet. This paper presents a first-of-its-kind, large-scale measurement of
toxicity in chatbots. We show that publicly available chatbots are prone to
providing toxic responses when fed toxic queries. Even more worryingly, some
non-toxic queries can trigger toxic responses too. We then set out to design
and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to
generate non-toxic queries that make chatbots respond in a toxic manner. Our
extensive experimental evaluation demonstrates that our attack is effective
against public chatbot models and outperforms manually-crafted malicious
queries proposed by previous work. We also evaluate three defense mechanisms
against ToxicBuddy, showing that they either reduce the attack performance at
the cost of affecting the chatbot's utility or are only effective at mitigating
a portion of the attack. This highlights the need for more research from the
computer security and online safety communities to ensure that chatbot models
do not hurt their users. Overall, we are confident that ToxicBuddy can be used
as an auditing tool and that our work will pave the way toward designing more
effective defenses for chatbot safety.",2022-09-07,"Wai Man Si, Michael Backes, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Savvas Zannettou, Yang Zhang"
Reconstructing signed relations from interaction data,"Positive and negative relations play an essential role in human behavior and
shape the communities we live in. Despite their importance, data about signed
relations is rare and commonly gathered through surveys. Interaction data is
more abundant, for instance, in the form of proximity or communication data. So
far, though, it could not be utilized to detect signed relations. In this
paper, we show how the underlying signed relations can be extracted with such
data. Employing a statistical network approach, we construct networks of signed
relations in four communities. We then show that these relations correspond to
the ones reported in surveys. Additionally, the inferred relations allow us to
study the homophily of individuals with respect to gender, religious beliefs,
and financial backgrounds. We evaluate the importance of triads in the signed
network to study group cohesion.",2022-09-07,"Georges Andres, Giona Casiraghi, Giacomo Vaccario, Frank Schweitzer"
"Composite Community-Aware Diversified Influence Maximization with
  Efficient Approximation","Influence Maximization (IM) is a famous topic in mobile networks and social
computing, which aims at finding a small subset of users to maximize the
influence spread through online information cascade. Recently, some careful
researchers paid attention to diversity of information dissemination,
especially community-aware diversity, and formulated the diversified IM
problem. The diversity is ubiquitous in a lot of real-world applications, but
they are all based on a given community structure. In social networks, we can
form heterogeneous community structures for the same group of users according
to different metrics. Therefore, how to quantify the diversity based on
multiple community structures is an interesting question. In this paper, we
propose the Composite Community-Aware Diversified IM (CC-DIM) problem, which
aims at selecting a seed set to maximize the influence spread and the composite
diversity over all possible community structures under consideration. To
address the NP-hardness of CC-DIM problem, we adopt the technique of reverse
influence sampling and design a random Generalized Reverse Reachable (G-RR) set
to estimate the objective function. The composition of a random G-RR set is
much more complex than the RR set used for the IM problem, which will lead to
inefficiency of traditional sampling-based approximation algorithms. Because of
this, we further propose a two-stage algorithm, Generalized HIST (G-HIST). It
can not only return a $(1-1/e-\varepsilon)$ approximate solution with at least
$(1-\delta)$ probability, but also improve the efficiency of sampling and ease
the difficulty of searching by significantly reducing the average size of G-RR
sets. Finally, we evaluate our G-HIST on real datasets against existing
algorithms. The experimental results show the effectiveness of our proposed
algorithm and its superiority over other baseline algorithms.",2022-09-07,"Jianxiong Guo, Qiufen Ni, Weili Wu, Ding-Zhu Du"
PERFECT: A Hyperbolic Embedding for Joint User and Community Alignment,"Social network alignment shows fundamental importance in a wide spectrum of
applications. To the best of our knowledge, existing studies mainly focus on
network alignment at the individual user level, requiring abundant common
information between shared individual users. For the networks that cannot meet
such requirements, social community structures actually provide complementary
and critical information at a slightly coarse-grained level, alignment of which
will provide additional information for user alignment. In turn, user alignment
also reveals more clues for community alignment. Hence, in this paper, we
introduce the problem of joint social network alignment, which aims to align
users and communities across social networks simultaneously. Key challenges lie
in that 1) how to learn the representations of both users and communities, and
2) how to make user alignment and community alignment benefit from each other.
To address these challenges, we first elaborate on the characteristics of
real-world networks with the notion of delta-hyperbolicity, and show the
superiority of hyperbolic space for representing social networks. Then, we
present a novel hyperbolic embedding approach for the joint social network
alignment, referred to as PERFECT, in a unified optimization. Extensive
experiments on real-world datasets show the superiority of PERFECT in both user
alignment and community alignment.",2022-09-07,"Li Sun, Zhongbao Zhang, Jiawei Zhang, Feiyang Wang, Yang Du, Sen Su, Philip S. Yu"
"SlateFree: a Model-Free Decomposition for Reinforcement Learning with
  Slate Actions","We consider the problem of sequential recommendations, where at each step an
agent proposes some slate of $N$ distinct items to a user from a much larger
catalog of size $K>>N$. The user has unknown preferences towards the
recommendations and the agent takes sequential actions that optimise (in our
case minimise) some user-related cost, with the help of Reinforcement Learning.
The possible item combinations for a slate is $\binom{K}{N}$, an enormous
number rendering value iteration methods intractable. We prove that the
slate-MDP can actually be decomposed using just $K$ item-related $Q$ functions
per state, which describe the problem in a more compact and efficient way.
Based on this, we propose a novel model-free SARSA and Q-learning algorithm
that performs $N$ parallel iterations per step, without any prior user
knowledge. We call this method \texttt{SlateFree}, i.e. free-of-slates, and we
show numerically that it converges very fast to the exact optimum for arbitrary
user profiles, and that it outperforms alternatives from the literature.",2022-09-05,Anastasios Giovanidis
"Migration patterns, friendship networks, and the diaspora: the potential
  of Facebook Social Connectedness Index to anticipate displacement patterns
  induced by Russia invasion of Ukraine in the European Union","The conflict in Ukraine is causing large-scale displacement in Europe and in
the World. Based on the United Nations High Commissioner for Refugees (UNHCR)
estimates, more than 7 million people fled the country as of 5 September 2022.
In this context, it is extremely important to anticipate where these people are
moving so that national to local authorities can better manage challenges
related to their reception and integration. This work shows how innovative data
from social media can provide useful insights on conflict-induced migration
flows. In particular, we explore the potential of Facebook's Social
Connectedness Index (SCI) for predicting migration flows in the context of the
war in Ukraine, building on previous research findings that the presence of a
diaspora network is one of the major migration drivers. To do so, we first
evaluate the relationship between the Ukrainian diaspora and the number of
refugees from Ukraine registered for Temporary Protection or similar national
schemes as a proxy of migratory flows into the EU. We find a very strong
correlation between the two (Pearson's r=0.94, p<0.0001), which indicates that
the diaspora is attracting the people fleeing the war, who tend to reach their
compatriots, in particular in the countries where the Ukrainian immigration was
more a recent phenomenon. Second, we compare Facebook's SCI with available
official data on diaspora at regional level in Europe. Our results suggest that
the index, along with other readily available covariates, is a strong predictor
of the Ukrainian diaspora at regional scale. Finally, we discuss the potential
of Facebook's SCI to provide timely and spatially detailed information on human
diaspora for those countries where this information might be missing or
outdated, and to complement official statistics for fast policy response during
conflicts.",2022-09-05,"Umberto Minora, Martina Belmonte, Claudio Bosco, Drew Johnston, Eugenia Giraudy, Stefano Iacus, Francesco Sermi"
"One Year of COVID-19 Vaccine Misinformation on Twitter: Longitudinal
  Study","Vaccinations play a critical role in mitigating the impact of COVID-19 and
other diseases. This study explores COVID-19 vaccine misinformation circulating
on Twitter during 2021, when vaccines were being released to the public in an
effort to mitigate the global pandemic. Our findings show a low prevalence of
low-credibility information compared to mainstream news. However, most popular
low-credibility sources had larger reshare volumes than authoritative sources
such as the CDC and WHO. We observed an increasing trend in the prevalence of
low-credibility news relative to mainstream news about vaccines. We also
observed a considerable amount of suspicious YouTube videos shared on Twitter.
Tweets by a small group of about 800 ""superspreaders"" verified by Twitter
accounted for approximately 35% of all reshares of misinformation on the
average day, with the top superspreader (@RobertKennedyJr) responsible for over
13% of retweets. Low-credibility news and suspicious YouTube videos were more
likely to be shared by automated accounts. Our findings are consistent with the
hypothesis that superspreaders are driven by financial incentives that allow
them to profit from health misinformation. Despite high-profile cases of
deplatformed misinformation superspreaders, our results show that in 2021 a few
individuals still played an outsize role in the spread of low-credibility
vaccine content. Social media policies should consider revoking the verified
status of repeat-spreaders of harmful content, especially during public health
crises.",2022-09-04,"Francesco Pierri, Matthew R. DeVerna, Kai-Cheng Yang, David Axelrod, John Bryden, Filippo Menczer"
"Cross-Network Social User Embedding with Hybrid Differential Privacy
  Guarantees","Integrating multiple online social networks (OSNs) has important implications
for many downstream social mining tasks, such as user preference modelling,
recommendation, and link prediction. However, it is unfortunately accompanied
by growing privacy concerns about leaking sensitive user information. How to
fully utilize the data from different online social networks while preserving
user privacy remains largely unsolved. To this end, we propose a Cross-network
Social User Embedding framework, namely DP-CroSUE, to learn the comprehensive
representations of users in a privacy-preserving way. We jointly consider
information from partially aligned social networks with differential privacy
guarantees. In particular, for each heterogeneous social network, we first
introduce a hybrid differential privacy notion to capture the variation of
privacy expectations for heterogeneous data types. Next, to find user linkages
across social networks, we make unsupervised user embedding-based alignment in
which the user embeddings are achieved by the heterogeneous network embedding
technology. To further enhance user embeddings, a novel cross-network GCN
embedding model is designed to transfer knowledge across networks through those
aligned users. Extensive experiments on three real-world datasets demonstrate
that our approach makes a significant improvement on user interest prediction
tasks as well as defending user attribute inference attacks from embedding.",2022-09-04,"Jiaqian Ren, Lei Jiang, Hao Peng, Lingjuan Lyu, Zhiwei Liu, Chaochao Chen, Jia Wu, Xu Bai, Philip S. Yu"
Neighborhood-aware Scalable Temporal Network Representation Learning,"Temporal networks have been widely used to model real-world complex systems
such as financial systems and e-commerce systems. In a temporal network, the
joint neighborhood of a set of nodes often provides crucial structural
information useful for predicting whether they may interact at a certain time.
However, recent representation learning methods for temporal networks often
fail to extract such information or depend on online construction of structural
features, which is time-consuming. To address the issue, this work proposes
Neighborhood-Aware Temporal network model (NAT). For each node in the network,
NAT abandons the commonly-used one-single-vector-based representation while
adopting a novel dictionary-type neighborhood representation. Such a dictionary
representation records a downsampled set of the neighboring nodes as keys, and
allows fast construction of structural features for a joint neighborhood of
multiple nodes. We also design a dedicated data structure termed N-cache to
support parallel access and update of those dictionary representations on GPUs.
NAT gets evaluated over seven real-world large-scale temporal networks. NAT not
only outperforms all cutting-edge baselines by averaged 1.2% and 4.2% in
transductive and inductive link prediction accuracy, respectively, but also
keeps scalable by achieving a speed-up of 4.1-76.7x against the baselines that
adopt joint structural features and achieves a speed-up of 1.6-4.0x against the
baselines that cannot adopt those features. The link to the code: https:
//github.com/Graph-COM/Neighborhood-Aware-Temporal-Network.",2022-09-02,"Yuhong Luo, Pan Li"
"Digital Traces of Brain Drain: Developers during the Russian Invasion of
  Ukraine","The Russian invasion of Ukraine has caused large scale destruction,
significant loss of life, and the displacement of millions of people. Besides
those fleeing direct conflict in Ukraine, many individuals in Russia are also
thought to have moved to third countries. In particular the exodus of skilled
human capital, sometimes called brain drain, out of Russia may have a
significant effect on the course of the war and the Russian economy in the long
run. Yet quantifying brain drain, especially during crisis situations is
generally difficult. This hinders our ability to understand its drivers and to
anticipate its consequences. To address this gap, I draw on and extend a large
scale dataset of the locations of highly active software developers collected
in February 2021, one year before the invasion. Revisiting those developers
that had been located in Russia in 2021, I confirm an ongoing exodus of
developers from Russia in snapshots taken in June and November 2022. By
November 11.1% of Russian developers list a new country, compared with 2.8% of
developers from comparable countries in the region but not directly involved in
the conflict. 13.2% of Russian developers have obscured their location (vs.
2.4% in the comparison set). Developers leaving Russia were significantly more
active and central in the collaboration network than those who remain. This
suggests that many of the most important developers have already left Russia.
In some receiving countries the number of arrivals is significant: I estimate
an increase in the number of local software developers of 42% in Armenia, 60%
in Cyprus and 94% in Georgia.",2022-09-02,Johannes Wachs
Representing Social Networks as Dynamic Heterogeneous Graphs,"Graph representations for real-world social networks in the past have missed
two important elements: the multiplexity of connections as well as representing
time. To this end, in this paper, we present a new dynamic heterogeneous graph
representation for social networks which includes time in every single
component of the graph, i.e., nodes and edges, each of different types that
captures heterogeneity. We illustrate the power of this representation by
presenting four time-dependent queries and deep learning problems that cannot
easily be handled in conventional homogeneous graph representations commonly
used. As a proof of concept we present a detailed representation of a new
social media platform (Steemit), which we use to illustrate both the dynamic
querying capability as well as prediction tasks using graph neural networks
(GNNs). The results illustrate the power of the dynamic heterogeneous graph
representation to model social networks. Given that this is a relatively
understudied area we also illustrate opportunities for future work in query
optimization as well as new dynamic prediction tasks on heterogeneous graph
structures.",2022-09-02,"Negar Maleki, Balaji Padamanabhan, Kaushik Dutta"
"Adversarial for Social Privacy: A Poisoning Strategy to Degrade User
  Identity Linkage","Privacy issues on social networks have been extensively discussed in recent
years. The user identity linkage (UIL) task, aiming at finding corresponding
users across different social networks, would be a threat to privacy if
unethically applied. The sensitive user information might be detected through
connected identities. A promising and novel solution to this issue is to design
an adversarial strategy to degrade the matching performance of UIL models.
However, most existing adversarial attacks on graphs are designed for models
working in a single network, while UIL is a cross-network learning task.
Meanwhile, privacy protection against UIL works unilaterally in real-world
scenarios, i.e., the service provider can only add perturbations to its own
network to protect its users from being linked. To tackle these challenges,
this paper proposes a novel adversarial attack strategy that poisons one target
network to prevent its nodes from being linked to other networks by UIL
algorithms. Specifically, we reformalize the UIL problem in the perspective of
kernelized topology consistency and convert the attack objective to maximizing
the structural changes within the target network before and after attacks. A
novel graph kernel is then defined with Earth mover's distance (EMD) on the
edge-embedding space. In terms of efficiency, a fast attack strategy is
proposed by greedy searching and replacing EMD with its lower bound. Results on
three real-world datasets indicate that the proposed attacks can best fool a
wide range of UIL models and reach a balance between attack effectiveness and
imperceptibility.",2022-09-01,"Jiangli Shao, Yongqing Wang, Boshen Shi, Hao Gao, Huawei Shen, Xueqi Cheng"
"Sparsification of the regularized magnetic Laplacian with multi-type
  spanning forests","In this paper, we consider a ${\rm U}(1)$-connection graph, that is, a graph
where each oriented edge is endowed with a unit modulus complex number that is
conjugated under orientation flip. A natural replacement for the combinatorial
Laplacian is then the magnetic Laplacian, an Hermitian matrix that includes
information about the graph's connection. Magnetic Laplacians appear, e.g., in
the problem of angular synchronization. In the context of large and dense
graphs, we study here sparsifiers of the magnetic Laplacian $\Delta$, i.e.,
spectral approximations based on subgraphs with few edges. Our approach relies
on sampling multi-type spanning forests (MTSFs) using a custom determinantal
point process, a probability distribution over edges that favours diversity. In
a word, an MTSF is a spanning subgraph whose connected components are either
trees or cycle-rooted trees. The latter partially capture the angular
inconsistencies of the connection graph, and thus provide a way to compress the
information contained in the connection. Interestingly, when the connection
graph has weakly inconsistent cycles, samples from the determinantal point
process under consideration can be obtained \`a la Wilson, using a random walk
with cycle popping. We provide statistical guarantees for a choice of natural
estimators of the connection Laplacian, and investigate two practical
applications of our sparsifiers: ranking with angular synchronization and
graph-based semi-supervised learning. From a statistical perspective, a side
result of this paper of independent interest is a matrix Chernoff bound with
intrinsic dimension, which allows considering the influence of a regularization
-- of the form $\Delta + q \mathbb{I}$ with $q>0$ -- on sparsification
guarantees.",2022-08-31,"Michaël Fanuel, Rémi Bardenet"
Graph Neural Networks with Motif-aware for Tenuous Subgraph Finding,"Tenuous subgraph finding aims to detect a subgraph with few social
interactions and weak relationships among nodes. Despite significant efforts
have been made on this task, they are mostly carried out in view of
graph-structured data. These methods depend on calculating the shortest path
and need to enumerate all the paths between nodes, which suffer the
combinatorial explosion. Moreover, they all lack the integration of
neighborhood information. To this end, we propose a novel model named Graph
Neural Network with Motif-aware for tenuous subgraph finding (GNNM), a
neighborhood aggregation based GNNs framework which can capture the latent
relationship between nodes. Specially, we design a GNN module to project nodes
into a low dimensional vector combining the higher-order correlation within
nodes based on a motif-aware module. And then design greedy algorithms in
vector space to obtain a tenuous subgraph whose size is greater than a
specified constraint. Particularly, considering existing evaluation indicators
cannot capture the latent friendship between nodes, we introduce a novel
Potential Friend(PF) concept to measure the tenuity of a graph from a new
perspective. Experimental results on the real-world and synthetic datasets
demonstrate that our proposed method GNNM outperforms existing algorithms in
efficiency and subgraph quality.",2022-08-31,"Heli sun, Miaomiao Sun, Liang He, Xiaolin Jia"
"Biased Bytes: On the Validity of Estimating Food Consumption from
  Digital Traces","Given that measuring food consumption at a population scale is a challenging
task, researchers have begun to explore digital traces (e.g., from social media
or from food-tracking applications) as potential proxies. However, it remains
unclear to what extent digital traces reflect real food consumption. The
present study aims to bridge this gap by quantifying the link between dietary
behaviors as captured via social media (Twitter) v.s. a food-tracking
application (MyFoodRepo). We focus on the case of Switzerland and contrast
images of foods collected through the two platforms, by designing and deploying
a novel crowdsourcing framework for estimating biases with respect to
nutritional properties and appearance. We find that the food type distributions
in social media v.s. food tracking diverge; e.g., bread is 2.5 times more
frequent among consumed and tracked foods than on Twitter, whereas cake is 12
times more frequent on Twitter. Controlling for the different food type
distributions, we contrast consumed and tracked foods of a given type with
foods shared on Twitter. Across food types, food posted on Twitter is perceived
as tastier, more caloric, less healthy, less likely to have been consumed at
home, more complex, and larger-portioned, compared to consumed and tracked
foods. The fact that there is a divergence between food consumption as measured
via the two platforms implies that at least one of the two is not a faithful
representation of the true food consumption in the general Swiss population.
Thus, researchers should be attentive and aim to establish evidence of validity
before using digital traces as a proxy for the true food consumption of a
general population. We conclude by discussing the potential sources of these
biases and their implications, outlining pitfalls and threats to validity, and
proposing actionable ways for overcoming them.",2022-08-30,"Kristina Gligorić, Irena Đorđević, Robert West"
"Who talks about what? Comparing the information treatment in traditional
  media with online discussions","We study the dynamics of interactions between a traditional medium, the New
York Times journal, and its followers in Twitter, using a massive dataset. It
consists of the metadata of the articles published by the journal during the
first year of the COVID-19 pandemic, and the posts published in Twitter by a
large set of followers of the @nytimes account along with those published by a
set of followers of several other media of different kind. The dynamics of
discussions held in Twitter by exclusive followers of a medium show a strong
dependence on the medium they follow: the followers of @FoxNews show the
highest similarity to each other and a strong differentiation of interests with
the general group. Our results also reveal the difference in the attention
payed to U.S. presidential elections by the journal and by its followers, and
show that the topic related to the ``Black Lives Matter'' movement started in
Twitter, and was addressed later by the journal.",2022-08-30,"Hendrik Schawe, Mariano Gastón Beiró, J. Ignacio Alvarez-Hamelin, Dimitris Kotzinos, Laura Hernández"
"Expressions Causing Differences in Emotion Recognition in Social
  Networking Service Documents","It is often difficult to correctly infer a writer's emotion from text
exchanged online, and differences in recognition between writers and readers
can be problematic. In this paper, we propose a new framework for detecting
sentences that create differences in emotion recognition between the writer and
the reader and for detecting the kinds of expressions that cause such
differences. The proposed framework consists of a bidirectional encoder
representations from transformers (BERT)-based detector that detects sentences
causing differences in emotion recognition and an analysis that acquires
expressions that characteristically appear in such sentences. The detector,
based on a Japanese SNS-document dataset with emotion labels annotated by both
the writer and three readers of the social networking service (SNS) documents,
detected ""hidden-anger sentences"" with AUC = 0.772; these sentences gave rise
to differences in the recognition of anger. Because SNS documents contain many
sentences whose meaning is extremely difficult to interpret, by analyzing the
sentences detected by this detector, we obtained several expressions that
appear characteristically in hidden-anger sentences. The detected sentences and
expressions do not convey anger explicitly, and it is difficult to infer the
writer's anger, but if the implicit anger is pointed out, it becomes possible
to guess why the writer is angry. Put into practical use, this framework would
likely have the ability to mitigate problems based on misunderstandings.",2022-08-30,"Tsubasa Nakagawa, Shunsuke Kitada, Hitoshi Iyatomi"
"Multi-dimensional Racism Classification during COVID-19: Stigmatization,
  Offensiveness, Blame, and Exclusion","Transcending the binary categorization of racist texts, our study takes cues
from social science theories to develop a multi-dimensional model for racism
detection, namely stigmatization, offensiveness, blame, and exclusion. With the
aid of BERT and topic modeling, this categorical detection enables insights
into the underlying subtlety of racist discussion on digital platforms during
COVID-19. Our study contributes to enriching the scholarly discussion on
deviant racist behaviours on social media. First, a stage-wise analysis is
applied to capture the dynamics of the topic changes across the early stages of
COVID-19 which transformed from a domestic epidemic to an international public
health emergency and later to a global pandemic. Furthermore, mapping this
trend enables a more accurate prediction of public opinion evolvement
concerning racism in the offline world, and meanwhile, the enactment of
specified intervention strategies to combat the upsurge of racism during the
global public health crisis like COVID-19. In addition, this interdisciplinary
research also points out a direction for future studies on social network
analysis and mining. Integration of social science perspectives into the
development of computational methods provides insights into more accurate data
detection and analytics.",2022-08-29,"Xin Pei, Deval Mehta"
"Influence Maximization (IM) in Complex Networks with Limited Visibility
  Using Statistical Methods","A social network (SN) is a social structure consisting of a group
representing the interaction between them. SNs have recently been widely used
and, subsequently, have become suitable and popular platforms for product
promotion and information diffusion. People in an SN directly influence each
other's interests and behavior. One of the most important problems in SNs is to
find people who can have the maximum influence on other nodes in the network in
a cascade manner if they are chosen as the seed nodes of a network diffusion
scenario. Influential diffusers are people who, if they are chosen as the seed
set in a publishing issue in the network, that network will have the most
people who have learned about that diffused entity. This is a well-known
problem in literature known as influence maximization (IM) problem. Although it
has been proven that this is an NP-complete problem and does not have a
solution in polynomial time, it has been argued that it has the properties of
sub modular functions and, therefore, can be solved using a greedy algorithm.
Most of the methods proposed to improve this complexity are based on the
assumption that the entire graph is visible. However, this assumption does not
hold for many real-world graphs. This study is conducted to extend current
maximization methods with link prediction techniques to pseudo-visibility
graphs. To this end, a graph generation method called the exponential random
graph model (ERGM) is used for link prediction. The proposed method is tested
using the data from the Snap dataset of Stanford University. According to the
experimental tests, the proposed method is efficient on real-world graphs.",2022-08-28,"Saeid Ghafouri, Seyed Hossein Khasteh, Seyed Omid Azarkasb"
"Opinion Leader Detection in Online Social Networks Based on Output and
  Input Links","The understanding of how users in a network update their opinions based on
their neighbours opinions has attracted a great deal of interest in the field
of network science, and a growing body of literature recognises the
significance of this issue. In this research paper, we propose a new dynamic
model of opinion formation in directed networks. In this model, the opinion of
each node is updated as the weighted average of its neighbours opinions, where
the weights represent social influence. We define a new centrality measure as a
social influence metric based on both influence and conformity. We measure this
new approach using two opinion formation models: (i) the Degroot model and (ii)
our own proposed model. Previously published research studies have not
considered conformity, and have only considered the influence of the nodes when
computing the social influence. In our definition, nodes with low in-degree and
high out-degree that were connected to nodes with high out-degree and low
in-degree had higher centrality. As the main contribution of this research, we
propose an algorithm for finding a small subset of nodes in a social network
that can have a significant impact on the opinions of other nodes. Experiments
on real-world data demonstrate that the proposed algorithm significantly
outperforms previously published state-of-the-art methods.",2022-08-28,"Zahra Ghorbani, Seyed Hossein Khasteh, Saeid Ghafouri"
An event detection technique using social media data,"People post information about different topics which are in their active
vocabulary over social media platforms (like Twitter, Facebook, PInterest and
Google+). They follow each other and it is more likely that the person who
posts information about current happenings will receive better response. Manual
analysis of huge amount of data on social media platforms is difficult. This
has opened new research directions for automatic analysis of usercontributed
social media documents. Automatic social media data analysis is difficult due
to abundant information shared by users. Many researchers use Twitter data for
Social Media Analysis (SMA) as the Twitter data is freely available in the
public domain. One of the most this research work. Event Detection from social
media data is used for different applications like traffic congestion
detection, disaster and emergency management, and live news detection. Nature
of the information which is shared on twitter platform is short-text, noisy,
and ambiguous. Thus, event detection and extraction of event phrases from
user-generated and illformed data becomes challenging. To address these
challenges, events are extracted from streaming social media data in the form
of keyphrases using different cognitive properties. The motivation behind this
research work is to provide substantial improvements in the lexical variation
of event phrases while detecting events and sub-events from twitter data. In
this research work, the approach towards event detection from social media data
is divided into three phases namely: Identifying sub-graphs in Microblog Word
Co-occurrence Network (WCN) which provides important information about
keyphrases; Identifying multiple events from social media data; and Ranking
contextual information of event phrases.",2022-08-27,Muskan Garg
"YouTube COVID-19 Vaccine Misinformation on Twitter: Platform
  Interactions and Moderation Blind Spots","While most social media companies have attempted to address the challenge of
COVID-19 misinformation, the success of those policies is difficult to assess,
especially when focusing on individual platforms. This study explores the
relationship between Twitter and YouTube in spreading COVID-19 vaccine-related
misinformation through a mixed-methods approach to analyzing a collection of
tweets in 2021 sharing YouTube videos where those Twitter accounts had also
linked to deleted YouTube videos. Principal components, cluster and network
analyses are used to group the videos and tweets into interpretable groups by
shared tweet dates, terms and sharing patterns; content analysis is employed to
assess the orientation of tweets and videos to COVID-19 messages. From this we
observe that a preponderance of anti-vaccine messaging remains among users who
previously shared suspect information, in which a dissident political framing
dominates, and which suggests moderation policy inefficacy where the platforms
interact.",2022-08-27,"David S. Axelrod, Brian P. Harper, John C. Paolillo"
Consistency between ordering and clustering methods for graphs,"A relational dataset is often analyzed by optimally assigning a label to each
element through clustering or ordering. While similar characterizations of a
dataset would be achieved by both clustering and ordering methods, the former
has been studied much more actively than the latter, particularly for the data
represented as graphs. This study fills this gap by investigating
methodological relationships between several clustering and ordering methods,
focusing on spectral techniques. Furthermore, we evaluate the resulting
performance of the clustering and ordering methods. To this end, we propose a
measure called the label continuity error, which generically quantifies the
degree of consistency between a sequence and partition for a set of elements.
Based on synthetic and real-world datasets, we evaluate the extents to which an
ordering method identifies a module structure and a clustering method
identifies a banded structure.",2022-08-27,"Tatsuro Kawamoto, Masaki Ochi, Teruyoshi Kobayashi"
"Combinations of Affinity Functions for Different Community Detection
  Algorithms in Social Networks","Social network analysis is a popular discipline among the social and
behavioural sciences, in which the relationships between different social
entities are modelled as a network. One of the most popular problems in social
network analysis is finding communities in its network structure. Usually, a
community in a social network is a functional sub-partition of the graph.
However, as the definition of community is somewhat imprecise, many algorithms
have been proposed to solve this task, each of them focusing on different
social characteristics of the actors and the communities. In this work we
propose to use novel combinations of affinity functions, which are designed to
capture different social mechanics in the network interactions. We use them to
extend already existing community detection algorithms in order to combine the
capacity of the affinity functions to model different social interactions than
those exploited by the original algorithms.",2022-08-26,"Javier Fumanal-Idocin, Oscar Cordón, María Minárová, Amparo Alonso-Betanzos, Humberto Bustince"
Remote Work Optimization with Robust Multi-channel Graph Neural Networks,"The spread of COVID-19 leads to the global shutdown of many corporate
offices, and encourages companies to open more opportunities that allow
employees to work from a remote location. As the workplace type expands from
onsite offices to remote areas, an emerging challenge for an online hiring
marketplace is how these remote opportunities and user intentions to work
remotely can be modeled and matched without prior information. Despite the
unprecedented amount of remote jobs posted amid COVID-19, there is no existing
approach that can be directly applied.
  Introducing a brand new workplace type naturally leads to the cold-start
problem, which is particularly more common for less active job seekers. It is
challenging, if not impossible, to onboard a new workplace type for any
predictive model if existing information sources can provide little information
related to a new category of jobs, including data from resumes and job
descriptions. Hence, in this work, we aim to propose a principled approach that
jointly models the remoteness of job seekers and job opportunities with limited
information, which also suffices the needs of web-scale applications. Existing
research on the emerging type of remote workplace mainly focuses on qualitative
studies, and classic predictive modeling approaches are inapplicable
considering the problem of cold-start and information scarcity. We precisely
try to close this gap with a novel graph neural architecture. Extensive
experiments on large-scale data from real-world applications have been
conducted to validate the superiority of the proposed approach over competitive
baselines. The improvement may translate to more rapid onboarding of the new
workplace type that can benefit job seekers who are interested in working
remotely.",2022-08-26,"Qinyi Zhu, Liang Wu, Qi Guo, Liangjie Hong"
"Deep Learning-Based Sentiment Analysis of COVID-19 Vaccination Responses
  from Twitter Data","This COVID-19 pandemic is so dreadful that it leads to severe anxiety,
phobias, and complicated feelings or emotions. Even after vaccination against
Coronavirus has been initiated, people feelings have become more diverse and
complex, and our goal is to understand and unravel their sentiments in this
research using some Deep Learning techniques. Social media is currently the
best way to express feelings and emotions, and with the help of it,
specifically Twitter, one can have a better idea of what is trending and what
is going on in people minds. Our motivation for this research is to understand
the sentiment of people regarding the vaccination process, and their diverse
thoughts regarding this. In this research, the timeline of the collected tweets
was from December 21 to July 21, and contained tweets about the most common
vaccines available recently from all across the world. The sentiments of people
regarding vaccines of all sorts were assessed by using a Natural Language
Processing (NLP) tool named Valence Aware Dictionary for sEntiment Reasoner
(VADER). By initializing the sentiment polarities into 3 groups (positive,
negative and neutral), the overall scenario was visualized here and our
findings came out as 33.96% positive, 17.55% negative and 48.49% neutral
responses. Recurrent Neural Network (RNN) oriented architecture such as Long
Short-Term Memory (LSTM and Bi-LSTM) is used to assess the performance of the
predictive models, with LSTM achieving an accuracy of 90.59% and Bi-LSTM
achieving an accuracy of 90.83%. Other performance metrics such as Precision,
Recall, F-1 score, and Confusion matrix were also shown to validate our models
and findings more effectively. This study will help everyone understand public
opinion on the COVID-19 vaccines and impact the aim of eradicating the
Coronavirus from our beautiful world.",2022-08-26,"Kazi Nabiul Alam, Md Shakib Khan, Abdur Rab Dhruba, Mohammad Monirujjaman Khan, Jehad F. Al-Amri, Mehedi Masud, Majdi Rawashdeh"
"Local Intrinsic Dimensionality Measures for Graphs, with Applications to
  Graph Embeddings","The notion of local intrinsic dimensionality (LID) is an important
advancement in data dimensionality analysis, with applications in data mining,
machine learning and similarity search problems. Existing distance-based LID
estimators were designed for tabular datasets encompassing data points
represented as vectors in a Euclidean space. After discussing their limitations
for graph-structured data considering graph embeddings and graph distances, we
propose NC-LID, a novel LID-related measure for quantifying the discriminatory
power of the shortest-path distance with respect to natural communities of
nodes as their intrinsic localities. It is shown how this measure can be used
to design LID-aware graph embedding algorithms by formulating two LID-elastic
variants of node2vec with personalized hyperparameters that are adjusted
according to NC-LID values. Our empirical analysis of NC-LID on a large number
of real-world graphs shows that this measure is able to point to nodes with
high link reconstruction errors in node2vec embeddings better than node
centrality metrics. The experimental evaluation also shows that the proposed
LID-elastic node2vec extensions improve node2vec by better preserving graph
structure in generated embeddings.",2022-08-25,"Miloš Savić, Vladimir Kurbalija, Miloš Radovanović"
Motif-Based Visual Analysis of Dynamic Networks,"Many data analysis problems rely on dynamic networks, such as social or
communication network analyses. Providing a scalable overview of long sequences
of such dynamic networks remains challenging due to the underlying large-scale
data containing elusive topological changes. We propose two complementary
pixel-based visualizations, which reflect occurrences of selected sub-networks
(motifs) and provide a time-scalable overview of dynamic networks: a
network-level census (motif significance profiles) linked with a node-level
sub-network metric (graphlet degree vectors) views to reveal structural
changes, trends, states, and outliers. The network census captures
significantly occurring motifs compared to their expected occurrences in random
networks and exposes structural changes in a dynamic network. The sub-network
metrics display the local topological neighborhood of a node in a single
network belonging to the dynamic network. The linked pixel-based visualizations
allow exploring motifs in different-sized networks to analyze the changing
structures within and across dynamic networks, for instance, to visually
analyze the shape and rate of changes in the network topology. We describe the
identification of visual patterns, also considering different reordering
strategies to emphasize visual patterns. We demonstrate the approach's
usefulness by a use case analysis based on real-world large-scale dynamic
networks, such as the evolving social networks of Reddit or Facebook.",2022-08-25,"Eren Cakmak, Johannes Fuchs, Dominik Jäckle, Tobias Schreck, Ulrik Brandes, Daniel Keim"
Graphical Models of False Information and Fact Checking Ecosystems,"The wide spread of false information online including misinformation and
disinformation has become a major problem for our highly digitised and
globalised society. A lot of research has been done to better understand
different aspects of false information online such as behaviours of different
actors and patterns of spreading, and also on better detection and prevention
of such information using technical and socio-technical means. One major
approach to detect and debunk false information online is to use human
fact-checkers, who can be helped by automated tools. Despite a lot of research
done, we noticed a significant gap on the lack of conceptual models describing
the complicated ecosystems of false information and fact checking. In this
paper, we report the first graphical models of such ecosystems, focusing on
false information online in multiple contexts, including traditional media
outlets and user-generated content. The proposed models cover a wide range of
entity types and relationships, and can be a new useful tool for researchers
and practitioners to study false information online and the effects of fact
checking.",2022-08-24,"Haiyue Yuan, Enes Altuncu, Shujun Li, Can Baskent"
Instance generation tool for on-demand transportation problems,"We present REQreate, a tool to generate instances for on-demand
transportation problems. Such problems consist of optimizing the routes of
vehicles according to passengers' demand for transportation under space and
time restrictions (requests). REQreate is flexible and can be configured to
generate instances for a large number of problems in this problem class. In
this paper, we demonstrate this by generating instances for the Dial-a-Ride
Problem (DARP) and On-demand Bus Routing Problem (ODBRP). In most of the
literature, researchers either test their algorithms with instances based on
artificial networks or perform real-life case studies on instances derived from
a specific city or region. Furthermore, locations of requests for on-demand
transportation problems are mostly randomly chosen according to a uniform
distribution.
  The aim of REQreate is to overcome these non-realistic and overfitting
shortcomings. Rather than relying on either artificial or limited data, we
retrieve real-world street networks from OpenStreetMaps (OSM). To the best of
our knowledge, this is the first tool to make use of real-life networks to
generate instances for an extensive catalogue of existing and upcoming
on-demand transportation problems. Additionally, we present a simple method
that can be embedded in the instance generation process to produce distinct
urban mobility patterns. We perform an analysis with real life datasets
reported by rideshare companies and compare them with properties of synthetic
instances generated with REQreate. Another contribution of this work is the
introduction of the concept of instance similarity that serves as support to
create diverse benchmark sets, in addition to properties (size, dynamism,
urgency and geographic dispersion) that could be used to comprehend what
affects the performance of algorithms.",2022-08-23,"Michell Queiroz, Flavien Lucas, Kenneth Sorensen"
"Community Detection in the Hypergraph SBM: Exact Recovery Given the
  Similarity Matrix","Community detection is a fundamental problem in network science. In this
paper, we consider community detection in hypergraphs drawn from the
$hypergraph$ $stochastic$ $block$ $model$ (HSBM), with a focus on exact
community recovery. We study the performance of polynomial-time algorithms
which operate on the $similarity$ $matrix$ $W$, where $W_{ij}$ reports the
number of hyperedges containing both $i$ and $j$. Under this information model,
while the precise information-theoretic limit is unknown, Kim, Bandeira, and
Goemans derived a sharp threshold up to which the natural min-bisection
estimator on $W$ succeeds. As min-bisection is NP-hard in the worst case, they
additionally proposed a semidefinite programming (SDP) relaxation and
conjectured that it achieves the same recovery threshold as the min-bisection
estimator.
  In this paper, we confirm this conjecture. We also design a simple and highly
efficient spectral algorithm with nearly linear runtime and show that it
achieves the min-bisection threshold. Moreover, the spectral algorithm also
succeeds in denser regimes and is considerably more efficient than previous
approaches, establishing it as the method of choice. Our analysis of the
spectral algorithm crucially relies on strong $entrywise$ bounds on the
eigenvectors of $W$. Our bounds are inspired by the work of Abbe, Fan, Wang,
and Zhong, who developed entrywise bounds for eigenvectors of symmetric
matrices with independent entries. Despite the complex dependency structure in
similarity matrices, we prove similar entrywise guarantees.",2022-08-23,"Julia Gaudio, Nirmit Joshi"
"Grad-Align+: Empowering Gradual Network Alignment Using Attribute
  Augmentation","Network alignment (NA) is the task of discovering node correspondences across
different networks. Although NA methods have achieved remarkable success in a
myriad of scenarios, their satisfactory performance is not without prior anchor
link information and/or node attributes, which may not always be available. In
this paper, we propose Grad-Align+, a novel NA method using node attribute
augmentation that is quite robust to the absence of such additional
information. Grad-Align+ is built upon a recent state-of-the-art NA method, the
so-called Grad-Align, that gradually discovers only a part of node pairs until
all node pairs are found. Specifically, Grad-Align+ is composed of the
following key components: 1) augmenting node attributes based on nodes'
centrality measures, 2) calculating an embedding similarity matrix extracted
from a graph neural network into which the augmented node attributes are fed,
and 3) gradually discovering node pairs by calculating similarities between
cross-network nodes with respect to the aligned cross-network neighbor-pair.
Experimental results demonstrate that Grad-Align+ exhibits (a) superiority over
benchmark NA methods, (b) empirical validation of our theoretical findings, and
(c) the effectiveness of our attribute augmentation module.",2022-08-23,"Jin-Duk Park, Cong Tran, Won-Yong Shin, Xin Cao"
"AI and 6G into the Metaverse: Fundamentals, Challenges and Future
  Research Trends","Since Facebook was renamed Meta, a lot of attention, debate, and exploration
have intensified about what the Metaverse is, how it works, and the possible
ways to exploit it. It is anticipated that Metaverse will be a continuum of
rapidly emerging technologies, usecases, capabilities, and experiences that
will make it up for the next evolution of the Internet. Several researchers
have already surveyed the literature on artificial intelligence (AI) and
wireless communications in realizing the Metaverse. However, due to the rapid
emergence and continuous evolution of technologies, there is a need for a
comprehensive and in-depth survey of the role of AI, 6G, and the nexus of both
in realizing the immersive experiences of Metaverse. Therefore, in this survey,
we first introduce the background and ongoing progress in augmented reality
(AR), virtual reality (VR), mixed reality (MR) and spatial computing, followed
by the technical aspects of AI and 6G. Then, we survey the role of AI in the
Metaverse by reviewing the state-of-the-art in deep learning, computer vision,
and Edge AI to extract the requirements of 6G in Metaverse. Next, we
investigate the promising services of B5G/6G towards Metaverse, followed by
identifying the role of AI in 6G networks and 6G networks for AI in support of
Metaverse applications, and the need for sustainability in Metaverse. Finally,
we enlist the existing and potential applications, usecases, and projects to
highlight the importance of progress in the Metaverse. Moreover, in order to
provide potential research directions to researchers, we underline the
challenges, research gaps, and lessons learned identified from the literature
review of the aforementioned technologies.",2022-08-23,"Muhammad Zawish, Fayaz Ali Dharejo, Sunder Ali Khowaja, Kapal Dev, Steven Davy, Nawab Muhammad Faseeh Qureshi, Paolo Bellavista"
"Fake News Identification using Machine Learning Algorithms Based on
  Graph Features","The spread of fake news has long been a social issue and the necessity of
identifying it has become evident since its dangers are well recognized. In
addition to causing uneasiness among the public, it has even more devastating
consequences. For instance, it might lead to death during pandemics due to
unverified medical instructions. This study aims to build a model for
identifying fake news using graphs and machine learning algorithms. Instead of
scanning the news content or user information, the research explicitly focuses
on the spreading network, which shows the interconnection among people, and
graph features such as the Eigenvector centrality, Jaccard Coefficient, and the
shortest path. Fourteen features are extracted from graphs and tested in
thirteen machine learning models. After analyzing these features and comparing
the test result of machine learning models, the results reflect that propensity
and centrality contribute highly to the classification. The best performing
models reach 0.9913 and 0.9987 separately from datasets Twitter15 and Twitter16
using a modified tree classifier and Support Vector Classifier. This model can
effectively predict fake news, prevent potential negative social impact caused
by fake news, and provide a new perspective on graph feature selection for
machine learning models.",2022-08-22,Yuxuan Tian
"Detect Hate Speech in Unseen Domains using Multi-Task Learning: A Case
  Study of Political Public Figures","Automatic identification of hateful and abusive content is vital in combating
the spread of harmful online content and its damaging effects. Most existing
works evaluate models by examining the generalization error on train-test
splits on hate speech datasets. These datasets often differ in their
definitions and labeling criteria, leading to poor model performance when
predicting across new domains and datasets. In this work, we propose a new
Multi-task Learning (MTL) pipeline that utilizes MTL to train simultaneously
across multiple hate speech datasets to construct a more encompassing
classification model. We simulate evaluation on new previously unseen datasets
by adopting a leave-one-out scheme in which we omit a target dataset from
training and jointly train on the other datasets. Our results consistently
outperform a large sample of existing work. We show strong results when
examining generalization error in train-test splits and substantial
improvements when predicting on previously unseen datasets. Furthermore, we
assemble a novel dataset, dubbed PubFigs, focusing on the problematic speech of
American Public Political Figures. We automatically detect problematic speech
in the $305,235$ tweets in PubFigs, and we uncover insights into the posting
behaviors of public figures.",2022-08-22,"Lanqin Yuan, Marian-Andrei Rizoiu"
Scalable link prediction in Twitter using self-configured framework,"Link prediction analysis becomes vital to acquire a deeper understanding of
events underlying social networks interactions and connections especially in
current evolving and large-scale social networks. Traditional link prediction
approaches underperformed for most large-scale social networks in terms of its
scalability and efficiency. Spark is a distributed open-source framework that
facilitate scalable link prediction efficiency in large-scale social networks.
The framework provides numerous tunable properties for users to manually
configure the parameters for the applications. However, manual configurations
open to performance issue when the applications start scaling tremendously,
which is hard to set up and expose to human errors. This paper introduced a
novel Self-Configured Framework (SCF) to provide an autonomous feature in Spark
that predicts and sets the best configuration instantly before the application
execution using XGBoost classifier. SCF is evaluated on the Twitter social
network using three link prediction applications: Graph Clustering (GC),
Overlapping Community Detection (OCD), and Redundant Graph Clustering (RGD) to
assess the impact of shifting data sizes on different applications in Twitter.
The result demonstrates a 40% reduction in prediction time as well as a
balanced resource consumption that makes full use of resources, especially for
limited number and size of clusters",2022-08-21,"Nur Nasuha Daud, Siti Hafizah Ab Hamid, Chempaka Seri, Muntadher Saadoon, Nor Badrul Anuar"
From Time Series to Networks in R with the ts2net Package,"Network science established itself as a prominent tool for modeling time
series and complex systems. This modeling process consists of transforming a
set or a single time series into a network. Nodes may represent complete time
series, segments, or single values, while links define associations or
similarities between the represented parts. R is one of the main programming
languages used in data science, statistics, and machine learning, with many
packages available. However, no single package provides the necessary methods
to transform time series into networks. This paper presents ts2net, an R
package for modeling one or multiple time series into networks. The package
provides the time series distance functions that can be easily computed in
parallel and in supercomputers to process larger data sets and methods to
transform distance matrices into networks. Ts2net also provides methods to
transform a single time series into a network, such as recurrence networks,
visibility graphs, and transition networks. Together with other packages,
ts2net permits using network science and graph mining tools to extract
information from time series.",2022-08-20,Leonardo N. Ferreira
Searching for Structure in Unfalsifiable Claims,"Social media platforms give rise to an abundance of posts and comments on
every topic imaginable. Many of these posts express opinions on various aspects
of society, but their unfalsifiable nature makes them ill-suited to
fact-checking pipelines. In this work, we aim to distill such posts into a
small set of narratives that capture the essential claims related to a given
topic. Understanding and visualizing these narratives can facilitate more
informed debates on social media. As a first step towards systematically
identifying the underlying narratives on social media, we introduce PAPYER, a
fine-grained dataset of online comments related to hygiene in public restrooms,
which contains a multitude of unfalsifiable claims. We present a
human-in-the-loop pipeline that uses a combination of machine and human kernels
to discover the prevailing narratives and show that this pipeline outperforms
recent large transformer models and state-of-the-art unsupervised topic models.",2022-08-19,"Peter Ebert Christensen, Frederik Warburg, Menglin Jia, Serge Belongie"
IRMA: Iterative Repair for graph MAtching,"The alignment of two similar graphs from different domains is a well-studied
problem. In many practical usages, there is no reliable information or labels
over the vertices or edges, leaving structural similarity as the only
information available to match such a graph. In such cases, one often assumes a
small amount of already aligned vertices -- called a seed. Current
state-of-the-art scalable seeded alignment algorithms are based on percolation.
Namely, aligned vertices are used to align their neighbors and gradually
percolate in parallel in both graphs. However, percolation-based graph
alignment algorithms are still limited in scale-free degree distributions. We
here propose `IRMA' -- Iterative Repair for graph MAtching to show that the
accuracy of percolation-based algorithms can be improved in real-world graphs
with a limited additional computational cost, and with lower run time when used
in a parallel version. IRMA starts by creating a primary alignment using an
existing percolation algorithm, then it iteratively repairs the mistakes in the
previous alignment steps. We prove that IRMA improves on single-iteration
algorithms. We then numerically show that it is significantly better than all
state-of-the-art seeded graph alignment algorithms on the graphs that they
tested. In scale-free networks, many vertices have a very low degree. Such
vertices have a high probability of erroneous alignments. We show that
combining iterations with high recall but low precision in the alignment leads
in the long run to higher recall and precision for the entire alignment.",2022-08-19,"Barak Babayov, Yoram Louzoun"
"Personalizing Intervened Network for Long-tailed Sequential User
  Behavior Modeling","In an era of information explosion, recommendation systems play an important
role in people's daily life by facilitating content exploration. It is known
that user activeness, i.e., number of behaviors, tends to follow a long-tail
distribution, where the majority of users are with low activeness. In practice,
we observe that tail users suffer from significantly lower-quality
recommendation than the head users after joint training. We further identify
that a model trained on tail users separately still achieve inferior results
due to limited data. Though long-tail distributions are ubiquitous in
recommendation systems, improving the recommendation performance on the tail
users still remains challenge in both research and industry. Directly applying
related methods on long-tail distribution might be at risk of hurting the
experience of head users, which is less affordable since a small portion of
head users with high activeness contribute a considerate portion of platform
revenue. In this paper, we propose a novel approach that significantly improves
the recommendation performance of the tail users while achieving at least
comparable performance for the head users over the base model. The essence of
this approach is a novel Gradient Aggregation technique that learns common
knowledge shared by all users into a backbone model, followed by separate
plugin prediction networks for the head users and the tail users
personalization. As for common knowledge learning, we leverage the backward
adjustment from the causality theory for deconfounding the gradient estimation
and thus shielding off the backbone training from the confounder, i.e., user
activeness. We conduct extensive experiments on two public recommendation
benchmark datasets and a large-scale industrial datasets collected from the
Alipay platform. Empirical studies validate the rationality and effectiveness
of our approach.",2022-08-19,"Zheqi Lv, Feng Wang, Shengyu Zhang, Kun Kuang, Hongxia Yang, Fei Wu"
"AHEAD: A Triple Attention Based Heterogeneous Graph Anomaly Detection
  Approach","Graph anomaly detection on attributed networks has become a prevalent
research topic due to its broad applications in many influential domains. In
real-world scenarios, nodes and edges in attributed networks usually display
distinct heterogeneity, i.e. attributes of different types of nodes show great
variety, different types of relations represent diverse meanings. Anomalies
usually perform differently from the majority in various perspectives of
heterogeneity in these networks. However, existing graph anomaly detection
approaches do not leverage heterogeneity in attributed networks, which is
highly related to anomaly detection. In light of this problem, we propose
AHEAD: a heterogeneity-aware unsupervised graph anomaly detection approach
based on the encoder-decoder framework. Specifically, for the encoder, we
design three levels of attention, i.e. attribute level, node type level, and
edge level attentions to capture the heterogeneity of network structure, node
properties and information of a single node, respectively. In the decoder, we
exploit structure, attribute, and node type reconstruction terms to obtain an
anomaly score for each node. Extensive experiments show the superiority of
AHEAD on several real-world heterogeneous information networks compared with
the state-of-arts in the unsupervised setting. Further experiments verify the
effectiveness and robustness of our triple attention, model backbone, and
decoder in general.",2022-08-17,"Shujie Yang, Binchi Zhang, Shangbin Feng, Zhaoxuan Tan, Qinghua Zheng, Jun Zhou, Minnan Luo"
"Dismantling Complex Networks by a Neural Model Trained from Tiny
  Networks","Can we employ one neural model to efficiently dismantle many complex yet
unique networks? This article provides an affirmative answer. Diverse
real-world systems can be abstracted as complex networks each consisting of
many functional nodes and edges. Percolation theory has indicated that removing
only a few vital nodes can cause the collapse of whole network. However,
finding the least number of such vital nodes is a rather challenging task for
large networks due to its NP-hardness. Previous studies have proposed many
centrality measures and heuristic algorithms to tackle this network dismantling
(ND) problem. Different from theirs, this article tries to approach the ND task
by designing a neural model which can be trained from tiny synthetic networks
but will be applied for various real-world networks. It seems a discouraging
mission at first sight, as network sizes and topologies are quite different
across distinct real-world networks. Nonetheless, this article initiates
insightful efforts of designing and training a neural influence ranking model
(NIRM). Experiments on fifteen real-world networks validate its effectiveness
for its mostly requiring fewer vital nodes to dismantle a network, compared
with the state-of-the-art competitors. The key to its success lies in that our
NIRM can efficiently encode both local structural and global topological
signals for ranking nodes, in addition to our innovative labelling method in
training dataset construction.",2022-08-16,"Jiazheng Zhang, Bang Wang"
"American cultural regions mapped through the lexical analysis of social
  media","Cultural areas represent a useful concept that cross-fertilizes diverse
fields in social sciences. Knowledge of how humans organize and relate their
ideas and behavior within a society helps to understand their actions and
attitudes towards different issues. However, the selection of common traits
that shape a cultural area is somewhat arbitrary. What is needed is a method
that can leverage the massive amounts of data coming online, especially through
social media, to identify cultural regions without ad-hoc assumptions, biases
or prejudices. This work takes a crucial step in this direction by introducing
a method to infer cultural regions based on the automatic analysis of large
datasets from microblogging posts. The approach presented here is based on the
principle that cultural affiliation can be inferred from the topics that people
discuss among themselves. Specifically, regional variations in written
discourse are measured in American social media. From the frequency
distributions of content words in geotagged Tweets, the regional hotspots of
words' usage are found, and from there, principal components of regional
variation are derived. Through a hierarchical clustering of the data in this
lower-dimensional space, this method yields clear cultural areas and the topics
of discussion that define them. It uncovers a manifest North-South separation,
which is primarily influenced by the African American culture, and further
contiguous (East-West) and non-contiguous divisions that provide a
comprehensive picture of today's cultural areas in the US.",2022-08-16,"Thomas Louf, Bruno Gonçalves, Jose J. Ramasco, David Sanchez, Jack Grieve"
"Reliable Decision from Multiple Subtasks through Threshold Optimization:
  Content Moderation in the Wild","Social media platforms struggle to protect users from harmful content through
content moderation. These platforms have recently leveraged machine learning
models to cope with the vast amount of user-generated content daily. Since
moderation policies vary depending on countries and types of products, it is
common to train and deploy the models per policy. However, this approach is
highly inefficient, especially when the policies change, requiring dataset
re-labeling and model re-training on the shifted data distribution. To
alleviate this cost inefficiency, social media platforms often employ
third-party content moderation services that provide prediction scores of
multiple subtasks, such as predicting the existence of underage personnel, rude
gestures, or weapons, instead of directly providing final moderation decisions.
However, making a reliable automated moderation decision from the prediction
scores of the multiple subtasks for a specific target policy has not been
widely explored yet. In this study, we formulate real-world scenarios of
content moderation and introduce a simple yet effective threshold optimization
method that searches the optimal thresholds of the multiple subtasks to make a
reliable moderation decision in a cost-effective way. Extensive experiments
demonstrate that our approach shows better performance in content moderation
compared to existing threshold optimization methods and heuristics.",2022-08-16,"Donghyun Son, Byounggyu Lew, Kwanghee Choi, Yongsu Baek, Seungwoo Choi, Beomjun Shin, Sungjoo Ha, Buru Chang"
"Bias amplification in experimental social networks is reduced by
  resampling","Large-scale social networks are thought to contribute to polarization by
amplifying people's biases. However, the complexity of these technologies makes
it difficult to identify the mechanisms responsible and to evaluate mitigation
strategies. Here we show under controlled laboratory conditions that
information transmission through social networks amplifies motivational biases
on a simple perceptual decision-making task. Participants in a large behavioral
experiment showed increased rates of biased decision-making when part of a
social network relative to asocial participants, across 40 independently
evolving populations. Drawing on techniques from machine learning and Bayesian
statistics, we identify a simple adjustment to content-selection algorithms
that is predicted to mitigate bias amplification. This algorithm generates a
sample of perspectives from within an individual's network that is more
representative of the population as a whole. In a second large experiment, this
strategy reduced bias amplification while maintaining the benefits of
information sharing.",2022-08-15,"Mathew D. Hardy, Bill D. Thompson, P. M. Krafft, Thomas L. Griffiths"
"From Known to Unknown: Quality-aware Self-improving Graph Neural Network
  for Open Set Social Event Detection","State-of-the-art Graph Neural Networks (GNNs) have achieved tremendous
success in social event detection tasks when restricted to a closed set of
events. However, considering the large amount of data needed for training a
neural network and the limited ability of a neural network in handling
previously unknown data, it remains a challenge for existing GNN-based methods
to operate in an open set setting. To address this problem, we design a
Quality-aware Self-improving Graph Neural Network (QSGNN) which extends the
knowledge from known to unknown by leveraging the best of known samples and
reliable knowledge transfer. Specifically, to fully exploit the labeled data,
we propose a novel supervised pairwise loss with an additional orthogonal
inter-class relation constraint to train the backbone GNN encoder. The learnt,
already-known events further serve as strong reference bases for the unknown
ones, which greatly prompts knowledge acquisition and transfer. When the model
is generalized to unknown data, to ensure the effectiveness and reliability, we
further leverage the reference similarity distribution vectors for pseudo
pairwise label generation, selection and quality assessment. Following the
diversity principle of active learning, our method selects diverse pair samples
with the generated pseudo labels to fine-tune the GNN encoder. Besides, we
propose a novel quality-guided optimization in which the contributions of
pseudo labels are weighted based on consistency. We thoroughly evaluate our
model on two large real-world social event datasets. Experiments demonstrate
that our model achieves state-of-the-art results and extends well to unknown
events.",2022-08-15,"Jiaqian Ren, Lei Jiang, Hao Peng, Yuwei Cao, Jia Wu, Philip S. Yu, Lifang He"
Untangling Force-Directed Layouts Using Persistent Homology,"Force-directed layouts belong to a popular class of methods used to position
nodes in a node-link diagram. However, they typically lack direct consideration
of global structures, which can result in visual clutter and the overlap of
unrelated structures. In this paper, we use the principles of persistent
homology to untangle force-directed layouts thus mitigating these issues.
First, we devise a new method to use 0-dimensional persistent homology to
efficiently generate an initial graph layout. The approach results in faster
convergence and better quality graph layouts. Second, we provide a new
definition and an efficient algorithm for 1-dimensional persistent homology
features (i.e., tunnels/cycles) on graphs. We provide users the ability to
interact with the 1-dimensional features by highlighting them and adding
cycle-emphasizing forces to the layout. Finally, we evaluate our approach with
32 synthetic and real-world graphs by computing various metrics, e.g.,
co-ranking, edge crossing, etc., to demonstrate the efficacy of our proposed
method.",2022-08-14,"Bhavana Doppalapudi, Bei Wang, Paul Rosen"
Hypergraph reconstruction from noisy pairwise observations,"The network reconstruction task aims to estimate a complex system's structure
from various data sources such as time series, snapshots, or interaction
counts. Recent work has examined this problem in networks whose relationships
involve precisely two entities-the pairwise case. Here we investigate the
general problem of reconstructing a network in which higher-order interactions
are also present. We study a minimal example of this problem, focusing on the
case of hypergraphs with interactions between pairs and triplets of vertices,
measured imperfectly and indirectly. We derive a
Metropolis-Hastings-within-Gibbs algorithm for this model and use the
algorithms to highlight the unique challenges that come with estimating
higher-order models. We show that this approach tends to reconstruct empirical
and synthetic networks more accurately than an equivalent graph model without
higher-order interactions.",2022-08-12,"Simon Lizotte, Jean-Gabriel Young, Antoine Allard"
A Re-Conceptualization of Online Misinformation Diffusion,"Online social networks facilitate the diffusion of misinformation. Some
theorists construe the problem of misinformation as a problem of knowledge,
hence of ignorance. This assumption leads to solutions in which misinformation
(false belief) is resisted by good information (true belief). We argue that
information is better understood as gossip. We believe that gossip spreads as
part of an economy of social capital that has a specific discursive grammar
that mimics ordinary human gossip. But there are some critical differences.
These differences have immense and divisive social and political effects. If we
shift our focus from the truth or falsity of information, and instead focus on
the social dynamics of gossip we can more effectively respond to the challenges
and dangers of online social networks.
  Our argument has three parts. (1) We briefly critique epistemological and
truth-centered accounts of misinformation. (2) We describe a basic discursive
grammar of gossip as a social practice. (3) We, then, match the properties of
online information with this discursive grammar of gossip. While gossip has a
particular discursive form, its online modes involve a number of unique social
features that will have immense and divisive social and political effects. Our
goal is not to replace current accounts of information diffusion but to augment
these accounts with a descriptive model of gossip. Information diffusion models
should be understood as tools with which to explore the sociology of evolving
online communities in conjunction with offline communities.",2022-08-12,"Brett Bourbon, Renita Murimi"
"Human mobility patterns in Mexico City and their links with
  socioeconomic variables during the COVID-19 pandemic","The availability of cellphone geolocation data provides a remarkable
opportunity to study human mobility patterns and how these patterns are
affected by the recent pandemic. Two simple centrality metrics allow us to
measure two different aspects of mobility in origin-destination networks
constructed with this type of data: variety of places connected to a certain
node (degree) and number of people that travel to or from a given node
(strength). In this contribution, we present an analysis of node degree and
strength in daily origin-destination networks for Greater Mexico City during
2020. Unlike what is observed in many complex networks, these
origin-destination networks are not scale free. Instead, there is a
characteristic scale defined by the distribution peak; centrality distributions
exhibit a skewed two-tail distribution with power law decay on each side of the
peak. We found that high mobility areas tend to be closer to the city center,
have higher population and better socioeconomic conditions. Areas with
anomalous behavior are almost always on the periphery of the city, where we can
also observe qualitative difference in mobility patterns between east and west.
Finally, we study the effect of mobility restrictions due to the outbreak of
the COVID-19 pandemics on these mobility patterns.",2022-08-12,"Oscar Fontanelli, Dulce I. Valdivia, Guillermo Romero, Oliver Medina, Wentian Li, Maribel Hernández-Rosales"
"Top Gear or Black Mirror: Inferring Political Leaning From Non-Political
  Content","Polarization and echo chambers are often studied in the context of explicitly
political events such as elections, and little scholarship has examined the
mixing of political groups in non-political contexts. A major obstacle to
studying political polarization in non-political contexts is that political
leaning (i.e., left vs right orientation) is often unknown. Nonetheless,
political leaning is known to correlate (sometimes quite strongly) with many
lifestyle choices leading to stereotypes such as the ""latte-drinking liberal.""
We develop a machine learning classifier to infer political leaning from
non-political text and, optionally, the accounts a user follows on social
media. We use Voter Advice Application results shared on Twitter as our
groundtruth and train and test our classifier on a Twitter dataset comprising
the 3,200 most recent tweets of each user after removing any tweets with
political text. We correctly classify the political leaning of most users (F1
scores range from 0.70 to 0.85 depending on coverage). We find no relationship
between the level of political activity and our classification results. We
apply our classifier to a case study of news sharing in the UK and discover
that, in general, the sharing of political news exhibits a distinctive
left-right divide while sports news does not.",2022-08-11,"Ahmet Kurnaz, Scott A. Hale"
"Modelling Socio-ecological Systems: Implementation of an Advanced Fuzzy
  Cognitive Map Framework for Policy development for addressing complex
  real-life challenges","This study implements a novel Fuzzy Cognitive Map (FCM) framework for
addressing large complex socio-ecological problems. These are characterized as
qualitative, dominated by uncertainty, human involvement with different and
vague perceptions/expectations, and complex systems dynamics due to feedback
relations. The FCM framework provides a participatory soft computing approach
to develop consensus solutions. We demonstrate its implementation in a case
study: a national-scale acute water scarcity crisis. The model has eight steps
starting from collecting data from stakeholders in the form of FCMs
(bi-directional graphs) represented by nodes and imprecise connections. All
subsequent steps operate within a new fuzzy 2-tuple framework that overcomes
previous FCM limitations through advanced processing methods, where large FCMs
are fuzzified and analyzed, condensed, and aggregated using graph-theoretic
measures. FCMs are simulated as Auto-Associative Neural Networks (AANN) to
assess policy solutions to address the problem. In this study, very large
cognitive maps were developed through interviews capturing perceptions of five
different stakeholder groups taking into consideration the causes, consequences
and challenges of the acute water scarcity problem in Jordan. The complex FCMs
containing 186 variables comprehensively covered all aspects of water scarcity.
FCMs were condensed into smaller maps in two levels. They were also combined
into five stakeholder group FCMs and one whole system FCM (total 123 FCMs).
AANN simulations of policy scenarios were conducted on the whole system FCM,
first at the most condensed level and then moved top-down through the next two
levels of granularity to explore potential solutions. These were ranked by a
novel fuzzy Appropriateness criterion to provide a number of high level and
effective strategies to mitigate the water crisis.",2022-08-10,"Mamoon Obiedat, Sandhya Samarasinghe"
Mathematical measures of societal polarisation,"In opinion dynamics, as in general usage, polarisation is subjective. To
understand polarisation, we need to develop more precise methods to measure the
agreement in society. This paper presents four mathematical measures of
polarisation derived from graph and network representations of societies and
information theoretic divergences or distance metrics. Two of the methods,
min-max flow and spectral radius, rely on graph theory and define polarisation
in terms of the structural characteristics of networks. The other two methods
represent opinions as probability density functions and use the Kullback
Leibler divergence and the Hellinger distance as polarisation measures. We
present a series of opinion dynamics simulations from two common models to test
the effectiveness of the methods. Results show that the four measures provide
insight into the different aspects of polarisation and allow real-time
monitoring of social networks for indicators of polarisation. The three
measures, the spectral radius, Kullback Leibler divergence and Hellinger
distance, smoothly delineated between different amounts of polarisation, i.e.
how many cluster there were in the simulation, while also measuring with more
granularity how close simulations were to consensus. Min-max flow failed to
accomplish such nuance.",2022-08-09,"Johnathan A. Adams, Gentry White, Robyn P. Araujo"
ENAGRAM: An App to Evaluate Preventative Nudges for Instagram,"Online self-disclosure is perhaps one of the last decade's most studied
communication processes, thanks to the introduction of Online Social Networks
(OSNs) like Facebook. Self-disclosure research has contributed significantly to
the design of preventative nudges seeking to support and guide users when
revealing private information in OSNs. Still, assessing the effectiveness of
these solutions is often challenging since changing or modifying the choice
architecture of OSN platforms is practically unfeasible. In turn, the
effectiveness of numerous nudging designs is supported primarily by
self-reported data instead of actual behavioral information. This work presents
ENAGRAM, an app for evaluating preventative nudges, and reports the first
results of an empirical study conducted with it. Such a study aims to showcase
how the app (and the data collected with it) can be leveraged to assess the
effectiveness of a particular nudging approach. We used ENAGRAM as a vehicle to
test a risk-based strategy for nudging the self-disclosure decisions of
Instagram users. For this, we created two variations of the same nudge and
tested it in a between-subjects experimental setting. Study participants (N=22)
were recruited via Prolific and asked to use the app regularly for 7 days. An
online survey was distributed at the end of the experiment to measure some
privacy-related constructs. From the data collected with ENAGRAM, we observed
lower (though non-significant) self-disclosure levels when applying risk-based
interventions. The constructs measured with the survey were not significant
either, except for participants' External Information Privacy Concerns. Our
results suggest that (i) ENAGRAM is a suitable alternative for conducting
longitudinal experiments in a privacy-friendly way, and (ii) it provides a
flexible framework for the evaluation of a broad spectrum of nudging solutions.",2022-08-09,"Nicolás E. Díaz Ferreyra, Sina Ostendorf, Esma Aïmeur, Maritta Heisel, Matthias Brand"
"E2EG: End-to-End Node Classification Using Graph Topology and Text-based
  Node Attributes","Node classification utilizing text-based node attributes has many real-world
applications, ranging from prediction of paper topics in academic citation
graphs to classification of user characteristics in social media networks.
State-of-the-art node classification frameworks, such as GIANT, use a two-stage
pipeline: first embedding the text attributes of graph nodes then feeding the
resulting embeddings into a node classification model. In this paper, we
eliminate these two stages and develop an end-to-end node classification model
that builds upon GIANT, called End-to-End-GIANT (E2EG). The tandem utilization
of a main and an auxiliary classification objectives in our approach results in
a more robust model, enabling the BERT backbone to be switched out for a
distilled encoder with a 25% - 40% reduction in the number of parameters.
Moreover, the model's end-to-end nature increases ease of use, as it avoids the
need of chaining multiple models for node classification. Compared to a
GIANT+MLP baseline on the ogbn-arxiv and ogbn-products datasets, E2EG obtains
slightly better accuracy in the transductive setting (+0.5%), while reducing
model training time by up to 40%. Our model is also applicable in the inductive
setting, outperforming GIANT+MLP by up to +2.23%.",2022-08-09,"Tu Anh Dinh, Jeroen den Boef, Joran Cornelisse, Paul Groth"
"Characterizing Social Movement Narratives in Online Communities: The
  2021 Cuban Protests on Reddit","Social movements are dominated by storytelling, as narratives play a key role
in how communities involved in these movements shape their identities. Thus,
recognizing the accepted narratives of different communities is central to
understanding social movements. In this context, journalists face the challenge
of making sense of these emerging narratives in social media when they seek to
report social protests. Thus, they would benefit from support tools that allow
them to identify and explore such narratives. In this work, we propose a
narrative extraction algorithm from social media that incorporates the concept
of community acceptance. Using our method, we study the 2021 Cuban protests and
characterize five relevant communities. The extracted narratives differ in both
structure and content across communities. Our work has implications in the
study of social movements, intelligence analysis, computational journalism, and
misinformation research.",2022-08-08,"Brian Felipe Keith Norambuena, Tanushree Mitra, Chris North"
Estimating Topic Exposure for Under-Represented Users on Social Media,"Online Social Networks (OSNs) facilitate access to a variety of data allowing
researchers to analyze users' behavior and develop user behavioral analysis
models. These models rely heavily on the observed data which is usually biased
due to the participation inequality. This inequality consists of three groups
of online users: the lurkers - users that solely consume the content, the
engagers - users that contribute little to the content creation, and the
contributors - users that are responsible for creating the majority of the
online content. Failing to consider the contribution of all the groups while
interpreting population-level interests or sentiments may yield biased results.
To reduce the bias induced by the contributors, in this work, we focus on
highlighting the engagers' contributions in the observed data as they are more
likely to contribute when compared to lurkers, and they comprise a bigger
population as compared to the contributors. The first step in behavioral
analysis of these users is to find the topics they are exposed to but did not
engage with. To do so, we propose a novel framework that aids in identifying
these users and estimates their topic exposure. The exposure estimation
mechanism is modeled by incorporating behavioral patterns from similar
contributors as well as users' demographic and profile information.",2022-08-07,"Mansooreh Karami, Ahmadreza Mosallanezhad, Paras Sheth, Huan Liu"
"LFGCF: Light Folksonomy Graph Collaborative Filtering for Tag-Aware
  Recommendation","Tag-aware recommendation is a task of predicting a personalized list of items
for a user by their tagging behaviors. It is crucial for many applications with
tagging capabilities like last.fm or movielens. Recently, many efforts have
been devoted to improving Tag-aware recommendation systems (TRS) with Graph
Convolutional Networks (GCN), which has become new state-of-the-art for the
general recommendation. However, some solutions are directly inherited from GCN
without justifications, which is difficult to alleviate the sparsity,
ambiguity, and redundancy issues introduced by tags, thus adding to
difficulties of training and degrading recommendation performance.
  In this work, we aim to simplify the design of GCN to make it more concise
for TRS. We propose a novel tag-aware recommendation model named Light
Folksonomy Graph Collaborative Filtering (LFGCF), which only includes the
essential GCN components. Specifically, LFGCF first constructs Folksonomy
Graphs from the records of user assigning tags and item getting tagged. Then we
leverage the simple design of aggregation to learn the high-order
representations on Folksonomy Graphs and use the weighted sum of the embeddings
learned at several layers for information updating. We share tags embeddings to
bridge the information gap between users and items. Besides, a regularization
function named TransRT is proposed to better depict user preferences and item
features. Extensive hyperparameters experiments and ablation studies on three
real-world datasets show that LFGCF uses fewer parameters and significantly
outperforms most baselines for the tag-aware top-N recommendations.",2022-08-06,"Yin Zhang, Can Xu, XianJun Wu, Yan Zhang, LiGang Dong, Weigang Wang"
"Improving the visibility of minorities through network growth
  interventions","Improving the position of minorities in networks via interventions is a
challenge of high theoretical and societal importance. In this work, we examine
how different network growth interventions impact the position of minority
nodes in degree rankings over time. We distinguish between two kinds of
interventions: (i) group size interventions, such as introducing quotas, that
regulate the ratio of incoming minority and majority nodes; and (ii)
behavioural interventions, such as homophily, i.e. varying how groups interact
and connect to each other. We find that even extreme group size interventions
do not have a strong effect on the position of minorities in rankings if
certain behavioural changes do not manifest at the same time. For example,
minority representation in rankings is not increased by high quotas if the
actors in the network do not adopt homophilic behaviour. As a result, a key
finding of our research is that in order for the visibility of minorities to
improve, group size and behavioural interventions need to be coordinated.
Moreover, their potential benefit is highly dependent on pre-intervention
conditions in social networks. In a real-world case study, we explore the
effectiveness of interventions to reach gender parity in academia. Our work
lays a theoretical and computational foundation for further studies aiming to
explore the effectiveness of interventions in growing networks.",2022-08-05,"Leonie Neuhäuser, Fariba Karimi, Jan Bachmann, Markus Strohmaier, Michael T. Schaub"
"Local Detour Centrality: A Novel Local Centrality Measure for Weighted
  Networks","Centrality, in some sense, captures the extent to which a vertex controls the
flow of information in a network. Here, we propose Local Detour Centrality as a
novel centrality-based betweenness measure that captures the extent to which a
vertex shortens paths between neighboring vertices as compared to alternative
paths. After presenting our measure, we demonstrate empirically that it differs
from other leading central measures, such as betweenness, degree, closeness,
and the number of triangles. Through an empirical case study, we provide a
possible interpretation for Local Detour Centrality as a measure that captures
the extent to which a word is characterized by contextual diversity within a
semantic network. We then examine the relationship between our measure and the
accessibility to knowledge stored in memory. To do so, we show that words that
occur in several different and distinct contexts are significantly more
effective in facilitating the retrieval of subsequent words than are words that
lack this contextual diversity.",2022-08-05,"Haim Cohen, Yinon Nachshon, Paz M. Naim, Jürgen Jost, Emil Saucan, Anat Maril"
Trust based attachment,"In social systems subject to indirect reciprocity, a positive reputation is
key for increasing one's likelihood of future positive interactions. The flow
of gossip can amplify the impact of a person's actions on their reputation
depending on how widely it spreads across the social network, which leads to a
percolation problem. To quantify this notion, we calculate the expected number
of individuals, the ""audience"", who find out about a particular interaction.
For a potential donor, a larger audience constitutes higher reputational
stakes, and thus a higher incentive, to perform ""good"" actions in line with
current social norms. For a receiver, a larger audience therefore increases the
trust that the partner will be cooperative. This idea can be used for an
algorithm that generates social networks, which we call trust based attachment
(TBA). TBA produces graphs that share crucial quantitative properties with
real-world networks, such as high clustering, small-world behavior, and power
law degree distributions. We also show that TBA can be approximated by simple
friend-of-friend routines based on triadic closure, which are known to be
highly effective at generating realistic social network structures. Therefore,
our work provides a new justification for triadic closure in social contexts
based on notions of trust, gossip, and social information spread. These factors
are thus identified as potential significant influences on how humans form
social ties.",2022-08-04,"Julian Kates-Harbeck, Martin A. Nowak"
"Twitter Attribute Classification with Q-Learning on Bitcoin Price
  Prediction","Aspiring to achieve an accurate Bitcoin price prediction based on people's
opinions on Twitter usually requires millions of tweets, using different text
mining techniques (preprocessing, tokenization, stemming, stop word removal),
and developing a machine learning model to perform the prediction. These
attempts lead to the employment of a significant amount of computer power,
central processing unit (CPU) utilization, random-access memory (RAM) usage,
and time. To address this issue, in this paper, we consider a classification of
tweet attributes that effects on price changes and computer resource usage
levels while obtaining an accurate price prediction. To classify tweet
attributes having a high effect on price movement, we collect all
Bitcoin-related tweets posted in a certain period and divide them into four
categories based on the following tweet attributes: $(i)$ the number of
followers of the tweet poster, $(ii)$ the number of comments on the tweet,
$(iii)$ the number of likes, and $(iv)$ the number of retweets. We separately
train and test by using the Q-learning model with the above four categorized
sets of tweets and find the best accurate prediction among them. Especially, we
design several reward functions to improve the prediction accuracy of the
Q-leaning. We compare our approach with a classic approach where all
Bitcoin-related tweets are used as input data for the model, by analyzing the
CPU workloads, RAM usage, memory, time, and prediction accuracy. The results
show that tweets posted by users with the most followers have the most
influence on a future price, and their utilization leads to spending 80\% less
time, 88.8\% less CPU consumption, and 12.5\% more accurate predictions
compared with the classic approach.",2022-08-04,"Sattarov Otabek, Jaeyoung Choi"
"Evaluating and improving social awareness of energy communities through
  semantic network analysis of online news","The implementation of energy communities represents a cross-disciplinary
phenomenon that has the potential to support the energy transition while
fostering citizens' participation throughout the energy system and their
exploitation of renewables. An important role is played by online information
sources in engaging people in this process and increasing their awareness of
associated benefits. In this view, this work analyses online news data on
energy communities to understand people's awareness and the media importance of
this topic. We use the Semantic Brand Score (SBS) indicator as an innovative
measure of semantic importance, combining social network analysis and text
mining methods. Results show different importance trends for energy communities
and other energy and society-related topics, also allowing the identification
of their connections. Our approach gives evidence to information gaps and
possible actions that could be taken to promote a low-carbon energy transition.",2022-08-03,"C. Piselli, A. Fronzetti Colladon, L. Segneri, A. L. Pisello"
"Link Prediction on Heterophilic Graphs via Disentangled Representation
  Learning","Link prediction is an important task that has wide applications in various
domains. However, the majority of existing link prediction approaches assume
the given graph follows homophily assumption, and designs similarity-based
heuristics or representation learning approaches to predict links. However,
many real-world graphs are heterophilic graphs, where the homophily assumption
does not hold, which challenges existing link prediction methods. Generally, in
heterophilic graphs, there are many latent factors causing the link formation,
and two linked nodes tend to be similar in one or two factors but might be
dissimilar in other factors, leading to low overall similarity. Thus, one way
is to learn disentangled representation for each node with each vector
capturing the latent representation of a node on one factor, which paves a way
to model the link formation in heterophilic graphs, resulting in better node
representation learning and link prediction performance. However, the work on
this is rather limited. Therefore, in this paper, we study a novel problem of
exploring disentangled representation learning for link prediction on
heterophilic graphs. We propose a novel framework DisenLink which can learn
disentangled representations by modeling the link formation and perform
factor-aware message-passing to facilitate link prediction. Extensive
experiments on 13 real-world datasets demonstrate the effectiveness of
DisenLink for link prediction on both heterophilic and hemophiliac graphs. Our
codes are available at https://github.com/sjz5202/DisenLink",2022-08-03,"Shijie Zhou, Zhimeng Guo, Charu Aggarwal, Xiang Zhang, Suhang Wang"
"Rumor Stance Classification in Online Social Networks: The
  State-of-the-Art, Prospects, and Future Challenges","The emergence of the Internet as a ubiquitous technology has facilitated the
rapid evolution of social media as the leading virtual platform for
communication, content sharing, and information dissemination. In spite of
revolutionizing the way news is delivered to people, this technology has also
brought along with itself inevitable demerits. One such drawback is the spread
of rumors expedited by social media platforms, which may provoke doubt and
fear. Therefore, it is essential to debunk rumors before their widespread use.
Over the years, many studies have been conducted to develop effective rumor
verification systems. One aspect of such studies focuses on rumor stance
classification, which involves the task of utilizing user viewpoints regarding
a rumorous post to better predict the veracity of a rumor. Relying on user
stances in rumor verification has gained significant importance, for it has
resulted in significant improvements in the model performance. In this paper,
we conduct a comprehensive literature review of rumor stance classification in
complex online social networks (OSNs). In particular, we present a thorough
description of these approaches and compare their performances. Moreover, we
introduce multiple datasets available for this purpose and highlight their
limitations. Finally, challenges and future directions are discussed to
stimulate further relevant research efforts.",2022-08-02,"Sarina Jami, Iman Sahebi, Mohammad M. Sabermahani, Seyed P. Shariatpanahi, Aresh Dadlani, Behrouz Maham"
"Characterizing Vaccination Movements on YouTube in the United States and
  Brazil","In the context of COVID-19 pandemic, social networks such as Twitter and
YouTube stand out as important sources of information. YouTube, as the largest
and most engaging online media consumption platform, has a large influence in
the spread of information and misinformation, which makes it important to study
how it deals with the problems that arise from disinformation, as well as how
its users interact with different types of content. Considering that United
States (USA) and Brazil (BR) are two countries with the highest COVID-19 death
tolls, we asked the following question: What are the nuances of vaccination
campaigns in the two countries? With that in mind, we engage in a comparative
analysis of pro and anti-vaccine movements on YouTube. We also investigate the
role of YouTube in countering online vaccine misinformation in USA and BR. For
this means, we monitored the removal of vaccine related content on the platform
and also applied various techniques to analyze the differences in discourse and
engagement in pro and anti-vaccine ""comment sections"". We found that American
anti-vaccine content tend to lead to considerably more toxic and negative
discussion than their pro-vaccine counterparts while also leading to 18% higher
user-user engagement, while Brazilian anti-vaccine content was significantly
less engaging. We also found that pro-vaccine and anti-vaccine discourses are
considerably different as the former is associated with conspiracy theories
(e.g. ccp), misinformation and alternative medicine (e.g. hydroxychloroquine),
while the latter is associated with protective measures. Finally, it was
observed that YouTube content removals are still insufficient, with only
approximately 16% of the anti-vaccine content being removed by the end of the
studied period, with the USA registering the highest percentage of removed
anti-vaccine content(34%) and BR registering the lowest(9.8%).",2022-08-02,"Marcelo Sartori Locatelli, Josemar Caetano, Wagner Meira Jr., Virgilio Almeida"
"Characterizing the 2022 Russo-Ukrainian Conflict Through the Lenses of
  Aspect-Based Sentiment Analysis: Dataset, Methodology, and Preliminary
  Findings","Online social networks (OSNs) play a crucial role in today's world. On the
one hand, they allow free speech, information sharing, and social-movements
organization, to cite a few. On the other hand, they are the tool of choice to
spread disinformation, hate speech, and to support propaganda. For these
reasons, OSNs data mining and analysis aimed at detecting disinformation
campaigns that may arm the society and, more in general, poison the democratic
posture of states, are essential activities during key events such as
elections, pandemics, and conflicts. In this paper, we studied the 2022
Russo-Ukrainian conflict on Twitter, one of the most used OSNs. We
quantitatively and qualitatively analyze a dataset of more than 5.5+ million
tweets related to the subject, generated by 1.8+ million unique users. By
leveraging statistical analysis techniques and aspect-based sentiment analysis
(ABSA), we discover hidden insights in the collected data and abnormal patterns
in the users' sentiment that in some cases confirm while in other cases
disprove common beliefs on the conflict. In particular, based on our findings
and contrary to what suggested in some mainstream media, there is no evidence
of massive disinformation campaigns. However, we have identified several
anomalies in the behavior of particular accounts and in the sentiment trend for
some subjects that represent a starting point for further analysis in the
field. The adopted techniques, the availability of the data, the replicability
of the experiments, and the preliminary findings, other than being interesting
on their own, also pave the way to further research in the domain.",2022-08-02,"Maurantonio Caprolu, Alireza Sadighian, Roberto Di Pietro"
Revisiting Information Cascades in Online Social Networks,"It's by now folklore that to understand the activity pattern of a user in an
online social network (OSN) platform, one needs to look at his friends or the
ones he follows. The common perception is that these friends exert influence on
the user, effecting his decision whether to re-share content or not. Hinging
upon this intuition, a variety of models were developed to predict how
information propagates in OSN, similar to the way infection spreads in the
population. In this paper, we revisit this world view and arrive at new
conclusions. Given a set of users $V$, we study the task of predicting whether
a user $u \in V$ will re-share content by some $v \in V$ at the following time
window given the activity of all the users in $V$ in the previous time window.
We design several algorithms for this task, ranging from a simple greedy
algorithm that only learns $u$'s conditional probability distribution, ignoring
the rest of $V$, to a convolutional neural network-based algorithm that
receives the activity of all of $V$, but does not receive explicitly the social
link structure. We tested our algorithms on four datasets that we collected
from Twitter, each revolving around a different popular topic in 2020. The best
performance, average F1-score of 0.86 over the four datasets, was achieved by
the convolutional neural network. The simple, social-link ignorant, algorithm
achieved an average F1-score of 0.78.",2022-08-01,"Michael Sidorov, Dan Vilenchik"
"Identifying Influential Brokers on Social Media from Social Network
  Structure","Identifying influencers in a given social network has become an important
research problem for various applications, including accelerating the spread of
information in viral marketing and preventing the spread of fake news and
rumors. The literature contains a rich body of studies on identifying
influential source spreaders who can spread their own messages to many other
nodes. In contrast, the identification of influential brokers who can spread
other nodes' messages to many nodes has not been fully explored. Theoretical
and empirical studies suggest that involvement of both influential source
spreaders and brokers is a key to facilitating large-scale information
diffusion cascades. Therefore, this paper explores ways to identify influential
brokers from a given social network. By using three social media datasets, we
investigate the characteristics of influential brokers by comparing them with
influential source spreaders and central nodes obtained from centrality
measures. Our results show that (i) most of the influential source spreaders
are not influential brokers (and vice versa) and (ii) the overlap between
central nodes and influential brokers is small (less than 15%) in Twitter
datasets. We also tackle the problem of identifying influential brokers from
centrality measures and node embeddings, and we examine the effectiveness of
social network features in the broker identification task. Our results show
that (iii) although a single centrality measure cannot characterize influential
brokers well, prediction models using node embedding features achieve F$_1$
scores of 0.35--0.68, suggesting the effectiveness of social network features
for identifying influential brokers.",2022-08-01,"Sho Tsugawa, Kohei Watabe"
"The impact of Twitter on political influence on the choice of a running
  mate: Social Network Analysis and Semantic Analysis -- A Review","In this new era of social media, social networks are becoming increasingly
important sources of user-generated content on the internet. These kinds of
information resources, which include a lot of people's feelings, opinions,
feedback, and reviews, are very useful for big businesses, markets, politics,
journalism, and many other fields. Politics is one of the most talked-about and
popular topics on social media networks right now. Many politicians use
micro-blogging services like Twitter because they have a large number of
followers and supporters on those networks. Politicians, political parties,
political organizations, and foundations use social media networks to
communicate with citizens ahead of time. Today, social media is used by
hundreds of thousands of political groups and politicians. On these social
media networks, every politician and political party has millions of followers,
and politicians find new and innovative ways to urge individuals to participate
in politics. Furthermore, social media assists politicians in various
decision-making processes by providing recommendations, such as developing
policies and strategies based on previous experiences, recommending and
selecting suitable candidates for a particular constituency, recommending a
suitable person for a particular position in the party, and launching a
political campaign based on citizen sentiments on various issues and
controversies, among other things. This research is a review on the use of
social network analysis (SNA) and semantic analysis (SA) on the Twitter
platform to study the supporters networks of political leaders because it can
help in decision-making when predicting their political futures.",2022-07-31,"Immaculate Wanza, Irad Kamuti, David Gichohi, Kinyua Gikunda"
Local Graph Embeddings Based on Neighbors Degree Frequency of Nodes,"We propose a local-to-global strategy for graph machine learning and network
analysis by defining certain local features and vector representations of nodes
and then using them to learn globally defined metrics and properties of the
nodes by means of deep neural networks. By extending the notion of the degree
of a node via Breath-First Search, a general family of {\bf parametric
centrality functions} is defined which are able to reveal the importance of
nodes. We introduce the {\bf neighbors degree frequency (NDF)}, as a locally
defined embedding of nodes of undirected graphs into euclidean spaces. This
gives rise to a vectorized labeling of nodes which encodes the structure of
local neighborhoods of nodes and can be used for graph isomorphism testing. We
add flexibility to our construction so that it can handle dynamic graphs as
well. Afterwards, the Breadth-First Search is used to extend NDF vector
representations into two different matrix representations of nodes which
contain higher order information about the neighborhoods of nodes. Our matrix
representations of nodes provide us with a new way of visualizing the shape of
the neighborhood of a node. Furthermore, we use these matrix representations to
obtain feature vectors, which are suitable for typical deep learning
algorithms. To demonstrate these node embeddings actually contain some
information about the nodes, in a series of examples, we show that PageRank and
closeness centrality can be learned by applying deep learning to these local
features. Our constructions are flexible enough to handle evolving graphs.
Finally, we explain how to adapt our constructions for directed graphs.",2022-07-30,Vahid Shirbisheh
"Efficient estimation and inference for the signed $β$-model in
  directed signed networks","This paper proposes a novel signed $\beta$-model for directed signed network,
which is frequently encountered in application domains but largely neglected in
literature. The proposed signed $\beta$-model decomposes a directed signed
network as the difference of two unsigned networks and embeds each node with
two latent factors for in-status and out-status. The presence of negative edges
leads to a non-concave log-likelihood, and a one-step estimation algorithm is
developed to facilitate parameter estimation, which is efficient both
theoretically and computationally. We also develop an inferential procedure for
pairwise and multiple node comparisons under the signed $\beta$-model, which
fills the void of lacking uncertainty quantification for node ranking.
Theoretical results are established for the coverage probability of confidence
interval, as well as the false discovery rate (FDR) control for multiple node
comparison. The finite sample performance of the signed $\beta$-model is also
examined through extensive numerical experiments on both synthetic and
real-life networks.",2022-07-30,"Haoran Zhang, Junhui Wang"
"SERCNN: Stacked Embedding Recurrent Convolutional Neural Network in
  Detecting Depression on Twitter","Conventional approaches to identify depression are not scalable, and the
public has limited awareness of mental health, especially in developing
countries. As evident by recent studies, social media has the potential to
complement mental health screening on a greater scale. The vast amount of
first-person narrative posts in chronological order can provide insights into
one's thoughts, feelings, behavior, or mood for some time, enabling a better
understanding of depression symptoms reflected in the online space. In this
paper, we propose SERCNN, which improves the user representation by (1)
stacking two pretrained embeddings from different domains and (2) reintroducing
the embedding context to the MLP classifier. Our SERCNN shows great performance
over state-of-the-art and other baselines, achieving 93.7% accuracy in a 5-fold
cross-validation setting. Since not all users share the same level of online
activity, we introduced the concept of a fixed observation window that
quantifies the observation period in a predefined number of posts. With as
minimal as 10 posts per user, SERCNN performed exceptionally well with an 87%
accuracy, which is on par with the BERT model, while having 98% less in the
number of parameters. Our findings open up a promising direction for detecting
depression on social media with a smaller number of posts for inference,
towards creating solutions for a cost-effective and timely intervention. We
hope that our work can bring this research area closer to real-world adoption
in existing clinical practice.",2022-07-29,"Heng Ee Tay, Mei Kuan Lim, Chun Yong Chong"
Topological structure of complex predictions,"Complex prediction models such as deep learning are the output from fitting
machine learning, neural networks, or AI models to a set of training data.
These are now standard tools in science. A key challenge with the current
generation of models is that they are highly parameterized, which makes
describing and interpreting the prediction strategies difficult. We use
topological data analysis to transform these complex prediction models into
pictures representing a topological view. The result is a map of the
predictions that enables inspection. The methods scale up to large datasets
across different domains and enable us to detect labeling errors in training
data, understand generalization in image classification, and inspect
predictions of likely pathogenic mutations in the BRCA1 gene.",2022-07-28,"Meng Liu, Tamal K. Dey, David F. Gleich"
"Analysis of Polkadot: Architecture, Internals, and Contradictions","Polkadot is a network protocol launched in 2020 with the ambition of
unlocking the full potential of blockchain technologies. Its novel multi-chain
protocol allows arbitrary data to be transferred across heterogeneous
blockchains, enabling the implementation of a wide range of novel use cases.
The Polkadot architecture is based on the principles of sharding, which
promises to solve scalability and interoperability shortcomings that encumber
many existing blockchain-based systems. Lured by these impressive features,
investors immediately appreciated the Polkadot project, which is now firmly
ranked among the top 10 cryptocurrencies by capitalization (around 20 Billions
USD). However, Polkadot has not received the same level of attention from
academia that other proposals in the crypto domain have received so far, like
Bitcoin, Ethereum, and Algorand, to cite a few. Polkadot architecture is
described and discussed only in the grey literature, and very little is known
about its internals.
  In this paper, we provide the first systematic study on the Polkadot
environment, detailing its protocols, governance, and economic model. Then, we
identify several limitations -- supported by an empirical analysis of its
ledger -- that could severely affect the scalability and overall security of
the network. Finally, based on our analysis, we provide future directions to
inspire researchers to investigate further the Polkadot ecosystem and its
pitfalls in terms of performance, security, and network aspects.",2022-07-28,"Hanaa Abbas, Maurantonio Caprolu, Roberto Di Pietro"
Data Driven Modeling Social Media Influence using Differential Equations,"Individuals modify their opinions towards a topic based on their social
interactions. Opinion evolution models conceptualize the change of opinion as a
uni-dimensional continuum, and the effect of influence is built by the group
size, the network structures, or the relations among opinions within the group.
However, how to model the personal opinion evolution process under the effect
of the online social influence as a function remains unclear. Here, we show
that the uni-dimensional continuous user opinions can be represented by
compressed high-dimensional word embeddings, and its evolution can be
accurately modelled by an ordinary differential equation (ODE) that reflects
the social network influencer interactions. Our three major contributions are:
(1) introduce a data-driven pipeline representing the personal evolution of
opinions with a time kernel, (2) based on previous psychology models, we model
the opinion evolution process as a function of online social influence using an
ordinary differential equation, and (3) applied Our opinion evolution model to
the real-time Twitter data. We perform our analysis on 87 active users with
corresponding influencers on the COVID-19 topic from 2020 to 2022. The
regression results demonstrate that 99% of the variation in the quantified
opinions can be explained by the way we model the connected opinions from their
influencers. Our research on the COVID-19 topic and for the account analysed
shows that social media users primarily shift their opinion based on
influencers they follow (e.g., model explains for 99% variation) and
self-evolution of opinion over a long time scale is limited.",2022-07-27,"Bailu Jin, Weisi Guo"
Contextualizing Online Conversational Networks,"Online social connections occur within a specific conversational context.
Prior work in network analysis of social media data attempts to contextualize
data through filtering. We propose a method of contextualizing online
conversational connections automatically and illustrate this method with
Twitter data. Specifically, we detail a graph neural network model capable of
representing tweets in a vector space based on their text, hashtags, URLs, and
neighboring tweets. Once tweets are represented, clusters of tweets uncover
conversational contexts. We apply our method to a dataset with 4.5 million
tweets discussing the 2020 US election. We find that even filtered data
contains many different conversational contexts, with users engaging in
multiple contexts. Central users in the contextualized networks differ
significantly from central users in the overall network. This result implies
that standard network analysis on social media data can be unreliable in the
face of multiple conversational contexts. We further demonstrate that dynamic
analysis of conversational contexts gives a qualitative understanding of
conversational flow.",2022-07-26,"Thomas Magelinski, Kathleen M. Carley"
Finding Maximum Cliques in Large Networks,"There are many methods to find a maximum (or maximal) clique in large
networks. Due to the nature of combinatorics, computation becomes exponentially
expensive as the number of vertices in a graph increases. Thus, there is a need
for efficient algorithms to find a maximum clique. In this paper, we present a
graph reduction method that significantly reduces the order of a graph, and so
enables the identification of a maximum clique in graphs of large order, that
would otherwise be computational infeasible to find the maximum. We find bounds
of the maximum (or maximal) clique using this reduction. We demonstrate our
method on real-life social networks and also on Erd\""{o}s-Renyi random graphs.",2022-07-26,"S. Y. Chan, K. Morgan, J. Ugon"
"On the Relation Between Opinion Change and Information Consumption on
  Reddit","While much attention has been devoted to the causes of opinion change, little
is known about its consequences. Our study sheds a light on the relationship
between one user's opinion change episode and subsequent behavioral change on
an online social media, Reddit. In particular, we look at r/ChangeMyView, an
online community dedicated to debating one's own opinions. Interestingly, this
forum adopts a well-codified schema for explicitly self-reporting opinion
change. Starting from this ground truth, we analyze changes in future online
information consumption behavior that arise after a self-reported opinion
change on sociopolitical topics; and in particular, operationalized in this
work as the participation to sociopolitical subreddits. Such participation
profile is important as it represents one's information diet, and is a reliable
proxy for, e.g., political affiliation or health choices.
  We find that people who report an opinion change are significantly more
likely to change their future participation in a specific subset of online
communities. We characterize which communities are more likely to be abandoned
after opinion change, and find a significant association (r=0.46) between
propaganda-like language used in a community and the increase in chances of
leaving it. We find comparable results (r=0.39) for the opposite direction,
i.e., joining a community. This finding suggests how propagandistic communities
act as a first gateway to internalize a shift in one's sociopolitical opinion.
Finally, we show that the textual content of the discussion associated with
opinion change is indicative of which communities are going to be subject to a
participation change. In fact, a predictive model based only on the opinion
change post is able to pinpoint these communities with an AP@5 of 0.20, similar
to what can be reached by using all the past history of participation in
communities.",2022-07-25,"Flavio Petruzzellis, Corrado Monti, Gianmarco De Francisci Morales, Francesco Bonchi"
Multi-Scale Asset Distribution Model for Dynamic Environments,"In many self-organising systems the ability to extract necessary resources
from the external environment is essential to the system's growth and survival.
Examples include the extraction of sunlight and nutrients in organic plants, of
monetary income in business organisations and of mobile robots in swarm
intelligence actions. When operating within competitive, ever-changing
environments, such systems must distribute their internal assets wisely so as
to improve and adapt their ability to extract available resources. As the
system size increases, the asset-distribution process often gets organised
around a multi-scale control topology. This topology may be static (fixed) or
dynamic (enabling growth and structural adaptation) depending on the system's
internal constraints and adaptive mechanisms. In this paper, we expand on a
plant-inspired asset-distribution model and introduce a more general
multi-scale model applicable across a wider range of natural and artificial
system domains. We study the impact that the topology of the multi-scale
control process has upon the system's ability to self-adapt asset distribution
when resource availability changes within the environment. Results show how
different topological characteristics and different competition levels between
system branches impact overall system profitability, adaptation delays and
disturbances when environmental changes occur. These findings provide a basis
for system designers to select the most suitable topology and configuration for
their particular application and execution environment.",2022-07-25,"Payam Zahadat, Ada Diaconescu"
On The Convexity Of The Effective Reproduction Number,"In this study we analyze the evolution of the effective reproduction number,
$R$, through a SIR spreading process in heterogeneous networks; Characterizing
its decay process allows to analytically study the effects of countermeasures
on the progress of the virus under heterogeneity, and to optimize their
policies.
  A striking result of recent studies has shown that heterogeneity across
nodes/individuals (or, super-spreading) may have a drastic effect on the
spreading process progression, which may cause a non-linear decrease of $R$ in
the number of infected individuals. We account for heterogeneity and analyze
the stochastic progression of the spreading process. We show that the decrease
of $R$ is, in fact, convex in the number of infected individuals, where this
convexity stems from heterogeneity. The analysis is based on establishing
stochastic monotonic relations between the susceptible populations in varying
times of the spread.
  We demonstrate that the convex behavior of the effective reproduction number
affects the performance of countermeasures used to fight a spread of a virus.
The results are applicable to the control of virus and malware spreading in
computer networks as well. We examine numerically the sensitivity of the Herd
Immunity Threshold (HIT) to the heterogeneity level and to the chosen policy.",2022-07-24,"Jhonatan Tavori, Hanoch Levy"
"An NLP-Assisted Bayesian Time Series Analysis for Prevalence of Twitter
  Cyberbullying During the COVID-19 Pandemic","COVID-19 has brought about many changes in social dynamics. Stay-at-home
orders and disruptions in school teaching can influence bullying behavior
in-person and online, both of which leading to negative outcomes in victims. To
study cyberbullying specifically, 1 million tweets containing keywords
associated with abuse were collected from the beginning of 2019 to the end of
2021 with the Twitter API search endpoint. A natural language processing model
pre-trained on a Twitter corpus generated probabilities for the tweets being
offensive and hateful. To overcome limitations of sampling, data was also
collected using the count endpoint. The fraction of tweets from a given daily
sample marked as abusive is multiplied to the number reported by the count
endpoint. Once these adjusted counts are assembled, a Bayesian autoregressive
Poisson model allows one to study the mean trend and lag functions of the data
and how they vary over time. The results reveal strong weekly and yearly
seasonality in hateful speech but with slight differences across years that may
be attributed to COVID-19.",2022-07-23,"Christopher Perez, Sayar Karmakar"
Vaccine Discourse on Twitter During the COVID-19 Pandemic,"Since the onset of the COVID-19 pandemic, vaccines have been an important
topic in public discourse. The discussions around vaccines are polarized as
some see them as an important measure to end the pandemic, and others are
hesitant or find them harmful. This study investigates posts related to
COVID-19 vaccines on Twitter and focuses on those which have a negative stance
toward vaccines. A dataset of 16,713,238 English tweets related to COVID-19
vaccines was collected covering the period from March 1, 2020, to July 31,
2021. We used the Scikit-learn Python library to apply a support vector machine
(SVM) classifier to identify the tweets with a negative stance toward the
COVID-19 vaccines. A total of 5,163 tweets were used to train the classifier,
out of which a subset of 2,484 tweets were manually annotated by us and made
publicly available. We used the BERTtopic model to extract and investigate the
topics discussed within the negative tweets and how they changed over time. We
show that the negativity with respect to COVID-19 vaccines has decreased over
time along with the vaccine roll-outs. We identify 37 topics of discussion and
present their respective importance over time. We show that popular topics
consist of conspiratorial discussions such as 5G towers and microchips, but
also contain legitimate concerns around vaccination safety and side effects as
well as concerns about policies. Our study shows that even unpopular opinions
or conspiracy theories can become widespread when paired with a widely popular
discussion topic such as COVID-19 vaccines. Understanding the concerns and the
discussed topics and how they change over time is essential for policymakers
and public health authorities to provide better and in-time information and
policies, to facilitate vaccination of the population in future similar crises.",2022-07-23,"Gabriel Lindelöf, Talayeh Aledavood, Barbara Keller"
"Platial mobility: expanding place and mobility in GIS via
  platio-temporal representations and the mobilities paradigm","While platial representations are being developed for sedentary entities, a
parallel and useful endeavour would be to consider time in so-called
""platio-temporal"" representations that would also expand notions of mobility in
GIScience, that are solely dependent on Euclidean space and time. Besides
enhancing such aspects of place and mobility via spatio-temporal, we also
include human aspects of these representations via considerations of the
sociological notions of mobility via the mobilities paradigm that can
systematically introduce representation of both platial information along with
mobilities associated with 'moving places.' We condense these aspects into
'platial mobility,' a novel conceptual framework, as an integration in
GIScience and the mobilities paradigm in sociology, that denotes movement of
places in our platio-temporal and sociology-based representations. As
illustrative cases for further study using platial mobility as a framework, we
explore its benefits and methodological aspects toward developing better
understanding for disaster management, disaster risk reduction and pandemics.
We then discuss some of the illustrative use cases to clarify the concept of
platial mobility and its application prospects in the areas of disaster
management, disaster risk reduction and pandemics. These use cases, which
include flood events and the ongoing COVID-19 pandemic, have led to displaced
and restricted communities having to change practices and places, which would
be particularly amenable to the conceptual framework developed in our work.",2022-07-23,"Farrukh Chishtie, Rizwan Bulbul, Panka Babukova, Johannes Scholz"
"A flexible PageRank-based graph embedding framework closely related to
  spectral eigenvector embeddings","We study a simple embedding technique based on a matrix of personalized
PageRank vectors seeded on a random set of nodes. We show that the embedding
produced by the element-wise logarithm of this matrix (1) are related to the
spectral embedding for a class of graphs where spectral embeddings are
significant, and hence useful representation of the data, (2) can be done for
the entire network or a smaller part of it, which enables precise local
representation, and (3) uses a relatively small number of PageRank vectors
compared to the size of the networks. Most importantly, the general nature of
this embedding strategy opens up many emerging applications, where eigenvector
and spectral techniques may not be well established, to the PageRank-based
relatives. For instance, similar techniques can be used on PageRank vectors
from hypergraphs to get ""spectral-like"" embeddings.",2022-07-22,"Disha Shur, Yufan Huang, David F. Gleich"
Modeling User Behavior With Interaction Networks for Spam Detection,"Spam is a serious problem plaguing web-scale digital platforms which
facilitate user content creation and distribution. It compromises platform's
integrity, performance of services like recommendation and search, and overall
business. Spammers engage in a variety of abusive and evasive behavior which
are distinct from non-spammers. Users' complex behavior can be well represented
by a heterogeneous graph rich with node and edge attributes. Learning to
identify spammers in such a graph for a web-scale platform is challenging
because of its structural complexity and size. In this paper, we propose SEINE
(Spam DEtection using Interaction NEtworks), a spam detection model over a
novel graph framework. Our graph simultaneously captures rich users' details
and behavior and enables learning on a billion-scale graph. Our model considers
neighborhood along with edge types and attributes, allowing it to capture a
wide range of spammers. SEINE, trained on a real dataset of tens of millions of
nodes and billions of edges, achieves a high performance of 80% recall with 1%
false positive rate. SEINE achieves comparable performance to the
state-of-the-art techniques on a public dataset while being pragmatic to be
used in a large-scale production system.",2022-07-21,"Prabhat Agarwal, Manisha Srivastava, Vishwakarma Singh, Charles Rosenberg"
"Digraphwave: Scalable Extraction of Structural Node Embeddings via
  Diffusion on Directed Graphs","Structural node embeddings, vectors capturing local connectivity information
for each node in a graph, have many applications in data mining and machine
learning, e.g., network alignment and node classification, clustering and
anomaly detection. For the analysis of directed graphs, e.g., transactions
graphs, communication networks and social networks, the capability to capture
directional information in the structural node embeddings is highly desirable,
as is scalability of the embedding extraction method. Most existing methods are
nevertheless only designed for undirected graph. Therefore, we present
Digraphwave -- a scalable algorithm for extracting structural node embeddings
on directed graphs. The Digraphwave embeddings consist of compressed diffusion
pattern signatures, which are twice enhanced to increase their discriminate
capacity. By proving a lower bound on the heat contained in the local vicinity
of a diffusion initialization node, theoretically justified diffusion timescale
values are established, and Digraphwave is left with only two easy-to-interpret
hyperparameters: the embedding dimension and a neighbourhood resolution
specifier. In our experiments, the two embedding enhancements, named
transposition and aggregation, are shown to lead to a significant increase in
macro F1 score for classifying automorphic identities, with Digraphwave
outperforming all other structural embedding baselines. Moreover, Digraphwave
either outperforms or matches the performance of all baselines on real graph
datasets, displaying a particularly large performance gain in a network
alignment task, while also being scalable to graphs with millions of nodes and
edges, running up to 30x faster than a previous diffusion pattern based method
and with a fraction of the memory consumption.",2022-07-20,"Ciwan Ceylan, Kambiz Ghoorchian, Danica Kragic"
"A Large-Scale Dataset of Twitter Chatter about Online Learning during
  the Current COVID-19 Omicron Wave","The COVID-19 Omicron variant, reported to be the most immune evasive variant
of COVID-19, is resulting in a surge of COVID-19 cases globally. This has
caused schools, colleges, and universities in different parts of the world to
transition to online learning. As a result, social media platforms such as
Twitter are seeing an increase in conversations related to online learning in
the form of tweets. Mining such tweets to develop a dataset can serve as a data
resource for different applications and use-cases related to the analysis of
interest, views, opinions, perspectives, attitudes, and feedback towards online
learning during the current surge of COVID-19 cases caused by the Omicron
variant. Therefore, this work presents a large-scale open-access Twitter
dataset of conversations about online learning from different parts of the
world since the first detected case of the COVID-19 Omicron variant in November
2021. The dataset is compliant with the privacy policy, developer agreement,
and guidelines for content redistribution of Twitter, as well as with the FAIR
principles (Findability, Accessibility, Interoperability, and Reusability)
principles for scientific data management. The paper also briefly outlines some
potential applications in the fields of Big Data, Data Mining, Natural Language
Processing, and their related disciplines, with a specific focus on online
learning during this Omicron wave that may be studied, explored, and
investigated by using this dataset.",2022-07-20,Nirmalya Thakur
"The structure of segregation in co-authorship networks and its impact on
  scientific production","Co-authorship networks, where nodes represent authors and edges represent
co-authorship relations, are key to understanding the production and diffusion
of knowledge in academia. Social constructs, biases (implicit and explicit),
and constraints (e.g. spatial, temporal) affect who works with whom and cause
co-authorship networks to organise into tight communities with different levels
of segregation. We aim to look at aspects of the co-authorship network
structure that lead to segregation and its impact on scientific production. We
measure segregation using the Spectral Segregation Index (SSI) and find 4
ordered segregation categories: completely segregated, highly segregated,
moderately segregated and non-segregated communities. We direct our attention
to the non-segregated and highly segregated communities, quantifying and
comparing their structural topologies and k-core positions. When considering
communities of both categories (controlling for size), our results show no
differences in density and clustering but substantial variability in core
position. Larger non-segregated communities are more likely to occupy cores
near the network nucleus, while the highly segregated ones tend to be closer to
the network periphery. Finally, we analyse differences in citations gained by
researchers within communities showing different segregation categories.
Researchers in highly segregated communities get more citations from their
community members in middle cores and gain more citations per publication in
middle/periphery cores. Those in non-segregated communities get more citations
per publication in the nucleus. To our knowledge, this work is the first to
characterise community segregation in co-authorship networks and investigate
the relationship between community segregation and author citations.",2022-07-20,"Ana Maria Jaramillo, Hywel T. P. Williams, Nicola Perra, Ronaldo Menezes"
"Identifying and characterizing superspreaders of low-credibility content
  on Twitter","The world's digital information ecosystem continues to struggle with the
spread of misinformation. Prior work has suggested that users who consistently
disseminate a disproportionate amount of low-credibility content -- so-called
superspreaders -- are at the center of this problem. We quantitatively confirm
this hypothesis and introduce simple metrics to predict the top superspreaders
several months into the future. We then conduct a qualitative review to
characterize the most prolific superspreaders and analyze their sharing
behaviors. Superspreaders include pundits with large followings,
low-credibility media outlets, personal accounts affiliated with those media
outlets, and a range of influencers. They are primarily political in nature and
use more toxic language than the typical user sharing misinformation. We also
find concerning evidence that suggests Twitter may be overlooking prominent
superspreaders. We hope this work will further public understanding of bad
actors and promote steps to mitigate their negative impacts on healthy digital
discourse.",2022-07-19,"Matthew R. DeVerna, Rachith Aiyappa, Diogo Pacheco, John Bryden, Filippo Menczer"
"Having your Privacy Cake and Eating it Too: Platform-supported Auditing
  of Social Media Algorithms for Public Interest","Social media platforms curate access to information and opportunities, and so
play a critical role in shaping public discourse today. The opaque nature of
the algorithms these platforms use to curate content raises societal questions.
Prior studies have used black-box methods to show that these algorithms can
lead to biased or discriminatory outcomes. However, existing auditing methods
face fundamental limitations because they function independent of the
platforms. Concerns of potential harm have prompted proposal of legislation in
both the U.S. and the E.U. to mandate a new form of auditing where vetted
external researchers get privileged access to social media platforms.
Unfortunately, to date there have been no concrete technical proposals to
provide such auditing, because auditing at scale risks disclosure of users'
private data and platforms' proprietary algorithms. We propose a new method for
platform-supported auditing that can meet the goals of the proposed
legislation. Our first contribution is to enumerate the challenges of existing
auditing methods to implement these policies at scale. Second, we suggest that
limited, privileged access to relevance estimators is the key to enabling
generalizable platform-supported auditing by external researchers. Third, we
show platform-supported auditing need not risk user privacy nor disclosure of
platforms' business interests by proposing an auditing framework that protects
against these risks. For a particular fairness metric, we show that ensuring
privacy imposes only a small constant factor increase (6.34x as an upper bound,
and 4x for typical parameters) in the number of samples required for accurate
auditing. Our technical contributions, combined with ongoing legal and policy
efforts, can enable public oversight into how social media platforms affect
individuals and society by moving past the privacy-vs-transparency hurdle.",2022-07-18,"Basileal Imana, Aleksandra Korolova, John Heidemann"
"Human Brains Can't Detect Fake News: A Neuro-Cognitive Study of Textual
  Disinformation Susceptibility","The spread of digital disinformation (aka ""fake news"") is arguably one of the
most significant threats on the Internet which can cause individual and
societal harm of large scales. The susceptibility to fake news attacks hinges
on whether Internet users perceive a fake news article/snippet to be legitimate
after reading it. In this paper, we attempt to garner an in-depth understanding
of users' susceptibility to text-centric fake news attacks via a
neuro-cognitive methodology. We investigate the neural underpinnings relevant
to fake/real news through EEG. We run an experiment with human users to pursue
a thorough investigation of users' perception and cognitive processing of
fake/real news. We analyze the neural activity associated with the fake/real
news detection task for different categories of news articles. Our results show
there may be no statistically significant or automatically inferable
differences in the way the human brain processes the fake vs. real news, while
marked differences are observed when people are subject to (real/fake) news vs.
resting state and even between some different categories of fake news. This
neuro-cognitive finding may help to justify users' susceptibility to fake news
attacks, as also confirmed from the behavioral analysis. In other words, the
fake news articles may seem almost indistinguishable from the real news
articles in both behavioral and neural domains. Our work serves to dissect the
fundamental neural phenomena underlying fake news attacks and explains users'
susceptibility to these attacks through the limits of human biology. We believe
this could be a notable insight for the researchers and practitioners
suggesting the human detection of fake news might be ineffective, which may
also have an adverse impact on the design of automated detection approaches
that crucially rely upon human labeling of text articles for building training
models",2022-07-18,"Cagri Arisoy, Anuradha Mandal, Nitesh Saxena"
"Improving tobacco social contagion models using agent-based simulations
  on networks","Over the years, population-level tobacco control policies have considerably
reduced smoking prevalence worldwide. However, the rate of decline of smoking
prevalence is slowing down. Therefore, there is a need for models that capture
the full complexity of the smoking epidemic. These models can then be used as
test-beds to develop new policies to limit the spread of smoking. Current
models of smoking dynamics mainly use ordinary differential equation (ODE)
models, where studying the effect of an individual's contact network is
challenging. They also do not consider all the interactions between individuals
that can lead to changes in smoking behaviour, implying that they do not
consider valuable information on the spread of smoking behaviour.
  In this context, we develop an agent-based model (ABM), calibrate and then
validate it on historical trends observed in the US and UK. Our ABM considers
spontaneous terms, interactions between agents, and the agent's contact
network. To explore the effect of the underlying network on smoking dynamics,
we test the ABM on six different networks, both synthetic and real-world. In
addition, we also compare the ABM with an ODE model. Our results suggest that
the dynamics from the ODE model are similar to the ABM only when the network
structure is fully connected (FC). The FC network performs poorly in
replicating the empirical trends in the data, while the real-world network best
replicates it amongst the six networks. Further, when information on the
real-world network is unavailable, our ABM on Lancichinetti-Fortunato-Radicchi
benchmark networks (or networks with a similar average degree as the real-world
network) can be used to model smoking behaviour. These results suggest that
networks are essential for modelling smoking behaviour and that our ABM can be
used to develop network-based intervention strategies and policies for tobacco
control.",2022-07-17,"Adarsh Prabhakaran, Valerio Restocchi, Benjamin D. Goddard"
Model-Agnostic and Diverse Explanations for Streaming Rumour Graphs,"The propagation of rumours on social media poses an important threat to
societies, so that various techniques for rumour detection have been proposed
recently. Yet, existing work focuses on \emph{what} entities constitute a
rumour, but provides little support to understand \emph{why} the entities have
been classified as such. This prevents an effective evaluation of the detected
rumours as well as the design of countermeasures. In this work, we argue that
explanations for detected rumours may be given in terms of examples of related
rumours detected in the past. A diverse set of similar rumours helps users to
generalize, i.e., to understand the properties that govern the detection of
rumours. Since the spread of rumours in social media is commonly modelled using
feature-annotated graphs, we propose a query-by-example approach that, given a
rumour graph, extracts the $k$ most similar and diverse subgraphs from past
rumours. The challenge is that all of the computations require fast assessment
of similarities between graphs. To achieve an efficient and adaptive
realization of the approach in a streaming setting, we present a novel graph
representation learning technique and report on implementation considerations.
Our evaluation experiments show that our approach outperforms baseline
techniques in delivering meaningful explanations for various rumour propagation
behaviours.",2022-07-17,"Thanh Tam Nguyen, Thanh Cong Phan, Minh Hieu Nguyen, Matthias Weidlich, Hongzhi Yin, Jun Jo, Quoc Viet Hung Nguyen"
Is Soccer a lie or simply a complex system?,"Understanding soccer as a complex system we base on nature and the collective
behavior of many organisms that ""do calculations,"" seeking to generate
solutions in a bioinspired way. When soccer mysteries appear, complex systems
science emerges as a means to provide explanations. However, given the variety
of interpretations that complexity and its associated properties can have and
the understanding of what a complex system is, it is convenient to provide some
elements to understand how unpredictability in soccer gives way to hundreds of
counterintuitive results and how the science of complexity could contribute to
the understanding of many phenomena in this sport. In this context, the
manuscript's objective is to synthetically address some of the most important
aspects of applied complexity to soccer to bring science and sport closer
together",2022-07-16,"Nelson Fernandez, Ricardo Bernal"
Quantifying human performance in chess,"From sports to science, the recent availability of large-scale data has
allowed to gain insights on the drivers of human innovation and success in a
variety of domains. Here we quantify human performance in the popular game of
chess by leveraging a very large dataset comprising of over 120 million games
between almost 1 million players. We find that individuals encounter hot
streaks of repeated success, longer for beginners than for expert players, and
even longer cold streaks of unsatisfying performance. Skilled players can be
distinguished from the others based on their gaming behaviour. Differences
appear from the very first moves of the game, with experts tending to
specialize and repeat the same openings while beginners explore and diversify
more. However, experts experience a broader response repertoire, and display a
deeper understanding of different variations within the same line. Over time,
the opening diversity of a player tends to decrease, hinting at the development
of individual playing styles. Nevertheless, we find that players are often not
able to recognize their most successful openings. Overall, our work contributes
to quantifying human performance in competitive settings, providing a first
large-scale quantitative analysis of individual careers in chess, helping
unveil the determinants separating elite from beginner performance.",2022-07-15,"Sandeep Chowdhary, Iacopo Iacopini, Federico Battiston"
Maximizing Fair Content Spread via Edge Suggestion in Social Networks,"Content spread inequity is a potential unfairness issue in online social
networks, disparately impacting minority groups. In this paper, we view
friendship suggestion, a common feature in social network platforms, as an
opportunity to achieve an equitable spread of content. In particular, we
propose to suggest a subset of potential edges (currently not existing in the
network but likely to be accepted) that maximizes content spread while
achieving fairness. Instead of re-engineering the existing systems, our
proposal builds a fairness wrapper on top of the existing friendship suggestion
components.
  We prove the problem is NP-hard and inapproximable in polynomial time unless
P = NP. Therefore, allowing relaxation of the fairness constraint, we propose
an algorithm based on LP-relaxation and randomized rounding with fixed
approximation ratios on fairness and content spread. We provide multiple
optimizations, further improving the performance of our algorithm in practice.
Besides, we propose a scalable algorithm that dynamically adds subsets of
nodes, chosen via iterative sampling, and solves smaller problems corresponding
to these nodes. Besides theoretical analysis, we conduct comprehensive
experiments on real and synthetic data sets. Across different settings, our
algorithms found solutions with nearzero unfairness while significantly
increasing the content spread. Our scalable algorithm could process a graph
with half a million nodes on a single machine, reducing the unfairness to
around 0.0004 while lifting content spread by 43%.",2022-07-15,"Ian P. Swift, Sana Ebrahimi, Azade Nova, Abolfazl Asudeh"
"How many others have shared this? Experimentally investigating the
  effects of social cues on engagement, misinformation, and unpredictability on
  social media","Unlike traditional media, social media typically provides quantified metrics
of how many users have engaged with each piece of content. Some have argued
that the presence of these cues promotes the spread of misinformation. Here we
investigate the causal effect of social cues on users' engagement with social
media posts. We conducted an experiment with N=628 Americans on a custom-built
newsfeed interface where we systematically varied the presence and strength of
social cues. We find that when cues are shown, indicating that a larger number
of others have engaged with a post, users were more likely to share and like
that post. Furthermore, relative to a control without social cues, the presence
of social cues increased the sharing of true relative to false news. The
presence of social cues also makes it more difficult to precisely predict how
popular any given post would be. Together, our results suggest that -- instead
of distracting users or causing them to share low-quality news -- social cues
may, in certain circumstances, actually boost truth discernment and reduce the
sharing of misinformation. Our work suggests that social cues play important
roles in shaping users' attention and engagement on social media, and platforms
should understand the effects of different cues before making changes to what
cues are displayed and how.",2022-07-15,"Ziv Epstein, Hause Lin, Gordon Pennycook, David Rand"
"An Approach for Link Prediction in Directed Complex Networks based on
  Asymmetric Similarity-Popularity","Complex networks are graphs representing real-life systems that exhibit
unique characteristics not found in purely regular or completely random graphs.
The study of such systems is vital but challenging due to the complexity of the
underlying processes. This task has nevertheless been made easier in recent
decades thanks to the availability of large amounts of networked data. Link
prediction in complex networks aims to estimate the likelihood that a link
between two nodes is missing from the network. Links can be missing due to
imperfections in data collection or simply because they are yet to appear.
Discovering new relationships between entities in networked data has attracted
researchers' attention in various domains such as sociology, computer science,
physics, and biology. Most existing research focuses on link prediction in
undirected complex networks. However, not all real-life systems can be
faithfully represented as undirected networks. This simplifying assumption is
often made when using link prediction algorithms but inevitably leads to loss
of information about relations among nodes and degradation in prediction
performance. This paper introduces a link prediction method designed explicitly
for directed networks. It is based on the similarity-popularity paradigm, which
has recently proven successful in undirected networks. The presented algorithms
handle the asymmetry in node relationships by modeling it as asymmetry in
similarity and popularity. Given the observed network topology, the algorithms
approximate the hidden similarities as shortest path distances using edge
weights that capture and factor out the links' asymmetry and nodes' popularity.
The proposed approach is evaluated on real-life networks, and the experimental
results demonstrate its effectiveness in predicting missing links across a
broad spectrum of networked data types and sizes.",2022-07-15,"Hafida Benhidour, Lama Almeshkhas, Said Kerrache"
"The wisdom_of_crowds: an efficient, philosophically-validated, social
  epistemological network profiling toolkit","The epistemic position of an agent often depends on their position in a
larger network of other agents who provide them with information. In general,
agents are better off if they have diverse and independent sources. Sullivan et
al. [2020] developed a method for quantitatively characterizing the epistemic
position of individuals in a network that takes into account both diversity and
independence; and presented a proof-of-concept, closed-source implementation on
a small graph derived from Twitter data [Sullivan et al. 2020]. This paper
reports on an open-source re-implementation of their algorithm in Python,
optimized to be usable on much larger networks. In addition to the algorithm
and package, we also show the ability to scale up our package to large
synthetic social network graph profiling, and finally demonstrate its utility
in analyzing real-world empirical evidence of `echo chambers' on online social
media, as well as evidence of interdisciplinary diversity in an academic
communications network.",2022-07-13,"Colin Klein, Marc Cheong, Marinus Ferreira, Emily Sullivan, Mark Alfano"
"QAnon Propaganda on Twitter as Information Warfare: Influencers,
  Networks, and Narratives","QAnon refers to a set of far-right, conspiratorial ideologies that have risen
in popularity in the U.S. since their initial promotion in 2017 on the 4chan
internet message board. A central narrative element of QAnon is that a powerful
group of elite, liberal members of the Democratic Party engage in morally
reprehensible practices, but that former U.S. President Donald J. Trump was
prosecuting them. Five studies investigated the influence and network
connectivity of accounts promoting QAnon on Twitter from August, 2020 through
January, 2021. Selection of Twitter accounts emphasized on-line influencers and
""persons of interest"" known or suspected of participation in QAnon propaganda
promotion activities. Evidence of large-scale coordination among accounts
promoting QAnon was observed, demonstrating rigorous, quantitative evidence of
""astroturfing"" in QAnon propaganda promotion on Twitter, as opposed to strictly
""grassroots"" activities of citizens acting independently. Further, evidence was
obtained supporting that networks of extreme far-right adherents engaged in
organized QAnon propaganda promotion, as revealed by network overlap among
accounts promoting far-right extremist (e.g., anti-Semitic) content and
insurrectionist themes; New Age, occult, and ""esoteric"" themes; and internet
puzzle games like Cicada 3301 and other ""alternate reality games."" Based on
well-grounded theories and findings from the social sciences, it is argued that
QAnon propaganda on Twitter in the months circa the 2020 U.S. Presidential
election likely reflected joint participation of multiple actors, including
nation-states like Russia, in innovative misuse of social media toward
undermining democratic processes by promoting ""magical"" thinking, ostracism of
Democrats and liberals, and salience of White extinction narratives common
among otherwise ideologically diverse groups on the extreme far-right.",2022-07-11,"L. Dilley, W. Welna, F. Foster"
Dynamic random graphs with vertex removal,"We introduce and analyse a Dynamic Random Graph with Vertex Removal (DRGVR)
defined as follows. At every step, with probability $p > 1/2$ a new vertex is
introduced, and with probability $1-p$ a vertex, chosen uniformly at random
among the present ones (if any), is removed from the graph together with all
edges adjacent to it. In the former case, the new vertex connects by an edge to
every other vertex with probability inversely proportional to the number of
vertices already present.
  We prove that the DRGVR converges to a local limit and determine this limit.
Moreover, we analyse its component structure and distinguish a subcritical and
a supercritical regime with respect to the existence of a giant component. As a
byproduct of this analysis, we obtain upper and lower bounds for the critical
parameter. Furthermore, we provide precise expression of the maximum degree (as
well as in- and out-degree for a natural orientation of the DRGVR). Several
concentration and stability results complete the study.",2022-07-11,"Josep Díaz, Lyuben Lichev, Bas Lodewijks"
Predicting Opinion Dynamics via Sociologically-Informed Neural Networks,"Opinion formation and propagation are crucial phenomena in social networks
and have been extensively studied across several disciplines. Traditionally,
theoretical models of opinion dynamics have been proposed to describe the
interactions between individuals (i.e., social interaction) and their impact on
the evolution of collective opinions. Although these models can incorporate
sociological and psychological knowledge on the mechanisms of social
interaction, they demand extensive calibration with real data to make reliable
predictions, requiring much time and effort. Recently, the widespread use of
social media platforms provides new paradigms to learn deep learning models
from a large volume of social media data. However, these methods ignore any
scientific knowledge about the mechanism of social interaction. In this work,
we present the first hybrid method called Sociologically-Informed Neural
Network (SINN), which integrates theoretical models and social media data by
transporting the concepts of physics-informed neural networks (PINNs) from
natural science (i.e., physics) into social science (i.e., sociology and social
psychology). In particular, we recast theoretical models as ordinary
differential equations (ODEs). Then we train a neural network that
simultaneously approximates the data and conforms to the ODEs that represent
the social scientific knowledge. In addition, we extend PINNs by integrating
matrix factorization and a language model to incorporate rich side information
(e.g., user profiles) and structural knowledge (e.g., cluster structure of the
social interaction network). Moreover, we develop an end-to-end training
procedure for SINN, which involves Gumbel-Softmax approximation to include
stochastic mechanisms of social interaction. Extensive experiments on
real-world and synthetic datasets show SINN outperforms six baseline methods in
predicting opinion dynamics.",2022-07-07,"Maya Okawa, Tomoharu Iwata"
fybrrChat: A Distributed Chat Application for Secure P2P Messaging,"The growing demand for connecting with each other across the world has proved
to be a boon to the growth of social media platforms. But when it comes to
ensuring the privacy and security of the platform, the control is in hands of
few monopolies. Some claim to provide a secure medium of communication but
their exploitation of users and misusing users' data with their centralized
control over the policies has led to various controversies. Lack of trust
towards these organisations have made people skeptical towards using these
applications for extremely secure communication use-cases. Thus, a system with
no central organisation in control and a trustless network is required. A
trustless network is a network which does not requires the participants (users)
to trust any central authority. These nodes themselves, as a group, can be
trusted to make a decision which aligns with the interests of all. This is
accompanied by a distributed network, where peers are connected to each other
to form a mesh-like network called Swarm. This distributed network of connected
peers is often attributed as the internet of tomorrow. The total number of
monthly active users on the top 3 chat applications surpassed 4 billion users
in July 2019. As of Oct 2020, WhatsApp alone has 2 billion monthly active users
sending around 100 billion messages per day. With such vast number of people
relying on chat applications, making these applications highly secure becomes a
task of paramount importance.",2022-07-06,"Debajyoti Halder, Saksham Bhushan, Gundu Shreya, Prashant Kumar"
Text Enriched Sparse Hyperbolic Graph Convolutional Networks,"Heterogeneous networks, which connect informative nodes containing text with
different edge types, are routinely used to store and process information in
various real-world applications. Graph Neural Networks (GNNs) and their
hyperbolic variants provide a promising approach to encode such networks in a
low-dimensional latent space through neighborhood aggregation and hierarchical
feature extraction, respectively. However, these approaches typically ignore
metapath structures and the available semantic information. Furthermore, these
approaches are sensitive to the noise present in the training data. To tackle
these limitations, in this paper, we propose Text Enriched Sparse Hyperbolic
Graph Convolution Network (TESH-GCN) to capture the graph's metapath structures
using semantic signals and further improve prediction in large heterogeneous
graphs. In TESH-GCN, we extract semantic node information, which successively
acts as a connection signal to extract relevant nodes' local neighborhood and
graph-level metapath features from the sparse adjacency tensor in a
reformulated hyperbolic graph convolution layer. These extracted features in
conjunction with semantic features from the language model (for robustness) are
used for the final downstream task. Experiments on various heterogeneous graph
datasets show that our model outperforms the current state-of-the-art
approaches by a large margin on the task of link prediction. We also report a
reduction in both the training time and model parameters compared to the
existing hyperbolic approaches through a reformulated hyperbolic graph
convolution. Furthermore, we illustrate the robustness of our model by
experimenting with different levels of simulated noise in both the graph
structure and text, and also, present a mechanism to explain TESH-GCN's
prediction by analyzing the extracted metapaths.",2022-07-06,"Nurendra Choudhary, Nikhil Rao, Karthik Subbian, Chandan K. Reddy"
"Deep Learning Reveals Patterns of Diverse and Changing Sentiments
  Towards COVID-19 Vaccines Based on 11 Million Tweets","Over 12 billion doses of COVID-19 vaccines have been administered at the time
of writing. However, public perceptions of vaccines have been complex. We
analyzed COVID-19 vaccine-related tweets to understand the evolving perceptions
of COVID-19 vaccines. We finetuned a deep learning classifier using a
state-of-the-art model, XLNet, to detect each tweet's sentiment automatically.
We employed validated methods to extract the users' race or ethnicity, gender,
age, and geographical locations from user profiles. Incorporating multiple data
sources, we assessed the sentiment patterns among subpopulations and juxtaposed
them against vaccine uptake data to unravel their interactive patterns.
11,211,672 COVID-19 vaccine-related tweets corresponding to 2,203,681 users
over two years were analyzed. The finetuned model for sentiment classification
yielded an accuracy of 0.92 on testing set. Users from various demographic
groups demonstrated distinct patterns in sentiments towards COVID-19 vaccines.
User sentiments became more positive over time, upon which we observed
subsequent upswing in the population-level vaccine uptake. Surrounding dates
where positive sentiments crest, we detected encouraging news or events
regarding vaccine development and distribution. Positive sentiments in
pregnancy-related tweets demonstrated a delayed pattern compared with trends in
general population, with postponed vaccine uptake trends. Distinctive patterns
across subpopulations suggest the need of tailored strategies. Global news and
events profoundly involved in shaping users' thoughts on social media.
Populations with additional concerns, such as pregnancy, demonstrated more
substantial hesitancy since lack of timely recommendations. Feature analysis
revealed hesitancies of various subpopulations stemmed from clinical trial
logics, risks and complications, and urgency of scientific evidence.",2022-07-05,"Hanyin Wang, Meghan R. Hutch, Yikuan Li, Adrienne S. Kline, Sebastian Otero, Leena B. Mithal, Emily S. Miller, Andrew Naidech, Yuan Luo"
Optimal Verification of Rumors in Networks,"We study the diffusion of a true and a false message when agents are biased
and able to verify messages. As a recipient of a rumor who verifies it becomes
informed of the truth, a higher rumor prevalence can increase the prevalence of
the truth. We uncover conditions such that this happens and discuss policy
implications. Specifically, a planner aiming to maximize the prevalence of the
truth should allow rumors to circulate if: verification overcomes ignorance of
messages, transmission of information is relatively low, and the planner's
budget to induce verification is neither too low nor too high.",2022-07-05,"Luca Paolo Merlino, Nicole Tabasso"
"Cybersecurity Discussions in Stack Overflow: A Developer-Centred
  Analysis of Engagement and Self-Disclosure Behaviour","Stack Overflow (SO) is a popular platform among developers seeking advice on
various software-related topics, including privacy and security. As for many
knowledge-sharing websites, the value of SO depends largely on users'
engagement, namely their willingness to answer, comment or post technical
questions. Still, many of these questions (including cybersecurity-related
ones) remain unanswered, putting the site's relevance and reputation into
question. Hence, it is important to understand users' participation in privacy
and security discussions to promote engagement and foster the exchange of such
expertise. Objective: Based on prior findings on online social networks, this
work elaborates on the interplay between users' engagement and their privacy
practices in SO. Particularly, it analyses developers' self-disclosure
behaviour regarding profile visibility and their involvement in discussions
related to privacy and security. Method: We followed a mixed-methods approach
by (i) analysing SO data from 1239 cybersecurity-tagged questions along with
7048 user profiles, and (ii) conducting an anonymous online survey (N=64).
Results: About 33% of the questions we retrieved had no answer, whereas more
than 50% had no accepted answer. We observed that ""proactive"" users tend to
disclose significantly less information in their profiles than ""reactive"" and
""unengaged"" ones. However, no correlations were found between these engagement
categories and privacy-related constructs such as Perceived Control or General
Privacy Concerns. Implications: These findings contribute to (i) a better
understanding of developers' engagement towards privacy and security topics,
and (ii) to shape strategies promoting the exchange of cybersecurity expertise
in SO.",2022-07-04,"Nicolás E. Díaz Ferreyra, Melina Vidoni, Maritta Heisel, Riccardo Scandariato"
"Terrorist attacks sharpen the binary perception of ""Us"" vs. ""Them""","Terrorist attacks not only harm citizens but also shift their attention,
which has long-lasting impacts on public opinion and government policies. Yet
measuring the changes in public attention beyond media coverage has been
methodologically challenging. Here we approach this problem by starting from
Wikipedia's r\'epertoire of 5.8 million articles and a sample of 15 recent
terrorist attacks. We deploy a complex exclusion procedure to identify topics
and themes that consistently received a significant increase in attention due
to these incidents. Examining their contents reveals a clear picture: terrorist
attacks foster establishing a sharp boundary between ""Us"" (the target society)
and ""Them"" (the terrorist as the enemy). In the midst of this, one seeks to
construct identities of both sides. This triggers curiosity to learn more about
""Them"" and soul-search for a clearer understanding of ""Us"". This systematic
analysis of public reactions to disruptive events could help mitigate their
societal consequences.",2022-07-04,"Milan Jović, Lovro Šubelj, Tea Golob, Matej Makarovič, Taha Yasseri, Danijela Boberić Krstićev, Srdjan Škrbić, Zoran Levnajić"
"Towards Real-Time Counting Shortest Cycles on Dynamic Graphs: A Hub
  Labeling Approach","With the ever-increasing prevalence of graph data in a wide spectrum of
applications, it becomes essential to analyze structural trends in dynamic
graphs on a continual basis. The shortest cycle is a fundamental pattern in
graph analytics. In this paper, we investigate the problem of shortest cycle
counting for a given vertex in dynamic graphs in light of its applicability to
problems such as fraud detection. To address such queries efficiently, we
propose a 2-hop labeling based algorithm called Counting Shortest Cycle (CSC
for short). Additionally, techniques for dynamically updating the CSC index are
explored. Comprehensive experiments are conducted to demonstrate the efficiency
and effectiveness of our method. In particular, CSC enables query evaluation in
a few hundreds of microseconds for graphs with millions of edges, and improves
query efficiency by two orders of magnitude when compared to the baseline
solutions. Also, the update algorithm could efficiently cope with edge
insertions (deletions).",2022-07-03,"Qingshuai Feng, You Peng, Wenjie Zhang, Ying Zhang, Xuemin Lin"
Finding Top-r Influential Communities under Aggregation Functions,"Community search is a problem that seeks cohesive and connected subgraphs in
a graph that satisfy certain topology constraints, e.g., degree constraints.
The majority of existing works focus exclusively on the topology and ignore the
nodes' influence in the communities. To tackle this deficiency, influential
community search is further proposed to include the node's influence. Each node
has a weight, namely influence value, in the influential community search
problem to represent its network influence. The influence value of a community
is produced by an aggregated function, e.g., max, min, avg, and sum, over the
influence values of the nodes in the same community. The objective of the
influential community search problem is to locate the top-r communities with
the highest influence values while satisfying the topology constraints.
Existing studies on influential community search have several limitations: (i)
they focus exclusively on simple aggregation functions such as min, which may
fall short of certain requirements in many real-world scenarios, and (ii) they
impose no limitation on the size of the community, whereas most real-world
scenarios do. This motivates us to conduct a new study to fill this gap. We
consider the problem of identifying the top-r influential communities
with/without size constraints while using more complicated aggregation
functions such as sum or avg. We give a theoretical analysis demonstrating the
hardness of the problems and propose efficient and effective heuristic
solutions for our topr influential community search problems. Extensive
experiments on real large graphs demonstrate that our proposed solution is
significantly more efficient than baseline solutions.",2022-07-03,"You Peng, Song Bian, Rui Li, Sibo Wang, Jeffrey Xu Yu"
"Emotion Analysis using Multi-Layered Networks for Graphical
  Representation of Tweets","Anticipating audience reaction towards a certain piece of text is integral to
several facets of society ranging from politics, research, and commercial
industries. Sentiment analysis (SA) is a useful natural language processing
(NLP) technique that utilizes both lexical/statistical and deep learning
methods to determine whether different sized texts exhibit a positive,
negative, or neutral emotion. However, there is currently a lack of tools that
can be used to analyse groups of independent texts and extract the primary
emotion from the whole set. Therefore, the current paper proposes a novel
algorithm referred to as the Multi-Layered Tweet Analyzer (MLTA) that
graphically models social media text using multi-layered networks (MLNs) in
order to better encode relationships across independent sets of tweets. Graph
structures are capable of capturing meaningful relationships in complex
ecosystems compared to other representation methods. State of the art Graph
Neural Networks (GNNs) are used to extract information from the Tweet-MLN and
make predictions based on the extracted graph features. Results show that not
only does the MLTA predict from a larger set of possible emotions, delivering a
more accurate sentiment compared to the standard positive, negative or neutral,
it also allows for accurate group-level predictions of Twitter data.",2022-07-02,"Anna Nguyen, Antonio Longa, Massimiliano Luca, Joe Kaul, Gabriel Lopez"
Mining Tourism Experience on Twitter: A case study,"With the increase of digital data and social network platforms the impact of
social media science in driving company decision related to product/service
features and customer care operations is becoming more crucial. In particular,
platform such as Twitter where people can share experience about almost
everything can drastically impact the reputation and offering of a company as
well as of a place or tourism site. Text mining tools are researched and
proposed in literature in order to gain value and perform trend topics and
sentiment analysis on Twitter. As data are the fuels for these models, the
""right"" ones, i.e the domain-related ones makes a difference on their accuracy.
In this paper, we describe a pipeline of \textit{DataOps / MLOps} operations
performed over a tourism related Twitter dataset in order to comprehend tourism
motivation and interest. The gained knowledge can be exploit, by the
travel/hospitality industry in order to develop data-driven strategic service,
and by travelers which can consume relevant information about tourist
destination.",2022-06-30,"Davide Stirparo, Beatrice Penna, Mohammad Kazemi, Ariona Shashaj"
Signed ego network model and its application to Twitter,"The Ego Network Model (ENM) describes how individuals organise their social
relations in concentric circles (typically five) of decreasing intimacy, and it
has been found almost ubiquitously in social networks, both offline and online.
The ENM gauges the tie strength between peers in terms of interaction
frequency, which is easy to measure and provides a good proxy for the time
spent nurturing the relationship. However, advances in signed network analysis
have shown that positive and negative relations play very different roles in
network dynamics. For this reason, this work sets out to investigate the ENM
when including signed relations. The main contributions of this paper are
twofold: firstly, a novel method of signing relationships between individuals
using sentiment analysis and, secondly, an investigation of the properties of
Signed Ego Networks (Ego Networks with signed connections). Signed Ego Networks
are then extracted for the users of eight different Twitter datasets composed
of both specialised users (e.g. journalists) and generic users. We find that
negative links are over-represented in the active part of the Ego Networks of
all types of users, suggesting that Twitter users tend to engage regularly with
negative connections. Further, we observe that negative relationships are
overwhelmingly predominant in the Ego Network circles of specialised users,
hinting at very polarised online interactions for this category of users. In
addition, negative relationships are found disproportionately more at the more
intimate levels of the ENM for journalists, while their percentages are stable
across the circles of the other Twitter users",2022-06-30,"Jack Tacchi, Chiara Boldrini, Andrea Passarella, Marco Conti"
The maximum capability of a topological feature in link prediction,"Networks offer a powerful approach to modeling complex systems by
representing the underlying set of pairwise interactions. Link prediction is
the task that predicts links of a network that are not directly visible, with
profound applications in biological, social, and other complex systems. Despite
intensive utilization of the topological feature in this task, it is unclear to
what extent a feature can be leveraged to infer missing links. Here, we aim to
unveil the capability of a topological feature in link prediction by
identifying its prediction performance upper bound. We introduce a theoretical
framework that is compatible with different indexes to gauge the feature,
different prediction approaches to utilize the feature, and different metrics
to quantify the prediction performance. The maximum capability of a topological
feature follows a simple yet theoretically validated expression, which only
depends on the extent to which the feature is held in missing and nonexistent
links. Because a family of indexes based on the same feature shares the same
upper bound, the potential of all others can be estimated from one single
index. Furthermore, a feature's capability is lifted in the supervised
prediction, which can be mathematically quantified, allowing us to estimate the
benefit of applying machine learning algorithms. The universality of the
pattern uncovered is empirically verified by 550 structurally diverse networks.
The findings have applications in feature and method selection, and shed light
on network characteristics that make a topological feature effective in link
prediction.",2022-06-30,"Yijun Ran, Xiao-Ke Xu, Tao Jia"
"CoVaxNet: An Online-Offline Data Repository for COVID-19 Vaccine
  Hesitancy Research","Despite the astonishing success of COVID-19 vaccines against the virus, a
substantial proportion of the population is still hesitant to be vaccinated,
undermining governmental efforts to control the virus. To address this problem,
we need to understand the different factors giving rise to such a behavior,
including social media discourses, news media propaganda, government responses,
demographic and socioeconomic statuses, and COVID-19 statistics, etc. However,
existing datasets fail to cover all these aspects, making it difficult to form
a complete picture in inferencing about the problem of vaccine hesitancy. In
this paper, we construct a multi-source, multi-modal, and multi-feature
online-offline data repository CoVaxNet. We provide descriptive analyses and
insights to illustrate critical patterns in CoVaxNet. Moreover, we propose a
novel approach for connecting online and offline data so as to facilitate the
inference tasks that exploit complementary information sources.",2022-06-30,"Bohan Jiang, Paras Sheth, Baoxin Li, Huan Liu"
"Breaking indecision in multi-agent, multi-option dynamics","How does a group of agents break indecision when deciding about options with
qualities that are hard to distinguish? Biological and artificial multi-agent
systems, from honeybees and bird flocks to bacteria, robots, and humans, often
need to overcome indecision when choosing among options in situations in which
the performance or even the survival of the group are at stake. Breaking
indecision is also important because in a fully indecisive state agents are not
biased toward any specific option and therefore the agent group is maximally
sensitive and prone to adapt to inputs and changes in its environment. Here, we
develop a mathematical theory to study how decisions arise from the breaking of
indecision. Our approach is grounded in both equivariant and network
bifurcation theory. We model decision from indecision as synchrony-breaking in
influence networks in which each node is the value assigned by an agent to an
option. First, we show that three universal decision behaviors, namely,
deadlock, consensus, and dissensus, are the generic outcomes of
synchrony-breaking bifurcations from a fully synchronous state of indecision in
influence networks. Second, we show that all deadlock and consensus value
patterns and some dissensus value patterns are predicted by the symmetry of the
influence networks. Third, we show that there are also many `exotic' dissensus
value patterns. These patterns are predicted by network architecture, but not
by network symmetries, through a new synchrony-breaking branching lemma. This
is the first example of exotic solutions in an application. Numerical
simulations of a novel influence network model illustrate our theoretical
results.",2022-06-29,"Alessio Franci, Martin Golubitsky, Ian Stewart, Anastasia Bizyaeva, Naomi Ehrich Leonard"
"Modeling Teams Performance Using Deep Representational Learning on
  Graphs","The large majority of human activities require collaborations within and
across formal or informal teams. Our understanding of how the collaborative
efforts spent by teams relate to their performance is still a matter of debate.
Teamwork results in a highly interconnected ecosystem of potentially
overlapping components where tasks are performed in interaction with team
members and across other teams. To tackle this problem, we propose a graph
neural network model designed to predict a team's performance while identifying
the drivers that determine such an outcome. In particular, the model is based
on three architectural channels: topological, centrality, and contextual which
capture different factors potentially shaping teams' success. We endow the
model with two attention mechanisms to boost model performance and allow
interpretability. A first mechanism allows pinpointing key members inside the
team. A second mechanism allows us to quantify the contributions of the three
driver effects in determining the outcome performance. We test model
performance on a wide range of domains outperforming most of the classical and
neural baselines considered. Moreover, we include synthetic datasets
specifically designed to validate how the model disentangles the intended
properties on which our model vastly outperforms baselines.",2022-06-29,"Francesco Carli, Pietro Foini, Nicolò Gozzi, Nicola Perra, Rossano Schifanella"
"Quantifying the structure of controversial discussions with unsupervised
  methods: a look into the Twitter climate change conversation","Social media provides an essential platform for shaping and sharing opinions
and consuming information in a decentralized way. However, users often interact
with and are exposed to information mostly aligned with their beliefs, creating
a positive feedback mechanism that reinforces those beliefs and excludes
contrasting ones. In this paper, we study such mechanisms by analyzing the
social network dynamics of controversial Twitter discussions using unsupervised
methods that demand little computational power. Specifically, we focus on the
retweet networks of the climate change conversation during 2019, when important
climate social movements flourished. We find echo chambers of climate believers
and climate skeptics that we identify based solely on the retweeting patterns
of Twitter users. In particular, we study the information sources, or chambers,
consumed by the audience of the leading users of the conversation. Users with
similar (contrasting) ideological positions show significantly high
(low)-overlapping chambers, resulting in a bimodal overlap distribution.
Further, we uncover the ideological position of previously unobserved
high-impact users based on how many audience members fall into either echo
chamber. We uncover the ideology of more than half of the retweeting population
as either climate believers or skeptics and find that the cross-group
communication is small. Moreover, we find that, while the echo chamber
structures are consistent throughout the year, most users inside the echo
chambers change from one week to the next, suggesting that they are a stable
emergent property of the Twittersphere. Interestingly, we detect a significant
decrease in polarization and a significant increase on the number of climate
skeptics that coincides with the main #FridaysForFuture strikes during
September, 2019.",2022-06-29,"Blas Kolic, Fabián Aguirre-López, Sergio Hernández-Williams, Guillermo Garduño-Hernández"
A Contribution to the Defense of Liquid Democracy,"Liquid democracy is a hybrid direct-representative decision making process
that provides each voter with the option of either voting directly or to
delegate their vote to another voter, i.e., to a representative of their
choice. One of the proposed advantages of liquid democracy is that, in general,
it is assumed that voters will delegate their vote to others that are better
informed, which leads to more informed and better decisions. Considering an
audience from various knowledge domains, we provide an accessible high-level
analysis of a prominent critique of liquid democracy by Caragiannis and Micha.
Caragiannis and Micha's critique contains three central topics: 1. Analysis
using their $\alpha$-delegation model, which does not assume delegation to the
more informed; 2. Novel delegation network structures where it is advantageous
to delegate to the less informed rather than the more informed; and 3. Due to
NP hardness, the implied impracticability of a social network obtaining an
optimal delegation structure. We show that in the real world, Caragiannis and
Micha's critique of liquid democracy has little or no relevance. Respectively,
our critique is based on: 1. The identification of incorrect
$\alpha$-delegation model assumptions; 2. A lack of novel delegation structures
and their effect in a real-world implementation of liquid democracy, which
would be guaranteed with constraints that sensibly distribute voting power; and
3. The irrelevance of an optimal delegation structure if the correct result is
guaranteed regardless. We conclude that Caragiannis and Micha's critique has no
significant negative relevance to the proposition of liquid democracy.",2022-06-28,"Gregory Butterworth, Richard Booth"
Sublinear-Time Clustering Oracle for Signed Graphs,"Social networks are often modeled using signed graphs, where vertices
correspond to users and edges have a sign that indicates whether an interaction
between users was positive or negative. The arising signed graphs typically
contain a clear community structure in the sense that the graph can be
partitioned into a small number of polarized communities, each defining a
sparse cut and indivisible into smaller polarized sub-communities. We provide a
local clustering oracle for signed graphs with such a clear community
structure, that can answer membership queries, i.e., ""Given a vertex $v$, which
community does $v$ belong to?"", in sublinear time by reading only a small
portion of the graph. Formally, when the graph has bounded maximum degree and
the number of communities is at most $O(\log n)$, then with
$\tilde{O}(\sqrt{n}\operatorname{poly}(1/\varepsilon))$ preprocessing time, our
oracle can answer each membership query in
$\tilde{O}(\sqrt{n}\operatorname{poly}(1/\varepsilon))$ time, and it correctly
classifies a $(1-\varepsilon)$-fraction of vertices w.r.t. a set of hidden
planted ground-truth communities. Our oracle is desirable in applications where
the clustering information is needed for only a small number of vertices.
Previously, such local clustering oracles were only known for unsigned graphs;
our generalization to signed graphs requires a number of new ideas and gives a
novel spectral analysis of the behavior of random walks with signs. We evaluate
our algorithm for constructing such an oracle and answering membership queries
on both synthetic and real-world datasets, validating its performance in
practice.",2022-06-28,"Stefan Neumann, Pan Peng"
The COVID-19 Pandemic on the Turkish Twittersphere,"With the increase in the time spent at home, social media platforms' role has
become an integral part of the public discussion in the COVID-19 period.
Individuals use social media platforms to express their emotions, interact, and
engage in public debate. Therefore, it is essential to analyze social media
platforms for those wanting to understand public opinion during the pandemic.
This thesis is the first study that examines the Turkish Twitter-sphere to
understand the change in public opinion during the COVID-19 outbreak. For that
purpose, starting from 12 February 2020 (one month before the first announced
coronavirus cases in Turkey), 4.3 million Turkish tweets with a broad range of
keywords are collected until June 2020 to investigate the public opinion change
on different topics and to examine the actors leading to that change. The scope
of the analysis is not only health-related discussion but also includes a
broader range of themes such as politics, economy, and disinformation. This
study also collects 4.15 million Turkish tweets with keywords of vaccine
(""a\c{s}{\i}"" in Turkish) from 4 April 2020 until 17 March 2021 to unpack the
health of the information ecosystem. Preliminary results suggest that (i)
religion is the prominent phenomenon in Turkish people's perception of the
pandemic, (ii) and the Turkish Twitter-sphere is highly vulnerable to
mis/disinformation operations, and (iii) several communities with divergent
interests exist in the vaccine network.",2022-06-28,Burak Ozturan
"Calibrated Nonparametric Scan Statistics for Anomalous Pattern Detection
  in Graphs","We propose a new approach, the calibrated nonparametric scan statistic
(CNSS), for more accurate detection of anomalous patterns in large-scale,
real-world graphs. Scan statistics identify connected subgraphs that are
interesting or unexpected through maximization of a likelihood ratio statistic;
in particular, nonparametric scan statistics (NPSSs) identify subgraphs with a
higher than expected proportion of individually significant nodes. However, we
show that recently proposed NPSS methods are miscalibrated, failing to account
for the maximization of the statistic over the multiplicity of subgraphs. This
results in both reduced detection power for subtle signals, and low precision
of the detected subgraph even for stronger signals. Thus we develop a new
statistical approach to recalibrate NPSSs, correctly adjusting for multiple
hypothesis testing and taking the underlying graph structure into account.
While the recalibration, based on randomization testing, is computationally
expensive, we propose both an efficient (approximate) algorithm and new,
closed-form lower bounds (on the expected maximum proportion of significant
nodes for subgraphs of a given size, under the null hypothesis of no anomalous
patterns). These advances, along with the integration of recent core-tree
decomposition methods, enable CNSS to scale to large real-world graphs, with
substantial improvement in the accuracy of detected subgraphs. Extensive
experiments on both semi-synthetic and real-world datasets are demonstrated to
validate the effectiveness of our proposed methods, in comparison with
state-of-the-art counterparts.",2022-06-26,"Chunpai Wang, Daniel B. Neill, Feng Chen"
Finding Proper Time Intervals for Dynamic Network Extraction,"Extracting a proper dynamic network for modelling a time-dependent complex
system is an important issue. Building a correct model is related to finding
out critical time points where a system exhibits considerable change. In this
work, we propose to measure network similarity to detect proper time intervals.
We develop three similarity metrics, node, link, and neighborhood similarities,
for any consecutive snapshots of a dynamic network. Rather than a label or a
user-defined threshold, we use statistically expected values of proposed
similarities under a null-model to state whether the system changes critically.
We experimented on two different data sets with different temporal dynamics:
The Wi-Fi access points logs of a university campus and Enron emails. Results
show that, first, proposed similarities reflect similar signal trends with
network topological properties with less noisy signals, and their scores are
scale invariant. Second, proposed similarities generate better signals than
adjacency correlation with optimal noise and diversity. Third, using
statistically expected values allows us to find different time intervals for a
system, leading to the extraction of non-redundant snapshots for dynamic
network modelling.",2022-06-25,"Günce Keziban Orman, Nadir Türe, Selim Balcisoy, Hasan Alp Boz"
Affective Signals in a Social Media Recommender System,"People come to social media to satisfy a variety of needs, such as being
informed, entertained and inspired, or connected to their friends and
community. Hence, to design a ranking function that gives useful and
personalized post recommendations, it would be helpful to be able to predict
the affective response a user may have to a post (e.g., entertained, informed,
angered). This paper describes the challenges and solutions we developed to
apply Affective Computing to social media recommendation systems.
  We address several types of challenges. First, we devise a taxonomy of
affects that was small (for practical purposes) yet covers the important
nuances needed for the application. Second, to collect training data for our
models, we balance between signals that are already available to us (namely,
different types of user engagement) and data we collected through a carefully
crafted human annotation effort on 800k posts. We demonstrate that affective
response information learned from this dataset improves a module in the
recommendation system by more than 8%. Online experimentation also demonstrates
statistically significant decreases in surfaced violating content and increases
in surfaced content that users find valuable.",2022-06-24,"Jane Dwivedi-Yu, Yi-Chia Wang, Lijing Qin, Cristian Canton-Ferrer, Alon Y. Halevy"
Inferring Tie Strength in Temporal Networks,"Inferring tie strengths in social networks is an essential task in social
network analysis. Common approaches classify the ties as wea} and strong ties
based on the strong triadic closure (STC). The STC states that if for three
nodes, $A$, $B$, and $C$, there are strong ties between $A$ and $B$, as well as
$A$ and $C$, there has to be a (weak or strong) tie between $B$ and $C$. A
variant of the STC called STC+ allows adding a few new weak edges to obtain
improved solutions. So far, most works discuss the STC or STC+ in static
networks. However, modern large-scale social networks are usually highly
dynamic, providing user contacts and communications as streams of edge updates.
Temporal networks capture these dynamics. To apply the STC to temporal
networks, we first generalize the STC and introduce a weighted version such
that empirical a priori knowledge given in the form of edge weights is
respected by the STC. Similarly, we introduce a generalized weighted version of
the STC+. The weighted STC is hard to compute, and our main contribution is an
efficient 2-approximation (resp. 3-approximation) streaming algorithm for the
weighted STC (resp. STC+) in temporal networks. As a technical contribution, we
introduce a fully dynamic $k$-approximation for the minimum weighted vertex
cover problem in hypergraphs with edges of size $k$, which is a crucial
component of our streaming algorithms. An empirical evaluation shows that the
weighted STC leads to solutions that better capture the a priori knowledge
given by the edge weights than the non-weighted STC. Moreover, we show that our
streaming algorithm efficiently approximates the weighted STC in real-world
large-scale social networks.",2022-06-23,"Lutz Oettershagen, Athanasios L. Konstantinidis, Giuseppe F. Italiano"
"Misinformation Mitigation under Differential Propagation Rates and
  Temporal Penalties","We propose an information propagation model that captures important temporal
aspects that have been well observed in the dynamics of fake news diffusion, in
contrast with the diffusion of truth. The model accounts for differential
propagation rates of truth and misinformation and for user reaction times. We
study a time-sensitive variant of the \textit{misinformation mitigation}
problem, where $k$ seeds are to be selected to activate a truth campaign so as
to minimize the number of users that adopt misinformation propagating through a
social network. We show that the resulting objective is non-submodular and
employ a sandwiching technique by defining submodular upper and lower bounding
functions, providing data-dependent guarantees. In order to enable the use of a
reverse sampling framework, we introduce a weighted version of reverse
reachability sets that captures the associated differential propagation rates
and establish a key equivalence between weighted set coverage probabilities and
mitigation with respect to the sandwiching functions. Further, we propose an
offline reverse sampling framework that provides $(1 - 1/e -
\epsilon)$-approximate solutions to our bounding functions and introduce an
importance sampling technique to reduce the sample complexity of our solution.
Finally, we show how our framework can provide an anytime solution to the
problem. Experiments over five datasets show that our approach outperforms
previous approaches and is robust to uncertainty in the model parameters.",2022-06-22,"Michael Simpson, Farnoosh Hashemi, Laks V. S. Lakshmanan"
"Precipitation event-based networks: an analysis of the relations between
  network metrics and meteorological properties","The study of complex systems in nature is essential to understand the
interactions between different elements and how they influence one another.
Complex network theory is a powerful tool that helps us to analyze these
interactions and gain insights into the behavior of such systems. Surprisingly,
this theory has been underutilized in the field of weather science, which
focuses on the immediate state of the atmosphere. Our research aims to fill
this gap by exploring the use of complex network theory in weather science.
Specifically, we employ weather radar data to construct event-based
geographical networks. By analyzing the relations between meteorological
properties and network metrics in these event-based networks, we can gain a
better understanding of the behavior of precipitation events. Our findings
reveal significant correlations between various meteorological properties and
network metrics, shedding light on the underlying mechanisms that govern
precipitation events. Through our work, we hope to demonstrate the potential of
complex network theory in weather science and inspire further research in this
field.",2022-06-22,"Aurelienne A. S. Jorge, Douglas Uba, Alex A. Fernandes, Izabelly C. Costa, Leonardo B. L. Santos"
"Exploring user needs in relation to algorithmically constructed
  classifications of publications","Algorithmic classification of research publications has been created to study
different aspects of research. Such classifications can be used to support
information needs in universities for decision making. However, the
classifications have foremost been evaluated quantitatively regarding their
content, but not qualitatively regarding their feasibility in a specific
context. The aim of this study was to explore and evaluate the usefulness of
such classifications to users in the context of exploring an emerging research
area. I conducted four interviews with managers of a project aimed to support
research and application of artificial intelligence at the Swedish medical
university Karolinska Institutet. The interviews focused on the information
need of the managers. To support the project, a classification was created by
clustering of publications in a citation network. A cluster map based on this
classification was provided to the project leader and one interview focused on
the use of the classification in the project in relation to the stated
information needs. The interviews showed that the aim of the project was to
improve competence, enhance communication between researchers and develop
support structures. Getting an overview of artificial intelligence at the
university and information about who is doing what was important to fulfill
this aim. The cluster map was used to support activities conducted by the
project leader, such as interviews and information gathering. It was also used
to get overview and display of AI research at KI. Interpretation was found to
be challenging in some cases. The interactivity of the map facilitated
interpretation. This study was small in scope, but it provides one piece of
knowledge about the information needs related to algorithmic classifications.",2022-06-22,Peter Sjögårde
"Online Coordination: Methods and Comparative Case Studies of Coordinated
  Groups across Four Events in the United States","Coordinated groups of user accounts working together in online social media
can be used to manipulate the online discourse and thus is an important area of
study. In this study, we work towards a general theory of coordination. There
are many ways to coordinate groups online: semantic, social, referral and many
more. Each represents a coordination dimension, where the more dimensions of
coordination are present for one event, the stronger the coordination present.
We build on existing approaches that detect coordinated groups by identifying
high levels of synchronized actions within a specified time window. A key
concern with this approach is the selection of the time window. We propose a
method that selects the optimal window size to accurately capture local
coordination while avoiding the capture of coincidental synchronicity. With
this enhanced method of coordination detection, we perform a comparative study
across four events: US Elections Primaries 2020, Reopen America 2020, Capitol
Riots 2021 and COVID Vaccine Release 2021. Herein, we explore the following
three dimensions of coordination for each event -- semantic, referral and
social coordination -- and perform group and user analysis within and among the
events. This allows us to expose different user coordination behavior patterns
and identify narratives and user support themes, hence estimating the degree
and theme of coordination.",2022-06-21,"Lynnette Hui Xian Ng, Kathleen M. Carley"
Twitter conversations predict the daily confirmed COVID-19 cases,"As of writing this paper, COVID-19 (Coronavirus disease 2019) has spread to
more than 220 countries and territories. Following the outbreak, the pandemic's
seriousness has made people more active on social media, especially on the
microblogging platforms such as Twitter and Weibo. The pandemic-specific
discourse has remained on-trend on these platforms for months now. Previous
studies have confirmed the contributions of such socially generated
conversations towards situational awareness of crisis events. The early
forecasts of cases are essential to authorities to estimate the requirements of
resources needed to cope with the outgrowths of the virus. Therefore, this
study attempts to incorporate the public discourse in the design of forecasting
models particularly targeted for the steep-hill region of an ongoing wave. We
propose a sentiment-involved topic-based latent variables search methodology
for designing forecasting models from publicly available Twitter conversations.
As a use case, we implement the proposed methodology on Australian COVID-19
daily cases and Twitter conversations generated within the country.
Experimental results: (i) show the presence of latent social media variables
that Granger-cause the daily COVID-19 confirmed cases, and (ii) confirm that
those variables offer additional prediction capability to forecasting models.
Further, the results show that the inclusion of social media variables
introduces 48.83--51.38% improvements on RMSE over the baseline models. We also
release the large-scale COVID-19 specific geotagged global tweets dataset,
MegaGeoCOV, to the public anticipating that the geotagged data of this scale
would aid in understanding the conversational dynamics of the pandemic through
other spatial and temporal contexts.",2022-06-21,"Rabindra Lamsal, Aaron Harwood, Maria Rodriguez Read"
"Online Trajectory Prediction for Metropolitan Scale Mobility Digital
  Twin","Knowing ""what is happening"" and ""what will happen"" of the mobility in a city
is the building block of a data-driven smart city system. In recent years,
mobility digital twin that makes a virtual replication of human mobility and
predicting or simulating the fine-grained movements of the subjects in a
virtual space at a metropolitan scale in near real-time has shown its great
potential in modern urban intelligent systems. However, few studies have
provided practical solutions. The main difficulties are four-folds. 1) The
daily variation of human mobility is hard to model and predict; 2) the
transportation network enforces a complex constraints on human mobility; 3)
generating a rational fine-grained human trajectory is challenging for existing
machine learning models; and 4) making a fine-grained prediction incurs high
computational costs, which is challenging for an online system. Bearing these
difficulties in mind, in this paper we propose a two-stage human mobility
predictor that stratifies the coarse and fine-grained level predictions. In the
first stage, to encode the daily variation of human mobility at a metropolitan
level, we automatically extract citywide mobility trends as crowd contexts and
predict long-term and long-distance movements at a coarse level. In the second
stage, the coarse predictions are resolved to a fine-grained level via a
probabilistic trajectory retrieval method, which offloads most of the heavy
computations to the offline phase. We tested our method using a real-world
mobile phone GPS dataset in the Kanto area in Japan, and achieved good
prediction accuracy and a time efficiency of about 2 min in predicting future
1h movements of about 220K mobile phone users on a single machine to support
more higher-level analysis of mobility prediction.",2022-06-21,"Zipei Fan, Xiaojie Yang, Wei Yuan, Renhe Jiang, Quanjun Chen, Xuan Song, Ryosuke Shibasaki"
Statistical network isomorphism,"Graph isomorphism is a problem for which there is no known polynomial-time
solution. Nevertheless, assessing (dis)similarity between two or more networks
is a key task in many areas, such as image recognition, biology, chemistry,
computer and social networks. Moreover, questions of similarity are typically
more general and their answers more widely applicable than the more restrictive
isomorphism question. In this article, we offer a statistical answer to the
following questions: a) {\it ``Are networks $G_1$ and $G_2$ similar?''}, b)
{\it ``How different are the networks $G_1$ and $G_2$?''} and c) {\it ``Is
$G_3$ more similar to $G_1$ or $G_2$?''}. Our comparisons begin with the
transformation of each graph into an all-pairs distance matrix. Our node-node
distance, Jaccard distance, has been shown to offer a good reflection of the
graph's connectivity structure. We then model these distances as probability
distributions. Finally, we use well-established statistical tools to gauge the
(dis)similarities in terms of probability distribution (dis)similarity. This
comparison procedure aims to detect (dis)similarities in connectivity
structure, not in easily observable graph characteristics, such as degrees,
edge counts or density. We validate our hypothesis that graphs can be
meaningfully summarized and compared via their node-node distance
distributions, using several synthetic and real-world graphs. Empirical results
demonstrate its validity and the accuracy of our comparison technique.",2022-06-21,"Pierre Miasnikof, Alexander Y. Shestopaloff, Cristián Bravo, Yuri Lawryshyn"
"A Bounded-Confidence Model of Opinion Dynamics with Heterogeneous
  Node-Activity Levels","Agent-based models of opinion dynamics allow one to examine the spread of
opinions between entities and to study phenomena such as consensus,
polarization, and fragmentation. By studying a model of opinion dynamics on a
social network, one can explore the effects of network structure on these
phenomena. In social networks, some individuals share their ideas and opinions
more frequently than others. These disparities can arise from heterogeneous
sociabilities, heterogeneous activity levels, different prevalences to share
opinions when engaging in a social-media platform, or something else. To
examine the impact of such heterogeneities on opinion dynamics, we generalize
the Deffuant--Weisbuch (DW) bounded-confidence model (BCM) of opinion dynamics
by incorporating node weights. The node weights allow us to model agents with
different probabilities of interacting. Using numerical simulations, we
systematically investigate (using a variety of network structures and
node-weight distributions) the effects of node weights, which we assign
uniformly at random to the nodes. We demonstrate that introducing heterogeneous
node weights results in longer convergence times and more opinion fragmentation
than in a baseline DW model. The node weights in our BCM allow one to consider
a variety of sociological scenarios in which agents have heterogeneous
probabilities of interacting with other agents.",2022-06-19,"Grace J. Li, Mason A. Porter"
"MetaGL: Evaluation-Free Selection of Graph Learning Models via
  Meta-Learning","Given a graph learning task, such as link prediction, on a new graph, how can
we select the best method as well as its hyperparameters (collectively called a
model) without having to train or evaluate any model on the new graph? Model
selection for graph learning has been largely ad hoc. A typical approach has
been to apply popular methods to new datasets, but this is often suboptimal. On
the other hand, systematically comparing models on the new graph quickly
becomes too costly, or even impractical. In this work, we develop the first
meta-learning approach for evaluation-free graph learning model selection,
called MetaGL, which utilizes the prior performances of existing methods on
various benchmark graph datasets to automatically select an effective model for
the new graph, without any model training or evaluations. To quantify
similarities across a wide variety of graphs, we introduce specialized
meta-graph features that capture the structural characteristics of a graph.
Then we design G-M network, which represents the relations among graphs and
models, and develop a graph-based meta-learner operating on this G-M network,
which estimates the relevance of each model to different graphs. Extensive
experiments show that using MetaGL to select a model for the new graph greatly
outperforms several existing meta-learning techniques tailored for graph
learning model selection (up to 47% better), while being extremely fast at test
time (~1 sec).",2022-06-18,"Namyong Park, Ryan Rossi, Nesreen Ahmed, Christos Faloutsos"
An Invertible Graph Diffusion Neural Network for Source Localization,"Localizing the source of graph diffusion phenomena, such as misinformation
propagation, is an important yet extremely challenging task. Existing source
localization models typically are heavily dependent on the hand-crafted rules.
Unfortunately, a large portion of the graph diffusion process for many
applications is still unknown to human beings so it is important to have
expressive models for learning such underlying rules automatically. This paper
aims to establish a generic framework of invertible graph diffusion models for
source localization on graphs, namely Invertible Validity-aware Graph Diffusion
(IVGD), to handle major challenges including 1) Difficulty to leverage
knowledge in graph diffusion models for modeling their inverse processes in an
end-to-end fashion, 2) Difficulty to ensure the validity of the inferred
sources, and 3) Efficiency and scalability in source inference. Specifically,
first, to inversely infer sources of graph diffusion, we propose a graph
residual scenario to make existing graph diffusion models invertible with
theoretical guarantees; second, we develop a novel error compensation mechanism
that learns to offset the errors of the inferred sources. Finally, to ensure
the validity of the inferred sources, a new set of validity-aware layers have
been devised to project inferred sources to feasible regions by flexibly
encoding constraints with unrolled optimization techniques. A linearization
technique is proposed to strengthen the efficiency of our proposed layers. The
convergence of the proposed IVGD is proven theoretically. Extensive experiments
on nine real-world datasets demonstrate that our proposed IVGD outperforms
state-of-the-art comparison methods significantly. We have released our code at
https://github.com/xianggebenben/IVGD.",2022-06-18,"Junxiang Wang, Junji Jiang, Liang Zhao"
"Utilitarian Welfare Optimization in the Generalized Vertex Coloring
  Games: An Implication to Venue Selection in Events Planning","We consider a general class of multi-agent games in networks, namely the
generalized vertex coloring games (G-VCGs), inspired by real-life applications
of the venue selection problem in events planning. Certain utility responding
to the contemporary coloring assignment will be received by each agent under
some particular mechanism, who, striving to maximize his own utility, is
restricted to local information thus self-organizing when choosing another
color. Our focus is on maximizing some utilitarian-looking welfare objective
function concerning the cumulative utilities across the network in a
decentralized fashion. Firstly, we investigate on a special class of the
G-VCGs, namely Identical Preference VCGs (IP-VCGs) which recovers the
rudimentary work by \cite{chaudhuri2008network}. We reveal its convergence even
under a completely greedy policy and completely synchronous settings, with a
stochastic bound on the converging rate provided. Secondly, regarding the
general G-VCGs, a greediness-preserved Metropolis-Hasting based policy is
proposed for each agent to initiate with the limited information and its
optimality under asynchronous settings is proved using theories from the
regular perturbed Markov processes. The policy was also empirically witnessed
to be robust under independently synchronous settings. Thirdly, in the spirit
of ``robust coloring'', we include an expected loss term in our objective
function to balance between the utilities and robustness. An optimal coloring
for this robust welfare optimization would be derived through a second-stage
MH-policy driven algorithm. Simulation experiments are given to showcase the
efficiency of our proposed strategy.",2022-06-18,Zeyi Chen
Predicting Hate Intensity of Twitter Conversation Threads,"Tweets are the most concise form of communication in online social media,
wherein a single tweet has the potential to make or break the discourse of the
conversation. Online hate speech is more accessible than ever, and stifling its
propagation is of utmost importance for social media companies and users for
congenial communication. Most of the research barring a recent few has focused
on classifying an individual tweet regardless of the tweet thread/context
leading up to that point. One of the classical approaches to curb hate speech
is to adopt a reactive strategy after the hate speech postage. The ex-post
facto strategy results in neglecting subtle posts that do not show the
potential to instigate hate speech on their own but may portend in the
subsequent discussion ensuing in the post's replies. In this paper, we propose
DRAGNET++, which aims to predict the intensity of hatred that a tweet can bring
in through its reply chain in the future. It uses the semantic and propagating
structure of the tweet threads to maximize the contextual information leading
up to and the fall of hate intensity at each subsequent tweet. We explore three
publicly available Twitter datasets -- Anti-Racism contains the reply tweets of
a collection of social media discourse on racist remarks during US political
and Covid-19 background; Anti-Social presents a dataset of 40 million tweets
amidst the COVID-19 pandemic on anti-social behaviours; and Anti-Asian presents
Twitter datasets collated based on anti-Asian behaviours during COVID-19
pandemic. All the curated datasets consist of structural graph information of
the Tweet threads. We show that DRAGNET++ outperforms all the state-of-the-art
baselines significantly. It beats the best baseline by an 11% margin on the
Person correlation coefficient and a decrease of 25% on RMSE for the
Anti-Racism dataset with a similar performance on the other two datasets.",2022-06-16,"Qing Meng, Tharun Suresh, Roy Ka-Wei Lee, Tanmoy Chakraborty"
"JU_NLP at HinglishEval: Quality Evaluation of the Low-Resource
  Code-Mixed Hinglish Text","In this paper we describe a system submitted to the INLG 2022 Generation
Challenge (GenChal) on Quality Evaluation of the Low-Resource Synthetically
Generated Code-Mixed Hinglish Text. We implement a Bi-LSTM-based neural network
model to predict the Average rating score and Disagreement score of the
synthetic Hinglish dataset. In our models, we used word embeddings for English
and Hindi data, and one hot encodings for Hinglish data. We achieved a F1 score
of 0.11, and mean squared error of 6.0 in the average rating score prediction
task. In the task of Disagreement score prediction, we achieve a F1 score of
0.18, and mean squared error of 5.0.",2022-06-16,"Prantik Guha, Rudra Dhar, Dipankar Das"
Research Topic Flows in Co-Authorship Networks,"In scientometrics, scientific collaboration is often analyzed by means of
co-authorships. An aspect which is often overlooked and more difficult to
quantify is the flow of expertise between authors from different research
topics, which is an important part of scientific progress. With the Topic Flow
Network (TFN) we propose a graph structure for the analysis of research topic
flows between scientific authors and their respective research fields.
  Based on a multi-graph and a topic model, our proposed network structure
accounts for intratopic as well as intertopic flows. Our method requires for
the construction of a TFN solely a corpus of publications (i.e., author and
abstract information). From this, research topics are discovered automatically
through non-negative matrix factorization. The thereof derived TFN allows for
the application of social network analysis techniques, such as common metrics
and community detection. Most importantly, it allows for the analysis of
intertopic flows on a large, macroscopic scale, i.e., between research topic,
as well as on a microscopic scale, i.e., between certain sets of authors.
  We demonstrate the utility of TFNs by applying our method to two
comprehensive corpora of altogether 20 Mio. publications spanning more than 60
years of research in the fields computer science and mathematics. Our results
give evidence that TFNs are suitable, e.g., for the analysis of topical
communities, the discovery of important authors in different fields, and, most
notably, the analysis of intertopic flows, i.e., the transfer of topical
expertise. Besides that, our method opens new directions for future research,
such as the investigation of influence relationships between research fields.",2022-06-16,"Bastian Schäfermeier, Johannes Hirth, Tom Hanika"
Summarizing Labeled Multi-Graphs,"Real-world graphs can be difficult to interpret and visualize beyond a
certain size. To address this issue, graph summarization aims to simplify and
shrink a graph, while maintaining its high-level structure and characteristics.
Most summarization methods are designed for homogeneous, undirected, simple
graphs; however, many real-world graphs are ornate; with characteristics
including node labels, directed edges, edge multiplicities, and self-loops. In
this paper we propose LM-Gsum, a versatile yet rigorous graph summarization
model that (to the best of our knowledge, for the first time) can handle graphs
with all the aforementioned characteristics (and any combination thereof).
Moreover, our proposed model captures basic sub-structures that are prevalent
in real-world graphs, such as cliques, stars, etc. LM-Gsum compactly quantifies
the information content of a complex graph using a novel encoding scheme, where
it seeks to minimize the total number of bits required to encode (i) the
summary graph, as well as (ii) the corrections required for reconstructing the
input graph losslessly. To accelerate the summary construction, it creates
super-nodes efficiently by merging nodes in groups. Experiments demonstrate
that LM-Gsum facilitates the visualization of real-world complex graphs,
revealing interpretable structures and high- level relationships. Furthermore,
LM-Gsum achieves better trade-off between compression rate and running time,
relative to existing methods (only) on comparable settings.",2022-06-15,"Dimitris Berberidis, Pierre J. Liang, Leman Akoglu"
Simplicially driven simple contagion,"Single contagion processes are known to display a continuous transition from
an epidemic-free phase at low contagion rates to the epidemic state for rates
above a critical threshold. This transition can become discontinuous when two
simple contagion processes are coupled in a bi-directional symmetric way.
However, in many cases, the coupling is not symmetric and the processes can be
of a different nature. For example, risky social behaviors -- such as not
wearing masks or engaging in large gatherings -- can affect the spread of a
disease, and their adoption dynamics via social reinforcement mechanisms are
better described by complex contagion models, rather than by the simple
contagion paradigm, which is more appropriate for disease spreading phenomena.
Motivated by this example, we consider a simplicial contagion (describing the
adoption of a behavior) that uni-directionally drives a simple contagion
(describing a disease propagation). We show that, above a critical driving
strength, such driven simple contagion can exhibit both discontinuous
transitions and bi-stability, which are instead absent in standard simple
contagions. We provide a mean-field analytical description of the phase diagram
of the system, and complement the results with Markov-chain simulations. Our
results provide a novel route for a simple contagion process to display the
phenomenology of a higher-order contagion, through a driving mechanism that may
be hidden or unobservable in many practical instances.",2022-06-15,"Maxime Lucas, Iacopo Iacopini, Thomas Robiglio, Alain Barrat, Giovanni Petri"
"SciTweets -- A Dataset and Annotation Framework for Detecting Scientific
  Online Discourse","Scientific topics, claims and resources are increasingly debated as part of
online discourse, where prominent examples include discourse related to
COVID-19 or climate change. This has led to both significant societal impact
and increased interest in scientific online discourse from various disciplines.
For instance, communication studies aim at a deeper understanding of biases,
quality or spreading pattern of scientific information whereas computational
methods have been proposed to extract, classify or verify scientific claims
using NLP and IR techniques. However, research across disciplines currently
suffers from both a lack of robust definitions of the various forms of
science-relatedness as well as appropriate ground truth data for distinguishing
them. In this work, we contribute (a) an annotation framework and corresponding
definitions for different forms of scientific relatedness of online discourse
in Tweets, (b) an expert-annotated dataset of 1261 tweets obtained through our
labeling framework reaching an average Fleiss Kappa $\kappa$ of 0.63, (c) a
multi-label classifier trained on our data able to detect science-relatedness
with 89% F1 and also able to detect distinct forms of scientific knowledge
(claims, references). With this work we aim to lay the foundation for
developing and evaluating robust methods for analysing science as part of
large-scale online discourse.",2022-06-15,"Salim Hafid, Sebastian Schellhammer, Sandra Bringay, Konstantin Todorov, Stefan Dietze"
TeKo: Text-Rich Graph Neural Networks with External Knowledge,"Graph Neural Networks (GNNs) have gained great popularity in tackling various
analytical tasks on graph-structured data (i.e., networks). Typical GNNs and
their variants follow a message-passing manner that obtains network
representations by the feature propagation process along network topology,
which however ignore the rich textual semantics (e.g., local word-sequence)
that exist in many real-world networks. Existing methods for text-rich networks
integrate textual semantics by mainly utilizing internal information such as
topics or phrases/words, which often suffer from an inability to
comprehensively mine the text semantics, limiting the reciprocal guidance
between network structure and text semantics. To address these problems, we
propose a novel text-rich graph neural network with external knowledge (TeKo),
in order to take full advantage of both structural and textual information
within text-rich networks. Specifically, we first present a flexible
heterogeneous semantic network that incorporates high-quality entities and
interactions among documents and entities. We then introduce two types of
external knowledge, that is, structured triplets and unstructured entity
description, to gain a deeper insight into textual semantics. We further design
a reciprocal convolutional mechanism for the constructed heterogeneous semantic
network, enabling network structure and textual semantics to collaboratively
enhance each other and learn high-level network representations. Extensive
experimental results on four public text-rich networks as well as a large-scale
e-commerce searching dataset illustrate the superior performance of TeKo over
state-of-the-art baselines.",2022-06-15,"Zhizhi Yu, Di Jin, Jianguo Wei, Ziyang Liu, Yue Shang, Yun Xiao, Jiawei Han, Lingfei Wu"
Resource-Mediated Consensus Formation,"In social sciences, simulating opinion dynamics to study the interplay
between homophily and influence, and the subsequent formation of echo chambers,
is of great importance. As such, in this paper we investigate echo chambers by
implementing a unique social game in which we spawn in a large number of
agents, each assigned one of the two opinions on an issue and a finite amount
of influence in the form of a game currency. Agents attempt to have an opinion
that is a majority at the end of the game, to obtain a reward also paid in the
game currency. At the beginning of each round, a randomly selected agent is
selected, referred to as a speaker. The second agent is selected in the radius
of speaker influence (which is a set subset of the speaker's neighbors) to
interact with the speaker as a listener. In this interaction, the speaker
proposes a payoff in the game currency from their personal influence budget to
persuade the listener to hold the speaker's opinion in future rounds until
chosen listener again. The listener can either choose to accept or reject this
payoff to hold the speaker's opinion for future rounds. The listener's choice
is informed only by their estimate of global majority opinion through a limited
view of the opinions of their neighboring agents. We show that the influence
game leads to the formation of ""echo chambers,"" or homogeneous clusters of
opinions. We also investigate various scenarios to disrupt the creation of such
echo chambers, including the introduction of resource disparity between agents
with different opinions, initially preferentially assigning opinions to agents,
and the introduction of committed agents, who never change their initial
opinion.",2022-06-14,"Omar Malik, James Flamino, Boleslaw K. Szymanski"
"RoSGAS: Adaptive Social Bot Detection with Reinforced Self-Supervised
  GNN Architecture Search","Social bots are referred to as the automated accounts on social networks that
make attempts to behave like human. While Graph Neural Networks (GNNs) has been
massively applied to the field of social bot detection, a huge amount of domain
expertise and prior knowledge is heavily engaged in the state-of-the art
approaches to design a dedicated neural network architecture for a specific
classification task. Involving oversized nodes and network layers in the model
design, however, usually causes the over-smoothing problem and the lack of
embedding discrimination. In this paper, we propose RoSGAS, a novel Reinforced
and Self-supervised GNN Architecture Search framework to adaptively pinpoint
the most suitable multi-hop neighborhood and the number of layers in the GNN
architecture. More specifically, we consider the social bot detection problem
as a user-centric subgraph embedding and classification task. We exploit
heterogeneous information network to present the user connectivity by
leveraging account metadata, relationships, behavioral features and content
features. RoSGAS uses a multi-agent deep reinforcement learning (RL) mechanism
for navigating the search of optimal neighborhood and network layers to learn
individually the subgraph embedding for each target user. A nearest neighbor
mechanism is developed for accelerating the RL training process, and RoSGAS can
learn more discriminative subgraph embedding with the aid of self-supervised
learning. Experiments on 5 Twitter datasets show that RoSGAS outperforms the
state-of-the-art approaches in terms of accuracy, training efficiency and
stability, and has better generalization when handling unseen samples.",2022-06-14,"Yingguang Yang, Renyu Yang, Yangyang Li, Kai Cui, Zhiqin Yang, Yue Wang, Jie Xu, Haiyong Xie"
"Limited-Trust in Diffusion of Competing Alternatives over Social
  Networks","We consider the diffusion of two alternatives in social networks using a
game-theoretic approach. Each individual plays a coordination game with its
neighbors repeatedly and decides which to adopt. As products are used in
conjunction with others and through repeated interactions, individuals are more
interested in their long-term benefits and tend to show trust to others to
maximize their long-term utility by choosing a suboptimal option with respect
to instantaneous payoff. To capture such trust behavior, we deploy
limited-trust equilibrium (LTE) in diffusion process. We analyze the
convergence of emerging dynamics to equilibrium points using mean-field
approximation and study the equilibrium state and the convergence rate of
diffusion using absorption probability and expected absorption time of a
reduced-size absorbing Markov chain. We also show that the diffusion model on
LTE under the best-response strategy can be converted to the well-known linear
threshold model. Simulation results show that when agents behave trustworthy,
their long-term utility will increase significantly compared to the case when
they are solely self-interested. Moreover, the Markov chain analysis provides a
good estimate of convergence properties over random networks.",2022-06-13,"Vincent Leon, S. Rasoul Etesami, Rakesh Nagi"
Absolute Expressiveness of Subgraph-based Centrality Measures,"In graph-based applications, a common task is to pinpoint the most important
or ``central'' vertex in a (directed or undirected) graph, or rank the vertices
of a graph according to their importance. To this end, a plethora of so-called
centrality measures have been proposed in the literature. Such measures assess
which vertices in a graph are the most important ones by analyzing the
structure of the underlying graph. A family of centrality measures that are
suited for graph databases has been recently proposed by relying on the
following simple principle: the importance of a vertex in a graph is relative
to the number of ``relevant'' connected subgraphs surrounding it; we refer to
the members of this family as subgraph-based centrality measures. Although it
has been shown that such measures enjoy several favourable properties, their
absolute expressiveness remains largely unexplored. The goal of this work is to
precisely characterize the absolute expressiveness of the family of
subgraph-based centrality measures by considering both directed and undirected
graphs. To this end, we characterize when an arbitrary centrality measure is a
subgraph-based one, or a subgraph-based measure relative to the induced
ranking. These characterizations provide us with technical tools that allow us
to determine whether well-established centrality measures are subgraph-based.
Such a classification, apart from being interesting in its own right, gives
useful insights on the structural similarities and differences among existing
centrality measures.",2022-06-13,"Andreas Pieris, Jorge Salas"
"Don't ""research fast and break things"": On the ethics of Computational
  Social Science","This article is concerned with setting up practical guardrails within the
research activities and environments of CSS. It aims to provide CSS scholars,
as well as policymakers and other stakeholders who apply CSS methods, with the
critical and constructive means needed to ensure that their practices are
ethical, trustworthy, and responsible. It begins by providing a taxonomy of the
ethical challenges faced by researchers in the field of CSS. These are
challenges related to (1) the treatment of research subjects, (2) the impacts
of CSS research on affected individuals and communities, (3) the quality of CSS
research and to its epistemological status, (4) research integrity, and (5)
research equity. Taking these challenges as a motivation for cultural
transformation, it then argues for the end-to-end incorporation of habits of
responsible research and innovation (RRI) into CSS practices, focusing on the
role that contextual considerations, anticipatory reflection, impact
assessment, public engagement, and justifiable and well-documented action
should play across the research lifecycle. In proposing the inclusion of habits
of RRI in CSS practices, the chapter lays out several practical steps needed
for ethical, trustworthy, and responsible CSS research activities. These
include stakeholder engagement processes, research impact assessments, data
lifecycle documentation, bias self-assessments, and transparent research
reporting protocols.",2022-06-12,David Leslie
Information theory of spatial network ensembles,"This chapter provides a comprehensive and self-contained discussion of the
most recent developments of information theory of networks. Maximum entropy
models of networks are the least biased ensembles enforcing a set of
constraints and are used in a number of application to produce null model of
networks. Here maximum entropy ensembles of networks are introduced by
distinguishing between microcanonical and canonical ensembles revealing the the
non-equivalence of these two classes of ensembles in the case in which an
extensive number of constraints is imposed. It is very common that network data
includes also meta-data describing feature of the nodes such as their position
in a real or in an abstract space. The features of the nodes can be treated as
latent variables that determine the cost associated to each link. Maximum
entropy network ensembles with latent variables include spatial networks and
their generalisation. In this chapter we cover the case of transportation
networks including airport and rail networks. Maximum entropy network ensemble
satisfy a given set of constraints. However traditional approaches do not
provide any insight on the origin of such constraints. We use information
theory principles to find the optimal distribution of latent variables in the
framework of the classical information theory of networks. This theory explains
the ""blessing of non-uniformity"" of data guaranteeing the efficiency of
inference algorithms.",2022-06-11,Ginestra Bianconi
Semi-Supervised Hierarchical Graph Classification,"Node classification and graph classification are two graph learning problems
that predict the class label of a node and the class label of a graph
respectively. A node of a graph usually represents a real-world entity, e.g., a
user in a social network, or a document in a document citation network. In this
work, we consider a more challenging but practically useful setting, in which a
node itself is a graph instance. This leads to a hierarchical graph perspective
which arises in many domains such as social network, biological network and
document collection. We study the node classification problem in the
hierarchical graph where a 'node' is a graph instance. As labels are usually
limited, we design a novel semi-supervised solution named SEAL-CI. SEAL-CI
adopts an iterative framework that takes turns to update two modules, one
working at the graph instance level and the other at the hierarchical graph
level. To enforce a consistency among different levels of hierarchical graph,
we propose the Hierarchical Graph Mutual Information (HGMI) and further present
a way to compute HGMI with theoretical guarantee. We demonstrate the
effectiveness of this hierarchical graph modeling and the proposed SEAL-CI
method on text and social network data.",2022-06-11,"Jia Li, Yongfeng Huang, Heng Chang, Yu Rong"
The Gender Gap in Scholarly Self-Promotion on Social Media,"Self-promotion in science is ubiquitous but may not be exercised equally by
men and women. Research on self-promotion in other domains suggests that, due
to bias in self-assessment and adverse reactions to non-gender-conforming
behaviors (``pushback''), women tend to self-promote less often than men. We
test whether this pattern extends to scholars by examining self-promotion over
six years using 23M Tweets about 2.8M research papers by 3.5M authors. Overall,
women are about 28% less likely than men to self-promote their papers even
after accounting for important confounds, and this gap has grown over time.
Moreover, differential adoption of Twitter does not explain the gender gap,
which is large even in relatively gender-balanced broad research areas, where
bias in self-assessment and pushback are expected to be smaller. Further, the
gap increases with higher performance and status, being most pronounced for
productive women from top-ranked institutions who publish in high-impact
journals. Critically, we find differential returns with respect to gender:
while self-promotion is associated with increased tweets of papers, the
increase is smaller for women than for men. Our findings suggest that
self-promotion varies meaningfully by gender and help explain gender
differences in the visibility of scientific ideas.",2022-06-10,"Hao Peng, Misha Teplitskiy, Daniel M. Romero, Emőke-Ágnes Horvát"
Scalable Deep Gaussian Markov Random Fields for General Graphs,"Machine learning methods on graphs have proven useful in many applications
due to their ability to handle generally structured data. The framework of
Gaussian Markov Random Fields (GMRFs) provides a principled way to define
Gaussian models on graphs by utilizing their sparsity structure. We propose a
flexible GMRF model for general graphs built on the multi-layer structure of
Deep GMRFs, originally proposed for lattice graphs only. By designing a new
type of layer we enable the model to scale to large graphs. The layer is
constructed to allow for efficient training using variational inference and
existing software frameworks for Graph Neural Networks. For a Gaussian
likelihood, close to exact Bayesian inference is available for the latent
field. This allows for making predictions with accompanying uncertainty
estimates. The usefulness of the proposed model is verified by experiments on a
number of synthetic and real world datasets, where it compares favorably to
other both Bayesian and deep learning methods.",2022-06-10,"Joel Oskarsson, Per Sidén, Fredrik Lindsten"
"Group Threat, Political Extremity, and Collective Dynamics in Online
  Discussions","Collectives adapt their network structure to the challenges they face. It has
been hypothesized that collectives experiencing a real or imagined threat from
an outgroup tend to consolidate behind a few influential group members, and
that network structures in which a few members have a very strong influence are
more likely in politically extreme groups. These hypotheses have not been
tested in large-scale real-world settings. We reconstruct networks of tens of
thousands of commenters participating in comment sections of high-profile U.S.
political news websites spanning the political spectrum from left to right,
including Mother Jones, The Atlantic, The Hill, and Breitbart. We investigate
the relationship between different indices of inequality of influence in
commenters' networks and perceived group threat associated with significant
societal events, from elections and political rallies to mass shootings. Our
findings support the hypotheses that groups facing a real or imagined outgroup
threat and groups that are more politically extreme are more likely to include
disproportionately influential commenters. These results provide an extensive
real-world test of theoretical accounts of collective adaptation to outgroup
threats.",2022-06-10,"N. Gizem Bacaksizlar Turbic, Mirta Galesic"
Mapping Philanthropic Support of Science,"While philanthropic support for science has increased in the past decade,
there is limited quantitative knowledge about the patterns that characterize it
and the mechanisms that drive its distribution. Here, we map philanthropic
funding to universities and research institutions based on IRS tax forms from
685,397 non-profit organizations. We identify nearly one million grants
supporting institutions involved in science and higher education, finding that
in volume and scope, philanthropic funding has grown to become comparable to
federal research funding. Yet, distinct from government support, philanthropic
funders tend to focus locally, indicating that criteria beyond research
excellence play an important role in funding decisions. We also show evidence
of persistence, i.e., once a grant-giving relationship begins, it tends to
continue in time. Finally, we leverage the bipartite network of supporters and
recipients to help us demonstrate the predictive power of the underlying
network in foreseeing future funder-recipient relationships. The developed
toolset could offer funding recommendations to organizations and help funders
diversify their portfolio. We discuss the policy implications of our findings
for philanthropic funders, individual researchers, and quantitative
understanding of philanthropy.",2022-06-09,"Louis M. Shekhtman, Alexander J. Gates, Albert-László Barabási"
Correlations of network trajectories,"Temporal networks model how the interaction between elements in a complex
system evolve over time. Just like complex systems display collective dynamics,
here we interpret temporal networks as trajectories performing a collective
motion in graph space, following a latent graph dynamical system. Under this
paradigm, we propose a way to measure how the network pulsates and collectively
fluctuates over time and space. To this aim, we extend the notion of linear
correlations function to the case of sequences of network snapshots, i.e. a
network trajectory. We construct stochastic and deterministic graph dynamical
systems and show that the emergent collective correlations are well captured by
simple measures, and illustrate how these patterns are revealed in empirical
networks arising in different domains.",2022-06-07,"Lucas Lacasa, Jorge P. Rodriguez, Victor M. Eguiluz"
"Detecting Global Community Structure in a COVID-19 Activity Correlation
  Network","The global pandemic of COVID-19 over the last 2.5 years have produced an
enormous amount of epidemic/public health datasets, which may also be useful
for studying the underlying structure of our globally connected world. Here we
used the Johns Hopkins University COVID-19 dataset to construct a correlation
network of countries/regions and studied its global community structure.
Specifically, we selected countries/regions that had at least 100,000
cumulative positive cases from the dataset and generated a 7-day moving average
time series of new positive cases reported for each country/region. We then
calculated a time series of daily change exponents by taking the day-to-day
difference in log of the number of new positive cases. We constructed a
correlation network by connecting countries/regions that had positive
correlations in their daily change exponent time series using their Pearson
correlation coefficient as the edge weight. Applying the modularity
maximization method revealed that there were three major communities: (1)
Mainly Europe + North America + Southeast Asia that showed similar six-peak
patterns during the pandemic, (2) mainly Near/Middle East + Central/South Asia
+ Central/South America that loosely followed Community 1 but had a notable
increase of activities because of the Delta variant and was later impacted
significantly by the Omicron variant, and (3) mainly Africa + Central/East
Canada + Australia that did not have much activities until a huge spike was
caused by the Omicron variant. These three communities were robustly detected
under varied settings. Constructing a 3D ""phase space"" by using the median
curves in those three communities for x-y-z coordinates generated an effective
summary trajectory of how the global pandemic progressed.",2022-06-07,Hiroki Sayama
"Content Privacy Enforcement Models in Decentralized Online Social
  Networks: State of Play, Solutions, Limitations, and Future Directions","In recent years, Decentralized Online Social Networks (DOSNs) have been
attracting the attention of many users because they reduce the risk of
censorship, surveillance, and information leakage from the service provider. In
contrast to the most popular Online Social Networks, which are based on
centralized architectures (e.g., Facebook, Twitter, or Instagram), DOSNs are
not based on a single service provider acting as a central authority. Indeed,
the contents that are published on DOSNs are stored on the devices made
available by their users, which cooperate to execute the tasks needed to
provide the service. To continuously guarantee their availability, the contents
published by a user could be stored on the devices of other users, simply
because they are online when required. Consequently, such contents must be
properly protected by the DOSN infrastructure, in order to ensure that they can
be really accessed only by users who have the permission of the publishers. As
a consequence, DOSNs require efficient solutions for protecting the privacy of
the contents published by each user with respect to the other users of the
social network. In this paper, we investigate and compare the principal content
privacy enforcement models adopted by current DOSNs evaluating their
suitability to support different types of privacy policies based on user
groups. Such evaluation is carried out by implementing several models and
comparing their performance for the typical operations performed on groups,
i.e., content publish, user join and leave. Further, we also highlight the
limitations of current approaches and show future research directions. This
contribution, other than being interesting on its own, provides a blueprint for
researchers and practitioners interested in implementing DOSNs, and also
highlights a few open research directions.",2022-06-07,"Andrea De Salve, Paolo Mori, Laura Ricci, Roberto Di Pietro"
"Ego Network Structure in Online Social Networks and its Impact on
  Information Diffusion","In the last few years, Online Social Networks (OSNs) attracted the interest
of a large number of researchers, thanks to their central role in the society.
Through the analysis of OSNs, many social phenomena have been studied, such as
the viral diffusion of information amongst people. What is still unclear is the
relation between micro-level structural properties of OSNs (i.e. the properties
of the personal networks of the users, also known as ego networks) and the
emergence of such phenomena. A better knowledge of this relation could be
essential for the creation of services for the Future Internet, such as highly
personalised advertisements fitted on users' needs and characteristics. In this
paper, we contribute to bridge this gap by analysing the ego networks of a
large sample of Facebook and Twitter users. Our results indicate that
micro-level structural properties of OSNs are interestingly similar to those
found in social networks formed offline. In particular, online ego networks
show the same structure found offline, with social contacts arranged in layers
with compatible size and composition. From the analysis of Twitter ego
networks, we have been able to find a direct impact of tie strength and ego
network circles on the diffusion of information in the network. Specifically,
there is a high correlation between the frequency of direct contact between
users and her friends in Twitter (a proxy for tie strength), and the frequency
of retweets made by the users from tweets generated by their friends. We
analysed the correlation for each ego network layer identified in Twitter,
discovering their role in the diffusion of information.",2022-06-06,"Valerio Arnaboldi, Marco Conti, Massimiliano La Gala, Andrea Passarella, Fabio Pezzoni"
"Restructuring Graph for Higher Homophily via Adaptive Spectral
  Clustering","While a growing body of literature has been studying new Graph Neural
Networks (GNNs) that work on both homophilic and heterophilic graphs, little
has been done on adapting classical GNNs to less-homophilic graphs. Although
the ability to handle less-homophilic graphs is restricted, classical GNNs
still stand out in several nice properties such as efficiency, simplicity, and
explainability. In this work, we propose a novel graph restructuring method
that can be integrated into any type of GNNs, including classical GNNs, to
leverage the benefits of existing GNNs while alleviating their limitations. Our
contribution is threefold: a) learning the weight of pseudo-eigenvectors for an
adaptive spectral clustering that aligns well with known node labels, b)
proposing a new density-aware homophilic metric that is robust to label
imbalance, and c) reconstructing the adjacency matrix based on the result of
adaptive spectral clustering to maximize the homophilic scores. The
experimental results show that our graph restructuring method can significantly
boost the performance of six classical GNNs by an average of 25% on
less-homophilic graphs. The boosted performance is comparable to
state-of-the-art methods.",2022-06-06,"Shouheng Li, Dongwoo Kim, Qing Wang"
"PHEE: A phased hybrid evaluation-enhanced approach for identifying
  influential users in social networks","For the purpose of maximizing the spread of influence caused by a certain
small number k of nodes in a social network, we are asked to find a k-subset of
nodes (i.e., a seed set) with the best capacity to influence the nodes not in
it. This problem of influence maximization (IM) has wide application, belongs
to subset problems, and is NP-hard. To solve it, we should theoretically
examine all seed sets and evaluate their influence spreads, which is
time-consuming. Therefore, metaheuristic strategies are generally employed to
gain a good seed set within a reasonable time. We observe that many algorithms
for the IM problem only adopt a uniform mechanism in the whole solution search
process, which lacks a response measure when the algorithm becomes trapped in a
local optimum. To address this issue, we propose a phased hybrid
evaluation-enhanced (PHEE) approach for IM, which utilizes two distinct search
strategies to enhance the search of optimal solutions: a randomized range
division evolutionary (RandRDE) algorithm to improve the solution quality, and
a fast convergence strategy. Our approach is evaluated on 10 real-world social
networks of different sizes and types. Experimental results demonstrate that
our algorithm is efficient and obtains the best influence spread for all the
datasets compared with three state-of-the-art algorithms, outperforms the time
consuming CELF algorithm on four datasets, and performs worse than CELF on only
two networks.",2022-06-04,"Enqiang Zhu, Haosen Wang, Yu Zhang, Kai Zhang, Chanjuan Liu"
"Two Ways of Understanding Social Dynamics: Analyzing the Predictability
  of Emergence of Objects in Reddit r/place Dependent on Locality in Space and
  Time","Lately, studying social dynamics in interacting agents has been boosted by
the power of computer models, which bring the richness of qualitative work,
while offering the precision, transparency, extensiveness, and replicability of
statistical and mathematical approaches. A particular set of phenomena for the
study of social dynamics is Web collaborative platforms. A dataset of interest
is r/place, a collaborative social experiment held in 2017 on Reddit, which
consisted of a shared online canvas of 1000 pixels by 1000 pixels co-edited by
over a million recorded users over 72 hours. In this paper, we designed and
compared two methods to analyze the dynamics of this experiment. Our first
method consisted in approximating the set of 2D cellular-automata-like rules
used to generate the canvas images and how these rules change over time. The
second method consisted in a convolutional neural network (CNN) that learned an
approximation to the generative rules in order to generate the complex outcomes
of the canvas. Our results indicate varying context-size dependencies for the
predictability of different objects in r/place in time and space. They also
indicate a surprising peak in difficulty to statistically infer behavioral
rules towards the middle of the social experiment, while user interactions did
not drop until before the end. The combination of our two approaches, one
rule-based and the other statistical CNN-based, shows the ability to highlight
diverse aspects of analyzing social dynamics.",2022-06-02,"Alyssa M Adams, Javier Fernandez, Olaf Witkowski"
Topological Deep Learning: Going Beyond Graph Data,"Topological deep learning is a rapidly growing field that pertains to the
development of deep learning models for data supported on topological domains
such as simplicial complexes, cell complexes, and hypergraphs, which generalize
many domains encountered in scientific computations. In this paper, we present
a unifying deep learning framework built upon a richer data structure that
includes widely adopted topological domains.
  Specifically, we first introduce combinatorial complexes, a novel type of
topological domain. Combinatorial complexes can be seen as generalizations of
graphs that maintain certain desirable properties. Similar to hypergraphs,
combinatorial complexes impose no constraints on the set of relations. In
addition, combinatorial complexes permit the construction of hierarchical
higher-order relations, analogous to those found in simplicial and cell
complexes. Thus, combinatorial complexes generalize and combine useful traits
of both hypergraphs and cell complexes, which have emerged as two promising
abstractions that facilitate the generalization of graph neural networks to
topological spaces.
  Second, building upon combinatorial complexes and their rich combinatorial
and algebraic structure, we develop a general class of message-passing
combinatorial complex neural networks (CCNNs), focusing primarily on
attention-based CCNNs. We characterize permutation and orientation
equivariances of CCNNs, and discuss pooling and unpooling operations within
CCNNs in detail.
  Third, we evaluate the performance of CCNNs on tasks related to mesh shape
analysis and graph learning. Our experiments demonstrate that CCNNs have
competitive performance as compared to state-of-the-art deep learning models
specifically tailored to the same tasks. Our findings demonstrate the
advantages of incorporating higher-order relations into deep learning models in
different applications.",2022-06-01,"Mustafa Hajij, Ghada Zamzmi, Theodore Papamarkou, Nina Miolane, Aldo Guzmán-Sáenz, Karthikeyan Natesan Ramamurthy, Tolga Birdal, Tamal K. Dey, Soham Mukherjee, Shreyas N. Samaga, Neal Livesay, Robin Walters, Paul Rosen, Michael T. Schaub"
"Learning common structures in a collection of networks. An application
  to food webs","Let a collection of networks represent interactions within several (social or
ecological) systems. We pursue two objectives: identifying similarities in the
topological structures that are held in common between the networks and
clustering the collection into sub-collections of structurally homogeneous
networks. We tackle these two questions with a probabilistic model based
approach. We propose an extension of the Stochastic Block Model (SBM) adapted
to the joint modeling of a collection of networks. The networks in the
collection are assumed to be independent realizations of SBMs. The common
connectivity structure is imposed through the equality of some parameters. The
model parameters are estimated with a variational Expectation-Maximization (EM)
algorithm. We derive an ad-hoc penalized likelihood criterion to select the
number of blocks and to assess the adequacy of the consensus found between the
structures of the different networks. This same criterion can also be used to
cluster networks on the basis of their connectivity structure. It thus provides
a partition of the collection into subsets of structurally homogeneous
networks. The relevance of our proposition is assessed on two collections of
ecological networks. First, an application to three stream food webs reveals
the homogeneity of their structures and the correspondence between groups of
species in different ecosystems playing equivalent ecological roles. Moreover,
the joint analysis allows a finer analysis of the structure of smaller
networks. Second, we cluster 67 food webs according to their connectivity
structures and demonstrate that five mesoscale structures are sufficient to
describe this collection.",2022-06-01,"Saint-Clair Chabert-Liddell, Pierre Barbillon, Sophie Donnet"
Privacy-Preserving Epidemiological Modeling on Mobile Graphs,"Over the last two years, governments all over the world have used a variety
of containment measures to control the spread of COVID-19, such as contact
tracing, social distance regulations, and curfews. Epidemiological simulations
are commonly used to assess the impact of those policies before they are
implemented in actuality. Unfortunately, their predictive accuracy is hampered
by the scarcity of relevant empirical data, concretely detailed social contact
graphs. As this data is inherently privacy-critical, there is an urgent need
for a method to perform powerful epidemiological simulations on real-world
contact graphs without disclosing sensitive information. In this work, we
present RIPPLE, a privacy-preserving epidemiological modeling framework that
enables the execution of a wide range of standard epidemiological models for
any infectious disease on a population's most recent real contact graph while
keeping all contact information private locally on the participants' devices.
In this regard, we also present PIR-SUM, a novel extension to private
information retrieval that allows users to securely download the sum of a set
of elements from a database rather than individual elements. Our theoretical
constructs are supported by a proof-of-concept implementation in which we show
that a 2-week simulation over a population of half a million can be finished in
7 minutes with each participant consuming less than 50 KB of data.",2022-06-01,"Daniel Günther, Marco Holz, Benjamin Judkewitz, Helen Möllering, Benny Pinkas, Thomas Schneider, Ajith Suresh"
"CALEB: A Conditional Adversarial Learning Framework to Enhance Bot
  Detection","The high growth of Online Social Networks (OSNs) over the last few years has
allowed automated accounts, known as social bots, to gain ground. As
highlighted by other researchers, most of these bots have malicious purposes
and tend to mimic human behavior, posing high-level security threats on OSN
platforms. Moreover, recent studies have shown that social bots evolve over
time by reforming and reinventing unforeseen and sophisticated characteristics,
making them capable of evading the current machine learning state-of-the-art
bot detection systems. This work is motivated by the critical need to establish
adaptive bot detection methods in order to proactively capture unseen evolved
bots towards healthier OSNs interactions. In contrast with most earlier
supervised ML approaches which are limited by the inability to effectively
detect new types of bots, this paper proposes CALEB, a robust end-to-end
proactive framework based on the Conditional Generative Adversarial Network
(CGAN) and its extension, Auxiliary Classifier GAN (AC-GAN), to simulate bot
evolution by creating realistic synthetic instances of different bot types.
These simulated evolved bots augment existing bot datasets and therefore
enhance the detection of emerging generations of bots before they even appear!
Furthermore, we show that our augmentation approach overpasses other earlier
augmentation techniques which fail at simulating evolving bots. Extensive
experimentation on well established public bot datasets, show that our approach
offers a performance boost of up to 10% regarding the detection of new unseen
bots. Finally, the use of the AC-GAN Discriminator as a bot detector, has
outperformed former ML approaches, showcasing the efficiency of our end to end
framework.",2022-05-31,"George Dialektakis, Ilias Dimitriadis, Athena Vakali"
"GraMeR: Graph Meta Reinforcement Learning for Multi-Objective Influence
  Maximization","Influence maximization (IM) is a combinatorial problem of identifying a
subset of nodes called the seed nodes in a network (graph), which when
activated, provide a maximal spread of influence in the network for a given
diffusion model and a budget for seed set size. IM has numerous applications
such as viral marketing, epidemic control, sensor placement and other
network-related tasks. However, the uses are limited due to the computational
complexity of current algorithms. Recently, learning heuristics for IM have
been explored to ease the computational burden. However, there are serious
limitations in current approaches such as: (1) IM formulations only consider
influence via spread and ignore self activation; (2) scalability to large
graphs; (3) generalizability across graph families; (4) low computational
efficiency with a large running time to identify seed sets for every test
network. In this work, we address each of these limitations through a unique
approach that involves (1) formulating a generic IM problem as a Markov
decision process that handles both intrinsic and influence activations; (2)
employing double Q learning to estimate seed nodes; (3) ensuring scalability
via sub-graph based representations; and (4) incorporating generalizability via
meta-learning across graph families. Extensive experiments are carried out in
various standard networks to validate performance of the proposed Graph Meta
Reinforcement learning (GraMeR) framework. The results indicate that GraMeR is
multiple orders faster and generic than conventional approaches.",2022-05-30,"Sai Munikoti, Balasubramaniam Natarajan, Mahantesh Halappanavar"
Softening online extremes organically and at scale,"Calls are escalating for social media platforms to do more to mitigate
extreme online communities whose views can lead to real-world harms, e.g.,
mis/disinformation and distrust that increased Covid-19 fatalities, and now
extend to monkeypox, unsafe baby formula alternatives, cancer, abortions, and
climate change; white replacement that inspired the 2022 Buffalo shooter and
will likely inspire others; anger that threatens elections, e.g., 2021 U.S.
Capitol attack; notions of male supremacy that encourage abuse of women;
anti-Semitism, anti-LGBQT hate and QAnon conspiracies. But should 'doing more'
mean doing more of the same, or something different? If so, what? Here we start
by showing why platforms doing more of the same will not solve the problem.
Specifically, our analysis of nearly 100 million Facebook users entangled over
vaccines and now Covid and beyond, shows that the extreme communities' ecology
has a hidden resilience to Facebook's removal interventions; that Facebook's
messaging interventions are missing key audience sectors and getting ridiculed;
that a key piece of these online extremes' narratives is being mislabeled as
incorrect science; and that the threat of censorship is inciting the creation
of parallel presences on other platforms with potentially broader audiences. We
then demonstrate empirically a new solution that can soften online extremes
organically without having to censor or remove communities or their content, or
check or correct facts, or promote any preventative messaging, or seek a
consensus. This solution can be automated at scale across social media
platforms quickly and with minimal cost.",2022-05-29,"Elvira Maria Restrepo, Martin Moreno, Lucia Illari, Neil F. Johnson"
"What are People Talking about in #BlackLivesMatter and #StopAsianHate?
  Exploring and Categorizing Twitter Topics Emerging in Online Social Movements
  through the Latent Dirichlet Allocation Model","Minority groups have been using social media to organize social movements
that create profound social impacts. Black Lives Matter (BLM) and Stop Asian
Hate (SAH) are two successful social movements that have spread on Twitter that
promote protests and activities against racism and increase the public's
awareness of other social challenges that minority groups face. However,
previous studies have mostly conducted qualitative analyses of tweets or
interviews with users, which may not comprehensively and validly represent all
tweets. Very few studies have explored the Twitter topics within BLM and SAH
dialogs in a rigorous, quantified and data-centered approach. Therefore, in
this research, we adopted a mixed-methods approach to comprehensively analyze
BLM and SAH Twitter topics. We implemented (1) the latent Dirichlet allocation
model to understand the top high-level words and topics and (2) open-coding
analysis to identify specific themes across the tweets. We collected more than
one million tweets with the #blacklivesmatter and #stopasianhate hashtags and
compared their topics. Our findings revealed that the tweets discussed a
variety of influential topics in depth, and social justice, social movements,
and emotional sentiments were common topics in both movements, though with
unique subtopics for each movement. Our study contributes to the topic analysis
of social movements on social media platforms in particular and the literature
on the interplay of AI, ethics, and society in general.",2022-05-29,"Xin Tong, Yixuan Li, Jiayi Li, Rongqi Bei, Luyao Zhang"
"Contributions to Representation Learning with Graph Autoencoders and
  Applications to Music Recommendation","Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as
two powerful groups of unsupervised node embedding methods, with various
applications to graph-based machine learning problems such as link prediction
and community detection. Nonetheless, at the beginning of this Ph.D. project,
GAE and VGAE models were also suffering from key limitations, preventing them
from being adopted in the industry. In this thesis, we present several
contributions to improve these models, with the general aim of facilitating
their use to address industrial-level problems involving graph representations.
Firstly, we propose two strategies to overcome the scalability issues of
previous GAE and VGAE models, permitting to effectively train these models on
large graphs with millions of nodes and edges. These strategies leverage graph
degeneracy and stochastic subgraph decoding techniques, respectively. Besides,
we introduce Gravity-Inspired GAE and VGAE, providing the first extensions of
these models for directed graphs, that are ubiquitous in industrial
applications. We also consider extensions of GAE and VGAE models for dynamic
graphs. Furthermore, we argue that GAE and VGAE models are often unnecessarily
complex, and we propose to simplify them by leveraging linear encoders. Lastly,
we introduce Modularity-Aware GAE and VGAE to improve community detection on
graphs, while jointly preserving good performances on link prediction. In the
last part of this thesis, we evaluate our methods on several graphs extracted
from the music streaming service Deezer. We put the emphasis on graph-based
music recommendation problems. In particular, we show that our methods can
improve the detection of communities of similar musical items to recommend to
users, that they can effectively rank similar artists in a cold start setting,
and that they permit modeling the music genre perception across cultures.",2022-05-29,Guillaume Salha-Galvan
"Large-Scale Privacy-Preserving Network Embedding against Private Link
  Inference Attacks","Network embedding represents network nodes by a low-dimensional informative
vector. While it is generally effective for various downstream tasks, it may
leak some private information of networks, such as hidden private links. In
this work, we address a novel problem of privacy-preserving network embedding
against private link inference attacks. Basically, we propose to perturb the
original network by adding or removing links, and expect the embedding
generated on the perturbed network can leak little information about private
links but hold high utility for various downstream tasks. Towards this goal, we
first propose general measurements to quantify privacy gain and utility loss
incurred by candidate network perturbations; we then design a PPNE framework to
identify the optimal perturbation solution with the best privacy-utility
trade-off in an iterative way. Furthermore, we propose many techniques to
accelerate PPNE and ensure its scalability. For instance, as the skip-gram
embedding methods including DeepWalk and LINE can be seen as matrix
factorization with closed form embedding results, we devise efficient privacy
gain and utility loss approximation methods to avoid the repetitive
time-consuming embedding training for every candidate network perturbation in
each iteration. Experiments on real-life network datasets (with up to millions
of nodes) verify that PPNE outperforms baselines by sacrificing less utility
and obtaining higher privacy protection.",2022-05-28,"Xiao Han, Leye Wang, Junjie Wu, Yuncong Yang"
Characterizing Tourist Daily Trip Chains Using Mobile Phone Big Data,"Tourists tend to visit multiple destinations out of their variety-seeking
motivations in their trips. Thus, it is critical to discover travel patterns
involving multi-destinations in tourism research. Existing relevant research
most relied on survey data or focused on citizens due to the lack of
large-scale, fine-grained tourism datasets. Several scholars have mentioned the
notion of trip chains, but few works have been done towards quantitatively
identifying the structures of trip chains. In this paper, we propose a model
for quantitatively characterizing tourist daily trip chains. After applying
this model to tourist mobile phone big data, underlying tourist travel patterns
are discovered. Through the framework, we find that: (1) Most ""hybrid""
(inter-city and intra-city) and ""intra-city"" (only intra-city) patterns can be
captured by only 13 key trip chains relatively; (2) For two continuous days,
almost all kinds of original chains have a rather high probability to transfer
to either the first two transferred chains, or other infrequent chains in our
study areas; (3) The principle of least efforts (PLE) affects tourists'
structures of trip chains. We can use average degree and average travel
distance to interpret tourist travel behavior (achieving tasks in PLE). This
study not only demonstrate the complex daily travel trip chains from tourism
big data, but also fill the gap in tourism literature on multi-destination
trips by discovering significant and underlying patterns based on mobile
datasets.",2022-05-28,Yan Luo
"The Structure of Online Social Networks Mirror Those in the Offline
  World","We use data on frequencies of bi-directional posts to define edges (or
relationships) in two Facebook datasets and a Twitter dataset and use these to
create ego-centric social networks. We explore the internal structure of these
networks to determine whether they have the same kind of layered structure as
has been found in offline face-to-face networks (which have a distinctively
scaled structure with successively inclusive layers at 5, 15, 50 and 150
alters). The two Facebook datasets are best described by a four-layer structure
and the Twitter dataset by a five-layer structure. The absolute sizes of these
layers and the mean frequencies of contact with alters within each layer match
very closely the observed values from offline networks. In addition, all three
datasets reveal the existence of an innermost network layer at ~1.5 alters. Our
analyses thus confirm the existence of the layered structure of ego-centric
social networks with a very much larger sample (in total, >185,000 egos) than
those previously used to describe them, as well as identifying the existence of
an additional network layer whose existence was only hypothesised in offline
social networks. In addition, our analyses indicate that online communities
have very similar structural characteristics to offline face-to-face networks.",2022-05-27,"R. I. M. Dunbar, Valerio Arnaboldi, Marco Conti, Andrea Passarella"
Diffusion of Community Fact-Checked Misinformation on Twitter,"The spread of misinformation on social media is a pressing societal problem
that platforms, policymakers, and researchers continue to grapple with. As a
countermeasure, recent works have proposed to employ non-expert fact-checkers
in the crowd to fact-check social media content. While experimental studies
suggest that crowds might be able to accurately assess the veracity of social
media content, an understanding of how crowd fact-checked (mis-)information
spreads is missing. In this work, we empirically analyze the spread of
misleading vs. not misleading community fact-checked posts on social media. For
this purpose, we employ a dataset of community-created fact-checks from
Twitter's Birdwatch pilot and map them to resharing cascades on Twitter.
Different from earlier studies analyzing the spread of misinformation listed on
third-party fact-checking websites (e.g., Snopes), we find that community
fact-checked misinformation is less viral. Specifically, misleading posts are
estimated to receive 36.62% fewer retweets than not misleading posts. A partial
explanation may lie in differences in the fact-checking targets: community
fact-checkers tend to fact-check posts from influential user accounts with many
followers, while expert fact-checks tend to target posts that are shared by
less influential users. We further find that there are significant differences
in virality across different sub-types of misinformation (e.g., factual errors,
missing context, manipulated media). Moreover, we conduct a user study to
assess the perceived reliability of (real-world) community-created fact-checks.
Here, we find that users, to a large extent, agree with community-created
fact-checks. Altogether, our findings offer insights into how misleading vs.
not misleading posts spread and highlight the crucial role of sample selection
when studying misinformation on social media.",2022-05-26,"Chiara Drolsbach, Nicolas Pröllochs"
On the Effect of Triadic Closure on Network Segregation,"The tendency for individuals to form social ties with others who are similar
to themselves, known as homophily, is one of the most robust sociological
principles. Since this phenomenon can lead to patterns of interactions that
segregate people along different demographic dimensions, it can also lead to
inequalities in access to information, resources, and opportunities. As we
consider potential interventions that might alleviate the effects of
segregation, we face the challenge that homophily constitutes a pervasive and
organic force that is difficult to push back against. Designing effective
interventions can therefore benefit from identifying counterbalancing social
processes that might be harnessed to work in opposition to segregation.
  In this work, we show that triadic closure -- another common phenomenon that
posits that individuals with a mutual connection are more likely to be
connected to one another -- can be one such process. In doing so, we challenge
a long-held belief that triadic closure and homophily work in tandem. By
analyzing several fundamental network models using popular integration
measures, we demonstrate the desegregating potential of triadic closure. We
further empirically investigate this effect on real-world dynamic networks,
surfacing observations that mirror our theoretical findings. We leverage these
insights to discuss simple interventions that can help reduce segregation in
settings that exhibit an interplay between triadic closure and homophily. We
conclude with a discussion on qualitative implications for the design of
interventions in settings where individuals arrive in an online fashion, and
the designer can influence the initial set of connections.",2022-05-26,"Rediet Abebe, Nicole Immorlica, Jon Kleinberg, Brendan Lucier, Ali Shirali"
Evolution of beliefs in social networks,"Evolution of beliefs of a society are a product of interactions between
people (horizontal transmission) in the society over generations (vertical
transmission). Researchers have studied both horizontal and vertical
transmission separately. Extending prior work, we propose a new theoretical
framework which allows application of tools from Markov chain theory to the
analysis of belief evolution via horizontal and vertical transmission. We
analyze three cases: static network, randomly changing network, and
homophily-based dynamic network. Whereas the former two assume network
structure is independent of beliefs, the latter assumes that people tend to
communicate with those who have similar beliefs. We prove under general
conditions that both static and randomly changing networks converge to a single
set of beliefs among all individuals along with the rate of convergence. We
prove that homophily-based network structures do not in general converge to a
single set of beliefs shared by all and prove lower bounds on the number of
different limiting beliefs as a function of initial beliefs. We conclude by
discussing implications for prior theories and directions for future work.",2022-05-26,"Pushpi Paranamana, Pei Wang, Patrick Shafto"
"AntiBenford Subgraphs: Unsupervised Anomaly Detection in Financial
  Networks","Benford's law describes the distribution of the first digit of numbers
appearing in a wide variety of numerical data, including tax records, and
election outcomes, and has been used to raise ""red flags"" about potential
anomalies in the data such as tax evasion. In this work, we ask the following
novel question: given a large transaction or financial graph, how do we find a
set of nodes that perform many transactions among each other that also deviate
significantly from Benford's law?
  We propose the AntiBenford subgraph framework that is founded on
well-established statistical principles. Furthermore, we design an efficient
algorithm that finds AntiBenford subgraphs in near-linear time on real data. We
evaluate our framework on both real and synthetic data against a variety of
competitors. We show empirically that our proposed framework enables the
detection of anomalous subgraphs in cryptocurrency transaction networks that go
undetected by state-of-the-art graph-based anomaly detection methods. Our
empirical findings show that our \ab framework is able to mine anomalous
subgraphs, and provide novel insights into financial transaction data.
  The code and the datasets are available at
\url{https://github.com/tsourakakis-lab/antibenford-subgraphs}.",2022-05-26,"Tianyi Chen, Charalampos E. Tsourakakis"
Preference Dynamics Under Personalized Recommendations,"Many projects (both practical and academic) have designed algorithms to match
users to content they will enjoy under the assumption that user's preferences
and opinions do not change with the content they see. Evidence suggests that
individuals' preferences are directly shaped by what content they see --
radicalization, rabbit holes, polarization, and boredom are all example
phenomena of preferences affected by content. Polarization in particular can
occur even in ecosystems with ""mass media,"" where no personalization takes
place, as recently explored in a natural model of preference dynamics
by~\citet{hkazla2019geometric} and~\citet{gaitonde2021polarization}. If all
users' preferences are drawn towards content they already like, or are repelled
from content they already dislike, uniform consumption of media leads to a
population of heterogeneous preferences converging towards only two poles.
  In this work, we explore whether some phenomenon akin to polarization occurs
when users receive \emph{personalized} content recommendations. We use a
similar model of preference dynamics, where an individual's preferences move
towards content the consume and enjoy, and away from content they consume and
dislike. We show that standard user reward maximization is an almost trivial
goal in such an environment (a large class of simple algorithms will achieve
only constant regret). A more interesting objective, then, is to understand
under what conditions a recommendation algorithm can ensure stationarity of
user's preferences. We show how to design a content recommendations which can
achieve approximate stationarity, under mild conditions on the set of available
content, when a user's preferences are known, and how one can learn enough
about a user's preferences to implement such a strategy even when user
preferences are initially unknown.",2022-05-25,"Sarah Dean, Jamie Morgenstern"
"Estimating Total Treatment Effect in Randomized Experiments with Unknown
  Network Structure","Randomized experiments are widely used to estimate the causal effects of a
proposed treatment in many areas of science, from medicine and healthcare to
the physical and biological sciences, from the social sciences to engineering,
to public policy and to the technology industry at large. Here, we consider
situations where classical methods for estimating the total treatment effect on
a target population are considerably biased due to confounding network effects,
i.e., the fact that the treatment of an individual may impact their neighbors'
outcomes, an issue referred to as network interference or as non-individualized
treatment response. A key challenge in these situations, is that the network is
often unknown, and difficult, or costly, to measure. In this paper, we
characterize the limitations in estimating the total treatment effect without
knowledge of the network that drives interference, assuming a potential
outcomes model with heterogeneous additive network effects. This model
encompasses a broad class of network interference sources, including spillover,
peer effects, and contagion. Within this framework, we show that, surprisingly,
given access to average historical baseline measurements prior to the
experiment, we can develop a simple estimator and efficient randomized design
that outputs an unbiased estimate with low variance. Our solution does not
require knowledge of the underlying network structure, and it comes with
statistical guarantees for a broad class of models. We believe our results are
poised to impact current randomized experimentation strategies due to its ease
of interpretation and implementation, alongside its provable theoretical
insights under heterogeneous network effects.",2022-05-25,"Christina Lee Yu, Edoardo M Airoldi, Christian Borgs, Jennifer T Chayes"
Maximising the Influence of Temporary Participants in Opinion Formation,"DeGroot-style opinion formation presumes a continuous interaction among
agents of a social network. Hence, it cannot handle agents external to the
social network that interact only temporarily with the permanent ones. Many
real-world organisations and individuals fall into such a category. For
instance, a company tries to persuade as many as possible to buy its products
and, due to various constraints, can only exert its influence for a limited
amount of time. We propose a variant of the DeGroot model that allows an
external agent to interact with the permanent ones for a preset period of time.
We obtain several insights on maximising an external agent's influence in
opinion formation by analysing and simulating the variant.",2022-05-25,"Zhiqiang Zhuang, Kewen Wang, Zhe Wang, Junhu Wang, Yinong Yang"
Inference of a Rumor's Source in the Independent Cascade Model,"We consider the so-called Independent Cascade Model for rumor spreading or
epidemic processes popularized by Kempe et al.\ [2003]. In this model, a small
subset of nodes from a network are the source of a rumor. In discrete time
steps, each informed node ""infects"" each of its uninformed neighbors with
probability $p$. While many facets of this process are studied in the
literature, less is known about the inference problem: given a number of
infected nodes in a network, can we learn the source of the rumor? In the
context of epidemiology this problem is often referred to as patient zero
problem. It belongs to a broader class of problems where the goal is to infer
parameters of the underlying spreading model, see, e.g., Lokhov [NeurIPS'16] or
Mastakouri et al. [NeurIPS'20].
  In this work we present a maximum likelihood estimator for the rumor's
source, given a snapshot of the process in terms of a set of active nodes $X$
after $t$ steps. Our results show that, for cycle-free graphs, the likelihood
estimator undergoes a non-trivial phase transition as a function $t$. We
provide a rigorous analysis for two prominent classes of acyclic network,
namely $d$-regular trees and Galton-Watson trees, and verify empirically that
our heuristics work well in various general networks.",2022-05-24,"Petra Berenbrink, Max Hahn-Klimroth, Dominik Kaaser, Lena Krieg, Malin Rau"
"HoSIM: Higher-order Structural Importance based Method for Multiple
  Local Community Detection","Local community detection has attracted much research attention recently, and
many methods have been proposed for the single local community detection that
finds a community containing the given set of query nodes. However, nodes may
belong to several communities in the network, and detecting all the communities
for the query node set, termed as the multiple local community detection
(MLCD), is more important as it could uncover more potential information. MLCD
is also more challenging because when a query node belongs to multiple
communities, it always locates in the complicated overlapping region and the
marginal region of communities. Accordingly, detecting multiple communities for
such nodes by applying seed expansion methods is insufficient.
  In this work, we address the MLCD based on higher-order structural importance
(HoSI). First, to effectively estimate the influence of higher-order
structures, we propose a new variant of random walk called Active Random Walk
to measure the HoSI score between nodes. Then, we propose two new metrics to
evaluate the HoSI score of a subgraph to a node and the HoSI score of a node,
respectively. Based on the proposed metrics, we present a novel algorithm
called HoSIM to detect multiple local communities for a single query node.
HoSIM enforces a three-stage processing, namely subgraph sampling, core member
identification, and local community detection. The key idea is utilizing HoSI
to find and identify the core members of communities relevant to the query node
and optimize the generated communities. Extensive experiments illustrate the
effectiveness of HoSIM.",2022-05-24,"Boyu Li, Meng Wang, John E. Hopcroft, Kun He"
"Evolution of biomedical innovation quantified via billions of distinct
  article-level MeSH keyword combinations","We develop a systematic approach to measuring combinatorial innovation in the
biomedical sciences based upon the comprehensive ontology of Medical Subject
Headings (MeSH). This approach leverages an expert-defined knowledge ontology
that features both breadth (27,875 MeSH analyzed across 25 million articles
indexed by PubMed from 1902 onwards) and depth (we differentiate between Major
and Minor MeSH terms to identify differences in the knowledge network
representation constructed from primary research topics only). With this level
of uniform resolution we differentiate between three different modes of
innovation contributing to the combinatorial knowledge network: (i) conceptual
innovation associated with the emergence of new concepts and entities (measured
as the entry of new MeSH); and (ii) recombinant innovation, associated with the
emergence of new combinations, which itself consists of two types: peripheral
(i.e., combinations involving new knowledge) and core (combinations comprised
of pre-existing knowledge only). Another relevant question we seek to address
is whether examining triplet and quartet combinations, in addition to the more
traditional dyadic or pairwise combinations, provide evidence of any new
phenomena associated with higher-order combinations. Analysis of the size,
growth, and coverage of combinatorial innovation yield results that are largely
independent of the combination order, thereby suggesting that the common dyadic
approach is sufficient to capture essential phenomena. Our main results are
twofold: (a) despite the persistent addition of new MeSH terms, the network is
densifying over time meaning that scholars are increasingly exploring and
realizing the vast space of all knowledge combinations; and (b) conceptual
innovation is increasingly concentrated within single research articles, a
harbinger of the recent paradigm shift towards convergence science.",2022-05-23,Alexander M. Petersen
"Social Fragmentation Transitions in Large-Scale Parameter Sweep
  Simulations of Adaptive Social Networks","Social fragmentation transition is a transition of social states between many
disconnected communities with distinct opinions and a well-connected single
network with homogeneous opinions. This is a timely research topic with high
relevance to various current societal issues. We had previously studied this
problem using numerical simulations of adaptive social network models and found
that two individual behavioral traits, homophily and attention to novelty, had
the most statistically significant impact on the outcomes of social network
evolution. However, our previous study was limited in terms of the range of
parameter values examined, and possible interactions between multiple
behavioral traits were largely ignored. In this study, we conducted a
substantially larger-scale parameter sweep numerical experiment of the same
model with expanded parameter ranges by an order of magnitude in each parameter
dimension, resulting in a total of 116,640 simulation runs. To capture
nontrivial interactions among behavioral parameters, we modeled and visualized
the dependence of outcome measures on the model parameters using artificial
neural networks. Results show that, while the competition between homophily and
attention to novelty is still the primary determinant of social fragmentation,
another transition plane emerges when individuals have strong social conformity
behavior, which was not previously known. This implies that social
fragmentation transition can also occur in the homophily-social conformity
trade-off, the two behavioral traits that have very similar microscopic
individual-level effects but produce very different macroscopic
collective-level outcomes, illustrating the nontrivial macroscopic dynamics of
complex collective systems.",2022-05-21,Hiroki Sayama
Hyper-diffusion on multiplex networks,"Multiplex networks describe systems whose interactions can be of different
nature, and are fundamental to understand complexity of networks beyond the
framework of simple graphs. Recently it has been pointed out that restricting
the attention to pairwise interactions is also a limitation, as the vast
majority of complex systems include higher-order interactions that strongly
affect their dynamics. Here, we propose hyper-diffusion on multiplex networks,
a dynamical process in which diffusion on each single layer is coupled with the
diffusion in other layers thanks to the presence of higher-order interactions
occurring when there exists link overlap. We show that hyper-diffusion on a
duplex network can be described by the Hyper-Laplacian in which the strength of
four-body interactions among every set of four replica nodes connected by a
multilink $(1,1)$ can be tuned by a parameter $\delta_{11}\ge 0$. The
Hyper-Laplacian reduces to the standard lower Laplacian, capturing pairwise
interactions at the two layers, when $\delta_{11}=0$. By combining tools of
spectral graph theory, applied topology and network science we provide a
general understanding of hyper-diffusion on duplex networks when
$\delta_{11}>0$, including theoretical bounds on the Fiedler and the largest
eigenvalue of Hyper-Laplacians and the asymptotic expansion of their spectrum
for $\delta_{11}\ll1$ and $\delta_{11}\gg1$. Although hyper-diffusion on
multiplex networks does not imply a direct ``transfer of mass"" among the layers
(i.e. the average state of replica nodes in each layer is a conserved quantity
of the dynamics), we find that the dynamics of the two layers is coupled as the
relaxation to the steady state becomes synchronous when higher-order
interactions are taken into account and the Fiedler eigenvalue of the
Hyper-Laplacian is not localized in a single layer of the duplex network.",2022-05-20,"Reza Ghorbanchian, Vito Latora, Ginestra Bianconi"
"The role of the Big Geographic Sort in the circulation of misinformation
  among U.S. Reddit users","Past research has attributed the online circulation of misinformation to two
main factors - individual characteristics (e.g., a person's information
literacy) and social media effects (e.g., algorithm-mediated information
diffusion) - and has overlooked a third one: the critical mass created by the
offline self-segregation of Americans into like-minded geographical regions
such as states (a phenomenon called ""The Big Sort""). We hypothesized that this
latter factor matters for the online spreading of misinformation not least
because online interactions, despite having the potential of being global, end
up being localized: interaction probability is known to rapidly decay with
distance. Upon analysis of more than 8M Reddit comments containing news links
spanning four years, from January 2016 to December 2019, we found that Reddit
did not work as an ""hype machine"" for misinformation (as opposed to what
previous work reported for other platforms, circulation was not mainly caused
by platform-facilitated network effects) but worked as a supply-and-demand
system: misinformation news items scaled linearly with the number of users in
each state (with a scaling exponent beta=1, and a goodness of fit R2 = 0.95).
Furthermore, deviations from such a universal pattern were best explained by
state-level personality and cultural factors (R2 = {0.12, 0.39}), rather than
socioeconomic conditions (R2 = {0.15, 0.29}) or, as one would expect, political
characteristics (R2 ={0.06, 0.21}). Higher-than-expected circulation of any
type of news (including reputable news) was found in states characterised by
residents who tend to be less diligent in terms of their personality (low in
conscientiousness) and by loose cultures understating the importance of
adherence to norms (low in cultural tightness).",2022-05-20,"Lia Bozarth, Daniele Quercia, Licia Capra, Sanja Scepanovic"
"Quantitative Analysis of Community Evolution in Developer Social
  Networks Around Open Source Software Projects","Understanding the evolution of communities in developer social networks
(DSNs) around open source software (OSS) projects can provide valuable insights
about the socio-technical process of OSS development. Existing studies show the
evolutionary behaviors of social communities can effectively be described using
patterns including split, shrink, merge, expand, emerge, and extinct. However,
existing pattern-based approaches are limited in supporting quantitative
analysis, and are potentially problematic for using the patterns in a mutually
exclusive manner when describing community evolution. In this work, we propose
that different patterns can occur simultaneously between every pair of
communities during the evolution, just in different degrees. Four entropy-based
indices are devised to measure the degree of community split, shrink, merge,
and expand, respectively, which can provide a comprehensive and quantitative
measure of community evolution in DSNs. The indices have properties desirable
to quantify community evolution including monotonicity, and bounded maximum and
minimum values that correspond to meaningful cases. They can also be combined
to describe more patterns such as community emerge and extinct. We conduct
experiments with real-world OSS projects to evaluate the validity of the
proposed indices. The results suggest the proposed indices can effectively
capture community evolution, and are consistent with existing approaches in
detecting evolution patterns in DSNs with an accuracy of 94.1\%. The results
also show that the indices are useful in predicting OSS team productivity with
an accuracy of 0.718. In summary, the proposed approach is among the first to
quantify the degree of community evolution with respect to different patterns,
which is promising in supporting future research and applications about DSNs
and OSS development.",2022-05-20,"Liang Wang, Ying Li, Jierui Zhang, Xianping Tao"
Recurrent segmentation meets block models in temporal networks,"A popular approach to model interactions is to represent them as a network
with nodes being the agents and the interactions being the edges. Interactions
are often timestamped, which leads to having timestamped edges. Many real-world
temporal networks have a recurrent or possibly cyclic behaviour. For example,
social network activity may be heightened during certain hours of day. In this
paper, our main interest is to model recurrent activity in such temporal
networks. As a starting point we use stochastic block model, a popular choice
for modelling static networks, where nodes are split into $R$ groups. We extend
this model to temporal networks by modelling the edges with a Poisson process.
We make the parameters of the process dependent on time by segmenting the time
line into $K$ segments. To enforce the recurring activity we require that only
$H < K$ different set of parameters can be used, that is, several, not
necessarily consecutive, segments must share their parameters. We prove that
the searching for optimal blocks and segmentation is an NP-hard problem.
Consequently, we split the problem into 3 subproblems where we optimize blocks,
model parameters, and segmentation in turn while keeping the remaining
structures fixed. We propose an iterative algorithm that requires $O(KHm + Rn +
R^2H)$ time per iteration, where $n$ and $m$ are the number of nodes and edges
in the network. We demonstrate experimentally that the number of required
iterations is typically low, the algorithm is able to discover the ground truth
from synthetic datasets, and show that certain real-world networks exhibit
recurrent behaviour as the likelihood does not deteriorate when $H$ is lowered.",2022-05-19,"Chamalee Wickrama Arachchi, Nikolaj Tatti"
"Women, artificial intelligence, and key positions in collaboration
  networks: Towards a more equal scientific ecosystem","Scientific collaboration in almost every discipline is mainly driven by the
need of sharing knowledge, expertise, and pooled resources. Science is becoming
more complex which has encouraged scientists to involve more in collaborative
research projects in order to better address the challenges. As a highly
interdisciplinary field with a rapidly evolving scientific landscape,
artificial intelligence calls for researchers with special profiles covering a
diverse set of skills and expertise. Understanding gender aspects of scientific
collaboration is of paramount importance, especially in a field such as
artificial intelligence that has been attracting large investments. Using
social network analysis, natural language processing, and machine learning and
focusing on artificial intelligence publications for the period from 2000 to
2019, in this work, we comprehensively investigated the effects of several
driving factors on acquiring key positions in scientific collaboration networks
through a gender lens. It was found that, regardless of gender, scientific
performance in terms of quantity and impact plays a crucial in possessing the
""social researcher"" in the network. However, subtle differences were observed
between female and male researchers in acquiring the ""local influencer"" role.",2022-05-19,"Anahita Hajibabaei, Andrea Schiffauerova, Ashkan Ebadi"
"A Weakly-Supervised Iterative Graph-Based Approach to Retrieve COVID-19
  Misinformation Topics","The COVID-19 pandemic has been accompanied by an `infodemic' -- of accurate
and inaccurate health information across social media. Detecting misinformation
amidst dynamically changing information landscape is challenging; identifying
relevant keywords and posts is arduous due to the large amount of human effort
required to inspect the content and sources of posts. We aim to reduce the
resource cost of this process by introducing a weakly-supervised iterative
graph-based approach to detect keywords, topics, and themes related to
misinformation, with a focus on COVID-19. Our approach can successfully detect
specific topics from general misinformation-related seed words in a few seed
texts. Our approach utilizes the BERT-based Word Graph Search (BWGS) algorithm
that builds on context-based neural network embeddings for retrieving
misinformation-related posts. We utilize Latent Dirichlet Allocation (LDA)
topic modeling for obtaining misinformation-related themes from the texts
returned by BWGS. Furthermore, we propose the BERT-based Multi-directional Word
Graph Search (BMDWGS) algorithm that utilizes greater starting context
information for misinformation extraction. In addition to a qualitative
analysis of our approach, our quantitative analyses show that BWGS and BMDWGS
are effective in extracting misinformation-related content compared to common
baselines in low data resource settings. Extracting such content is useful for
uncovering prevalent misconceptions and concerns and for facilitating precision
public health messaging campaigns to improve health behaviors.",2022-05-19,"Harry Wang, Sharath Chandra Guntuku"
Joint Communication and Sensing: Models and Potential of Using MIMO,"The sixth-generation (6G) network is envisioned to integrate communication
and sensing functions, so as to improve the spectrum efficiency (SE) and
support explosive novel applications. Although the similarities of wireless
communication and radio sensing lay the foundation for their combination, there
is still considerable incompatible interest between them. To simultaneously
guarantee the communication capacity and the sensing accuracy, the
multiple-input and multiple-output (MIMO) technique plays an important role due
to its unique capability of spatial beamforming and waveform shaping. However,
the configuration of MIMO also brings high hardware cost, high power
consumption, and high signal processing complexity. How to efficiently apply
MIMO to achieve balanced communication and sensing performance is still open.
In this survey, we discuss joint communication and sensing (JCAS) in the
context of MIMO. We first outline the roles of MIMO in the process of wireless
communication and radar sensing. Then, we present current advances in both
communication and sensing coexistence and integration in detail. Three novel
JCAS MIMO models are subsequently discussed by combining cutting-edge
technologies, i.e., cloud random access networks (C-RANs), unmanned aerial
vehicles (UAVs) and reconfigurable intelligent surfaces (RISs). Examined from
the practical perspective, the potential and challenges of MIMO in JCAS are
summarized, and promising solutions are provided. Motivated by the great
potential of the Internet of Things (IoT), we also specify JCAS in IoT
scenarios and discuss the uniqueness of applying JCAS to IoT. In the end, open
issues are outlined to envisage a ubiquitous, intelligent and secure JCAS
network in the near future.",2022-05-19,"Xinran Fang, Wei Feng, Yunfei Chen, Ning Ge, Yan Zhang"
Finding Qs: Profiling QAnon Supporters on Parler,"The social media platform ""Parler"" has emerged into a prominent fringe
community where a significant part of the user base are self-reported
supporters of QAnon, a far-right conspiracy theory alleging that a cabal of
elites controls global politics. QAnon is considered to have had an influential
role in the public discourse during the 2020 U.S. presidential election.
However, little is known about QAnon supporters on Parler and what sets them
aside from other users. Building up on social identity theory, we aim at
profiling the characteristics of QAnon supporters on Parler. We analyze a
large-scale dataset with more than 600,000 profiles of English-speaking users
on Parler. Based on users' profiles, posts, and comments, we then extract a
comprehensive set of user features, linguistic features, network features, and
content features. This allows us to perform user profiling and understand to
what extent these features discriminate between QAnon and non-QAnon supporters
on Parler. Our analysis is three-fold: (1) We quantify the number of QAnon
supporters on Parler, finding that 34,913 users (5.5% of all users) openly
report to support the conspiracy. (2) We examine differences between QAnon vs.
non-QAnon supporters. We find that QAnon supporters differ statistically
significantly from non-QAnon supporters across multiple dimensions. For
example, they have, on average, a larger number of followers, followees, and
posts, and thus have a large impact on the Parler network. (3) We use machine
learning to identify which user characteristics discriminate QAnon from
non-QAnon supporters. We find that user features, linguistic features, network
features, and content features, can - to a large extent - discriminate QAnon
vs. non-QAnon supporters on Parler. In particular, we find that user features
are highly discriminatory, followed by content features and linguistic
features.",2022-05-18,"Dominik Bär, Nicolas Pröllochs, Stefan Feuerriegel"
Generating fine-grained surrogate temporal networks,"Temporal networks are essential for modeling and understanding systems whose
behavior varies in time, from social interactions to biological systems. Often,
however, real-world data are prohibitively expensive to collect in a large
scale or unshareable due to privacy concerns. A promising way to bypass the
problem consists in generating arbitrarily large and anonymized synthetic
graphs with the properties of real-world networks, namely `surrogate networks'.
Until now, the generation of realistic surrogate temporal networks has remained
an open problem, due to the difficulty of capturing both the temporal and
topological properties of the input network, as well as their correlations, in
a scalable model. Here, we propose a novel and simple method for generating
surrogate temporal networks. Our method decomposes the input network into
star-like structures evolving in time. Then those structures are used as
building blocks to generate a surrogate temporal network. Our model vastly
outperforms current methods across multiple examples of temporal networks in
terms of both topological and dynamical similarity. We further show that beyond
generating realistic interaction patterns, our method is able to capture
intrinsic temporal periodicity of temporal networks, all with an execution time
lower than competing methods by multiple orders of magnitude. The simplicity of
our algorithm makes it easily interpretable, extendable and algorithmically
scalable.",2022-05-18,"Antonio Longa, Giulia Cencetti, Sune Lehmann, Andrea Passerini, Bruno Lepri"
ViralBERT: A User Focused BERT-Based Approach to Virality Prediction,"Recently, Twitter has become the social network of choice for sharing and
spreading information to a multitude of users through posts called 'tweets'.
Users can easily re-share these posts to other users through 'retweets', which
allow information to cascade to many more users, increasing its outreach.
Clearly, being able to know the extent to which a post can be retweeted has
great value in advertising, influencing and other such campaigns. In this paper
we propose ViralBERT, which can be used to predict the virality of tweets using
content- and user-based features. We employ a method of concatenating numerical
features such as hashtags and follower numbers to tweet text, and utilise two
BERT modules: one for semantic representation of the combined text and
numerical features, and another module purely for sentiment analysis of text,
as both the information within text and it's ability to elicit an emotional
response play a part in retweet proneness. We collect a dataset of 330k tweets
to train ViralBERT and validate the efficacy of our model using baselines from
current studies in this field. Our experiments show that our approach
outperforms these baselines, with a 13% increase in both F1 Score and Accuracy
compared to the best performing baseline method. We then undergo an ablation
study to investigate the importance of chosen features, finding that text
sentiment and follower counts, and to a lesser extent mentions and following
counts, are the strongest features for the model, and that hashtag counts are
detrimental to the model.",2022-05-17,"Rikaz Rameez, Hossein A. Rahmani, Emine Yilmaz"
Sustainability of Stack Exchange Q\&A communities: the role of trust,"Knowledge-sharing communities are a fundamental element of any
knowledge-based society. Understanding how they emerge, function, and disappear
is thus of crucial importance. Many social and economic factors influence
sustainable knowledge-sharing communities. Here we explore the role of the
structure of social interactions and social trust in the emergence of these
communities. Using tools from complex network theory, we analyze the early
evolution of social structure in four pairs of StackExchange communities, each
corresponding to one active and one closed community on the same topic. We
adapt the dynamical reputation model to quantify the evolution of social trust
in these communities. Our analysis shows that active communities have higher
local cohesiveness and develop stable and more strongly connected cores. The
average reputation is higher in sustainable communities. In these communities,
the trust between core members develops early and remains high over time. Our
results imply that efforts to create a stable and trustworthy core may be
crucial for building a sustainable knowledge-sharing community.",2022-05-16,"Ana Vranić, Aleksandar Tomašević, Aleksandra Alorić, Marija Mitrović Dankulov"
"PrEF: Percolation-based Evolutionary Framework for the
  diffusion-source-localization problem in large networks","We assume that the state of a number of nodes in a network could be
investigated if necessary, and study what configuration of those nodes could
facilitate a better solution for the diffusion-source-localization (DSL)
problem. In particular, we formulate a candidate set which contains the
diffusion source for sure, and propose the method, Percolation-based
Evolutionary Framework (PrEF), to minimize such set. Hence one could further
conduct more intensive investigation on only a few nodes to target the source.
To achieve that, we first demonstrate that there are some similarities between
the DSL problem and the network immunization problem. We find that the
minimization of the candidate set is equivalent to the minimization of the
order parameter if we view the observer set as the removal node set. Hence,
PrEF is developed based on the network percolation and evolutionary algorithm.
The effectiveness of the proposed method is validated on both model and
empirical networks in regard to varied circumstances. Our results show that the
developed approach could achieve a much smaller candidate set compared to the
state of the art in almost all cases. Meanwhile, our approach is also more
stable, i.e., it has similar performance irrespective of varied infection
probabilities, diffusion models, and outbreak ranges. More importantly, our
approach might provide a new framework to tackle the DSL problem in extreme
large networks.",2022-05-16,"Yang Liu, Xiaoqi Wang, Xi Wang, Zhen Wang, Jürgen Kurths"
"The Detection and effect of social events on Wikipedia data-set for
  studying human preferences","Several studies have used Wikipedia (WP) data-set to analyse worldwide human
preferences by languages. However, those studies could suffer from bias related
to exceptional social circumstances. Any massive event promoting the
exceptional edition of WP can be defined as a source of bias. In this article,
we follow a procedure for detecting outliers. Our study is based on $12$
languages and $13$ different categories. Our methodology defines a parameter,
which is language-depending instead of being externally fixed. We also study
the presence of human cyclic behaviour to evaluate apparent outliers. After our
analysis, we found that the outliers in our data set do not significantly
affect using the whole Wikipedia-data set as a digital footprint to analyse
worldwide human preferences.",2022-05-14,"Julien Assuied, Yérali Gandica"
Comparative evaluation of community-aware centrality measures,"Influential nodes play a critical role in boosting or curbing spreading
phenomena in complex networks. Numerous centrality measures have been proposed
for identifying and ranking the nodes according to their importance. Classical
centrality measures rely on various local or global properties of the nodes.
They do not take into account the network community structure. Recently, a
growing number of researches have shifted to community-aware centrality
measures. Indeed, it is a ubiquitous feature in a vast majority of real-world
networks. In the literature, the focus is on designing community-aware
centrality measures. However, up to now, there is no systematic evaluation of
their effectiveness. This study fills this gap. It allows answering which
community-aware centrality measure should be used in practical situations. We
investigate seven influential community-aware centrality measures in an
epidemic spreading process scenario using the Susceptible-Infected-Recovered
(SIR) model on a set of fifteen real-world networks. Results show that
generally, the correlation between community-aware centrality measures is low.
Furthermore, in a multiple-spreader problem, when resources are available,
targeting distant hubs using Modularity Vitality is more effective. However,
with limited resources, diffusion expands better through bridges, especially in
networks with a medium or strong community structure.",2022-05-14,"Stephany Rajeh, Marinette Savonnet, Eric Leclercq, Hocine Cherifi"
Algorithms for spanning trees of unweighted networks,"Spanning tree of a network or a graph is a subgraph connecting all the nodes
with the minimum number of edges. Spanning tree retains the connectivity of a
network and possibly other structural properties, and is one of the simplest
techniques for network simplification or sampling, and for revealing its
backbone or skeleton. The Prim's algorithm and the Kruskal's algorithm are well
known algorithms for computing a spanning tree of a weighted network. In this
paper, we study the performance of these algorithms on unweighted networks, and
compare them to different priority-first search algorithms. We show that the
distances between the nodes and the diameter of a network are best preserved by
an algorithm based on the breadth-first search node traversal. The algorithm
computes a spanning tree with properties of a balanced tree and a power-law
node degree distribution. We support our results by experiments on synthetic
graphs and more than a thousand real networks, and demonstrate different
practical applications of computed spanning trees. We conclude that, if a
spanning tree is supposed to retain the distances between the nodes or the
diameter of an unweighted network, then the breadth-first search algorithm
should be the preferred choice.",2022-05-13,Lovro Šubelj
"Framework for inferring empirical causal graphs from binary data to
  support multidimensional poverty analysis","Poverty is one of the fundamental issues that mankind faces. To solve poverty
issues, one needs to know how severe the issue is. The Multidimensional Poverty
Index (MPI) is a well-known approach that is used to measure a degree of
poverty issues in a given area. To compute MPI, it requires information of MPI
indicators, which are \textbf{binary variables} collecting by surveys, that
represent different aspects of poverty such as lacking of education, health,
living conditions, etc. Inferring impacts of MPI indicators on MPI index can be
solved by using traditional regression methods. However, it is not obvious that
whether solving one MPI indicator might resolve or cause more issues in other
MPI indicators and there is no framework dedicating to infer empirical causal
relations among MPI indicators.
  In this work, we propose a framework to infer causal relations on binary
variables in poverty surveys. Our approach performed better than baseline
methods in simulated datasets that we know ground truth as well as correctly
found a causal relation in the Twin births dataset. In Thailand poverty survey
dataset, the framework found a causal relation between smoking and alcohol
drinking issues. We provide R CRAN package `BiCausality' that can be used in
any binary variables beyond the poverty analysis context.",2022-05-12,"Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok, Suttipong Thajchayapong"
Information flow estimation: a study of news on Twitter,"News media has long been an ecosystem of creation, reproduction, and
critique, where news outlets report on current events and add commentary to
ongoing stories. Understanding the dynamics of news information creation and
dispersion is important to accurately ascribe credit to influential work and
understand how societal narratives develop. These dynamics can be modelled
through a combination of information-theoretic natural language processing and
networks; and can be parameterised using large quantities of textual data.
However, it is challenging to see ""the wood for the trees"", i.e., to detect
small but important flows of information in a sea of noise. Here we develop new
comparative techniques to estimate temporal information flow between pairs of
text producers. Using both simulated and real text data we compare the
reliability and sensitivity of methods for estimating textual information flow,
showing that a metric that normalises by local neighbourhood structure provides
a robust estimate of information flow in large networks. We apply this metric
to a large corpus of news organisations on Twitter and demonstrate its
usefulness in identifying influence within an information ecosystem, finding
that average information contribution to the network is not correlated with the
number of followers or the number of tweets. This suggests that small local
organisations and right-wing organisations which have lower average follower
counts still contribute significant information to the ecosystem. Further, the
methods are applied to smaller full-text datasets of specific news events
across news sites and Russian troll accounts on Twitter. The information flow
estimation reveals and quantifies features of how these events develop and the
role of groups of trolls in setting disinformation narratives.",2022-05-12,"Tobin South, Bridget Smart, Matthew Roughan, Lewis Mitchell"
"Cryptocurrency Bubble Detection: A New Stock Market Dataset, Financial
  Task & Hyperbolic Models","The rapid spread of information over social media influences quantitative
trading and investments. The growing popularity of speculative trading of
highly volatile assets such as cryptocurrencies and meme stocks presents a
fresh challenge in the financial realm. Investigating such ""bubbles"" - periods
of sudden anomalous behavior of markets are critical in better understanding
investor behavior and market dynamics. However, high volatility coupled with
massive volumes of chaotic social media texts, especially for underexplored
assets like cryptocoins pose a challenge to existing methods. Taking the first
step towards NLP for cryptocoins, we present and publicly release
CryptoBubbles, a novel multi-span identification task for bubble detection, and
a dataset of more than 400 cryptocoins from 9 exchanges over five years
spanning over two million tweets. Further, we develop a set of
sequence-to-sequence hyperbolic models suited to this multi-span identification
task based on the power-law dynamics of cryptocurrencies and user behavior on
social media. We further test the effectiveness of our models under zero-shot
settings on a test set of Reddit posts pertaining to 29 ""meme stocks"", which
see an increase in trade volume due to social media hype. Through quantitative,
qualitative, and zero-shot analyses on Reddit and Twitter spanning cryptocoins
and meme-stocks, we show the practical applicability of CryptoBubbles and
hyperbolic models.",2022-05-11,"Ramit Sawhney, Shivam Agarwal, Vivek Mittal, Paolo Rosso, Vikram Nanda, Sudheer Chava"
"To incentivize or not: Impact of blockchain-based cryptoeconomic tokens
  on human information sharing behavior","Cryptoeconomic incentives in the form of blockchain-based tokens are seen as
an enabler of the sharing economy that could shift society towards greater
sustainability. Nevertheless, knowledge of the impact of these tokens on human
sharing behavior is still limited and this poses a challenge to the design of
effective cryptoeconomic incentives. This study applies the theory of
self-determination to investigate the impact of such tokens on human behavior
in an information-sharing scenario. By utilizing an experimental methodology in
the form of a randomized control trial with a 2x2 factorial design involving
132 participants, the effects of two token incentives on human
information-sharing behavior are analyzed. Individuals obtain these tokens in
exchange for their shared information. Based on the collected tokens,
individuals receive a monetary payment and build reputation. Besides
investigating the effect of these incentives on the quantity of shared
information, the study includes quality characteristics of the information,
such as accuracy and contextualization. The focus on quantity while excluding
quality has been identified as a limitation in previous work. In addition to
confirming previously known effects such as a crowding-out of intrinsic
motivation by incentives, which also exists for blockchain-based tokens, the
findings of this paper point to a hitherto unreported interaction effect
between multiple tokens when applied simultaneously. The findings are
critically discussed and put into the context of recent work and ethical
considerations. The theory-based-empirical study is of interest to those
investigating the effect of cryptoeconomic tokens or digital currencies on
human behavior and supports the community in the design of effective
personalized incentives for sharing economies.",2022-05-10,Mark Christopher Ballandies
"TeamX@DravidianLangTech-ACL2022: A Comparative Analysis for Troll-Based
  Meme Classification","The spread of fake news, propaganda, misinformation, disinformation, and
harmful content online raised concerns among social media platforms, government
agencies, policymakers, and society as a whole. This is because such harmful or
abusive content leads to several consequences to people such as physical,
emotional, relational, and financial. Among different harmful content
\textit{trolling-based} online content is one of them, where the idea is to
post a message that is provocative, offensive, or menacing with an intent to
mislead the audience. The content can be textual, visual, a combination of
both, or a meme. In this study, we provide a comparative analysis of
troll-based memes classification using the textual, visual, and multimodal
content. We report several interesting findings in terms of code-mixed text,
multimodal setting, and combining an additional dataset, which shows
improvements over the majority baseline.",2022-05-09,"Rabindra Nath Nandi, Firoj Alam, Preslav Nakov"
SoK: Blockchain Decentralization,"Blockchain introduces decentralized trust in peer-to-peer networks, advancing
security and democratizing systems. Yet, a unified definition for
decentralization remains elusive. Our Systematization of Knowledge (SoK) seeks
to bridge this gap, emphasizing quantification and methodological coherence.
We've formulated a taxonomy defining blockchain decentralization across five
facets: consensus, network, governance, wealth, and transaction. Despite the
prevalent focus on consensus decentralization, our novel index, based on
Shannon entropy, provides comprehensive insights. Moreover, we delve into
alternative metrics like the Gini and Nakamoto Coefficients and the
Herfindahl-Hirschman Index (HHI), supplemented by an open-source Python tool on
GitHub. In terms of methodology, blockchain research has often bypassed
stringent scientific methods. By employing descriptive, predictive, and causal
methods, our study showcases the potential of structured research in
blockchain. Descriptively, we observe a trend of converging decentralization
levels over time. Examining DeFi platforms reveals exchange and lending
applications as more decentralized than their payment and derivatives
counterparts. Predictively, there's a notable correlation between Ether's
returns and transaction decentralization in Ether-backed stablecoins. Causally,
Ethereum's transition to the EIP-1559 transaction fee model has a profound
impact on DeFi transaction decentralization. To conclude, our work outlines
directions for blockchain research, emphasizing the delicate balance among
decentralization facets, fostering long-term decentralization, and the ties
between decentralization, security, privacy, and efficiency. We end by
spotlighting challenges in grasping blockchain decentralization intricacies.",2022-05-09,"Luyao Zhang, Xinshi Ma, Yulin Liu"
"Characterizing Multi-Domain False News and Underlying User Effects on
  Chinese Weibo","False news that spreads on social media has proliferated over the past years
and has led to multi-aspect threats in the real world. While there are studies
of false news on specific domains (like politics or health care), little work
is found comparing false news across domains. In this article, we investigate
false news across nine domains on Weibo, the largest Twitter-like social media
platform in China, from 2009 to 2019. The newly collected data comprise 44,728
posts in the nine domains, published by 40,215 users, and reposted over 3.4
million times. Based on the distributions and spreads of the multi-domain
dataset, we observe that false news in domains that are close to daily life
like health and medicine generated more posts but diffused less effectively
than those in other domains like politics, and that political false news had
the most effective capacity for diffusion. The widely diffused false news posts
on Weibo were associated strongly with certain types of users -- by gender,
age, etc. Further, these posts provoked strong emotions in the reposts and
diffused further with the active engagement of false-news starters. Our
findings have the potential to help design false news detection systems in
suspicious news discovery, veracity prediction, and display and explanation.
The comparison of the findings on Weibo with those of existing work
demonstrates nuanced patterns, suggesting the need for more research on data
from diverse platforms, countries, or languages to tackle the global issue of
false news. The code and new anonymized dataset are available at
https://github.com/ICTMCG/Characterizing-Weibo-Multi-Domain-False-News.",2022-05-06,"Qiang Sheng, Juan Cao, H. Russell Bernard, Kai Shu, Jintao Li, Huan Liu"
"Evaluating the principle of relatedness: Estimation, drivers and
  implications for policy","A growing body of research documents that the size and growth of an industry
in a place depends on how much related activity is found there. This fact is
commonly referred to as the ""principle of relatedness"". However, there is no
consensus on why we observe the principle of relatedness, how best to determine
which industries are related or how this empirical regularity can help inform
local industrial policy. We perform a structured search over tens of thousands
of specifications to identify robust -- in terms of out-of-sample predictions
-- ways to determine how well industries fit the local economies of US cities.
To do so, we use data that allow us to derive relatedness from observing which
industries co-occur in the portfolios of establishments, firms, cities and
countries. Different portfolios yield different relatedness matrices, each of
which help predict the size and growth of local industries. However, our
specification search not only identifies ways to improve the performance of
such predictions, but also reveals new facts about the principle of relatedness
and important trade-offs between predictive performance and interpretability of
relatedness patterns. We use these insights to deepen our theoretical
understanding of what underlies path-dependent development in cities and expand
existing policy frameworks that rely on inter-industry relatedness analysis.",2022-05-05,"Yang Li, Frank Neffke"
Computing Traffic Accident High-Risk Locations Using Graph Analytics,"Analysis of the dynamic relationship between traffic accident events and road
network topology based on connectivity and graph analytics offers a new
approach to identifying, ranking and profiling traffic accident high
risk-locations at different levels of space and time granularities. Previous
studies on traffic accident hot spots have mostly adopted spatial statistics
and Geographic Information Systems (GIS) where spatial point patterns are
discovered based only on spatial dependence with no recognition of the temporal
dependence of the events. A limitation arises from the fact that the results
are either under or over-estimated because of the temporal aggregation of the
events to an absolute time point. Furthermore, the existing methods apart from
the Network Kernel Density Estimation (NETKDE), consider traffic accident
events as events randomly on a 2-D geographic space. However, traffic accident
events are network constrained events that happens majorly on the road network
space. Therefore, in this paper, we adopt the connectivity of graph on a
network space approach that identifies accident high risk-locations based on
space-time-varying connectivity between traffic accident events and the road
network geometry. A simple but extensible traffic accident space time-varying
graph (STVG) model is developed and implemented for this study. Traffic
accident high risk-locations are identified and ranked in space and time using
time-dependent degree centrality and PageRank centrality graph metrics
respectively through time-incremental graph queries. This study offers urban
traffic accident analysts with a new and efficient approach to identify, rank
and profile accident-prone areas in space and time at different scales.",2022-05-05,"Iyke Maduako, Elijah Ebinne, Victus Uzodinma, Chukwuma Okolie, Emmanuel Chiemelu"
"Using network structure and community detection to discover important
  website features when distinguishing between phishing and legitimate ones","In this paper, we uncover the essential features of websites that allow
intelligent models to distinguish between phishing and legitimate sites.
Phishing websites are those that are made with a similar user interface and a
near similar address to trustworthy websites in order to persuade users to
input their private data for potential future misuse by attackers. Detecting
phishing websites with intelligent systems is an important goal to protect
users, companies, and other online services that use the HTTP protocol. An
intelligent model needs to distinguish features that are important as input to
predict phishing sites. In this research, using correlation-based networks, we
provide a novel network-based method to find features that are more important
in phishing detection. The networks are trained and tested on an established
phishing dataset. Three different networks are made by partitioning the dataset
by its data instance labels. The important features are found by discovering
the hubs of these networks, and the results are presented and analysed. This is
the first time using a network-based approach for feature selection which is a
fast and accurate way to do so.",2022-05-05,"Arash Negahdari Kia, Finbarr Murphy, Zahra Dehghani Mohammadabadi, Parisa Shamsi"
"Generating Simple Directed Social Network Graphs for Information
  Spreading","Online social networks are a dominant medium in everyday life to stay in
contact with friends and to share information. In Twitter, users can connect
with other users by following them, who in turn can follow back. In recent
years, researchers studied several properties of social networks and designed
random graph models to describe them. Many of these approaches either focus on
the generation of undirected graphs or on the creation of directed graphs
without modeling the dependencies between reciprocal (i.e., two directed edges
of opposite direction between two nodes) and directed edges. We propose an
approach to generate directed social network graphs that creates reciprocal and
directed edges and considers the correlation between the respective degree
sequences.
  Our model relies on crawled directed graphs in Twitter, on which information
w.r.t. a topic is exchanged or disseminated. While these graphs exhibit a high
clustering coefficient and small average distances between random node pairs
(which is typical in real-world networks), their degree sequences seem to
follow a $\chi^2$-distribution rather than power law. To achieve high
clustering coefficients, we apply an edge rewiring procedure that preserves the
node degrees.
  We compare the crawled and the created graphs, and simulate certain
algorithms for information dissemination and epidemic spreading on them. The
results show that the created graphs exhibit very similar topological and
algorithmic properties as the real-world graphs, providing evidence that they
can be used as surrogates in social network analysis. Furthermore, our model is
highly scalable, which enables us to create graphs of arbitrary size with
almost the same properties as the corresponding real-world networks.",2022-05-05,"Christoph Schweimer, Christine Gfrerer, Florian Lugstein, David Pape, Jan A. Velimsky, Robert Elsässer, Bernhard C. Geiger"
"Trust-SIoT: Towards Trustworthy Object Classification in the Social
  Internet of Things","The recent emergence of the promising paradigm of the Social Internet of
Things (SIoT) is a result of an intelligent amalgamation of the social
networking concepts with the Internet of Things (IoT) objects (also referred to
as ""things"") in an attempt to unravel the challenges of network discovery,
navigability, and service composition. This is realized by facilitating the IoT
objects to socialize with one another, i.e., similar to the social interactions
amongst the human beings. A fundamental issue that mandates careful attention
is to thus establish, and over time, maintain trustworthy relationships amongst
these IoT objects. Therefore, a trust framework for SIoT must include
object-object interactions, the aspects of social relationships, credible
recommendations, etc., however, the existing literature has only focused on
some aspects of trust by primarily relying on the conventional approaches that
govern linear relationships between input and output. In this paper, an
artificial neural network-based trust framework, Trust-SIoT, has been envisaged
for identifying the complex non-linear relationships between input and output
in a bid to classify the trustworthy objects. Moreover, Trust-SIoT has been
designed for capturing a number of key trust metrics as input, i.e., direct
trust by integrating both current and past interactions, reliability, and
benevolence of an object, credible recommendations, and the degree of
relationship by employing a knowledge graph embedding. Finally, we have
performed extensive experiments to evaluate the performance of Trust-SIoT
vis-a-vis state-of-the-art heuristics on two real-world datasets. The results
demonstrate that Trust-SIoT achieves a higher F1 and lower MAE and MSE scores.",2022-05-04,"Subhash Sagar, Adnan Mahmood, Kai Wang, Quan Z. Sheng, Wei Emma Zhang"
"Hazard Exposure Heterophily: A Latent Characteristic in Socio-Spatial
  Networks Influencing Community Resilience","We present a latent characteristic in socio-spatial networks, hazard-exposure
heterophily, to capture the extent to which populations with similar hazard
exposure could assist each other through social ties. Heterophily is the
tendency of unlike individuals to form social ties. Conversely, populations in
spatial areas with significant hazard exposure similarity, homophily, would
lack sufficient resourcefulness to aid each other to lessen the impact of
hazards. In the context of the Houston metropolitan area, we use Meta's Social
Connectedness data to construct a socio-spatial network in juxtaposition with
flood exposure data from National Flood Hazard Layer to analyze flood hazard
exposure of spatial areas. The results reveal the extent and spatial variation
of hazard-exposure heterophily in the study area. Notably, the results show
that lower-income areas have lower hazard-exposure heterophily possibly caused
by income segregation and the tendency of affordable housing development to be
located in flood zones. Less resourceful social ties due to high
hazard-exposure homophily may inhibit low-income areas from better coping with
hazard impacts and could contribute to their slower recovery. Overall, the
results underscore the significance of characterizing hazard-exposure
heterophily in socio-spatial networks to reveal community vulnerability and
resilience to hazards.",2022-05-04,"Chia-Fu Liu, Ali Mostafavi"
"Exploration of the possibility of infusing Social Media Trends into
  generating NFT Recommendations","Recommendations Systems have been identified to be one of the integral
elements of driving sales in e-commerce sites. The utilization of opinion
mining data extracted from trends has been attempted to improve the
recommendations that can be provided by baseline methods in this research when
user-click data is lacking or is difficult to be collected due to privacy
concerns.
  Utilizing social trends to influence the recommendations generated for a set
of unique items has been explored with the use of a suggested scoring
mechanism. Embracing concepts from decentralized networks that are expected to
change how users interact via the internet over the next couple of decades, the
suggested Recommendations System attempts to make use of multiple sources of
information, applying coherent information retrieval techniques to extract
probable trending items.
  The proposed Recommendations Architecture in the research presents a method
to integrate social trends with recommendations to produce promising outputs.",2022-05-03,"Dinuka Ravijaya Piyadigama, Guhanathan Poravi"
"A Review on Pushing the Limits of Baseline Recommendation Systems with
  the integration of Opinion Mining & Information Retrieval Techniques","Recommendations Systems allow users to identify trending items among a
community while being timely and relevant to the user's expectations. When the
purpose of various Recommendation Systems differs, the required type of
recommendations also differs for each use case. While one Recommendation System
may focus on recommending popular items, another may focus on recommending
items that are comparable to the user's interests. Content-based filtering,
user-to-user & item-to-item Collaborative filtering, and more recently; Deep
Learning methods have been brought forward by the researchers to achieve better
quality recommendations.
  Even though each of these methods has proven to perform well individually,
there have been attempts to push the boundaries of their limitations. Following
a wide range of methods, researchers have tried to expand on the capabilities
of standard recommendation systems to provide the most effective
recommendations to users while being more profitable from a business's
perspective. This has been achieved by taking a hybrid approach when building
models and architectures for Recommendation Systems.
  This paper is a review of the novel models & architectures of hybrid
Recommendation Systems. The author identifies possibilities of expanding the
capabilities of baseline models & the advantages and drawbacks of each model
with selected use cases in this review.",2022-05-03,"Dinuka Ravijaya Piyadigama, Guhanathan Poravi"
"Explain and Conquer: Personalised Text-based Reviews to Achieve
  Transparency","There are many contexts in which dyadic data are present. Social networks are
a well-known example. In these contexts, pairs of elements are linked building
a network that reflects interactions. Explaining why these relationships are
established is essential to obtain transparency, an increasingly important
notion. These explanations are often presented using text, thanks to the spread
of the natural language understanding tasks. Our aim is to represent and
explain pairs established by any agent (e.g., a recommender system or a paid
promotion mechanism), so that text-based personalisation is taken into account.
We have focused on the TripAdvisor platform, considering the applicability to
other dyadic data contexts. The items are a subset of users and restaurants and
the interactions the reviews posted by these users. We propose the PTER
(Personalised TExt-based Reviews) model. We predict, from the available reviews
for a given restaurant, those that fit to the specific user interactions. PTER
leverages the BERT (Bidirectional Encoders Representations from Transformers)
transformer-encoder model. We customised a deep neural network following the
feature-based approach, presenting a LTR (Learning To Rank) downstream task. We
carried out several comparisons of our proposal with a random baseline and
other models of the state of the art, following the EXTRA (EXplanaTion RAnking)
benchmark. Our method outperforms other collaborative filtering proposals.",2022-05-03,"Iñigo López-Riobóo Botana, Verónica Bolón-Canedo, Bertha Guijarro-Berdiñas, Amparo Alonso-Betanzos"
"Meaningful Context, a Red Flag, or Both? Users' Preferences for Enhanced
  Misinformation Warnings on Twitter","Warning users about misinformation on social media is not a simple usability
task. Soft moderation has to balance between debunking falsehoods and avoiding
moderation bias while preserving the social media consumption flow. Platforms
thus employ minimally distinguishable warning tags with generic text under a
suspected misinformation content. This approach resulted in an unfavorable
outcome where the warnings ""backfired"" and users believed the misinformation
more, not less. In response, we developed enhancements to the misinformation
warnings where users are advised on the context of the information hazard and
exposed to standard warning iconography. We ran an A/B evaluation with the
Twitter's original warning tags in a 337 participant usability study. The
majority of the participants preferred the enhancements as a nudge toward
recognizing and avoiding misinformation. The enhanced warning tags were most
favored by the politically left-leaning and to a lesser degree moderate
participants, but they also appealed to roughly a third of the right-leaning
participants. The education level was the only demographic factor shaping
participants' preferences. We use our findings to propose user-tailored
improvements in the soft moderation of misinformation on social media.",2022-05-02,"Filipo Sharevski, Amy Devine, Emma Pieroni, Peter Jacnim"
FirmTruss Community Search in Multilayer Networks,"In applications such as biological, social, and transportation networks,
interactions between objects span multiple aspects. For accurately modeling
such applications, multilayer networks have been proposed. Community search
allows for personalized community discovery and has a wide range of
applications in large real-world networks. While community search has been
widely explored for single-layer graphs, the problem for multilayer graphs has
just recently attracted attention. Existing community models in multilayer
graphs have several limitations, including disconnectivity, free-rider effect,
resolution limits, and inefficiency. To address these limitations, we study the
problem of community search over large multilayer graphs. We first introduce
FirmTruss, a novel dense structure in multilayer networks, which extends the
notion of truss to multilayer graphs. We show that FirmTrusses possess nice
structural and computational properties and bring many advantages compared to
the existing models. Building on this, we present a new community model based
on FirmTruss, called FTCS, and show that finding an FTCS community is NP-hard.
We propose two efficient 2-approximation algorithms, and show that no
polynomial-time algorithm can have a better approximation guarantee unless P =
NP. We propose an index-based method to further improve the efficiency of the
algorithms. We then consider attributed multilayer networks and propose a new
community model based on network homophily. We show that community search in
attributed multilayer graphs is NP-hard and present an effective and efficient
approximation algorithm. Experimental studies on real-world graphs with
ground-truth communities validate the quality of the solutions we obtain and
the efficiency of the proposed algorithms.",2022-05-02,"Ali Behrouz, Farnoosh Hashemi, Laks V. S. Lakshmanan"
"HashNWalk: Hash and Random Walk Based Anomaly Detection in Hyperedge
  Streams","Sequences of group interactions, such as emails, online discussions, and
co-authorships, are ubiquitous; and they are naturally represented as a stream
of hyperedges. Despite their broad potential applications, anomaly detection in
hypergraphs (i.e., sets of hyperedges) has received surprisingly little
attention, compared to that in graphs. While it is tempting to reduce
hypergraphs to graphs and apply existing graph-based methods, according to our
experiments, taking higher-order structures of hypergraphs into consideration
is worthwhile. We propose HashNWalk, an incremental algorithm that detects
anomalies in a stream of hyperedges. It maintains and updates a constant-size
summary of the structural and temporal information about the stream. Using the
summary, which is the form of a proximity matrix, HashNWalk measures the
anomalousness of each new hyperedge as it appears. HashNWalk is (a) Fast: it
processes each hyperedge in near real-time and billions of hyperedges within a
few hours, (b) Space Efficient: the size of the maintained summary is a
predefined constant, (c) Effective: it successfully detects anomalous
hyperedges in real-world hypergraphs.",2022-04-29,"Geon Lee, Minyoung Choe, Kijung Shin"
"Trends in Remote Learning-based Google Shopping in the United States due
  to COVID-19","The United States of America has been the worst affected country in terms of
the number of cases and deaths on account of the severe acute respiratory
syndrome coronavirus 2 (SARS-CoV-2) or COVID-19, a highly transmissible and
pathogenic coronavirus that started spreading globally in late 2019. On account
of the surge of infections, accompanied by hospitalizations and deaths due to
COVID-19, and lack of a definitive cure at that point, a national emergency was
declared in the United States on March 13, 2020. To prevent the rapid spread of
the virus, several states declared stay at home and remote work guidelines
shortly after this declaration of an emergency. Such guidelines caused schools,
colleges, and universities, both private and public, in all the 50-United
States to switch to remote or online forms of teaching for a significant period
of time. As a result, Google, the most widely used search engine in the United
States, experienced a surge in online shopping of remote learning-based
software, systems, applications, and gadgets by both educators and students
from all the 50-United States, due to both these groups responding to the
associated needs and demands related to switching to remote teaching and
learning. This paper aims to investigate, analyze, and interpret these trends
of Google Shopping related to remote learning that emerged since March 13,
2020, on account of COVID-19 and the subsequent remote learning adoption in
almost all schools, colleges, and universities, from all the 50-United States.
The study was performed using Google Trends, which helps to track and study
Google Shopping-based online activity emerging from different geolocations. The
results and discussions show that the highest interest related to Remote
Learning-based Google Shopping was recorded from Oregon, which was followed by
Illinois, Florida, Texas, California, and the other states.",2022-04-27,"Isabella Hall, Nirmalya Thakur, Chia Y. Han"
Nonbacktracking spectral clustering of nonuniform hypergraphs,"Spectral methods offer a tractable, global framework for clustering in graphs
via eigenvector computations on graph matrices. Hypergraph data, in which
entities interact on edges of arbitrary size, poses challenges for matrix
representations and therefore for spectral clustering. We study spectral
clustering for nonuniform hypergraphs based on the hypergraph nonbacktracking
operator. After reviewing the definition of this operator and its basic
properties, we prove a theorem of Ihara-Bass type which allows eigenpair
computations to take place on a smaller matrix, often enabling faster
computation. We then propose an alternating algorithm for inference in a
hypergraph stochastic blockmodel via linearized belief-propagation which
involves a spectral clustering step again using nonbacktracking operators. We
provide proofs related to this algorithm that both formalize and extend several
previous results. We pose several conjectures about the limits of spectral
methods and detectability in hypergraph stochastic blockmodels in general,
supporting these with in-expectation analysis of the eigeinpairs of our studied
operators. We perform experiments in real and synthetic data that demonstrate
the benefits of hypergraph methods over graph-based ones when interactions of
different sizes carry different information about cluster structure.",2022-04-27,"Philip Chodrow, Nicole Eikmeier, Jamie Haddock"
"Quantifying the selective, stochastic, and complementary drivers of the
  institutional evolution in online communities","Institutions and cultures evolve adaptively in response to the current
environmental incentives, usually. But sometimes institutional change is due to
stochastic drives beyond current fitness, including drift, path dependency,
blind imitation, and complementary cooperation in fluctuating environments.
Disentangling the selective and stochastic components of social system change
enables us to identify the key features to organizational development in the
long run. Evolutionary approaches provide organizational science abundant
theories to demonstrate organizational evolution by tracking particular
beneficial or harmful features. We measure these different drivers empirically
in institutional evolution among 20,000 Minecraft communities with the help of
two of the most applied evolutionary models, the Price equation and the
bet-hedging model. As a result, we find strong selection pressure on
administrative rules and information rules, suggesting that their positive
correlation with community fitness is the main reason for their frequency
change. We also find that stochastic drives decrease the average frequency of
administrative rules. The result makes sense when explained in light of
evolutionary bet-hedging. We show through the bet-hedging result that
institutional diversity contributes to the growth and stability of rules
related to information, communication, and economic behaviors.",2022-04-26,"Qiankun Zhong, Seth Frey, Martin Hilbert"
"Social learning spontaneously emerges by searching optimal heuristics
  with deep reinforcement learning","How have individuals of social animals in nature evolved to learn from each
other, and what would be the optimal strategy for such learning in a specific
environment? Here, we address both problems by employing a deep reinforcement
learning model to optimize the social learning strategies (SLSs) of agents in a
cooperative game in a multi-dimensional landscape. Throughout the training for
maximizing the overall payoff, we find that the agent spontaneously learns
various concepts of social learning, such as copying, focusing on frequent and
well-performing neighbors, self-comparison, and the importance of balancing
between individual and social learning, without any explicit guidance or prior
knowledge about the system. The SLS from a fully trained agent outperforms all
of the traditional, baseline SLSs in terms of mean payoff. We demonstrate the
superior performance of the reinforcement learning agent in various
environments, including temporally changing environments and real social
networks, which also verifies the adaptability of our framework to different
social settings.",2022-04-26,"Seungwoong Ha, Hawoong Jeong"
GypSum: Learning Hybrid Representations for Code Summarization,"Code summarization with deep learning has been widely studied in recent
years. Current deep learning models for code summarization generally follow the
principle in neural machine translation and adopt the encoder-decoder
framework, where the encoder learns the semantic representations from source
code and the decoder transforms the learnt representations into human-readable
text that describes the functionality of code snippets. Despite they achieve
the new state-of-the-art performance, we notice that current models often
either generate less fluent summaries, or fail to capture the core
functionality, since they usually focus on a single type of code
representations. As such we propose GypSum, a new deep learning model that
learns hybrid representations using graph attention neural networks and a
pre-trained programming and natural language model. We introduce particular
edges related to the control flow of a code snippet into the abstract syntax
tree for graph construction, and design two encoders to learn from the graph
and the token sequence of source code, respectively. We modify the
encoder-decoder sublayer in the Transformer's decoder to fuse the
representations and propose a dual-copy mechanism to facilitate summary
generation. Experimental results demonstrate the superior performance of GypSum
over existing code summarization models.",2022-04-26,"Yu Wang, Yu Dong, Xuesong Lu, Aoying Zhou"
"Long-run User Value Optimization in Recommender Systems through Content
  Creation Modeling","Content recommender systems are generally adept at maximizing immediate user
satisfaction but to optimize for the \textit{long-run} user value, we need more
statistically sophisticated solutions than off-the-shelf simple recommender
algorithms. In this paper we lay out such a solution to optimize
\textit{long-run} user value through discounted utility maximization and a
machine learning method we have developed for estimating it. Our method
estimates which content producers are most likely to create the highest
long-run user value if their content is shown more to users who enjoy it in the
present. We do this estimation with the help of an A/B test and heterogeneous
effects machine learning model. We have used such models in Facebook's feed
ranking system, and such a model can be used in other recommender systems.",2022-04-25,"Akos Lada, Xiaoxuan Liu, Jens Rischbieth, Yi Wang, Yuwen Zhang"
"Adaptive cognitive fit: Artificial intelligence augmented management of
  information facets and representations","Explosive growth in big data technologies and artificial intelligence [AI]
applications have led to increasing pervasiveness of information facets and a
rapidly growing array of information representations. Information facets, such
as equivocality and veracity, can dominate and significantly influence human
perceptions of information and consequently affect human performance. Extant
research in cognitive fit, which preceded the big data and AI era, focused on
the effects of aligning information representation and task on performance,
without sufficient consideration to information facets and attendant cognitive
challenges. Therefore, there is a compelling need to understand the interplay
of these dominant information facets with information representations and
tasks, and their influence on human performance. We suggest that artificially
intelligent technologies that can adapt information representations to overcome
cognitive limitations are necessary for these complex information environments.
To this end, we propose and test a novel *Adaptive Cognitive Fit* [ACF]
framework that explains the influence of information facets and AI-augmented
information representations on human performance. We draw on information
processing theory and cognitive dissonance theory to advance the ACF framework
and a set of propositions. We empirically validate the ACF propositions with an
economic experiment that demonstrates the influence of information facets, and
a machine learning simulation that establishes the viability of using AI to
improve human performance.",2022-04-25,"Jim Samuel, Rajiv Kashyap, Yana Samuel, Alexander Pelaez"
"Heterogeneous Information Network based Default Analysis on Banking
  Micro and Small Enterprise Users","Risk assessment is a substantial problem for financial institutions that has
been extensively studied both for its methodological richness and its various
practical applications. With the expansion of inclusive finance, recent
attentions are paid to micro and small-sized enterprises (MSEs). Compared with
large companies, MSEs present a higher exposure rate to default owing to their
insecure financial stability. Conventional efforts learn classifiers from
historical data with elaborate feature engineering. However, the main obstacle
for MSEs involves severe deficiency in credit-related information, which may
degrade the performance of prediction. Besides, financial activities have
diverse explicit and implicit relations, which have not been fully exploited
for risk judgement in commercial banks. In particular, the observations on real
data show that various relationships between company users have additional
power in financial risk analysis. In this paper, we consider a graph of banking
data, and propose a novel HIDAM model for the purpose. Specifically, we attempt
to incorporate heterogeneous information network with rich attributes on
multi-typed nodes and links for modeling the scenario of business banking
service. To enhance feature representation of MSEs, we extract interactive
information through meta-paths and fully exploit path information. Furthermore,
we devise a hierarchical attention mechanism respectively to learn the
importance of contents inside each meta-path and the importance of different
metapahs. Experimental results verify that HIDAM outperforms state-of-the-art
competitors on real-world banking data.",2022-04-24,"Zheng Zhang, Yingsheng Ji, Jiachen Shen, Xi Zhang, Guangwen Yang"
"The SCORE normalization, especially for highly heterogeneous network and
  text data","SCORE was introduced as a spectral approach to network community detection.
Since many networks have severe degree heterogeneity, the ordinary spectral
clustering (OSC) approach to community detection may perform unsatisfactorily.
SCORE alleviates the effect of degree heterogeneity by introducing a new
normalization idea in the spectral domain and makes OSC more effective. SCORE
is easy to use and computationally fast. It adapts easily to new directions and
sees an increasing interest in practice. In this paper, we review the basics of
SCORE, the adaption of SCORE to network mixed membership estimation and topic
modeling, and the application of SCORE in real data, including two datasets on
the publications of statisticians. We also review the theoretical 'ideology'
underlying SCORE. We show that in the spectral domain, SCORE converts a
simplicial cone to a simplex, and provides a simple and direct link between the
simplex and network memberships. SCORE attains an exponential rate and a sharp
phase transition in community detection, and achieves optimal rates in mixed
membership estimation and topic modeling.",2022-04-23,"Zheng Tracy Ke, Jiashun Jin"
"Subscriptions and external links help drive resentful users to
  alternative and extremist YouTube videos","Do online platforms facilitate the consumption of potentially harmful
content? Using paired behavioral and survey data provided by participants
recruited from a representative sample in 2020 (n=1,181), we show that exposure
to alternative and extremist channel videos on YouTube is heavily concentrated
among a small group of people with high prior levels of gender and racial
resentment. These viewers often subscribe to these channels (prompting
recommendations to their videos) and follow external links to them. In
contrast, non-subscribers rarely see or follow recommendations to videos from
these channels. Our findings suggest YouTube's algorithms were not sending
people down ""rabbit holes"" during our observation window in 2020, possibly due
to changes that the company made to its recommender system in 2019. However,
the platform continues to play a key role in facilitating exposure to content
from alternative and extremist channels among dedicated audiences.",2022-04-22,"Annie Y. Chen, Brendan Nyhan, Jason Reifler, Ronald E. Robertson, Christo Wilson"
"Tweets2Stance: Users stance detection exploiting Zero-Shot Learning
  Algorithms on Tweets","In the last years there has been a growing attention towards predicting the
political orientation of active social media users, being this of great help to
study political forecasts, opinion dynamics modeling and users polarization.
Existing approaches, mainly targeting Twitter users, rely on content-based
analysis or are based on a mixture of content, network and communication
analysis. The recent research perspective exploits the fact that a user's
political affinity mainly depends on his/her positions on major political and
social issues, thus shifting the focus on detecting the stance of users through
user-generated content shared on social networks. The work herein described
focuses on a completely unsupervised stance detection framework that predicts
the user's stance about specific social-political statements by exploiting
content-based analysis of its Twitter timeline. The ground-truth user's stance
may come from Voting Advice Applications, online tools that help citizens to
identify their political leanings by comparing their political preferences with
party political stances. Starting from the knowledge of the agreement level of
six parties on 20 different statements, the objective of the study is to
predict the stance of a Party p in regard to each statement s exploiting what
the Twitter Party account wrote on Twitter. To this end we propose
Tweets2Stance (T2S), a novel and totally unsupervised stance detector framework
which relies on the zero-shot learning technique to quickly and accurately
operate on non-labeled data. Interestingly, T2S can be applied to any social
media user for any context of interest, not limited to the political one.
Results obtained from multiple experiments show that, although the general
maximum F1 value is 0.4, T2S can correctly predict the stance with a general
minimum MAE of 1.13, which is a great achievement considering the task
complexity.",2022-04-22,"Margherita Gambini, Tiziano Fagni, Caterina Senette, Maurizio Tesconi"
"A Bayesian actor-oriented multilevel relational event model with
  hypothesis testing procedures","Relational event network data are becoming increasingly available.
Consequently, statistical models for such data have also surfaced. These models
mainly focus on the analysis of single networks, while in many applications,
multiple independent event sequences are observed, which are likely to display
similar social interaction dynamics. Furthermore, statistical methods for
testing hypotheses about social interaction behavior are underdeveloped.
Therefore, the contribution of the current paper is twofold. First, we present
a multilevel extension of the dynamic actor-oriented model, which allows
researchers to model sender and receiver processes separately. The multilevel
formulation enables principled probabilistic borrowing of information across
networks to accurately estimate drivers of social dynamics. Second, a flexible
methodology is proposed to test hypotheses about common and heterogeneous
social interaction drivers across relational event sequences. Social
interaction data between children and teachers in classrooms are used to
showcase the methodology.",2022-04-22,"Fabio Vieira, Roger Leenders, Daniel McFarland, Joris Mulder"
"Global Mapping of Gene/Protein Interactions in PubMed Abstracts: A
  Framework and an Experiment with P53 Interactions","Gene/protein interactions provide critical information for a thorough
understanding of cellular processes. Recently, considerable interest and effort
has been focused on the construction and analysis of genome-wide gene networks.
The large body of biomedical literature is an important source of gene/protein
interaction information. Recent advances in text mining tools have made it
possible to automatically extract such documented interactions from free-text
literature. In this paper, we propose a comprehensive framework for
constructing and analyzing large-scale gene functional networks based on the
gene/protein interactions extracted from biomedical literature repositories
using text mining tools. Our proposed framework consists of analyses of the
network topology, network topology-gene function relationship, and temporal
network evolution to distill valuable information embedded in the gene
functional interactions in literature. We demonstrate the application of the
proposed framework using a testbed of P53-related PubMed abstracts, which shows
that literature-based P53 networks exhibit small-world and scale-free
properties. We also found that high degree genes in the literature-based
networks have a high probability of appearing in the manually curated database
and genes in the same pathway tend to form local clusters in our
literature-based networks. Temporal analysis showed that genes interacting with
many other genes tend to be involved in a large number of newly discovered
interactions.",2022-04-22,"Xin Li, Hsinchun Chen, Zan Huang, Hua Su, Jesse D. Martinez"
Scalable Motif Counting for Large-scale Temporal Graphs,"One fundamental problem in temporal graph analysis is to count the
occurrences of small connected subgraph patterns (i.e., motifs), which benefits
a broad range of real-world applications, such as anomaly detection, structure
prediction, and network representation learning. However, existing works
focused on exacting temporal motif are not scalable to large-scale temporal
graph data, due to their heavy computational costs or inherent inadequacy of
parallelism. In this work, we propose a scalable parallel framework for exactly
counting temporal motifs in large-scale temporal graphs. We first categorize
the temporal motifs based on their distinct properties, and then design
customized algorithms that offer efficient strategies to exactly count the
motif instances of each category. Moreover, our compact data structures, namely
triple and quadruple counters, enable our algorithms to directly identify the
temporal motif instances of each category, according to edge information and
the relationship between edges, therefore significantly improving the counting
efficiency. Based on the proposed counting algorithms, we design a hierarchical
parallel framework that features both inter- and intra-node parallel
strategies, and fully leverages the multi-threading capacity of modern CPU to
concurrently count all temporal motifs. Extensive experiments on sixteen
real-world temporal graph datasets demonstrate the superiority and capability
of our proposed framework for temporal motif counting, achieving up to 538*
speedup compared to the state-of-the-art methods. The source code of our method
is available at: https://github.com/steven-ccq/FAST-temporal-motif.",2022-04-20,"Zhongqiang Gao, Chuanqi Cheng, Yanwei Yu, Lei Cao, Chao Huang, Junyu Dong"
Heterogeneous Feature Augmentation for Ponzi Detection in Ethereum,"While blockchain technology triggers new industrial and technological
revolutions, it also brings new challenges. Recently, a large number of new
scams with a ""blockchain"" sock-puppet continue to emerge, such as Ponzi
schemes, money laundering, etc., seriously threatening financial security.
Existing fraud detection methods in blockchain mainly concentrate on manual
feature and graph analytics, which first construct a homogeneous transaction
graph using partial blockchain data and then use graph analytics to detect
anomaly, resulting in a loss of pattern information. In this paper, we mainly
focus on Ponzi scheme detection and propose HFAug, a generic Heterogeneous
Feature Augmentation module that can capture the heterogeneous information
associated with account behavior patterns and can be combined with existing
Ponzi detection methods. HFAug learns the metapath-based behavior
characteristics in an auxiliary heterogeneous interaction graph, and aggregates
the heterogeneous features to corresponding account nodes in the homogeneous
one where the Ponzi detection methods are performed. Comprehensive experimental
results demonstrate that our HFAug can help existing Ponzi detection methods
achieve significant performance improvement on Ethereum datasets, suggesting
the effectiveness of heterogeneous information on detecting Ponzi schemes.",2022-04-19,"Chengxiang Jin, Jie Jin, Jiajun Zhou, Jiajing Wu, Qi Xuan"
"Bots, Disinformation, and the First Trump Impeachment","Automated social media accounts, known as bots, have been shown to spread
disinformation and manipulate online discussions. We study the behavior of
retweet bots on Twitter during the first impeachment of U.S. President Donald
Trump. We collect over 67.7 million impeachment related tweets from 3.6 million
users, along with their 53.6 million edge follower network. We find although
bots represent 1% of all users, they generate over 31% of all impeachment
related tweets. We also find bots share more disinformation, but use less toxic
language than other users. Among supporters of the Qanon conspiracy theory, a
popular disinformation campaign, bots have a prevalence near 10%. The follower
network of Qanon supporters exhibits a hierarchical structure, with bots acting
as central hubs surrounded by isolated humans. We quantify bot impact using the
generalized harmonic influence centrality measure. We find there are a greater
number of pro-Trump bots, but on a per bot basis, anti-Trump and pro-Trump bots
have similar impact, while Qanon bots have less impact. This lower impact is
due to the homophily of the Qanon follower network, suggesting this
disinformation is spread mostly within online echo-chambers.",2022-04-19,"Michael Rossetti, Tauhid Zaman"
Rumor Detection with Self-supervised Learning on Texts and Social Graph,"Rumor detection has become an emerging and active research field in recent
years. At the core is to model the rumor characteristics inherent in rich
information, such as propagation patterns in social network and semantic
patterns in post content, and differentiate them from the truth. However,
existing works on rumor detection fall short in modeling heterogeneous
information, either using one single information source only (e.g. social
network, or post content) or ignoring the relations among multiple sources
(e.g. fusing social and content features via simple concatenation). Therefore,
they possibly have drawbacks in comprehensively understanding the rumors, and
detecting them accurately. In this work, we explore contrastive self-supervised
learning on heterogeneous information sources, so as to reveal their relations
and characterize rumors better. Technically, we supplement the main supervised
task of detection with an auxiliary self-supervised task, which enriches post
representations via post self-discrimination. Specifically, given two
heterogeneous views of a post (i.e. representations encoding social patterns
and semantic patterns), the discrimination is done by maximizing the mutual
information between different views of the same post compared to that of other
posts. We devise cluster-wise and instance-wise approaches to generate the
views and conduct the discrimination, considering different relations of
information sources. We term this framework as Self-supervised Rumor Detection
(SRD). Extensive experiments on three real-world datasets validate the
effectiveness of SRD for automatic rumor detection on social media.",2022-04-19,"Yuan Gao, Xiang Wang, Xiangnan He, Huamin Feng, Yongdong Zhang"
"A Multi-Opinion Based Method for Quantifying Polarization on Social
  Networks","Social media platforms have emerged as a hub for political and social
interactions, and analyzing the polarization of opinions has been gaining
attention. In this study, we have proposed a measure to quantify polarization
on social networks. The proposed metric, unlike state-of-the-art methods, does
not assume a two-opinion case and applies to multiple opinions. We tested our
metric on different networks with a multi-opinion scenario and varying degrees
of polarization. The scores obtained from the proposed metric were comparable
to state-of-the-art methods on binary opinion-based benchmark networks. The
technique also differentiated among networks with different levels of
polarization in a multi-opinion scenario. We also quantified polarization in a
retweet network obtained from Twitter regarding the usage of drugs like
hydroxychloroquine or chloroquine in treating COVID-19. Our metric indicated a
high level of polarized opinions among the users. These findings suggest
uncertainty among users in the benefits of using hydroxychloroquine and
chloroquine drugs to treat COVID-19 patients.",2022-04-19,"Maneet Singh, S. R. S. Iyengar, Rishemjit Kaur"
"Modeling Complex Interactions in a Disrupted Environment: Relational
  Events in the WTC Response","When subjected to a sudden, unanticipated threat, human groups
characteristically self-organize to identify the threat, determine potential
responses, and act to reduce its impact. Central to this process is the
challenge of coordinating information sharing and response activity within a
disrupted environment. In this paper, we consider coordination in the context
of responses to the 2001 World Trade Center disaster. Using records of
communications among 17 organizational units, we examine the mechanisms driving
communication dynamics, with an emphasis on the emergence of coordinating
roles. We employ relational event models (REMs) to identify the mechanisms
shaping communications in each unit, finding a consistent pattern of behavior
across units with very different characteristics. Using a simulation-based
""knock-out"" study, we also probe the importance of different mechanisms for hub
formation. Our results suggest that, while preferential attachment and
pre-disaster role structure generally contribute to the emergence of hub
structure, temporally local conversational norms play a much larger role. We
discuss broader implications for the role of microdynamics in driving
macroscopic outcomes, and for the emergence of coordination in other settings.",2022-04-17,"Scott Leo Renshaw, Selena M. Livas, Miruna G. Petrescu-Prahova, Carter T. Butts"
DMCS : Density Modularity based Community Search,"Community Search, or finding a connected subgraph (known as a community)
containing the given query nodes in a social network, is a fundamental problem.
Most of the existing community search models only focus on the internal
cohesiveness of a community. However, a high-quality community often has high
modularity, which means dense connections inside communities and sparse
connections to the nodes outside the community. In this paper, we conduct a
pioneer study on searching a community with high modularity. We point out that
while modularity has been popularly used in community detection (without query
nodes), it has not been adopted for community search, surprisingly, and its
application in community search (related to query nodes) brings in new
challenges. We address these challenges by designing a new graph modularity
function named Density Modularity. To the best of our knowledge, this is the
first work on the community search problem using graph modularity. The
community search based on the density modularity, termed as DMCS, is to find a
community in a social network that contains all the query nodes and has high
density-modularity. We prove that the DMCS problem is NP-hard. To efficiently
address DMCS, we present new algorithms that run in log-linear time to the
graph size. We conduct extensive experimental studies in real-world and
synthetic networks, which offer insights into the efficiency and effectiveness
of our algorithms. In particular, our algorithm achieves up to 8.5 times higher
accuracy in terms of NMI than baseline algorithms.",2022-04-16,"Junghoon Kim, Siqiang Luo, Gao Cong, Wenyuan Yu"
"Stability of China's Stock Market: Measure and Forecast by Ricci
  Curvature on Network","The systemic stability of a stock market is one of the core issues in the
financial field. The market can be regarded as a complex network whose nodes
are stocks connected by edges that signify their correlation strength. Since
the market is a strongly nonlinear system, it is difficult to measure the
macroscopic stability and depict market fluctuations in time. In this paper, we
use a geometric measure derived from discrete Ricci curvature to capture the
higher-order nonlinear architecture of financial networks. In order to confirm
the effectiveness of our method, we use it to analyze the CSI 300 constituents
of China's stock market from 2005--2020 and the systemic stability of the
market is quantified through the network's Ricci type curvatures. Furthermore,
we use a hybrid model to analyze the curvature time series and predict the
future trends of the market accurately. As far as we know, this is the first
paper to apply Ricci curvature to forecast the systemic stability of domestic
stock market, and our results show that Ricci curvature has good explanatory
power for the market stability and can be a good indicator to judge the future
risk and volatility of the domestic market.",2022-04-14,"Xinyu Wang, Liang Zhao, Ning Zhang, Liu Feng, Haibo Lin"
AHP: Learning to Negative Sample for Hyperedge Prediction,"Hypergraphs (i.e., sets of hyperedges) naturally represent group relations
(e.g., researchers co-authoring a paper and ingredients used together in a
recipe), each of which corresponds to a hyperedge (i.e., a subset of nodes).
Predicting future or missing hyperedges bears significant implications for many
applications (e.g., collaboration and recipe recommendation). What makes
hyperedge prediction particularly challenging is the vast number of
non-hyperedge subsets, which grows exponentially with the number of nodes.
Since it is prohibitive to use all of them as negative examples for model
training, it is inevitable to sample a very small portion of them, and to this
end, heuristic sampling schemes have been employed. However, trained models
suffer from poor generalization capability for examples of different natures.
In this paper, we propose AHP, an adversarial training-based
hyperedge-prediction method. It learns to sample negative examples without
relying on any heuristic schemes. Using six real hypergraphs, we show that AHP
generalizes better to negative examples of various natures. It yields up to
28.2% higher AUROC than the best existing methods and often even outperforms
its variants with sampling schemes tailored to test sets.",2022-04-13,"Hyunjin Hwang, Seungwoo Lee, Chanyoung Park, Kijung Shin"
"On the dynamics of credit history and social interaction features, and
  their impact on creditworthiness assessment performance","For more than a half-century, credit risk management has used credit scoring
models in each of its well-defined stages to manage credit risk. Application
scoring is used to decide whether to grant a credit or not, while behavioral
scoring is used mainly for portfolio management and to take preventive actions
in case of default signals. In both cases, network data has recently been shown
to be valuable to increase the predictive power of these models, especially
when the borrower's historical data is scarce or not available. This study aims
to understand the creditworthiness assessment performance dynamics and how it
is influenced by the credit history, repayment behavior, and social network
features. To accomplish this, we introduced a machine learning classification
framework to analyze 97.000 individuals and companies from the moment they
obtained their first loan to 12 months afterward. Our novel and massive dataset
allow us to characterize each borrower according to their credit behavior, and
social and economic relationships. Our research shows that borrowers' history
increases performance at a decreasing rate during the first six months and then
stabilizes. The most notable effect on perfomance of social networks features
occurs at loan application; in personal scoring, this effect prevails a few
months, while in business scoring adds value throughout the study period. These
findings are of great value to improve credit risk management and optimize the
use of traditional information and alternative data sources.",2022-04-13,"Ricardo Muñoz-Cancino, Cristián Bravo, Sebastián A. Ríos, Manuel Graña"
"A Hierarchical Block Distance Model for Ultra Low-Dimensional Graph
  Representations","Graph Representation Learning (GRL) has become central for characterizing
structures of complex networks and performing tasks such as link prediction,
node classification, network reconstruction, and community detection. Whereas
numerous generative GRL models have been proposed, many approaches have
prohibitive computational requirements hampering large-scale network analysis,
fewer are able to explicitly account for structure emerging at multiple scales,
and only a few explicitly respect important network properties such as
homophily and transitivity. This paper proposes a novel scalable graph
representation learning method named the Hierarchical Block Distance Model
(HBDM). The HBDM imposes a multiscale block structure akin to stochastic block
modeling (SBM) and accounts for homophily and transitivity by accurately
approximating the latent distance model (LDM) throughout the inferred
hierarchy. The HBDM naturally accommodates unipartite, directed, and bipartite
networks whereas the hierarchy is designed to ensure linearithmic time and
space complexity enabling the analysis of very large-scale networks. We
evaluate the performance of the HBDM on massive networks consisting of millions
of nodes. Importantly, we find that the proposed HBDM framework significantly
outperforms recent scalable approaches in all considered downstream tasks.
Surprisingly, we observe superior performance even imposing ultra-low
two-dimensional embeddings facilitating accurate direct and hierarchical-aware
network visualization and interpretation.",2022-04-12,"Nikolaos Nakis, Abdulkadir Çelikkanat, Sune Lehmann Jørgensen, Morten Mørup"
"The consensus problem for opinion dynamics with local average random
  interactions","We study the consensus formation for an agents based model, generalizing that
originally proposed by Krause \cite{Kr}, by allowing the communication channels
between any couple of agents to be switched on or off randomly, at each time
step, with a probability law depending on the proximity of the agents'
opinions. Namely, we consider a system of agents sharing their opinions
according to the following updating protocol. At time $t+1$ the opinion
$X_{i}\left( t+1\right) \in\left[ 0,1\right] $ of agent $i$ is updated at the
weighted average of the opinions of the agents communicating with it at time
$t.$ The weights model the confidence level an agent assign to the opinions of
the other agents and are kept fixed by the system dynamics, but the set of
agents communicating with any agent $i$ at time $t+1$ is randomly updated in
such a way that the agent $j$ can be chosen to belong to this set independently
of the other agents with a probability that is a non increasing function of
$\left\vert X_{i}\left( t\right) -X_{j}\left( t\right) \right\vert .$ This
condition models the fact that a communication among the agents is more likely
to happen if their opinions are close. We prove that the system reaches
consensus, i.e. as the time tends to infinity the agents' opinions will reach
the same value exponentially fast.",2022-04-12,"Gianfelice Michele, Giuseppe Scola"
Inference of hyperedges and overlapping communities in hypergraphs,"Hypergraphs, encoding structured interactions among any number of system
units, have recently proven a successful tool to describe many real-world
biological and social networks. Here we propose a framework based on
statistical inference to characterize the structural organization of
hypergraphs. The method allows to infer missing hyperedges of any size in a
principled way, and to jointly detect overlapping communities in presence of
higher-order interactions. Furthermore, our model has an efficient numerical
implementation, and it runs faster than dyadic algorithms on pairwise records
projected from higher-order data. We apply our method to a variety of
real-world systems, showing strong performance in hyperedge prediction tasks,
detecting communities well aligned with the information carried by
interactions, and robustness against addition of noisy hyperedges. Our approach
illustrates the fundamental advantages of a hypergraph probabilistic model when
modeling relational systems with higher-order interactions.",2022-04-12,"Martina Contisciani, Federico Battiston, Caterina De Bacco"
Harmonic Centralization of Some Graph Families,"Centrality describes the importance of nodes in a graph and is modeled by
various measures. Its global analogue, called centralization, is a general
formula for calculating a graph-level centrality score based on the node-level
centrality measure. The latter enables us to compare graphs based on the extent
to which the connections of a given network are concentrated on a single vertex
or group of vertices. One of the measures of centrality in social network
analysis is harmonic centrality. It sums the inverse of the geodesic distances
of each node to other nodes where it is 0 if there is no path from one node to
another, with the sum normalized by dividing it by $m-1$, where $m$ is the
number of nodes of the graph. In this paper, we present some results regarding
the harmonic centralization of some important families of graphs with the hope
that formulas generated herein will be of use when one determines the harmonic
centralization of more complex graphs.",2022-04-09,"Jose Mari E. Ortega, Rolito G. Eballe"
"Online Emotions During the Storming of the U.S. Capitol: Evidence from
  the Social Media Network Parler","The storming of the U.S. Capitol on January 6, 2021 has led to the killing of
5 people and is widely regarded as an attack on democracy. The storming was
largely coordinated through social media networks such as Parler. Yet little is
known regarding how users interacted on Parler during the storming of the
Capitol. In this work, we examine the emotion dynamics on Parler during the
storming with regard to heterogeneity across time and users. For this, we
segment the user base into different groups (e.g., Trump supporters and QAnon
supporters). We use affective computing (Kratzwald et al. 2018) to infer the
emotions in the contents, thereby allowing us to provide a comprehensive
assessment of online emotions. Our evaluation is based on a large-scale dataset
from Parler, comprising of 717,300 posts from 144,003 users. We find that the
user base responded to the storming of the Capitol with an overall negative
sentiment. Akin to this, Trump supporters also expressed a negative sentiment
and high levels of unbelief. In contrast to that, QAnon supporters did not
express a more negative sentiment during the storming. We further provide a
cross-platform analysis and compare the emotion dynamics on Parler and Twitter.
Our findings point at a comparatively less negative response to the incidents
on Parler compared to Twitter accompanied by higher levels of disapproval and
outrage. Our contribution to research is three-fold: (1) We identify online
emotions that were characteristic of the storming; (2) we assess emotion
dynamics across different user groups on Parler; (3) we compare the emotion
dynamics on Parler and Twitter. Thereby, our work offers important implications
for actively managing online emotions to prevent similar incidents in the
future.",2022-04-08,"Johannes Jakubik, Michael Vössing, Dominik Bär, Nicolas Pröllochs, Stefan Feuerriegel"
"""Gettr-ing"" Deep Insights from the Social Network Gettr","As yet another alternative social network, Gettr positions itself as the
""marketplace of ideas"" where users should expect the truth to emerge without
any administrative censorship. We looked deep inside the platform by analyzing
it's structure, a sample of 6.8 million posts, and the responses from a sample
of 124 Gettr users we interviewed to see if this actually is the case.
Administratively, Gettr makes a deliberate attempt to stifle any external
evaluation of the platform as collecting data is marred with unpredictable and
abrupt changes in their API. Content-wise, Gettr notably hosts pro-Trump
content mixed with conspiracy theories and attacks on the perceived ""left.""
It's social network structure is asymmetric and centered around prominent
right-thought leaders, which is characteristic for all alt-platforms. While
right-leaning users joined Gettr as a result of a perceived freedom of speech
infringement by the mainstream platforms, left-leaning users followed them in
numbers as to ""keep up with the misinformation."" We contextualize these
findings by looking into the Gettr's user interface design to provide a
comprehensive insight into the incentive structure for joining and competing
for the truth on Gettr.",2022-04-08,"Filipo Sharevski, Peter Jachim, Emma Pieroni, Amy Devine"
"Efficient Community Detection in Large-Scale Dynamic Networks Using
  Topological Data Analysis","In this paper, we propose a method that extends the persistence-based
topological data analysis (TDA) that is typically used for characterizing
shapes to general networks. We introduce the concept of the community tree, a
tree structure established based on clique communities from the clique
percolation method, to summarize the topological structures in a network from a
persistence perspective. Furthermore, we develop efficient algorithms to
construct and update community trees by maintaining a series of clique graphs
in the form of spanning forests, in which each spanning tree is built on an
underlying Euler Tour tree. With the information revealed by community trees
and the corresponding persistence diagrams, our proposed approach is able to
detect clique communities and keep track of the major structural changes during
their evolution given a stability threshold. The results demonstrate its
effectiveness in extracting useful structural insights for time-varying social
networks.",2022-04-07,"Wei Guo, Ruqian Chen, Yen-Chi Chen, Ashis G. Banerjee"
"Closed Ranks: The Discursive Value of Military Support for Indian
  Politicians on Social Media","Influencers play a crucial role in shaping public narratives through
information creation and diffusion in the Global South. While public figures
from various walks of life and their impact on public discourse have been
studied, defence veterans as influencers of the political discourse have been
largely overlooked. Veterans matter in the public spehere as a normatively
important political lobby. They are also interesting because, unlike
active-duty military officers, they are not restricted from taking public sides
on politics, so their posts may provide a window into the views of those still
in the service. In this work, we systematically analyze the engagement on
Twitter of self-described defence-related accounts and politician accounts that
post on defence-related issues. We find that self-described defence-related
accounts disproportionately engage with the current ruling party in India. We
find that politicians promote their closeness to the defence services and
nationalist credentials through engagements with defence-related influencers.
We briefly consider the institutional implications of these patterns and
connections",2022-04-06,"Agrima Seth, Soham De, Arshia Arya, Steven Wilkinson, Sushant Singh, Joyojeet Pal"
Inclusion unlocks the creative potential of gender diversity in teams,"Diversity in teams can boost creativity, and gender diversity was shown to be
a contributor to collective creativity. We show that gender diversity requires
inclusion to lead to benefits in creativity by analyzing teams in 4011 video
game projects. Recording data on the weighted network from past collaborations,
we developed four measures of inclusion, depending on a lack of segregation,
strong ties across genders, and the incorporation of women into the core of the
team s network. We found that gender diversity without inclusion does not
contribute to creativity, while with maximal inclusion one standard deviation
change in diversity results in .04 to .09 standard deviation change in
creativity, depending on the measure of inclusion. To reap creative benefits of
diversity, developer firms need to include 23 percent or more female developers
(as opposed to the 15 percent mean female proportion) and include them in the
team along all dimensions. Inclusion at low diversity has a negative effect. By
analyzing the sequences of diversity and inclusion across games within firms,
we found that adding diversity first, and developing inclusion later can lead
to higher diversity and inclusion, compared to adding female developers with
already existing cross-gender ties to the team.",2022-04-06,"Balazs Vedres, Orsolya Vasarhelyi"
A Survey on Graph Representation Learning Methods,"Graphs representation learning has been a very active research area in recent
years. The goal of graph representation learning is to generate graph
representation vectors that capture the structure and features of large graphs
accurately. This is especially important because the quality of the graph
representation vectors will affect the performance of these vectors in
downstream tasks such as node classification, link prediction and anomaly
detection. Many techniques are proposed for generating effective graph
representation vectors. Two of the most prevalent categories of graph
representation learning are graph embedding methods without using graph neural
nets (GNN), which we denote as non-GNN based graph embedding methods, and graph
neural nets (GNN) based methods. Non-GNN graph embedding methods are based on
techniques such as random walks, temporal point processes and neural network
learning methods. GNN-based methods, on the other hand, are the application of
deep learning on graph data. In this survey, we provide an overview of these
two categories and cover the current state-of-the-art methods for both static
and dynamic graphs. Finally, we explore some open and ongoing research
directions for future work.",2022-04-04,"Shima Khoshraftar, Aijun An"
"This Sample seems to be good enough! Assessing Coverage and Temporal
  Reliability of Twitter's Academic API","Because of its willingness to share data with academia and industry, Twitter
has been the primary social media platform for scientific research as well as
for consulting businesses and governments in the last decade. In recent years,
a series of publications have studied and criticized Twitter's APIs and Twitter
has partially adapted its existing data streams. The newest Twitter API for
Academic Research allows to ""access Twitter's real-time and historical public
data with additional features and functionality that support collecting more
precise, complete, and unbiased datasets."" The main new feature of this API is
the possibility of accessing the full archive of all historic Tweets. In this
article, we will take a closer look at the Academic API and will try to answer
two questions. First, are the datasets collected with the Academic API
complete? Secondly, since Twitter's Academic API delivers historic Tweets as
represented on Twitter at the time of data collection, we need to understand
how much data is lost over time due to Tweet and account removal from the
platform. Our work shows evidence that Twitter's Academic API can indeed create
(almost) complete samples of Twitter data based on a wide variety of search
terms. We also provide evidence that Twitter's data endpoint v2 delivers better
samples than the previously used endpoint v1.1. Furthermore, collecting Tweets
with the Academic API at the time of studying a phenomenon rather than creating
local archives of stored Tweets, allows for a straightforward way of following
Twitter's developer agreement. Finally, we will also discuss technical
artifacts and implications of the Academic API. We hope that our work can add
another layer of understanding of Twitter data collections leading to more
reliable studies of human behavior via social media data.",2022-04-04,"Juergen Pfeffer, Angelina Mooseder, Jana Lasser, Luca Hammer, Oliver Stritzel, David Garcia"
Synthetic Graph Generation to Benchmark Graph Learning,"Graph learning algorithms have attained state-of-the-art performance on many
graph analysis tasks such as node classification, link prediction, and
clustering. It has, however, become hard to track the field's burgeoning
progress. One reason is due to the very small number of datasets used in
practice to benchmark the performance of graph learning algorithms. This
shockingly small sample size (~10) allows for only limited scientific insight
into the problem.
  In this work, we aim to address this deficiency. We propose to generate
synthetic graphs, and study the behaviour of graph learning algorithms in a
controlled scenario. We develop a fully-featured synthetic graph generator that
allows deep inspection of different models. We argue that synthetic graph
generations allows for thorough investigation of algorithms and provides more
insights than overfitting on three citation datasets. In the case study, we
show how our framework provides insight into unsupervised and supervised graph
neural network models.",2022-04-04,"Anton Tsitsulin, Benedek Rozemberczki, John Palowitch, Bryan Perozzi"
"Characterizing Urban Lifestyle Signatures Using Motif Properties in
  Network of Places","The lifestyles of urban dwellers could reveal important insights regarding
the dynamics and complexity of cities. Despite growing research on analysis of
lifestyle patterns in cities, little is known about the characteristics of
people's lifestyles patterns at urban scale. This limitation is primarily due
to challenges in characterizing lifestyle patterns when human movement data is
aggregated to protect the privacy of users. In this study, we model cities
based on aggregated human visitation data to construct a network of places. We
then examine the subgraph signatures in the networks of places to map and
characterize lifestyle patterns at city scale. Location-based data from Harris
County, Dallas County, New York County, and Broward County in the United States
were examined to reveal lifestyle signatures in cities. For the motif analysis,
two-node, three-node, and four-node motifs without location attributes were
extracted from human visitation networks. Second, homogenized nodes in motifs
were encoded with location categories from NAICS codes. Multiple statistical
measures, including network metrics and motif properties, were quantified to
characterize lifestyle signatures. The results show that: people's lifestyles
in urban environments can be well depicted and quantified based on distribution
and attributes of motifs in networks of places; motifs in networks of places
show stability in quantity and distance as well as periodicity on weekends and
weekdays indicating the stability of lifestyle patterns in cities; human
visitation networks and lifestyle patterns show similarities across different
metropolitan areas implying the universality of lifestyle signatures across
cities. The findings provide deeper insights into urban lifestyles signatures
in urban studies and provide important insights for data-informed urban
planning and management.",2022-04-03,"Junwei Ma, Bo Li, Ali Mostafavi"
"Development of current estimated household data and agent-based
  simulation of the future population distribution of households in Japan","In response to the declining population and aging infrastructure in Japan,
local governments are implementing compact city policies such as the location
normalization plan. To optimize the reorganization of urban public
infrastructure, it is important to provide detailed and accurate forecasts of
the distribution of urban populations and households. However, many local
governments do not have the necessary data and forecasting capability.
Moreover, current forecasts of gender- and age-based population data only exist
at the municipal level, and household data are only available by family type at
the prefecture level. Meanwhile, the accuracy is limited with an assumption of
same change rate of population in all municipalities and within each city.
Therefore, the aim of this study was to develop an agent-based microsimulation
household transition model, with the household as the unit and agent, and
household data was estimated for all cities in Japan from 2015. Estimated
household data comprised the family type, house type, and address, age, and
gender of household members, obtained from the national census, and building
data. The resulting household transition model was used to forecast the
attributes of each household every five years. Simulations in Toyama and
Shizuoka Prefectures, Japan from 1980 to 2010 provided highly accurate
estimates of municipal-level population by age and household volume by family
type. The proposed model was also applied to predict the future distribution of
disappearing villages and vacant houses in Japan.",2022-04-01,"Kajiwara Kento, Jue Ma, Toshikazu Seto, Yoshihide Sekimoto, Yoshiki Ogawa, Hiroshi Omata"
"Semantics between customers and providers: The relation between product
  descriptions, reviews, and customer satisfaction in E-commerce","In social commerce, users dialogue with each other on the topics related to
the providers' products. However, the language customers use may vary from the
language vendors use on their e-commerce websites and product descriptions.
This situation can lead to possible misunderstandings in the social dialogue
between customers, and incidental costs in the dialogue between customers and
vendors. One possible reason for this difference is that words used by
customers may have different meanings compared to those used by product
description writers. We present a novel approach to measure this potential
lexical-semantic gap for various e-commerce domains using an
information-theoretical approach based on a large corpus of user reviews and
product descriptions. Additionally, we use neural word embeddings to identify
words with the highest semantic drift between reviews and descriptions as a
tool to construct a ground truth for the task. We found that low levels of
lexical-semantic gap are related to better customer satisfaction. Besides, this
work is a step towards a better understanding of the effect of the use of
language in e-commerce and social commerce. Potential applications of this
technology could lead to better communication between customers and
improvements in customer satisfaction, services, and revenue. Furthermore, this
study opens up perspectives for applications in other domains with
relationships beyond client-vendor, such as citizen-government and
patient-healthcare system.",2022-03-30,"Carlos A. Rodriguez-Diaz, Sergio Jimenez, Daniel Bejarano, Julio A. Bernal-Chávez, Alexander Gelbukh"
"Research topic trend prediction of scientific papers based on spatial
  enhancement and dynamic graph convolution network","In recent years, with the increase of social investment in scientific
research, the number of research results in various fields has increased
significantly. Accurately and effectively predicting the trends of future
research topics can help researchers discover future research hotspots.
However, due to the increasingly close correlation between various research
themes, there is a certain dependency relationship between a large number of
research themes. Viewing a single research theme in isolation and using
traditional sequence problem processing methods cannot effectively explore the
spatial dependencies between these research themes. To simultaneously capture
the spatial dependencies and temporal changes between research topics, we
propose a deep neural network-based research topic hotness prediction
algorithm, a spatiotemporal convolutional network model. Our model combines a
graph convolutional neural network (GCN) and Temporal Convolutional Network
(TCN), specifically, GCNs are used to learn the spatial dependencies of
research topics a and use space dependence to strengthen spatial
characteristics. TCN is used to learn the dynamics of research topics' trends.
Optimization is based on the calculation of weighted losses based on time
distance. Compared with the current mainstream sequence prediction models and
similar spatiotemporal models on the paper datasets, experiments show that, in
research topic prediction tasks, our model can effectively capture
spatiotemporal relationships and the predictions outperform state-of-art
baselines.",2022-03-30,"Changwei Zheng, Zhe Xue, Meiyu Liang, Feifei Kou"
Co-Membership-based Generic Anomalous Communities Detection,"Nowadays, detecting anomalous communities in networks is an essential task in
research, as it helps discover insights into community-structured networks.
Most of the existing methods leverage either information regarding attributes
of vertices or the topological structure of communities. In this study, we
introduce the Co-Membership-based Generic Anomalous Communities Detection
Algorithm (referred as to CMMAC), a novel and generic method that utilizes the
information of vertices co-membership in multiple communities. CMMAC is
domain-free and almost unaffected by communities' sizes and densities.
Specifically, we train a classifier to predict the probability of each vertex
in a community being a member of the community. We then rank the communities by
the aggregated membership probabilities of each community's vertices. The
lowest-ranked communities are considered to be anomalous. Furthermore, we
present an algorithm for generating a community-structured random network
enabling the infusion of anomalous communities to facilitate research in the
field. We utilized it to generate two datasets, composed of thousands of
labeled anomaly-infused networks, and published them. We experimented
extensively on thousands of simulated, and real-world networks, infused with
artificial anomalies. CMMAC outperformed other existing methods in a range of
settings. Additionally, we demonstrated that CMMAC can identify abnormal
communities in real-world unlabeled networks in different domains, such as
Reddit and Wikipedia.",2022-03-30,"Shay Lapid, Dima Kagan, Michael Fire"
"Information Consumption and Boundary Spanning in Decentralized Online
  Social Networks: the case of Mastodon Users","Decentralized Online Social Networks (DOSNs) represent a growing trend in the
social media landscape, as opposed to the well-known centralized peers, which
are often in the spotlight due to privacy concerns and a vision typically
focused on monetization through user relationships. By exploiting open-source
software, DOSNs allow users to create their own servers, or instances, thus
favoring the proliferation of platforms that are independent yet interconnected
with each other in a transparent way. Nonetheless, the resulting cooperation
model, commonly known as the Fediverse, still represents a world to be fully
discovered, since existing studies have mainly focused on a limited number of
structural aspects of interest in DOSNs. In this work, we aim to fill a lack of
study on user relations and roles in DOSNs, by taking two main actions:
understanding the impact of decentralization on how users relate to each other
within their membership instance and/or across different instances, and
unveiling user roles that can explain two interrelated axes of social
behavioral phenomena, namely information consumption and boundary spanning. To
this purpose, we build our analysis on user networks from Mastodon, since it
represents the most widely used DOSN platform. We believe that the findings
drawn from our study on Mastodon users' roles and information flow can pave a
way for further development of fascinating research on DOSNs.",2022-03-29,"Lucio La Cava, Andrea Tagarelli"
Are Edge Weights in Summary Graphs Useful? -- A Comparative Study,"Which one is better between two representative graph summarization models
with and without edge weights? From web graphs to online social networks, large
graphs are everywhere. Graph summarization, which is an effective graph
compression technique, aims to find a compact summary graph that accurately
represents a given large graph. Two versions of the problem, where one allows
edge weights in summary graphs and the other does not, have been studied in
parallel without direct comparison between their underlying representation
models. In this work, we conduct a systematic comparison by extending three
search algorithms to both models and evaluating their outputs on eight datasets
in five aspects: (a) reconstruction error, (b) error in node importance, (c)
error in node proximity, (d) the size of reconstructed graphs, and (e)
compression ratios. Surprisingly, using unweighted summary graphs leads to
outputs significantly better in all the aspects than using weighted ones, and
this finding is supported theoretically. Notably, we show that a
state-of-the-art algorithm can be improved substantially (specifically, 8.2X,
7.8X, and 5.9X in terms of (a), (b), and (c), respectively, when (e) is fixed)
based on the observation.",2022-03-29,"Shinhwan Kang, Kyuhan Lee, Kijung Shin"
"Human-AI Collaboration Enables More Empathic Conversations in Text-based
  Peer-to-Peer Mental Health Support","Advances in artificial intelligence (AI) are enabling systems that augment
and collaborate with humans to perform simple, mechanistic tasks like
scheduling meetings and grammar-checking text. However, such Human-AI
collaboration poses challenges for more complex, creative tasks, such as
carrying out empathic conversations, due to difficulties of AI systems in
understanding complex human emotions and the open-ended nature of these tasks.
Here, we focus on peer-to-peer mental health support, a setting in which
empathy is critical for success, and examine how AI can collaborate with humans
to facilitate peer empathy during textual, online supportive conversations. We
develop Hailey, an AI-in-the-loop agent that provides just-in-time feedback to
help participants who provide support (peer supporters) respond more
empathically to those seeking help (support seekers). We evaluate Hailey in a
non-clinical randomized controlled trial with real-world peer supporters on
TalkLife (N=300), a large online peer-to-peer support platform. We show that
our Human-AI collaboration approach leads to a 19.60% increase in
conversational empathy between peers overall. Furthermore, we find a larger
38.88% increase in empathy within the subsample of peer supporters who
self-identify as experiencing difficulty providing support. We systematically
analyze the Human-AI collaboration patterns and find that peer supporters are
able to use the AI feedback both directly and indirectly without becoming
overly reliant on AI while reporting improved self-efficacy post-feedback. Our
findings demonstrate the potential of feedback-driven, AI-in-the-loop writing
systems to empower humans in open-ended, social, creative tasks such as
empathic conversations.",2022-03-28,"Ashish Sharma, Inna W. Lin, Adam S. Miner, David C. Atkins, Tim Althoff"
"Temporal Cascade Model for Analyzing Spread in Evolving Networks with
  Disease Monitoring Applications","Current approaches for modeling propagation in networks (e.g., spread of
disease) are unable to adequately capture temporal properties of the data such
as order and duration of evolving connections or dynamic likelihoods of
propagation along these connections. Temporal models in evolving networks are
crucial in many applications that need to analyze dynamic spread. For example,
a disease-spreading virus has varying transmissibility based on interactions
between individuals occurring over time with different frequency, proximity,
and venue population density. To capture such behaviors, we first develop the
Temporal Independent Cascade (T-IC) model and propose a novel spread function,
that we prove to be submodular, with a hypergraph-based sampling strategy that
efficiently utilizes dynamic propagation probabilities. We then introduce the
notion of 'reverse spread' using the proposed T-IC processes, and develop
solutions to identify both sentinel/detector nodes and highly susceptible
nodes. The proven guarantees of approximation quality enable scalable analysis
of highly granular temporal networks. Extensive experimental results on a
variety of real-world datasets show that the proposed approach significantly
outperforms the alternatives in modeling both if and how spread occurs, by
considering evolving network topology as well as granular contact/interaction
information. Our approach has numerous applications, including its utility for
the vital challenge of monitoring disease spread. Utilizing the proposed
methods and T-IC, we analyze the impact of various intervention strategies over
real spatio-temporal contact networks. Our approach is shown also to be highly
effective in quantifying the importance of superspreaders, designing targeted
restrictions for controlling spread, and backward contact tracing.",2022-03-28,"Aparajita Haldar, Shuang Wang, Gunduz Demirci, Joe Oakley, Hakan Ferhatosmanoglu"
"Who is next: rising star prediction via diffusion of user interest in
  social networks","Finding items with potential to increase sales is of great importance in
online market. In this paper, we propose to study this novel and practical
problem: rising star prediction. We call these potential items Rising Star,
which implies their ability to rise from low-turnover items to best-sellers in
the future. Rising stars can be used to help with unfair recommendation in
e-commerce platform, balance supply and demand to benefit the retailers and
allocate marketing resources rationally. Although the study of rising star can
bring great benefits, it also poses challenges to us. The sales trend of rising
star fluctuates sharply in the short-term and exhibits more contingency caused
by some external events (e.g., COVID-19 caused increasing purchase of the face
mask) than other items, which cannot be solved by existing sales prediction
methods. To address above challenges, in this paper, we observe that the
presence of rising stars is closely correlated with the early diffusion of user
interest in social networks, which is validated in the case of Taocode (an
intermediary that diffuses user interest in Taobao). Thus, we propose a novel
framework, RiseNet, to incorporate the user interest diffusion process with the
item dynamic features to effectively predict rising stars. Specifically, we
adopt a coupled mechanism to capture the dynamic interplay between items and
user interest, and a special designed GNN based framework to quantify user
interest. Our experimental results on large-scale real-world datasets provided
by Taobao demonstrate the effectiveness of our proposed framework.",2022-03-28,"Xuan Yang, Yang Yang, Jintao Su, Yifei Sun, Shen Fan, Zhongyao Wang, Jun Zhang, Jingmin Chen"
"""Born in Rome"" or ""Sleeping Beauty"": Emergence of hashtag popularity on
  the Chinese microblog Sina Weibo","To understand the emergence of hashtag popularity in online social networking
complex systems, we study the largest Chinese microblogging site Sina Weibo,
which has a Hot Search List (HSL) showing in real time the ranking of the 50
most popular hashtags based on search activity. We investigate the prehistory
of successful hashtags from 17 July 2020 to 17 September 2020 by mapping out
the related interaction network preceding the selection to HSL. We have found
that the circadian activity pattern has an impact on the time needed to get to
the HSL. When analyzing this time we distinguish two extreme categories: a)
""Born in Rome"", which means hashtags are mostly first created by super-hubs or
reach super-hubs at an early stage during their propagation and thus gain
immediate wide attention from the broad public, and b) ""Sleeping Beauty"",
meaning the hashtags gain little attention at the beginning and reach
system-wide popularity after a considerable time lag. The evolution of the
repost networks of successful hashtags before getting to the HSL show two types
of growth patterns: ""smooth"" and ""stepwise"". The former is usually dominated by
a super-hub and the latter results from consecutive waves of contributions of
smaller hubs. The repost networks of unsuccessful hashtags exhibit a simple
evolution pattern.",2022-03-28,"Hao Cui, János Kertész"
"Personalized Graph Summarization: Formulation, Scalable Algorithms, and
  Applications","Are users of an online social network interested equally in all connections
in the network? If not, how can we obtain a summary of the network personalized
to specific users? Can we use the summary for approximate query answering?
  As massive graphs (e.g., online social networks, hyperlink networks, and road
networks) have become pervasive, graph compression has gained importance for
the efficient processing of such graphs with limited resources. Graph
summarization is an extensively-studied lossy compression method. It provides a
summary graph where nodes with similar connectivity are merged into supernodes,
and a variety of graph queries can be answered approximately from the summary
graph.
  In this work, we introduce a new problem, namely personalized graph
summarization, where the objective is to obtain a summary graph where more
emphasis is put on connections closer to a given set of target nodes. Then, we
propose PeGaSus, a linear-time algorithm for the problem. Through experiments
on six real-world graphs, we demonstrate that PeGaSus is (a) Effective:
node-similarity queries for target nodes can be answered significantly more
accurately from personalized summary graphs than from non-personalized ones of
similar size, (b) Scalable: it summarizes graphs with up to one billion edges,
and (c) Applicable to distributed multi-query answering: it successfully
replaces graph partitioning for communication-free multi-query processing.",2022-03-28,"Shinhwan Kang, Kyuhan Lee, Kijung Shin"
"Bridging separate communities with common interest in distributed social
  networks through the use of social objects","In light of the growing number of user privacy violations in centralized
social networks, the need to define effective platforms for decentralized
online social networks (DOSNs) is deeply felt. Interesting solutions have been
proposed in the past, which own the necessary mechanisms to allow users keeping
control over their personal information and setting the rules to regulate the
access of other users. Unfortunately, the effectiveness of this type of
solutions is severely reduced by the fact that different user communities with
a shared interest could be disconnected/separated from each other. This
translates into a reduced ability in effectively spreading data of common
interest towards all interested users, as it currently happens in centralized
social networks. In order to overcome the cited limitation, this paper proposes
a disruptive approach, which exploits the availability of a new class of
Internet of Things (IoT) devices with autonomous social behaviors and cognitive
abilities. Such devices can be leveraged as friendship intermediaries between
devices' owners who are connected to a DOSN platform and share the same
interest. We will demonstrate that clear advantages can be achieved in terms of
increased percentage of Interested Reachable Nodes (a specific measure of
Delivery Ratio) in distributed social networks among humans, when enhanced with
so called Mediator Objects adhering to the well-known social IoT (SIoT)
paradigm.",2022-03-27,"D. Garompolo, A. Molinaro, A. Iera"
"Influence-aware Task Assignment in Spatial Crowdsourcing (Technical
  Report)","With the widespread diffusion of smartphones, Spatial Crowdsourcing (SC),
which aims to assign spatial tasks to mobile workers, has drawn increasing
attention in both academia and industry. One of the major issues is how to best
assign tasks to workers. Given a worker and a task, the worker will choose to
accept the task based on her affinity towards the task, and the worker can
propagate the information of the task to attract more workers to perform it.
These factors can be measured as worker-task influence. Since workers'
affinities towards tasks are different and task issuers may ask workers who
performed tasks to propagate the information of tasks to attract more workers
to perform them, it is important to analyze worker-task influence when making
assignments. We propose and solve a novel influence-aware task assignment
problem in SC, where tasks are assigned to workers in a manner that achieves
high worker-task influence. In particular, we aim to maximize the number of
assigned tasks and worker-task influence. To solve the problem, we first
determine workers' affinities towards tasks by identifying workers' historical
task-performing patterns. Next, a Historical Acceptance approach is developed
to measure workers' willingness of performing a task, i.e., the probability of
workers visiting the location of the task when they are informed. Next, we
propose a Random reverse reachable-based Propagation Optimization algorithm
that exploits reverse reachable sets to calculate the probability of workers
being informed about tasks in a social network. Based on worker-task influence
derived from the above three factors, we propose three influence-aware task
assignment algorithms that aim to maximize the number of assigned tasks and
worker-task influence. Extensive experiments on two real-world datasets offer
detailed insight into the effectiveness of our solutions.",2022-03-27,"Xuanhao Chen, Yan Zhao, Kai Zheng, Bin Yang, Christian S. Jensen"
"Multi-modal Misinformation Detection: Approaches, Challenges and
  Opportunities","As social media platforms are evolving from text-based forums into
multi-modal environments, the nature of misinformation in social media is also
transforming accordingly. Taking advantage of the fact that visual modalities
such as images and videos are more favorable and attractive to the users and
textual contents are sometimes skimmed carelessly, misinformation spreaders
have recently targeted contextual connections between the modalities e.g., text
and image. Hence many researchers have developed automatic techniques for
detecting possible cross-modal discordance in web-based content. We analyze,
categorize and identify existing approaches in addition to challenges and
shortcomings they face in order to unearth new research opportunities in the
field of multi-modal misinformation detection.",2022-03-25,"Sara Abdali, Sina shaham, Bhaskar Krishnamachari"
"Answering Should Self-Publishing Video Game Developers Market Their Game
  on Twitter","In the marketing of video games made by self-publishing, independent
developers, there is common advice to market a game using the social media
platform Twitter. However, the advice that stems from industry sources is
somewhat contradictory, and many self-publishing independent developers elect
not to use Twitter at all. This presents an opportunity for researchers to
investigate this tension and determine if using Twitter does have a causal
influence on the successful release of a game by using relatively recent
developments in causal data science techniques. In this sense, this paper
highlights these causal inference developments while simultaneously informing
self-publishing independent developers whether they should indeed market their
games using Twitter. It was found that using Twitter results in an average
increase of 85.4 reviews during release week, corresponding to a 314% positive
difference. Using Twitter also doubles the chance of reaching a critical
10-review inflection point threshold on release week. These effects, however,
are moderated by the characteristics of the game, expressed as 'tags', yet in
no case is the effect of Twitter use reduced to 0. Based on these findings, it
is advised that new, self-publishing video game developers do use Twitter to
market their games.",2022-03-25,Nathaniel Francis Golding
"Machine-Learning Based Objective Function Selection for Community
  Detection","NECTAR, a Node-centric ovErlapping Community deTection AlgoRithm, presented
in 2016 by Cohen et. al, chooses dynamically between two objective functions
which function to optimize, based on the network on which it is invoked. This
approach, as shown by Cohen et al., outperforms six state-of-the-art algorithms
for overlapping community detection. In this work, we present NECTAR-ML, an
extension of the NECTAR algorithm that uses a machine-learning based model for
automating the selection of the objective function, trained and evaluated on a
dataset of 15,755 synthetic and 7 real-world networks. Our analysis shows that
in approximately 90% of the cases our model was able to successfully select the
correct objective function. We conducted a competitive analysis of NECTAR and
NECTAR-ML. NECTAR-ML was shown to significantly outperform NECTAR's ability to
select the best objective function. We also conducted a competitive analysis of
NECTAR-ML and two additional state-of-the-art multi-objective community
detection algorithms. NECTAR-ML outperformed both algorithms in terms of
average detection quality. Multiobjective EAs (MOEAs) are considered to be the
most popular approach to solve MOP and the fact that NECTAR-ML significantly
outperforms them demonstrates the effectiveness of ML-based objective function
selection.",2022-03-25,"Asa Bornstein, Amir Rubin, Danny Hendler"
"Socially Fair Mitigation of Misinformation on Social Networks via
  Constraint Stochastic Optimization","Recent social networks' misinformation mitigation approaches tend to
investigate how to reduce misinformation by considering a whole-network
statistical scale. However, unbalanced misinformation exposures among
individuals urge to study fair allocation of mitigation resources. Moreover,
the network has random dynamics which change over time. Therefore, we introduce
a stochastic and non-stationary knapsack problem, and we apply its resolution
to mitigate misinformation in social network campaigns. We further propose a
generic misinformation mitigation algorithm that is robust to different social
networks' misinformation statistics, allowing a promising impact in real-world
scenarios. A novel loss function ensures fair mitigation among users. We
achieve fairness by intelligently allocating a mitigation incentivization
budget to the knapsack, and optimizing the loss function. To this end, a team
of Learning Automata (LA) drives the budget allocation. Each LA is associated
with a user and learns to minimize its exposure to misinformation by performing
a non-stationary and stochastic walk over its state space. Our results show how
our LA-based method is robust and outperforms similar misinformation mitigation
methods in how the mitigation is fairly influencing the network users.",2022-03-23,"Ahmed Abouzeid, Ole-Christoffer Granmo, Christian Webersik, Morten Goodwin"
"Author Multidisciplinarity and Disciplinary Roles in Field of Study
  Networks","When studying large research corpora, ""distant reading"" methods are vital to
understand the topics and trends in the corresponding research space. In
particular, given the recognised benefits of multidisciplinary research, it may
be important to map schools or communities of diverse research topics, and to
understand the multidisciplinary role that topics play within and between these
communities. This work proposes Field of Study (FoS) networks as a novel
network representation for use in scientometric analysis. We describe the
formation of FoS networks, which relate research topics according to the
authors who publish in them, from corpora of articles in which fields of study
can be identified. FoS networks are particularly useful for the distant reading
of large datasets of research papers when analysed through the lens of
exploring multidisciplinary science. In an evolving scientific landscape,
modular communities in FoS networks offer an alternative categorisation
strategy for research topics and sub-disciplines, when compared to traditional
prescribed discipline classification schemes. Furthermore, structural role
analysis of FoS networks can highlight important characteristics of topics in
such communities. To support this, we present two case studies which explore
multidisciplinary research in corpora of varying size and scope; namely, 6,323
articles relating to network science research and 4,184,011 articles relating
to research on the COVID-19-pandemic.",2022-03-23,"Eoghan Cunningham, Barry Smyth, Derek Greene"
Effective Seed Scheduling for Fuzzing with Graph Centrality Analysis,"Seed scheduling, the order in which seeds are selected, can greatly affect
the performance of a fuzzer. Existing approaches schedule seeds based on their
historical mutation data, but ignore the structure of the underlying Control
Flow Graph (CFG). Examining the CFG can help seed scheduling by revealing the
potential edge coverage gain from mutating a seed. An ideal strategy will
schedule seeds based on a count of all reachable and feasible edges from a seed
through mutations, but computing feasibility along all edges is prohibitively
expensive. Therefore, a seed scheduling strategy must approximate this count.
We observe that an approximate count should have 3 properties -- (i) it should
increase if there are more edges reachable from a seed; (ii) it should decrease
if mutation history information suggests an edge is hard to reach or is located
far away from currently visited edges; and (iii) it should be efficient to
compute over large CFGs. We observe that centrality measures from graph
analysis naturally provide these three properties and therefore can efficiently
approximate the likelihood of reaching unvisited edges by mutating a seed. We
therefore build a graph called the edge horizon graph that connects seeds to
their closest unvisited nodes and compute the seed node's centrality to measure
the potential edge coverage gain from mutating a seed. We implement our
approach in K-scheduler and compare with many popular seed scheduling
strategies. We find that K-scheduler increases feature coverage by 25.89%
compared to Entropic and edge coverage by 4.21% compared to the next-best
AFL-based seed scheduler, in arithmetic mean on 12 Google FuzzBench programs.
It also finds 3 more previously-unknown bugs than the next-best AFL-based seed
scheduler.",2022-03-22,"Dongdong She, Abhishek Shah, Suman Jana"
"Sustainable Development Goal Target Interactions in the Philippines: A
  Two-Method Approach","In 2015, the United Nations adopted 17 Sustainable Development Goals (SDGs)
with 169 targets for transformation toward a more sustainable future by 2030.
This study seeks to evaluate and analyze SDG target interactions in the
Philippines to resolve conflicting targets, and prioritize targets that
reinforce others and have no conflicts. To evaluate all 14196 target
interactions, two methods are employed. First, experts with over five years of
SDG-related experience evaluated interactions using a 7-point scale. Second, a
non-parametric Spearman rank correlation is used on official indicator data
with resulting coefficients serving as interaction scores. Interaction scores
are then coded as synergies (interact positively), trade-offs (negatively) or
non-classified (neutrally). Targets are also modelled as nodes and interactions
as edges in graphs presented in sdginteractions.herokuapp.com. Results from the
two methods were synthesized to formulate recommendations for concerned
parties. This includes resolving negative intra-goal target interactions
involving targets 3.1 'Reduce maternal mortality', 3.6 'Reduce road injuries
and deaths', and 3.7 'Universal access to sexual and reproductive care, family
planning, and education'. Ugly targets (at least one negative interaction)
including target 3.6, 3.7, and 8.2 'Diversify, innovate, and upgrade for
economic productivity' need to be resolved. Targets that reinforce their
corresponding SDGs should be prioritized, including 1.1 'Eradicate extreme
poverty', 4.2 'Equal access to quality pre-primary education', 6.2 'End open
defecation and provide access to sanitation and hygiene', 8.1 'Sustainable
economic growth', and 9.4 'Upgrade all industries and infrastructures for
sustainability'. Beautiful targets (no negative interactions) should also be
prioritized, including target 8.5 and 17.5 'Invest in least developed
countries'.",2022-03-22,"Vena Pearl Bongolan, Spencer C. Soria, Roselle Leah K. Rivera"
backbone: An R package to extract network backbones,"Networks are useful for representing phenomena in a broad range of domains.
Although their ability to represent complexity can be a virtue, it is sometimes
useful to focus on a simplified network that contains only the most important
edges: the backbone. This paper introduces and demonstrates the `backbone'
package for R, which implements methods for extracting the backbone from
weighted networks, weighted bipartite projections, and unweighted networks. For
each type of network, fully replicable code is presented first for small toy
examples, then for complete empirical examples using transportation, political,
and social networks. The paper also demonstrates the implications of several
issues of statistical inference that arise in backbone extraction. It concludes
by briefly reviewing existing applications of backbone extraction using the
`backbone' package, and future directions for research on network backbone
extraction.",2022-03-21,Zachary P. Neal
"Zoom Out and Observe: News Environment Perception for Fake News
  Detection","Fake news detection is crucial for preventing the dissemination of
misinformation on social media. To differentiate fake news from real ones,
existing methods observe the language patterns of the news post and ""zoom in""
to verify its content with knowledge sources or check its readers' replies.
However, these methods neglect the information in the external news environment
where a fake news post is created and disseminated. The news environment
represents recent mainstream media opinion and public attention, which is an
important inspiration of fake news fabrication because fake news is often
designed to ride the wave of popular events and catch public attention with
unexpected novel content for greater exposure and spread. To capture the
environmental signals of news posts, we ""zoom out"" to observe the news
environment and propose the News Environment Perception Framework (NEP). For
each post, we construct its macro and micro news environment from recent
mainstream news. Then we design a popularity-oriented and a novelty-oriented
module to perceive useful signals and further assist final prediction.
Experiments on our newly built datasets show that the NEP can efficiently
improve the performance of basic fake news detectors.",2022-03-21,"Qiang Sheng, Juan Cao, Xueyao Zhang, Rundong Li, Danding Wang, Yongchun Zhu"
Temporal Correlation of Internet Observatories and Outposts,"The Internet has become a critical component of modern civilization requiring
scientific exploration akin to endeavors to understand the land, sea, air, and
space environments. Understanding the baseline statistical distributions of
traffic are essential to the scientific understanding of the Internet.
Correlating data from different Internet observatories and outposts can be a
useful tool for gaining insights into these distributions. This work compares
observed sources from the largest Internet telescope (the CAIDA darknet
telescope) with those from a commercial outpost (the GreyNoise honeyfarm).
Neither of these locations actively emit Internet traffic and provide distinct
observations of unsolicited Internet traffic (primarily botnets and scanners).
Newly developed GraphBLAS hyperspace matrices and D4M associative array
technologies enable the efficient analysis of these data on significant scales.
The CAIDA sources are well approximated by a Zipf-Mandelbrot distribution. Over
a 6-month period 70\% of the brightest (highest frequency) sources in the CAIDA
telescope are consistently detected by coeval observations in the GreyNoise
honeyfarm. This overlap drops as the sources dim (reduce frequency) and as the
time difference between the observations grows. The probability of seeing a
CAIDA source is proportional to the logarithm of the brightness. The temporal
correlations are well described by a modified Cauchy distribution. These
observations are consistent with a correlated high frequency beam of sources
that drifts on a time scale of a month.",2022-03-19,"Jeremy Kepner, Michael Jones, Daniel Andersen, Aydın Buluç, Chansup Byun, K Claffy, Timothy Davis, William Arcand, Jonathan Bernays, David Bestor, William Bergeron, Vijay Gadepally, Daniel Grant, Micheal Houle, Matthew Hubbell, Hayden Jananthan, Anna Klein, Chad Meiners, Lauren Milechin, Andrew Morris, Julie Mullen, Sandeep Pisharody, Andrew Prout, Albert Reuther, Antonio Rosa, Siddharth Samsi, Doug Stetson, Charles Yee, Peter Michaleas"
Subreddit Links Drive Community Creation and User Engagement on Reddit,"On Reddit, individual subreddits are used to organize content and connect
users. One mode of interaction is the subreddit link, which occurs when a user
makes a direct reference to a subreddit in another community. Based on the
ubiquity of these references, we have undertaken a study on subreddit links on
Reddit, with the goal of understanding their impact on both the referenced
subreddit, and on the subreddit landscape as a whole. By way of an extensive
observational study along with several natural experiments using the entire
history of Reddit, we were able to determine that (1) subreddit links are a
significant driver of new suberddit creation; (2) subreddit links (2a)
substantially drive activity in the referenced subreddit, and (2b) are
frequently created in response to high levels of activity in the referenced
subreddit; and (3) the graph of subreddit links has become less dense and more
treelike over time. We conclude with a discussion of how these results confirm,
add to, and in some cases conflict with existing theories on
information-seeking behavior and self-organizing behavior in online social
systems.",2022-03-18,"Rachel Krohn, Tim Weninger"
Characterizing Alternative Monetization Strategies on YouTube,"One of the key emerging roles of the YouTube platform is providing creators
the ability to generate revenue from their content and interactions. Alongside
tools provided directly by the platform, such as revenue-sharing from
advertising, creators co-opt the platform to use a variety of off-platform
monetization opportunities. In this work, we focus on studying and
characterizing these alternative monetization strategies. Leveraging a large
longitudinal YouTube dataset of popular creators, we develop a taxonomy of
alternative monetization strategies and a simple methodology to detect their
usage automatically. We then proceed to characterize the adoption of these
strategies. First, we find that the use of external monetization is expansive
and increasingly prevalent, used in 18% of all videos, with 61% of channels
using one such strategy at least once. Second, we show that the adoption of
these strategies varies substantially among channels of different kinds and
popularity, and that channels that establish these alternative revenue streams
often become more productive on the platform. Lastly, we investigate how
potentially problematic channels -- those that produce Alt-lite, Alt-right, and
Manosphere content -- leverage alternative monetization strategies, finding
that they employ a more diverse set of such strategies significantly more often
than a carefully chosen comparison set of channels. This finding complicates
YouTube's role as a gatekeeper, since the practice of excluding
policy-violating content from its native on-platform monetization may not be
effective. Overall, this work provides an important step toward broadening the
understanding of the monetary incentives behind content creation on YouTube.",2022-03-18,"Yiqing Hua, Manoel Horta Ribeiro, Robert West, Thomas Ristenpart, Mor Naaman"
Blockchain for the Metaverse: A Review,"Since Facebook officially changed its name to Metaverse in Oct. 2021, the
metaverse has become a new norm of social networks and three-dimensional (3D)
virtual worlds. The metaverse aims to bring 3D immersive and personalized
experiences to users by leveraging many pertinent technologies. Despite great
attention and benefits, a natural question in the metaverse is how to secure
its users' digital content and data. In this regard, blockchain is a promising
solution owing to its distinct features of decentralization, immutability, and
transparency. To better understand the role of blockchain in the metaverse, we
aim to provide an extensive survey on the applications of blockchain for the
metaverse. We first present a preliminary to blockchain and the metaverse and
highlight the motivations behind the use of blockchain for the metaverse. Next,
we extensively discuss blockchain-based methods for the metaverse from
technical perspectives, such as data acquisition, data storage, data sharing,
data interoperability, and data privacy preservation. For each perspective, we
first discuss the technical challenges of the metaverse and then highlight how
blockchain can help. Moreover, we investigate the impact of blockchain on
key-enabling technologies in the metaverse, including Internet-of-Things,
digital twins, multi-sensory and immersive applications, artificial
intelligence, and big data. We also present some major projects to showcase the
role of blockchain in metaverse applications and services. Finally, we present
some promising directions to drive further research innovations and
developments towards the use of blockchain in the metaverse in the future.",2022-03-18,"Thippa Reddy Gadekallu, Thien Huynh-The, Weizheng Wang, Gokul Yenduri, Pasika Ranaweera, Quoc-Viet Pham, Daniel Benevides da Costa, Madhusanka Liyanage"
"GAC: A Deep Reinforcement Learning Model Toward User Incentivization in
  Unknown Social Networks","In recent years, many applications have deployed incentive mechanisms to
promote users' attention and engagement. Most incentive mechanisms determine
specific incentive values based on users' attributes (e.g., preferences), while
such information is unavailable in many real-world applications. Meanwhile, due
to budget restrictions, realizing successful incentivization for all users can
be challenging to complete. In this light, we consider leveraging social
influence to maximize the incentivization result. We can directly incentivize
influential users to affect more users, so the cost of incentivizing these
users can be decreased. However, identifying influential users in a social
network requires complete information about influence strength among users,
which is impractical to acquire in real-world situations. In this research, we
propose an end-to-end reinforcement learning-based framework, called Geometric
Actor-Critic (GAC), to tackle the abovementioned problem. The proposed approach
can realize effective incentive allocation without having prior knowledge about
users' attributes. Three real-world social network datasets have been adopted
in the experiments to evaluate the performance of GAC. The experimental results
indicate that GAC can learn and apply effective incentive allocation policies
in unknown social networks and outperform existing incentive allocation
approaches.",2022-03-17,"Shiqing Wu, Weihua Li, Quan Bai"
"Ranking of Communities in Multiplex Spatiotemporal Models of Brain
  Dynamics","As a relatively new field, network neuroscience has tended to focus on
aggregate behaviours of the brain averaged over many successive experiments or
over long recordings in order to construct robust brain models. These models
are limited in their ability to explain dynamic state changes in the brain
which occurs spontaneously as a result of normal brain function. Hidden Markov
Models (HMMs) trained on neuroimaging time series data have since arisen as a
method to produce dynamical models that are easy to train but can be difficult
to fully parametrise or analyse. We propose an interpretation of these neural
HMMs as multiplex brain state graph models we term Hidden Markov Graph Models
(HMGMs). This interpretation allows for dynamic brain activity to be analysed
using the full repertoire of network analysis techniques. Furthermore, we
propose a general method for selecting HMM hyperparameters in the absence of
external data, based on the principle of maximum entropy, and use this to
select the number of layers in the multiplex model. We produce a new tool for
determining important communities of brain regions using a spatiotemporal
random walk-based procedure that takes advantage of the underlying Markov
structure of the model. Our analysis of real multi-subject fMRI data provides
new results that corroborate the modular processing hypothesis of the brain at
rest as well as contributing new evidence of functional overlap between and
within dynamic brain state communities. Our analysis pipeline provides a way to
characterise dynamic network activity of the brain under novel behaviours or
conditions.",2022-03-17,"James Wilsenach, Katie Warnaby, Charlotte M. Deane, Gesine Reinert"
Database of Indian Social Media Influencers on Twitter,"Databases of highly networked individuals have been indispensable in studying
narratives and influence on social media. To support studies on Twitter in
India, we present a systematically categorised database of accounts of
influence on Twitter in India, identified and annotated through an iterative
process of friends, networks, and self-described profile information, verified
manually. We built an initial set of accounts based on the friend network of a
seed set of accounts based on real-world renown in various fields, and then
snowballed ""friends of friends"" multiple times, and rank ordered individuals
based on the number of in-group connections, and overall followers. We then
manually classified identified accounts under the categories of entertainment,
sports, business, government, institutions, journalism, civil society accounts
that have independent standing outside of social media, as well as a category
of ""digital first"" referring to accounts that derive their primary influence
from online activity. Overall, we annotated 11580 unique accounts across all
categories. The database is useful studying various questions related to the
role of influencers in polarisation, misinformation, extreme speech, political
discourse etc.",2022-03-17,"Arshia Arya, Soham De, Dibyendu Mishra, Gazal Shekhawat, Ankur Sharma, Anmol Panda, Faisal Lalani, Parantak Singh, Ramaravind Kommiya Mothilal, Rynaa Grover, Sachita Nishal, Saloni Dash, Shehla Shora, Syeda Zainab Akbar, Joyojeet Pal"
FairFoody: Bringing in Fairness in Food Delivery,"Along with the rapid growth and rise to prominence of food delivery
platforms, concerns have also risen about the terms of employment of the gig
workers underpinning this growth. Our analysis on data derived from a
real-world food delivery platform across three large cities from India show
that there is significant inequality in the money delivery agents earn. In this
paper, we formulate the problem of fair income distribution among agents while
also ensuring timely food delivery. We establish that the problem is not only
NP-hard but also inapproximable in polynomial time. We overcome this
computational bottleneck through a novel matching algorithm called FairFoody.
Extensive experiments over real-world food delivery datasets show FairFoody
imparts up to 10 times improvement in equitable income distribution when
compared to baseline strategies, while also ensuring minimal impact on customer
experience.",2022-03-16,"Anjali Gupta, Rahul Yadav, Ashish Nair, Abhijnan Chakraborty, Sayan Ranu, Amitabha Bagchi"
"Behaviour in social media for floods and heat waves in disaster response
  via Artificial Intelligence","This paper analyses social media data in multiple disaster-related
collections of floods and heat waves in the UK. The proposed method uses
machine learning classifiers based on deep bidirectional neural networks
trained on benchmark datasets of disaster responses and extreme events. The
resulting models are applied to perform sentiment and qualitative analysis of
inferred topics in text data. We further analyse a set of behavioural
indicators and match them with climate variables via decoding synoptical
records to analyse thermal comfort. We highlight the advantages of aligning
behavioural indicators along with climate variables to provide with additional
valuable information to be considered especially in different phases of a
disaster and applicable to extreme weather periods. The positiveness of
messages is around 8% for disaster, 1% for disaster and medical response, 7%
for disaster and humanitarian related messages. This shows the reliability of
such data for our case studies. We show the transferability of this approach to
be applied to any social media data collection.",2022-03-16,"Victor Ponce-López, Catalina Spataru"
"Stress-testing the Resilience of the Austrian Healthcare System Using
  Agent-Based Simulation","Patients do not access physicians at random but rather via naturally emerging
networks of patient flows between them. As retirements, mass quarantines and
absence due to sickness during pandemics, or other shocks thin out these
networks, the system might be pushed closer to a tipping point where it loses
its ability to deliver care to the population. Here we propose a data-driven
framework to quantify the regional resilience to such shocks of primary and
secondary care in Austria via an agent-based model. For each region and medical
specialty we construct detailed patient-sharing networks from administrative
data and stress-test these networks by removing increasing numbers of
physicians from the system. This allows us to measure regional resilience
indicators describing how many physicians can be removed from a certain area
before individual patients won't be treated anymore. We find that such tipping
points do indeed exist and that regions and medical specialties differ
substantially in their resilience. These systemic differences can be related to
indicators for individual physicians by quantifying how much their hypothetical
removal would stress the system (risk score) or how much of the stress from the
removal of other physicians they would be able to absorb (benefit score). Our
stress-testing framework could enable health authorities to rapidly identify
bottlenecks in access to care as well as to inspect these naturally emerging
physician networks and how potential absences would impact them.",2022-03-15,"Michaela Kaleta, Jana Lasser, Elma Dervic, Liuhuaying Yang, Johannes Sorger, Ruggiero Lo Sardo, Stefan Thurner, Alexandra Kautzky-Willer, Peter Klimek"
"Tweets in Time of Conflict: A Public Dataset Tracking the Twitter
  Discourse on the War Between Ukraine and Russia","On February 24, 2022, Russia invaded Ukraine. In the days that followed,
reports kept flooding in from layman to news anchors of a conflict quickly
escalating into war. Russia faced immediate backlash and condemnation from the
world at large. While the war continues to contribute to an ongoing
humanitarian and refugee crisis in Ukraine, a second battlefield has emerged in
the online space, both in the use of social media to garner support for both
sides of the conflict and also in the context of information warfare. In this
paper, we present a collection of over 63 million tweets, from February 22,
2022 through March 8, 2022 that we are publishing for the wider research
community to use. This dataset can be found at
https://github.com/echen102/ukraine-russia and will be maintained and regularly
updated as the war continues to unfold. Our preliminary analysis already shows
evidence of public engagement with Russian state sponsored media and other
domains that are known to push unreliable information; the former saw a spike
in activity on the day of the Russian invasion. Our hope is that this public
dataset can help the research community to further understand the ever evolving
role that social media plays in information dissemination, influence campaigns,
grassroots mobilization, and much more, during a time of conflict.",2022-03-14,"Emily Chen, Emilio Ferrara"
GRAND+: Scalable Graph Random Neural Networks,"Graph neural networks (GNNs) have been widely adopted for semi-supervised
learning on graphs. A recent study shows that the graph random neural network
(GRAND) model can generate state-of-the-art performance for this problem.
However, it is difficult for GRAND to handle large-scale graphs since its
effectiveness relies on computationally expensive data augmentation procedures.
In this work, we present a scalable and high-performance GNN framework GRAND+
for semi-supervised graph learning. To address the above issue, we develop a
generalized forward push (GFPush) algorithm in GRAND+ to pre-compute a general
propagation matrix and employ it to perform graph data augmentation in a
mini-batch manner. We show that both the low time and space complexities of
GFPush enable GRAND+ to efficiently scale to large graphs. Furthermore, we
introduce a confidence-aware consistency loss into the model optimization of
GRAND+, facilitating GRAND+'s generalization superiority. We conduct extensive
experiments on seven public datasets of different sizes. The results
demonstrate that GRAND+ 1) is able to scale to large graphs and costs less
running time than existing scalable GNNs, and 2) can offer consistent accuracy
improvements over both full-batch and scalable GNNs across all datasets.",2022-03-12,"Wenzheng Feng, Yuxiao Dong, Tinglin Huang, Ziqi Yin, Xu Cheng, Evgeny Kharlamov, Jie Tang"
"DeepTrust: A Reliable Financial Knowledge Retrieval Framework For
  Explaining Extreme Pricing Anomalies","Extreme pricing anomalies may occur unexpectedly without a trivial cause, and
equity traders typically experience a meticulous process to source disparate
information and analyze its reliability before integrating it into the trusted
knowledge base. We introduce DeepTrust, a reliable financial knowledge
retrieval framework on Twitter to explain extreme price moves at speed, while
ensuring data veracity using state-of-the-art NLP techniques. Our proposed
framework consists of three modules, specialized for anomaly detection,
information retrieval and reliability assessment. The workflow starts with
identifying anomalous asset price changes using machine learning models trained
with historical pricing data, and retrieving correlated unstructured data from
Twitter using enhanced queries with dynamic search conditions. DeepTrust
extrapolates information reliability from tweet features, traces of generative
language model, argumentation structure, subjectivity and sentiment signals,
and refine a concise collection of credible tweets for market insights. The
framework is evaluated on two self-annotated financial anomalies, i.e., Twitter
and Facebook stock price on 29 and 30 April 2021. The optimal setup outperforms
the baseline classifier by 7.75% and 15.77% on F0.5-scores, and 10.55% and
18.88% on precision, respectively, proving its capability in screening
unreliable information precisely. At the same time, information retrieval and
reliability assessment modules are analyzed individually on their effectiveness
and causes of limitations, with identified subjective and objective factors
that influence the performance. As a collaborative project with Refinitiv, this
framework paves a promising path towards building a scalable commercial
solution that assists traders to reach investment decisions on pricing
anomalies with authenticated knowledge from social media platforms in
real-time.",2022-03-11,Pok Wah Chan
Anonymous Hyperlocal Communities: What do they talk about?,"In this paper, we study what users talk about in a plethora of independent
hyperlocal and anonymous online communities in a single country: Saudi Arabia
(KSA). We base this perspective on performing a content classification of the
Jodel network in the KSA. To do so, we first contribute a content
classification schema that assesses both the intent (why) and the topic (what)
of posts. We use the schema to label 15k randomly sampled posts and further
classify the top 1k hashtags. We observe a rich set of benign (yet at times
controversial in conservative regimes) intents and topics that dominantly
address information requests, entertainment, or dating/flirting. By comparing
two large cities (Riyadh and Jeddah), we further show that hyperlocality leads
to shifts in topic popularity between local communities. By evaluating votes
(content appreciation) and replies (reactions), we show that the communities
react differently to different topics; e.g., entertaining posts are much
appreciated through votes, receiving the least replies, while beliefs &
politics receive similarly few replies but are controversially voted.",2022-03-10,"Jens Helge Reelfs, Oliver Hohlfeld, Niklas Henckell"
Tailored vertex ordering for faster triangle listing in large graphs,"Listing triangles is a fundamental graph problem with many applications, and
large graphs require fast algorithms. Vertex ordering allows the orientation of
edges from lower to higher vertex indices, and state-of-the-art triangle
listing algorithms use this to accelerate their execution and to bound their
time complexity. Yet, only basic orderings have been tested. In this paper, we
show that studying the precise cost of algorithms instead of their bounded
complexity leads to faster solutions. We introduce cost functions that link
ordering properties with the running time of a given algorithm. We prove that
their minimization is NP-hard and propose heuristics to obtain new orderings
with different trade-offs between cost reduction and ordering time. Using
datasets with up to two billion edges, we show that our heuristics accelerate
the listing of triangles by an average of 38% when the ordering is already
given as an input, and 16% when the ordering time is included.",2022-03-09,"Fabrice Lécuyer, Louis Jachiet, Clémence Magnien, Lionel Tabourier"
"Transitions between peace and systemic war as bifurcations in a signed
  network dynamical system","We investigate structural features and processes associated with the onset of
systemic conflict using an approach which integrates complex systems theory
with network modeling and analysis. We present a signed network model of
cooperation and conflict dynamics in the context of international relations
between states. The model evolves ties between nodes under the influence of a
structural balance force and a dyad-specific force. Model simulations exhibit a
sharp bifurcation from peace to systemic war as structural balance pressures
increase, a bistable regime in which both peace and war stable equilibria
exist, and a hysteretic reverse bifurcation from war to peace. We show how the
analytical expression we derive for the peace-to-war bifurcation condition
implies that polarized network structure increases susceptibility to systemic
war. We develop a framework for identifying patterns of relationship
perturbations that are most destabilizing and apply it to the network of
European great powers before World War I. We also show that the model exhibits
critical slowing down, in which perturbations to the peace equilibrium take
longer to decay as the system draws closer to the bifurcation. We discuss how
our results relate to international relations theories on the causes and
catalysts of systemic war.",2022-03-08,"Megan Morrison, J. Nathan Kutz, Michael Gabbay"
ARcall: Real-Time AR Communication using Smartphones and Smartglasses,"Augmented Reality (AR) smartglasses are increasingly regarded as the next
generation personal computing platform. However, there is a lack of
understanding about how to design communication systems using them. We present
ARcall, a novel Augmented Reality-based real-time communication system that
enables an immersive, delightful, and privacy-preserving experience between a
smartphone user and a smartglasses wearer. ARcall allows a remote friend
(Friend) to send and project AR content to a smartglasses wearer (Wearer). The
ARcall system was designed with the practical limits of existing AR glasses in
mind, including shorter battery life and a reduced field of view. We conduct a
qualitative evaluation of the three main components of ARcall: Drop-In,
ARaction, and Micro-Chat. Our results provide novel insights for building
future AR-based communication methods, including, the importance of context
priming, user control over AR content placement, and the feeling of co-presence
while conversing.",2022-03-08,"Hemant Bhaskar Surale, Yu Jiang Tham, Brian A. Smith, Rajan Vaish"
"High-order Order Proximity-Incorporated, Symmetry and Graph-Regularized
  Nonnegative Matrix Factorization for Community Detection","Community describes the functional mechanism of a network, making community
detection serve as a fundamental graph tool for various real applications like
discovery of social circle. To date, a Symmetric and Non-negative Matrix
Factorization (SNMF) model has been frequently adopted to address this issue
owing to its high interpretability and scalability. However, most existing
SNMF-based community detection methods neglect the high-order connection
patterns in a network. Motivated by this discovery, in this paper, we propose a
High-Order Proximity (HOP)-incorporated, Symmetry and Graph-regularized NMF
(HSGN) model that adopts the following three-fold ideas: a) adopting a weighted
pointwise mutual information (PMI)-based approach to measure the HOP indices
among nodes in a network; b) leveraging an iterative reconstruction scheme to
encode the captured HOP into the network; and c) introducing a symmetry and
graph-regularized NMF algorithm to detect communities accurately. Extensive
empirical studies on eight real-world networks demonstrate that an HSGN-based
community detector significantly outperforms both benchmark and
state-of-the-art community detectors in providing highly-accurate community
detection results.",2022-03-08,"Zhigang Liu, Xin Luo"
Unit Perturbations in Budgeted Spanning Tree Problems,"The minimum spanning tree of a graph is a well-studied structure that is the
basis of countless graph theoretic and optimization problem. We study the
minimum spanning tree (MST) perturbation problem where the goal is to spend a
fixed budget to increase the weight of edges in order to increase the weight of
the MST as much as possible. Two popular models of perturbation are bulk and
continuous. In the bulk model, the weight of any edge can be increased exactly
once to some predetermined weight. In the continuous model, one can pay a
fractional amount of cost to increase the weight of any edge by a proportional
amount. Frederickson and Solis-Oba \cite{FS96} have studied these two models
and showed that bulk perturbation for MST is as hard as the $k$-cut problem
while the continuous perturbation model is solvable in poly-time. In this
paper, we study an intermediate unit perturbation variation of this problem
where the weight of each edge can be increased many times but at an integral
unit amount every time. We provide an $(opt/2 -1)$-approximation in polynomial
time where $opt$ is the optimal increase in the weight. We also study the
associated dual targeted version of the problem where the goal is to increase
the weight of the MST by a target amount while minimizing the cost of
perturbation. We provide a $2$-approximation for this variation. Furthermore we
show that assuming the Small Set Expansion Hypothesis, both problems are hard
to approximate. We also point out an error in the proof provided by
Frederickson and Solis-Oba in \cite{FS96} with regard to their solution to the
continuous perturbation model. Although their algorithm is correct, their
analysis is flawed. We provide a correct proof here.",2022-03-07,"Hassene Aissi, Solal Attias, Da Qi Chen, R. Ravi"
"Emotion Regulation and Dynamics of Moral Concerns During the Early
  COVID-19 Pandemic","The COVID-19 pandemic has upended daily life around the globe, posing a
threat to public health. Intuitively, we expect that surging cases and deaths
would lead to fear, distress and other negative emotions. However, using
state-of-the-art methods to measure sentiment, emotions, and moral concerns in
social media messages posted in the early stage of the pandemic, we see a
counter-intuitive rise in positive affect. We hypothesize that the increase of
positivity is associated with a decrease of uncertainty and emotion regulation.
Finally, we identify a partisan divide in moral and emotional reactions that
emerged after the first US death. Overall, these results show how collective
emotional states have changed since the pandemic began, and how social media
can provide a useful tool to understand, and even regulate, diverse patterns
underlying human affect.",2022-03-07,"Siyi Guo, Keith Burghardt, Ashwin Rao, Kristina Lerman"
Using Timeliness in Tracking Infections,"We consider real-time timely tracking of infection status (e.g., covid-19) of
individuals in a population. In this work, a health care provider wants to
detect infected people as well as people who have recovered from the disease as
quickly as possible. In order to measure the timeliness of the tracking
process, we use the long-term average difference between the actual infection
status of the people and their real-time estimate by the health care provider
based on the most recent test results. We first find an analytical expression
for this average difference for given test rates, infection rates and recovery
rates of people. Next, we propose an alternating minimization based algorithm
to find the test rates that minimize the average difference. We observe that if
the total test rate is limited, instead of testing all members of the
population equally, only a portion of the population may be tested in unequal
rates calculated based on their infection and recovery rates. Next, we
characterize the average difference when the test measurements are erroneous
(i.e., noisy). Further, we consider the case where the infection status of
individuals may be dependent, which happens when an infected person spreads the
disease to another person if they are not detected and isolated by the health
care provider. Then, we consider an age of incorrect information based error
metric where the staleness metric increases linearly over time as long as the
health care provider does not detect the changes in the infection status of the
people. In numerical results, we observe that an increased population size
increases diversity of people with different infection and recovery rates which
may be exploited to spend testing capacity more efficiently. Depending on the
health care provider's preferences, test rate allocation can be adjusted to
detect either the infected people or the recovered people more quickly.",2022-03-07,"Melih Bastopcu, Sennur Ulukus"
Trajectory Test-Train Overlap in Next-Location Prediction Datasets,"Next-location prediction, consisting of forecasting a user's location given
their historical trajectories, has important implications in several fields,
such as urban planning, geo-marketing, and disease spreading. Several
predictors have been proposed in the last few years to address it, including
last-generation ones based on deep learning. This paper tests the
generalization capability of these predictors on public mobility datasets,
stratifying the datasets by whether the trajectories in the test set also
appear fully or partially in the training set. We consistently discover a
severe problem of trajectory overlapping in all analyzed datasets, highlighting
that predictors memorize trajectories while having limited generalization
capacities. We thus propose a methodology to rerank the outputs of the
next-location predictors based on spatial mobility patterns. With these
techniques, we significantly improve the predictors' generalization capability,
with a relative improvement on the accuracy up to 96.15% on the trajectories
that cannot be memorized (i.e., low overlap with the training set).",2022-03-07,"Massimiliano Luca, Luca Pappalardo, Bruno Lepri, Gianni Barlacchi"
"Verification of Bitcoin Script in Agda using Weakest Preconditions for
  Access Control","This paper contributes to the verification of programs written in Bitcoin's
smart contract language SCRIPT in the interactive theorem prover Agda. It
focuses on the security property of access control for SCRIPT programs that
govern the distribution of Bitcoins. It advocates that weakest preconditions in
the context of Hoare triples are the appropriate notion for verifying access
control. It aims at obtaining human-readable descriptions of weakest
preconditions in order to close the validation gap between user requirements
and formal specification of smart contracts.
  As examples for the proposed approach, the paper focuses on two standard
SCRIPT programs that govern the distribution of Bitcoins, Pay to Public Key
Hash (P2PKH) and Pay to Multisig (P2MS). The paper introduces an operational
semantics of the SCRIPT commands used in P2PKH and P2MS, which is formalised in
the Agda proof assistant and reasoned about using Hoare triples. Two
methodologies for obtaining human-readable descriptions of weakest
preconditions are discussed:
  (1) a step-by-step approach, which works backwards instruction by instruction
through a script, sometimes grouping several instructions together;
  (2) symbolic execution of the code and translation into a nested case
distinction, which allows to read off weakest preconditions as the disjunction
of conjunctions of conditions along accepting paths.
  A syntax for equational reasoning with Hoare Triples is defined in order to
formalise those approaches in Agda.
  Keywords and phrases: Blockchain; Cryptocurrency; Bitcoin; Agda;
Verification; Hoare logic; Bitcoin script; P2PKH; P2MS; Access control; Weakest
precondition; Predicate transformer semantics; Provable correctness; Symbolic
execution; Smart contracts",2022-03-06,"Fahad F. Alhabardi, Arnold Beckmann, Bogdan Lazar, Anton Setzer"
Routing with Privacy for Drone Package Delivery Systems,"Unmanned aerial vehicles (UAVs), or drones, are increasingly being used to
deliver goods from vendors to customers. To safely conduct these operations at
scale, drones are required to broadcast position information as codified in
remote identification (remote ID) regulations. However, location broadcast of
package delivery drones introduces a privacy risk for customers using these
delivery services: Third-party observers may leverage broadcast drone
trajectories to link customers with their purchases, potentially resulting in a
wide range of privacy risks. We propose a probabilistic definition of privacy
risk based on the likelihood of associating a customer to a vendor given a
package delivery route. Next, we quantify these risks, enabling drone operators
to assess privacy risks when planning delivery routes. We then evaluate the
impacts of various factors (e.g., drone capacity) on privacy and consider the
trade-offs between privacy and delivery wait times. Finally, we propose
heuristics for generating routes with privacy guarantees to avoid exhaustive
enumeration of all possible routes and evaluate their performance on several
realistic delivery scenarios.",2022-03-04,"Geoffrey Ding, Alex Berke, Karthik Gopalakrishnan, Kwassi H. Degue, Hamsa Balakrishnan, Max Z. Li"
Bayesian community detection for networks with covariates,"The increasing prevalence of network data in a vast variety of fields and the
need to extract useful information out of them have spurred fast developments
in related models and algorithms. Among the various learning tasks with network
data, community detection, the discovery of node clusters or ""communities,"" has
arguably received the most attention in the scientific community. In many
real-world applications, the network data often come with additional
information in the form of node or edge covariates that should ideally be
leveraged for inference. In this paper, we add to a limited literature on
community detection for networks with covariates by proposing a Bayesian
stochastic block model with a covariate-dependent random partition prior. Under
our prior, the covariates are explicitly expressed in specifying the prior
distribution on the cluster membership. Our model has the flexibility of
modeling uncertainties of all the parameter estimates including the community
membership. Importantly, and unlike the majority of existing methods, our model
has the ability to learn the number of the communities via posterior inference
without having to assume it to be known. Our model can be applied to community
detection in both dense and sparse networks, with both categorical and
continuous covariates, and our MCMC algorithm is very efficient with good
mixing properties. We demonstrate the superior performance of our model over
existing models in a comprehensive simulation study and an application to two
real datasets.",2022-03-04,"Luyi Shen, Arash Amini, Nathaniel Josephs, Lizhen Lin"
SaPHyRa: A Learning Theory Approach to Ranking Nodes in Large Networks,"Ranking nodes based on their centrality stands a fundamental, yet,
challenging problem in large-scale networks. Approximate methods can quickly
estimate nodes' centrality and identify the most central nodes, but the ranking
for the majority of remaining nodes may be meaningless. For example, ranking
for less-known websites in search queries is known to be noisy and unstable. To
this end, we investigate a new node ranking problem with two important
distinctions: a) ranking quality, rather than the centrality estimation
quality, as the primary objective; and b) ranking only nodes of interest, e.g.,
websites that matched search criteria. We propose Sample space Partitioning
Hypothesis Ranking, or SaPHyRa, that transforms node ranking into a hypothesis
ranking in machine learning. This transformation maps nodes' centrality to the
expected risks of hypotheses, opening doors for theoretical machine learning
(ML) tools. The key of SaPHyRa is to partition the sample space into exact and
approximate subspaces. The exact subspace contains samples related to the nodes
of interest, increasing both estimation and ranking qualities. The approximate
space can be efficiently sampled with ML-based techniques to provide
theoretical guarantees on the estimation error. Lastly, we present SaPHyRa_bc,
an illustration of SaPHyRa on ranking nodes' betweenness centrality (BC). By
combining a novel bi-component sampling, a 2-hop sample partitioning, and
improved bounds on the Vapnik-Chervonenkis dimension, SaPHyRa_bc can
effectively rank any node subset in BC. Its performance is up to 200x faster
than state-of-the-art methods in approximating BC, while its rank correlation
to the ground truth is improved by multifold.",2022-03-03,"Phuc Thai, My T. Thai, Tam Vu, Thang N. Dinh"
Partisan Asymmetries in Exposure to Misinformation,"Health misinformation is believed to have contributed to vaccine hesitancy
during the Covid-19 pandemic, highlighting concerns about the role of social
media in polarization and social stability. While previous research has
identified a link between political partisanship and misinformation sharing
online, the interaction between partisanship and how much misinformation people
see within their social networks has not been well studied. As a result, we do
not know whether partisanship drives exposure to misinformation or people
selectively share misinformation despite being exposed to factual content. We
study Twitter discussions about the Covid-19 pandemic, classifying users
ideologically along political and factual dimensions. We find partisan
asymmetries in both sharing behaviors and exposure, with conservatives more
likely to see and share misinformation and moderate liberals seeing the most
factual content. We identify multi-dimensional echo chambers that expose users
to ideologically congruent content; however, the interaction between political
and factual dimensions creates conditions for the highly polarized users --
hardline conservatives and liberals -- to amplify misinformation. Despite this,
misinformation receives less attention than factual content and political
moderates, who represent the bulk of users in our sample, help filter out
misinformation, reducing the amount of low factuality content in the
information ecosystem. Identifying the extent of polarization and how political
ideology can exacerbate misinformation can potentially help public health
experts and policy makers improve their messaging to promote consensus.",2022-03-02,"Ashwin Rao, Fred Morstatter, Kristina Lerman"
"Dynamic Coupling Strategy for Interdependent Network Systems Against
  Cascading Failures","Cascading failures are a common phenomenon in complex networked systems where
failures at only a few nodes may trigger a process of sequential failure. We
applied a flow redistribution model to investigate the robustness against
cascading failures in modern systems carrying flows/loads (i.e. power grid,
transportation system, etc.) that contain multiple interdependent networks. In
such a system, the coupling coefficients between networks, which determine how
much flows/loads are redistributed between networks, are a key factor
determining the robustness to cascading failures. We derive recursive
expressions to characterize the evolution of such a system under dynamic
network coupling. Using these expressions, we enhance the robustness of
interdependent network systems by dynamically adjusting the coupling
coefficients based on current system situations, minimizing the subsequent
failures. The analytical and simulation results show a significant improvement
in robustness compared to prior work, which considers only fixed coupling
coefficients. Our proposed Step-wise Optimization (SWO) method not only shows
good performance against cascading failures, but also offers better
computational complexity, scalability to multiple networks, and flexibility to
different attack types. We show in simulation that SWO provides robustness
against cascading failures for multiple different network topologies.",2022-03-02,"I-Cheng Lin, Carlee Joe-Wong, Osman Yagan"
Large-Scale Hate Speech Detection with Cross-Domain Transfer,"The performance of hate speech detection models relies on the datasets on
which the models are trained. Existing datasets are mostly prepared with a
limited number of instances or hate domains that define hate topics. This
hinders large-scale analysis and transfer learning with respect to hate
domains. In this study, we construct large-scale tweet datasets for hate speech
detection in English and a low-resource language, Turkish, consisting of
human-labeled 100k tweets per each. Our datasets are designed to have equal
number of tweets distributed over five domains. The experimental results
supported by statistical tests show that Transformer-based language models
outperform conventional bag-of-words and neural models by at least 5% in
English and 10% in Turkish for large-scale hate speech detection. The
performance is also scalable to different training sizes, such that 98% of
performance in English, and 97% in Turkish, are recovered when 20% of training
instances are used. We further examine the generalization ability of
cross-domain transfer among hate domains. We show that 96% of the performance
of a target domain in average is recovered by other domains for English, and
92% for Turkish. Gender and religion are more successful to generalize to other
domains, while sports fail most.",2022-03-02,"Cagri Toraman, Furkan Şahinuç, Eyup Halit Yilmaz"
"Structural invariants and semantic fingerprints in the ""ego network"" of
  words","Well-established cognitive models coming from anthropology have shown that,
due to the cognitive constraints that limit our ""bandwidth"" for social
interactions, humans organize their social relations according to a regular
structure. In this work, we postulate that similar regularities can be found in
other cognitive processes, such as those involving language production. In
order to investigate this claim, we analyse a dataset containing tweets of a
heterogeneous group of Twitter users (regular users and professional writers).
Leveraging a methodology similar to the one used to uncover the
well-established social cognitive constraints, we find regularities at both the
structural and semantic level. At the former, we find that a concentric layered
structure (which we call ego network of words, in analogy to the ego network of
social relationships) very well captures how individuals organise the words
they use. The size of the layers in this structure regularly grows
(approximately 2-3 times with respect to the previous one) when moving
outwards, and the two penultimate external layers consistently account for
approximately 60% and 30% of the used words, irrespective of the number of the
total number of layers of the user. For the semantic analysis, each ring of
each ego network is described by a semantic profile, which captures the topics
associated with the words in the ring. We find that ring #1 has a special role
in the model. It is semantically the most dissimilar and the most diverse among
the rings. We also show that the topics that are important in the innermost
ring also have the characteristic of being predominant in each of the other
rings, as well as in the entire ego network. In this respect, ring #1 can be
seen as the semantic fingerprint of the ego network of words.",2022-03-01,"Kilian Ollivier, Chiara Boldrini, Andrea Passarella, Marco Conti"
"Mental Health Pandemic during the COVID-19 Outbreak: Social Media as a
  Window to Public Mental Health","Intensified preventive measures during the COVID-19 pandemic, such as
lockdown and social distancing, heavily increased the perception of social
isolation (i.e., a discrepancy between one's social needs and the provisions of
the social environment) among young adults. Social isolation is closely
associated with situational loneliness (i.e., loneliness emerging from
environmental change), a risk factor for depressive symptoms. Prior research
suggested vulnerable young adults are likely to seek support from an online
social platform such as Reddit, a perceived comfortable environment for lonely
individuals to seek mental health help through anonymous communication with a
broad social network. Therefore, this study aims to identify and analyze
depression-related dialogues on loneliness subreddits during the COVID-19
outbreak, with the implications on depression-related infoveillance during the
pandemic. Our study utilized logistic regression and topic modeling to classify
and examine depression-related discussions on loneliness subreddits before and
during the pandemic. Our results showed significant increases in the volume of
depression-related discussions (i.e., topics related to mental health, social
interaction, family, and emotion) where challenges were reported during the
pandemic. We also found a switch in dominant topics emerging from
depression-related discussions on loneliness subreddits, from dating
(prepandemic) to online interaction and community (pandemic), suggesting the
increased expressions or need of online social support during the pandemic. The
current findings suggest the potential of social media to serve as a window for
monitoring public mental health. Our future study will clinically validate the
current approach, which has implications for designing a surveillance system
during the crisis.",2022-03-01,"Michelle Bak, Chungyi Chiu, Jessie Chin"
"Ordered Submodularity and its Applications to Diversifying
  Recommendations","A fundamental task underlying many important optimization problems, from
influence maximization to sensor placement to content recommendation, is to
select the optimal group of $k$ items from a larger set. Submodularity has been
very effective in allowing approximation algorithms for such subset selection
problems. However, in several applications, we are interested not only in the
elements of a set, but also the order in which they appear, breaking the
assumption that all selected items receive equal consideration. One such
category of applications involves the presentation of search results, product
recommendations, news articles, and other content, due to the well-documented
phenomenon that humans pay greater attention to higher-ranked items. As a
result, optimization in content presentation for diversity, user coverage,
calibration, or other objectives more accurately represents a sequence
selection problem, to which traditional submodularity approximation results no
longer apply. Although extensions of submodularity to sequences have been
proposed, none is designed to model settings where items contribute based on
their position in a ranked list, and hence they are not able to express these
types of optimization problems. In this paper, we aim to address this modeling
gap.
  Here, we propose a new formalism of ordered submodularity that captures these
ordering problems in content presentation, and more generally a category of
optimization problems over ranked sequences in which different list positions
contribute differently to the objective function. We analyze the natural
ordered analogue of the greedy algorithm and show that it provides a
$2$-approximation. We also show that this bound is tight, establishing that our
new framework is conceptually and quantitatively distinct from previous
formalisms of set and sequence submodularity.",2022-03-01,"Jon Kleinberg, Emily Ryu, Éva Tardos"
"Equivariant and Stable Positional Encoding for More Powerful Graph
  Neural Networks","Graph neural networks (GNN) have shown great advantages in many graph-based
learning tasks but often fail to predict accurately for a task-based on sets of
nodes such as link/motif prediction and so on. Many works have recently
proposed to address this problem by using random node features or node distance
features. However, they suffer from either slow convergence, inaccurate
prediction, or high complexity. In this work, we revisit GNNs that allow using
positional features of nodes given by positional encoding (PE) techniques such
as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because
they are not generalizable to unseen graphs (inductive) or stable. Here, we
study these issues in a principled way and propose a provable solution, a class
of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate
channels to update the original node features and positional features. PEG
imposes permutation equivariance w.r.t. the original node features and imposes
$O(p)$ (orthogonal group) equivariance w.r.t. the positional features
simultaneously, where $p$ is the dimension of used positional features.
Extensive link prediction experiments over 8 real-world networks demonstrate
the advantages of PEG in generalization and scalability.",2022-03-01,"Haorui Wang, Haoteng Yin, Muhan Zhang, Pan Li"
GraphWorld: Fake Graphs Bring Real Insights for GNNs,"Despite advances in the field of Graph Neural Networks (GNNs), only a small
number (~5) of datasets are currently used to evaluate new models. This
continued reliance on a handful of datasets provides minimal insight into the
performance differences between models, and is especially challenging for
industrial practitioners who are likely to have datasets which look very
different from those used as academic benchmarks. In the course of our work on
GNN infrastructure and open-source software at Google, we have sought to
develop improved benchmarks that are robust, tunable, scalable,and
generalizable. In this work we introduce GraphWorld, a novel methodology and
system for benchmarking GNN models on an arbitrarily-large population of
synthetic graphs for any conceivable GNN task. GraphWorld allows a user to
efficiently generate a world with millions of statistically diverse datasets.
It is accessible, scalable, and easy to use. GraphWorld can be run on a single
machine without specialized hardware, or it can be easily scaled up to run on
arbitrary clusters or cloud frameworks. Using GraphWorld, a user has
fine-grained control over graph generator parameters, and can benchmark
arbitrary GNN models with built-in hyperparameter tuning. We present insights
from GraphWorld experiments regarding the performance characteristics of tens
of thousands of GNN models over millions of benchmark datasets. We further show
that GraphWorld efficiently explores regions of benchmark dataset space
uncovered by standard benchmarks, revealing comparisons between models that
have not been historically obtainable. Using GraphWorld, we also are able to
study in-detail the relationship between graph properties and task performance
metrics, which is nearly impossible with the classic collection of real-world
benchmarks.",2022-02-28,"John Palowitch, Anton Tsitsulin, Brandon Mayer, Bryan Perozzi"
Structure from Voltage,"Effective resistance (ER) is an attractive way to interrogate the structure
of graphs. It is an alternative to computing the eigen-vectors of the graph
Laplacian. Graph laplacians are used to find low dimensional structures in high
dimensional data. Here too, ER based analysis has advantages over eign-vector
based methods. Unfortunately Von Luxburg et al. (2010) show that, when vertices
correspond to a sample from a distribution over a metric space, the limit of
the ER between distant points converges to a trivial quantity that holds no
information about the structure of the graph. We show that by using scaling
resistances in a graph with $n$ vertices by $n^2$, one gets a meaningful limit
of the voltages and of effective resistances. We also show that by adding a
""ground"" node to a metric graph one gets a simple and natural way to compute
all of the distances from a chosen point to all other points.",2022-02-28,"Robi Bhattacharjee, Alex Cloninger, Yoav Freund, Andreas Oslandsbotn"
Did AI get more negative recently?,"In this paper, we classify scientific articles in the domain of natural
language processing (NLP) and machine learning (ML), as core subfields of
artificial intelligence (AI), into whether (i) they extend the current
state-of-the-art by the introduction of novel techniques which beat existing
models or whether (ii) they mainly criticize the existing state-of-the-art,
i.e. that it is deficient with respect to some property (e.g. wrong evaluation,
wrong datasets, misleading task specification). We refer to contributions under
(i) as having a 'positive stance' and contributions under (ii) as having a
'negative stance' (to related work). We annotate over 1.5 k papers from NLP and
ML to train a SciBERT-based model to automatically predict the stance of a
paper based on its title and abstract. We then analyse large-scale trends on
over 41 k papers from the last approximately 35 years in NLP and ML, finding
that papers have become substantially more positive over time, but negative
papers also got more negative and we observe considerably more negative papers
in recent years. Negative papers are also more influential in terms of
citations they receive.",2022-02-28,"Dominik Beese, Begüm Altunbaş, Görkem Güzeler, Steffen Eger"
"Sparsity-aware neural user behavior modeling in online interaction
  platforms","Modern online platforms offer users an opportunity to participate in a
variety of content-creation, social networking, and shopping activities. With
the rapid proliferation of such online services, learning data-driven user
behavior models is indispensable to enable personalized user experiences.
Recently, representation learning has emerged as an effective strategy for user
modeling, powered by neural networks trained over large volumes of interaction
data. Despite their enormous potential, we encounter the unique challenge of
data sparsity for a vast majority of entities, e.g., sparsity in ground-truth
labels for entities and in entity-level interactions (cold-start users, items
in the long-tail, and ephemeral groups).
  In this dissertation, we develop generalizable neural representation learning
frameworks for user behavior modeling designed to address different sparsity
challenges across applications. Our problem settings span transductive and
inductive learning scenarios, where transductive learning models entities seen
during training and inductive learning targets entities that are only observed
during inference. We leverage different facets of information reflecting user
behavior (e.g., interconnectivity in social networks, temporal and attributed
interaction information) to enable personalized inference at scale. Our
proposed models are complementary to concurrent advances in neural
architectural choices and are adaptive to the rapid addition of new
applications in online platforms.",2022-02-28,Aravind Sankar
"How Do Mothers and Fathers Talk About Parenting to Different Audiences?:
  Stereotypes and Audience Effects: An Analysis of r/Daddit, r/Mommit, and
  r/Parenting Using Topic Modelling","While major strides have been made towards gender equality in public life,
serious inequality remains in the domestic sphere, especially around parenting.
The present study analyses discussions about parenting on Reddit to explore
audience effects and gender stereotypes. It suggests a novel method to study
topical variation in individuals' language when interacting with different
audiences. Comments posted in 2020 were collected from three parenting
subreddits, described as being for fathers (r/Daddit), mothers (r/Mommit), and
all parents (r/Parenting). Users posting on r/Parenting and r/Daddit or on
r/Parenting and r/Mommit were assumed to identify as fathers or mothers,
respectively, allowing gender comparison. Users' comments on r/Parenting (to a
mixed-gender audience) were compared with their comments to single-gender
audiences on r/Daddit or r/Mommit using LDA topic modelling. Results showed
that the most discussed topic among parents is about education and family
advice, a topic mainly discussed in the mixed-gender subreddit and more by
fathers than mothers. Regarding the basic needs of children (sleep, food, and
medical care), mothers seemed to be more concerned regardless of the audience.
In contrast, topics such as birth and pregnancy announcements and physical
appearance were more discussed by fathers in the father-centric subreddit.
Overall, findings seem to show that mothers are generally more concerned about
the practical sides of parenting while fathers' expressed concerns are more
contextual: with other fathers, there seems to be a desire to show their
fatherhood and be recognized for it while they discuss education with mothers.
These results demonstrate that concerns expressed by parents on Reddit are
context-sensitive but also consistent with gender stereotypes, potentially
reflecting a persistent gendered and unequal division of labour in parenting.",2022-02-25,"Melody Sepahpour-Fard, Michael Quayle"
"Venture Capital investments through the lens of Network and Functional
  Data Analysis","In this paper we characterize the performance of venture capital-backed firms
based on their ability to attract investment. The aim of the study is to
identify relevant predictors of success built from the network structure of
firms' and investors' relations. Focusing on deal-level data for the health
sector, we first create a bipartite network among firms and investors, and then
apply functional data analysis (FDA) to derive progressively more refined
indicators of success captured by a binary, a scalar and a functional outcome.
More specifically, we use different network centrality measures to capture the
role of early investments for the success of the firm. Our results, which are
robust to different specifications, suggest that success has a strong positive
association with centrality measures of the firm and of its large investors,
and a weaker but still detectable association with centrality measures of small
investors and features describing firms as knowledge bridges. Finally, based on
our analyses, success is not associated with firms' and investors' spreading
power (harmonic centrality), nor with the tightness of investors' community
(clustering coefficient) and spreading ability (VoteRank).",2022-02-25,"Christian Esposito, Marco Gortan, Lorenzo Testa, Francesca Chiaromonte, Giorgio Fagiolo, Andrea Mina, Giulio Rossetti"
Core-periphery detection in hypergraphs,"Core-periphery detection is a key task in exploratory network analysis where
one aims to find a core, a set of nodes well-connected internally and with the
periphery, and a periphery, a set of nodes connected only (or mostly) with the
core. In this work we propose a model of core-periphery for higher-order
networks modeled as hypergraphs and we propose a method for computing a
core-score vector that quantifies how close each node is to the core. In
particular, we show that this method solves the corresponding non-convex
core-periphery optimization problem globally to an arbitrary precision. This
method turns out to coincide with the computation of the Perron eigenvector of
a nonlinear hypergraph operator, suitably defined in term of the incidence
matrix of the hypergraph, generalizing recently proposed centrality models for
hypergraphs. We perform several experiments on synthetic and real-world
hypergraphs showing that the proposed method outperforms alternative
core-periphery detection algorithms, in particular those obtained by
transferring established graph methods to the hypergraph setting via clique
expansion.",2022-02-25,"Francesco Tudisco, Desmond J. Higham"
"A Deep Learning Approach for Network-wide Dynamic Traffic Prediction
  during Hurricane Evacuation","Proactive evacuation traffic management largely depends on real-time
monitoring and prediction of traffic flow at a high spatiotemporal resolution.
However, evacuation traffic prediction is challenging due to the uncertainties
caused by sudden changes in projected hurricane paths and consequently
household evacuation behavior. Moreover, modeling spatiotemporal traffic flow
patterns requires extensive data over a longer time period, whereas evacuations
typically last for 2 to 5 days. In this paper, we present a novel data-driven
approach for predicting evacuation traffic at a network scale. We develop a
dynamic graph convolution LSTM (DGCN-LSTM) model to learn the network dynamics
of hurricane evacuation. We first train the model for non-evacuation period
traffic data showing that the model outperforms existing deep learning models
for predicting non-evacuation period traffic with an RMSE value of 226.84.
However, when we apply the model for evacuation period, the RMSE value
increased to 1440.99. We overcome this issue by adopting a transfer learning
approach with additional features related to evacuation traffic demand such as
distance from the evacuation zone, time to landfall, and other zonal level
features to control the transfer of information (network dynamics) from
non-evacuation periods to evacuation periods. The final transfer learned
DGCN-LSTM model performs well to predict evacuation traffic flow (RMSE=399.69).
The implemented model can be applied to predict evacuation traffic over a
longer forecasting horizon (6 hour). It will assist transportation agencies to
activate appropriate traffic management strategies to reduce delays for
evacuating traffic.",2022-02-25,"Rezaur Rahman, Samiul Hasan"
"Construction of Large-Scale Misinformation Labeled Datasets from Social
  Media Discourse using Label Refinement","Malicious accounts spreading misinformation has led to widespread false and
misleading narratives in recent times, especially during the COVID-19 pandemic,
and social media platforms struggle to eliminate these contents rapidly. This
is because adapting to new domains requires human intensive fact-checking that
is slow and difficult to scale. To address this challenge, we propose to
leverage news-source credibility labels as weak labels for social media posts
and propose model-guided refinement of labels to construct large-scale, diverse
misinformation labeled datasets in new domains. The weak labels can be
inaccurate at the article or social media post level where the stance of the
user does not align with the news source or article credibility. We propose a
framework to use a detection model self-trained on the initial weak labels with
uncertainty sampling based on entropy in predictions of the model to identify
potentially inaccurate labels and correct for them using self-supervision or
relabeling. The framework will incorporate social context of the post in terms
of the community of its associated user for surfacing inaccurate labels towards
building a large-scale dataset with minimum human effort. To provide labeled
datasets with distinction of misleading narratives where information might be
missing significant context or has inaccurate ancillary details, the proposed
framework will use the few labeled samples as class prototypes to separate high
confidence samples into false, unproven, mixture, mostly false, mostly true,
true, and debunk information. The approach is demonstrated for providing a
large-scale misinformation dataset on COVID-19 vaccines.",2022-02-24,"Karishma Sharma, Emilio Ferrara, Yan Liu"
"The Challenge of Understanding What Users Want: Inconsistent Preferences
  and Engagement Optimization","Online platforms have a wealth of data, run countless experiments and use
industrial-scale algorithms to optimize user experience. Despite this, many
users seem to regret the time they spend on these platforms. One possible
explanation is misaligned incentives: platforms are not optimizing for user
happiness. We suggest the problem runs deeper, transcending the specific
incentives of any particular platform, and instead stems from a mistaken
foundational assumption: To understand what users want, platforms look at what
users do. Yet research has demonstrated, and personal experience affirms, that
we often make choices in the moment that are inconsistent with what we actually
want. In this work, we develop a model of media consumption where users have
inconsistent preferences. We consider a platform which simply wants to maximize
user utility, but only observes user engagement. We show how our model of
users' preference inconsistencies produces phenomena that are familiar from
everyday experience, but difficult to capture in traditional user interaction
models. A key ingredient in our model is a formulation for how platforms
determine what to show users: they optimize over a large set of potential
content (the content manifold) parametrized by underlying features of the
content. Whether improving engagement improves user welfare depends on the
direction of movement in the content manifold: for certain directions of
change, increasing engagement makes users less happy, while in other
directions, increasing engagement makes users happier. We characterize the
structure of content manifolds for which increasing engagement fails to
increase user utility. By linking these effects to abstractions of platform
design choices, our model thus creates a theoretical framework and vocabulary
in which to explore interactions between design, behavioral science, and social
media.",2022-02-23,"Jon Kleinberg, Sendhil Mullainathan, Manish Raghavan"
"MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation
  Social Network Dataset","Misinformation is becoming increasingly prevalent on social media and in news
articles. It has become so widespread that we require algorithmic assistance
utilising machine learning to detect such content. Training these machine
learning models require datasets of sufficient scale, diversity and quality.
However, datasets in the field of automatic misinformation detection are
predominantly monolingual, include a limited amount of modalities and are not
of sufficient scale and quality. Addressing this, we develop a data collection
and linking system (MuMiN-trawl), to build a public misinformation graph
dataset (MuMiN), containing rich social media data (tweets, replies, users,
images, articles, hashtags) spanning 21 million tweets belonging to 26 thousand
Twitter threads, each of which have been semantically linked to 13 thousand
fact-checked claims across dozens of topics, events and domains, in 41
different languages, spanning more than a decade. The dataset is made available
as a heterogeneous graph via a Python package (mumin). We provide baseline
results for two node classification tasks related to the veracity of a claim
involving social media, and demonstrate that these are challenging tasks, with
the highest macro-average F1-score being 62.55% and 61.45% for the two tasks,
respectively. The MuMiN ecosystem is available at
https://mumin-dataset.github.io/, including the data, documentation, tutorials
and leaderboards.",2022-02-23,"Dan Saattrup Nielsen, Ryan McConville"
How to optimize an academic team when the outlier member is leaving?,"An academic team is a highly-cohesive collaboration group of scholars, which
has been recognized as an effective way to improve scientific output in terms
of both quality and quantity. However, the high staff turnover brings about a
series of problems that may have negative influence on team performance. To
address this challenge, we first detect the tendency of the member who may
potentially leave. Here the outlierness is defined with respect to familiarity,
which is quantified by using collaboration intensity. It is assumed that if a
team member has a higher familiarity with scholars outside the team, then this
member might probably leave the team. To minimize the influence caused by the
leaving of such an outlier member, we propose an optimization solution to find
a proper candidate who can replace the outlier member. Based on random walk
with graph kernel, our solution involves familiarity matching, skill matching,
as well as structure matching. The proposed approach proves to be effective and
outperforms existing methods when applied to computer science academic teams.",2022-02-23,"Shuo Yu, Jiaying Liu, Feng Xia, Haoran Wei, Hanghang Tong"
"Exploring the effects of activity-preserving time dilation on the
  dynamic interplay of airborne contagion processes and temporal networks using
  an interaction-driven model","Contacts' temporal ordering and dynamics are crucial for understanding the
transmission of infectious diseases. We introduce an interaction-driven model
of an airborne disease over contact networks. We demonstrate our
interaction-driven contagion model, instantiated for COVID-19, over
history-maintaining random temporal networks and real-world contacts. We use it
to evaluate temporal, spatiotemporal, and spatial social distancing policies.
We find that a spatial distancing policy is mainly beneficial at the early
stages of a disease.
  We then continue to evaluate temporal social distancing, that is, timeline
dilation that maintains the activity potential. We expand our model to consider
the exposure to viral load, which we correlate with meetings' duration. Using
real-life contact data, we demonstrate the beneficial effect of timeline
dilation on overall infection rates.
  Our results demonstrate that given the same transmission level, there is a
decrease in the disease's infection rate and overall prevalence under timeline
dilation conditions. We further show that slow-spreading pathogens (i.e.,
require more prolonged exposure to infect) spread roughly at the same rate as
fast-spreading ones in highly active communities. This is surprising since
slower pathogens follow paths that include longer meetings, while faster
pathogens can potentially follow paths that include shorter meetings, which are
more common. Our results demonstrate that the temporal dynamics of a community
have a more significant effect on the spread of the disease than the
characteristics of the spreading processes.",2022-02-23,"Alex Abbey, Yanir Marmor, Yuval Shahar, Osnat Mokryn"
Message passing all the way up,"The message passing framework is the foundation of the immense success
enjoyed by graph neural networks (GNNs) in recent years. In spite of its
elegance, there exist many problems it provably cannot solve over given input
graphs. This has led to a surge of research on going ""beyond message passing"",
building GNNs which do not suffer from those limitations -- a term which has
become ubiquitous in regular discourse. However, have those methods truly moved
beyond message passing? In this position paper, I argue about the dangers of
using this term -- especially when teaching graph representation learning to
newcomers. I show that any function of interest we want to compute over graphs
can, in all likelihood, be expressed using pairwise message passing -- just
over a potentially modified graph, and argue how most practical implementations
subtly do this kind of trick anyway. Hoping to initiate a productive
discussion, I propose replacing ""beyond message passing"" with a more tame term,
""augmented message passing"".",2022-02-22,Petar Veličković
"Assessing the influence of French vaccine critics during the two first
  years of the COVID-19 pandemic","When the threat of COVID-19 became widely acknowledged, many hoped that this
epidemic would squash ""the anti-vaccine movement"". However, when vaccines
started arriving in rich countries at the end of 2020, it appeared that vaccine
hesitancy might be an issue even in the context of this major epidemic. Does it
mean that the mobilization of vaccine-critical activists on social media is one
of the main causes of this reticence to vaccinate against COVID-19? In this
paper, we wish to contribute to current work on vaccine hesitancy during the
COVID-19 epidemic by looking at one of the many mechanisms which can cause
reticence towards vaccines: the capacity of vaccine-critical activists to
influence a wider public on social media. We analyze the evolution of debates
over the COVID-19 vaccine on the French Twittosphere, during two first years of
the pandemic, with a particular attention to the spreading capacity of
vaccine-critical websites. We address two main questions: 1) Did
vaccine-critical contents gain ground during this period? 2) Who were the
central actors in the diffusion of these contents? While debates over vaccines
experienced a tremendous surge during this period, the share of
vaccine-critical contents in these debates remains stable except for a limited
number of short periods associated with specific events. Secondly, analyzing
the community structure of the re-tweets hyper-graph, we reconstruct the
mesoscale structure of the information flows, identifying and characterizing
the major communities of users. We analyze their role in the information
ecosystem: the largest right-wing community has a typical echo-chamber behavior
collecting all the vaccine-critical tweets from outside and recirculating it
inside the community. The smaller left-wing community is less permeable to
vaccine-critical contents but, has a large capacity to spread it once adopted.",2022-02-22,"Mauro Faccin, Floriana Gargiulo, Laëtitia Atlani-Duault, Jeremy K. Ward"
Relational Causal Models with Cycles:Representation and Reasoning,"Causal reasoning in relational domains is fundamental to studying real-world
social phenomena in which individual units can influence each other's traits
and behavior. Dynamics between interconnected units can be represented as an
instantiation of a relational causal model; however, causal reasoning over such
instantiation requires additional templating assumptions that capture feedback
loops of influence. Previous research has developed lifted representations to
address the relational nature of such dynamics but has strictly required that
the representation has no cycles. To facilitate cycles in relational
representation and learning, we introduce relational $\sigma$-separation, a new
criterion for understanding relational systems with feedback loops. We also
introduce a new lifted representation, $\sigma$-abstract ground graph which
helps with abstracting statistical independence relations in all possible
instantiations of the cyclic relational model. We show the necessary and
sufficient conditions for the completeness of $\sigma$-AGG and that relational
$\sigma$-separation is sound and complete in the presence of one or more cycles
with arbitrary length. To the best of our knowledge, this is the first work on
representation of and reasoning with cyclic relational causal models.",2022-02-22,"Ragib Ahsan, David Arbour, Elena Zheleva"
"Don't be a Victim During a Pandemic! Analysing Security and Privacy
  Threats in Twitter During COVID-19","There has been a huge spike in the usage of social media platforms during the
COVID-19 lockdowns. These lockdown periods have resulted in a set of new
cybercrimes, thereby allowing attackers to victimise social media users with a
range of threats. This paper performs a large-scale study to investigate the
impact of a pandemic and the lockdown periods on the security and privacy of
social media users. We analyse 10.6 Million COVID-related tweets from 533 days
of data crawling and investigate users' security and privacy behaviour in three
different periods (i.e., before, during, and after the lockdown). Our study
shows that users unintentionally share more personal identifiable information
when writing about the pandemic situation (e.g., sharing nearby coronavirus
testing locations) in their tweets. The privacy risk reaches 100% if a user
posts three or more sensitive tweets about the pandemic. We investigate the
number of suspicious domains shared on social media during different phases of
the pandemic. Our analysis reveals an increase in the number of suspicious
domains during the lockdown compared to other lockdown phases. We observe that
IT, Search Engines, and Businesses are the top three categories that contain
suspicious domains. Our analysis reveals that adversaries' strategies to
instigate malicious activities change with the country's pandemic situation.",2022-02-21,"Bibhas Sharma, Ishan Karunanayake, Rahat Masood, Muhammad Ikram"
PGE: Robust Product Graph Embedding Learning for Error Detection,"Although product graphs (PGs) have gained increasing attentions in recent
years for their successful applications in product search and recommendations,
the extensive power of PGs can be limited by the inevitable involvement of
various kinds of errors. Thus, it is critical to validate the correctness of
triples in PGs to improve their reliability. Knowledge graph (KG) embedding
methods have strong error detection abilities. Yet, existing KG embedding
methods may not be directly applicable to a PG due to its distinct
characteristics: (1) PG contains rich textual signals, which necessitates a
joint exploration of both text information and graph structure; (2) PG contains
a large number of attribute triples, in which attribute values are represented
by free texts. Since free texts are too flexible to define entities in KGs,
traditional way to map entities to their embeddings using ids is no longer
appropriate for attribute value representation; (3) Noisy triples in a PG
mislead the embedding learning and significantly hurt the performance of error
detection. To address the aforementioned challenges, we propose an end-to-end
noise-tolerant embedding learning framework, PGE, to jointly leverage both text
information and graph structure in PG to learn embeddings for error detection.
Experimental results on real-world product graph demonstrate the effectiveness
of the proposed framework comparing with the state-of-the-art approaches.",2022-02-20,"Kewei Cheng, Xian Li, Yifan Ethan Xu, Xin Luna Dong, Yizhou Sun"
Online Platforms and the Fair Exposure Problem Under Homophily,"In the wake of increasing political extremism, online platforms have been
criticized for contributing to polarization. One line of criticism has focused
on echo chambers and the recommended content served to users by these
platforms. In this work, we introduce the fair exposure problem: given limited
intervention power of the platform, the goal is to enforce balance in the
spread of content (e.g., news articles) among two groups of users through
constraints similar to those imposed by the Fairness Doctrine in the United
States in the past. Groups are characterized by different affiliations (e.g.,
political views) and have different preferences for content. We develop a
stylized framework that models intra- and intergroup content propagation under
homophily, and we formulate the platform's decision as an optimization problem
that aims at maximizing user engagement, potentially under fairness
constraints. Our main notion of fairness requires that each group see a mixture
of their preferred and non-preferred content, encouraging information
diversity. Promoting such information diversity is often viewed as desirable
and a potential means for breaking out of harmful echo chambers. We study the
solutions to both the fairness-agnostic and fairness-aware problems. We prove
that a fairness-agnostic approach inevitably leads to group-homogeneous
targeting by the platform. This is only partially mitigated by imposing
fairness constraints: we show that there exist optimal fairness-aware solutions
which target one group with different types of content and the other group with
only one type that is not necessarily the group's most preferred. Finally,
using simulations with real-world data, we study the system dynamics and
quantify the price of fairness.",2022-02-20,"Jakob Schoeffer, Alexander Ritchie, Keziah Naggita, Faidra Monachou, Jessie Finocchiaro, Marc Juarez"
"Social network analysis of Staphylococcus aureus carriage in a general
  youth population","Staphylococcus aureus nasal carriage increases risk of infection and has been
associated with lifestyle behavior and biological host characteristics. We used
social network analysis to evaluate whether contacts have the same S. aureus
genotype, or whether contagiousness is an indirect effect of contacts sharing
the same lifestyle or characteristics.
  The Fit Futures 1 study collected data on social contact among 1038 first
level students in the same high school district in Norway. S. aureus persistent
carriage was determined from two nasal swab cultures and genotype from
spa-typing of a positive throat swab culture. Bootstrap, t-tests, logistic
regression, and autocorrelation were used to evaluate social network influence
on host risk factors and S. aureus carriage.
  Both persistent carriage and spa-type were transmitted in the social network
(p<0.001). The probability of carriage increased by 3.7% and 5.0% for each
additional S. aureus positive friend, in univariable regression and
multivariable autocorrelation analysis respectively. Male sex was associated
with a 15% lower risk of transmission compared to women, although the
prevalence of carriage was higher for men (36% versus 24%). Medium physical
activity, medium and high alcohol-use, and normal-weight students had higher
number of contacts, and increased risk of transmission (p<0.002).
  We demonstrate direct social transmission of S. aureus in a general youth
population. Lifestyle factors are associated with risk of transmission
suggesting indirect social group effects from having more similar environmental
exposures. The predominance in carriage is determined by sex-specific
predisposing host characteristics as social transmission is less frequent than
in females. Better understanding of how social interactions influence S. aureus
carriage dynamics in the population is important for developing new preventive
measures.",2022-02-17,"Dina Benedicte Stensen, Rafael Adolfo Nozal Cañadas, Lars Småbrekke, Karina Olsen, Christopher Sivert Nielsen, Kristian Svendsen, Anne Merethe Hanssen, Johanna Sollid, Gunnar Skov Simonsen, Lars Ailo Bongo, Anne-Sofie Furberg"
Listing Maximal k-Plexes in Large Real-World Graphs,"Listing dense subgraphs in large graphs plays a key task in varieties of
network analysis applications like community detection. Clique, as the densest
model, has been widely investigated. However, in practice, communities rarely
form as cliques for various reasons, e.g., data noise. Therefore, $k$-plex, --
graph with each vertex adjacent to all but at most $k$ vertices, is introduced
as a relaxed version of clique. Often, to better simulate cohesive communities,
an emphasis is placed on connected $k$-plexes with small $k$. In this paper, we
continue the research line of listing all maximal $k$-plexes and maximal
$k$-plexes of prescribed size. Our first contribution is algorithm ListPlex
that lists all maximal $k$-plexes in $O^*(\gamma^D)$ time for each constant
$k$, where $\gamma$ is a value related to $k$ but strictly smaller than 2, and
$D$ is the degeneracy of the graph that is far less than the vertex number $n$
in real-word graphs. Compared to the trivial bound of $2^n$, the improvement is
significant, and our bound is better than all previously known results. In
practice, we further use several techniques to accelerate listing $k$-plexes of
a given size, such as structural-based prune rules, cache-efficient data
structures, and parallel techniques. All these together result in a very
practical algorithm. Empirical results show that our approach outperforms the
state-of-the-art solutions by up to orders of magnitude.",2022-02-17,"Zhengren Wang, Yi Zhou, Mingyu Xiao, Bakhadyr Khoussainov"
"Conscious Commerce -- Digital Nudging and Sustainable E-commerce
  Purchase Decisions","So-called 'fast fashion' consumption, amplified through cost-effective
e-commerce, constitutes a major factor negatively impacting climate change. A
recently noted strategy to motivate consumers to more sustainable decisions is
digital nudging. This paper explores the capability of digital nudging in the
context of green fashion e-commerce. To do so, digital default and social norm
nudges are tested in an experimental setting of green fashion purchases. An
online experiment (n=320) was conducted, simulating an online retail scenario.
Results failed to show statistically significant relationships between nudging
strategies and purchase decisions. However, explorative analyses show a
backfiring effect for the combination of nudges and thus, reveal a hitherto
neglected impact of participants' identification on the effectiveness of the
digital nudging strategies. Consequently, this study contributes to digital
nudging literature and informs practice with new insights on effective choice
architectures in e-commerce.",2022-02-17,"Milad Mirbabaie, Julian Marx, Johanna Germies"
"Schedule-based Analysis of Transmission Risk in Public Transportation
  Systems","Airborne diseases, including COVID-19, raise the question of transmission
risk in public transportation systems. However, quantitative analysis of the
effectiveness of transmission risk mitigation methods in public transportation
is lacking. The paper develops a transmission risk modeling framework based on
the Wells-Riley model using as inputs transit operating characteristics,
schedule, Origin-Destination (OD) demand, and virus characteristics. The model
is sensitive to various factors that operators can control, as well as external
factors that may be subject of broader policy decisions (e.g. mask wearing).
The model is utilized to assess transmission risk as a function of OD flows,
planned operations, and factors such as mask-wearing, ventilation, and
infection rates. Using actual data from the Massachusetts Bay Transportation
Authority (MBTA) Red Line, the paper explores the transmission risk under
different infection rate scenarios, both in magnitude and spatial
characteristics. The paper assesses the combined impact from viral load related
factors and passenger load factors. Increasing frequency can mitigate
transmission risk, but cannot fully compensate for increases in infection
rates. Imbalanced passenger distribution on different cars of a train is shown
to increase the overall system-wide infection probability. Spatial infection
rate patterns should also be taken into account during policymaking as it is
shown to impact transmission risk. For lines with branches, demand distribution
among the branches is important and headway allocation adjustment among
branches to balance the load on trains to different branches can help reduce
risk.",2022-02-17,"Jiali Zhou, Haris N. Koutsopoulos"
"Collaborative Self Organizing Map with DeepNNs for Fake Task Prevention
  in Mobile Crowdsensing","Mobile Crowdsensing (MCS) is a sensing paradigm that has transformed the way
that various service providers collect, process, and analyze data. MCS offers
novel processes where data is sensed and shared through mobile devices of the
users to support various applications and services for cutting-edge
technologies. However, various threats, such as data poisoning, clogging task
attacks and fake sensing tasks adversely affect the performance of MCS systems,
especially their sensing, and computational capacities. Since fake sensing task
submissions aim at the successful completion of the legitimate tasks and mobile
device resources, they also drain MCS platform resources. In this work, Self
Organizing Feature Map (SOFM), an artificial neural network that is trained in
an unsupervised manner, is utilized to pre-cluster the legitimate data in the
dataset, thus fake tasks can be detected more effectively through less
imbalanced data where legitimate/fake tasks ratio is lower in the new dataset.
After pre-clustered legitimate tasks are separated from the original dataset,
the remaining dataset is used to train a Deep Neural Network (DeepNN) to reach
the ultimate performance goal. Pre-clustered legitimate tasks are appended to
the positive prediction outputs of DeepNN to boost the performance of the
proposed technique, which we refer to as pre-clustered DeepNN (PrecDeepNN). The
results prove that the initial average accuracy to discriminate the legitimate
and fake tasks obtained from DeepNN with the selected set of features can be
improved up to an average accuracy of 0.9812 obtained from the proposed machine
learning technique.",2022-02-17,"Murat Simsek, Burak Kantarci, Azzedine Boukerche"
A deep dive into the consistently toxic 1% of Twitter,"Misbehavior in online social networks (OSN) is an ever-growing phenomenon.
The research to date tends to focus on the deployment of machine learning to
identify and classify types of misbehavior such as bullying, aggression, and
racism to name a few. The main goal of identification is to curb natural and
mechanical misconduct and make OSNs a safer place for social discourse. Going
beyond past works, we perform a longitudinal study of a large selection of
Twitter profiles, which enables us to characterize profiles in terms of how
consistently they post highly toxic content. Our data spans 14 years of tweets
from 122K Twitter profiles and more than 293M tweets. From this data, we
selected the most extreme profiles in terms of consistency of toxic content and
examined their tweet texts, and the domains, hashtags, and URLs they shared. We
found that these selected profiles keep to a narrow theme with lower diversity
in hashtags, URLs, and domains, they are thematically similar to each other (in
a coordinated manner, if not through intent), and have a high likelihood of
bot-like behavior (likely to have progenitors with intentions to influence).
Our work contributes a substantial and longitudinal online misbehavior dataset
to the research community and establishes the consistency of a profile's toxic
behavior as a useful factor when exploring misbehavior as potential accessories
to influence operations on OSNs.",2022-02-16,"Hina Qayyum, Benjamin Zi Hao Zhao, Ian D. Wood, Muhammad Ikram, Mohamed Ali Kaafar, Nicolas Kourtellis"
"Learning Asymmetric Embedding for Attributed Networks via Convolutional
  Neural Network","Recently network embedding has gained increasing attention due to its
advantages in facilitating network computation tasks such as link prediction,
node classification and node clustering. The objective of network embedding is
to represent network nodes in a low-dimensional vector space while retaining as
much information as possible from the original network including structural,
relational, and semantic information. However, asymmetric nature of directed
networks poses many challenges as how to best preserve edge directions in the
embedding process. Here, we propose a novel deep asymmetric attributed network
embedding model based on convolutional graph neural network, called AAGCN. The
main idea is to maximally preserve the asymmetric proximity and asymmetric
similarity of directed attributed networks. AAGCN introduces two neighbourhood
feature aggregation schemes to separately aggregate the features of a node with
the features of its in- and out- neighbours. Then, it learns two embedding
vectors for each node, one source embedding vector and one target embedding
vector. The final representations are the results of concatenating source and
target embedding vectors. We test the performance of AAGCN on three real-world
networks for network reconstruction, link prediction, node classification and
visualization tasks. The experimental results show the superiority of AAGCN
against state-of-the-art embedding methods.",2022-02-13,"Mohammadreza Radmanesh, Hossein Ghorbanzadeh, Ahmad Asgharian Rezaei, Mahdi Jalili, Xinghuo Yu"
"Vital Node Identification in Complex Networks Using a Machine
  Learning-Based Approach","Vital node identification is the problem of finding nodes of highest
importance in complex networks. This problem has crucial applications in
various contexts such as viral marketing or controlling the propagation of
virus or rumours in real-world networks. Existing approaches for vital node
identification mainly focus on capturing the importance of a node through a
mathematical expression which directly relates structural properties of the
node to its vitality. Although these heuristic approaches have achieved good
performance in practice, they have weak adaptability, and their performance is
limited to specific settings and certain dynamics. Inspired by the power of
machine learning models for efficiently capturing different types of patterns
and relations, we propose a machine learning-based, data driven approach for
vital node identification. The main idea is to train the model with a small
portion of the graph, say 0.5% of the nodes, and do the prediction on the rest
of the nodes. The ground-truth vitality for the train data is computed by
simulating the SIR diffusion method starting from the train nodes. We use
collective feature engineering where each node in the network is represented by
incorporating elements of its connectivity, degree and extended coreness.
Several machine learning models are trained on the node representations, but
the best results are achieved by a Support Vector Regression machine with RBF
kernel. The empirical results confirms that the proposed model outperforms
state-of-the-art models on a selection of datasets, while it also shows more
adaptability to changes in the dynamics parameters.",2022-02-13,"Ahmad Asgharian Rezaei, Justin Munoz, Mahdi Jalili, Hamid Khayyam"
"Wildfires and Climate Change: What does social media tell us on linkages
  and public understanding? (Preliminary White Paper, February 11, 2022)","Wildfires are increasing in frequency and size across the western U.S., with
some of the deadliest fires in recorded history occurring in the last few
years. The public, as well as elected officials, use social media to convey
opinions and knowledge on topics that are impacting their communities. We
utilize the platform Twitter to assess connections of wildfire to climate
change during recent events and evaluate the differences in knowledge between
the public and their government officials. Results show some linkages of
wildfire cause and effect, although this relationship was not large (only 5%)
and was even lower at the governmental level (2%), suggesting that a broader
number of the public and government did not relate climate change to recent
extreme wildfires.",2022-02-12,"Reza Abdi, Terri S. Hogue"
"Designing a Social Media Analytics Dashboard for Government Agency
  Crisis Communications","Social media have become a valuable source for extracting data about societal
crises and an important outlet to disseminate official information. Government
agencies are increasingly turning to social media to use it as a mouthpiece in
times of crisis. Gaining intelligence through social media analytics, however,
remains a challenge for government agencies, e.g. due to a lack of training and
instruments. To mitigate this shortcoming, government agencies need tools that
support them in analysing social media data for the public good. This paper
presents a design science research approach that guides the development of a
social media analytics dashboard for a regional government agency. Preliminary
results from a workshop and the resulting design of a first prototype are
reported. A user-friendly and responsive design that is secure, flexible, and
quick in use could identified as requirements, as well as information display
of regional discussion statistics, sentiment, and emerging topics.",2022-02-11,"Ali Sercan Basyurt, Julian Marx, Stefan Stieglitz, Milad Mirbabaie"
"Characterizing, Detecting, and Predicting Online Ban Evasion","Moderators and automated methods enforce bans on malicious users who engage
in disruptive behavior. However, malicious users can easily create a new
account to evade such bans. Previous research has focused on other forms of
online deception, like the simultaneous operation of multiple accounts by the
same entities (sockpuppetry), impersonation of other individuals, and studying
the effects of de-platforming individuals and communities. Here we conduct the
first data-driven study of ban evasion, i.e., the act of circumventing bans on
an online platform, leading to temporally disjoint operation of accounts by the
same user.
  We curate a novel dataset of 8,551 ban evasion pairs (parent, child)
identified on Wikipedia and contrast their behavior with benign users and
non-evading malicious users. We find that evasion child accounts demonstrate
similarities with respect to their banned parent accounts on several behavioral
axes - from similarity in usernames and edited pages to similarity in content
added to the platform and its psycholinguistic attributes. We reveal key
behavioral attributes of accounts that are likely to evade bans. Based on the
insights from the analyses, we train logistic regression classifiers to detect
and predict ban evasion at three different points in the ban evasion lifecycle.
Results demonstrate the effectiveness of our methods in predicting future
evaders (AUC = 0.78), early detection of ban evasion (AUC = 0.85), and matching
child accounts with parent accounts (MRR = 0.97). Our work can aid moderators
by reducing their workload and identifying evasion pairs faster and more
efficiently than current manual and heuristic-based approaches. Dataset is
available https://github.com/srijankr/ban_evasion.",2022-02-10,"Manoj Niverthi, Gaurav Verma, Srijan Kumar"
Social interactions affect discovery processes,"Our network of acquaintances determines how we get exposed to ideas,
products, or cultural artworks (books, music, movies, etc.). Though this
principle is part of our common sense, little is known about the specific
pathways through which our peers influence our discovery processes and our
experience of the new. Here, we fill this gap by investigating a data set
containing the whole listening histories of a large, socially connected sample
of users from the online music platform \emph{Last.fm}. We demonstrate that
users exhibit highly heterogeneous discovery rates of new songs and artists and
that their social neighborhood significantly influences their behavior. More
explorative users tend to interact with peers more prone to explore new
content. We capture this phenomenology in a modeling scheme where users are
represented by random walkers exploring a graph of songs or artists and
interacting with each other through their social links. Even starting from a
uniform population of agents (no natural differences among the individuals),
our model predicts the emergence of strong heterogeneous exploration patterns,
with users clustered according to their musical tastes and propensity to
explore. We contend our approach can pave the way to a quantitative approach to
collective discovery processes.",2022-02-10,"Gabriele Di Bona, Enrico Ubaldi, Iacopo Iacopini, Bernardo Monechi, Vito Latora, Vittorio Loreto"
"Networks and Identity Drive Geographic Properties of the Diffusion of
  Linguistic Innovation","Adoption of cultural innovation (e.g., music, beliefs, language) is often
geographically correlated, with adopters largely residing within the boundaries
of relatively few well-studied, socially significant areas. These cultural
regions are often hypothesized to be the result of either (i) identity
performance driving the adoption of cultural innovation, or (ii) homophily in
the networks underlying diffusion. In this study, we show that demographic
identity and network topology are both required to model the diffusion of
innovation, as they play complementary roles in producing its spatial
properties. We develop an agent-based model of cultural adoption, and validate
geographic patterns of transmission in our model against a novel dataset of
innovative words that we identify from a 10% sample of Twitter. Using our
model, we are able to directly compare a combined network + identity model of
diffusion to simulated network-only and identity-only counterfactuals --
allowing us to test the separate and combined roles of network and identity.
While social scientists often treat either network or identity as the core
social structure in modeling culture change, we show that key geographic
properties of diffusion actually depend on both factors as each one influences
different mechanisms of diffusion. Specifically, the network principally drives
spread among urban counties via weak-tie diffusion, while identity plays a
disproportionate role in transmission among rural counties via strong-tie
diffusion. Diffusion between urban and rural areas, a key component in
innovation diffusing nationally, requires both network and identity. Our work
suggests that models must integrate both factors in order to understand and
reproduce the adoption of innovation.",2022-02-10,"Aparna Ananthasubramaniam, David Jurgens, Daniel M. Romero"
"Erasing Labor with Labor: Dark Patterns and Lockstep Behaviors on Google
  Play","Google Play's policy forbids the use of incentivized installs, ratings, and
reviews to manipulate the placement of apps. However, there still exist apps
that incentivize installs for other apps on the platform. To understand how
install-incentivizing apps affect users, we examine their ecosystem through a
socio-technical lens and perform a mixed-methods analysis of their reviews and
permissions. Our dataset contains 319K reviews collected daily over five months
from 60 such apps that cumulatively account for over 160.5M installs. We
perform qualitative analysis of reviews to reveal various types of dark
patterns that developers incorporate in install-incentivizing apps,
highlighting their normative concerns at both user and platform levels.
Permissions requested by these apps validate our discovery of dark patterns,
with over 92% apps accessing sensitive user information. We find evidence of
fraudulent reviews on install-incentivizing apps, following which we model them
as an edge stream in a dynamic bipartite graph of apps and reviewers. Our
proposed reconfiguration of a state-of-the-art microcluster anomaly detection
algorithm yields promising preliminary results in detecting this fraud. We
discover highly significant lockstep behaviors exhibited by reviews that aim to
boost the overall rating of an install-incentivizing app. Upon evaluating the
50 most suspicious clusters of boosting reviews detected by the algorithm, we
find (i) near-identical pairs of reviews across 94% (47 clusters), and (ii)
over 35% (1,687 of 4,717 reviews) present in the same form near-identical pairs
within their cluster. Finally, we conclude with a discussion on how fraud is
intertwined with labor and poses a threat to the trust and transparency of
Google Play.",2022-02-09,"Ashwin Singh, Arvindh Arun, Ayushi Jain, Pooja Desur, Pulak Malhotra, Duen Horng Chau, Ponnurangam Kumaraguru"
"Privacy Concerns Raised by Pervasive User Data Collection From
  Cyberspace and Their Countermeasures","The virtual dimension called `Cyberspace' built on internet technologies has
served people's daily lives for decades. Now it offers advanced services and
connected experiences with the developing pervasive computing technologies that
digitise, collect, and analyse users' activity data. This changes how user
information gets collected and impacts user privacy at traditional cyberspace
gateways, including the devices carried by users for daily use. This work
investigates the impacts and surveys privacy concerns caused by this data
collection, namely identity tracking from browsing activities, user input data
disclosure, data accessibility in mobile devices, security of delicate data
transmission, privacy in participating sensing, and identity privacy in
opportunistic networks. Each of the surveyed privacy concerns is discussed in a
well-defined scope according to the impacts mentioned above. Existing
countermeasures are also surveyed and discussed, which identifies corresponding
research gaps. To complete the perspectives, three complex open problems,
namely trajectory privacy, privacy in smart metering, and involuntary privacy
leakage with ambient intelligence, are briefly discussed for future research
directions before a succinct conclusion to our survey at the end.",2022-02-09,"Yinhao Jiang, Ba Dung Le, Tanveer Zia, Praveen Gauravaram"
Spotting Anomalous Trades in NFT Markets: The Case of NBA Topshot,"Non-Fungible Token (NFT) markets are one of the fastest growing digital
markets today, with the sales during the third quarter of 2021 exceeding $10
billions! Nevertheless, these emerging markets - similar to traditional
emerging marketplaces - can be seen as a great opportunity for illegal
activities (e.g., money laundering, sale of illegal goods etc.). In this study
we focus on a specific marketplace, namely NBA TopShot, that facilitates the
purchase and (peer-to-peer) trading of sports collectibles. Our objective is to
build a framework that is able to label peer-to-peer transactions on the
platform as anomalous or not. To achieve our objective we begin by building a
model for the profit to be made by selling a specific collectible on the
platform. We then use RFCDE - a random forest model for the conditional density
of the dependent variable - to model the errors from the profit models. This
step allows us to estimate the probability of a transaction being anomalous. We
finally label as anomalous any transaction whose aforementioned probability is
less than 1%. Given the absence of ground truth for evaluating the model in
terms of its classification of transactions, we analyze the trade networks
formed from these anomalous transactions and compare it with the full trade
network of the platform. Our results indicate that these two networks are
statistically different when it comes to network metrics such as, edge density,
closure, node centrality and node degree distribution. This network analysis
provides additional evidence that these transactions do not follow the same
patterns that the rest of the trades on the platform follow. However, we would
like to emphasize here that this does not mean that these transactions are also
illegal. These transactions will need to be further audited from the
appropriate entities to verify whether or not they are illicit.",2022-02-08,"Konstantinos Pelechrinis, Xin Liu, Prashant Krishnamurthy, Amy Babay"
"Impact of Network Centrality and Income on Slowing Infection Spread
  after Outbreaks","The COVID-19 pandemic has shed light on how the spread of infectious diseases
worldwide are importantly shaped by both human mobility networks and
socio-economic factors. Few studies, however, have examined the interaction of
mobility networks with socio-spatial inequalities to understand the spread of
infection. We introduce a novel methodology, called the Infection Delay Model,
to calculate how the arrival time of an infection varies geographically,
considering both effective distance-based metrics and differences in regions'
capacity to isolate -- a feature associated with socioeconomic inequalities. To
illustrate an application of the Infection Delay Model, this paper integrates
household travel survey data with cell phone mobility data from the S\~ao Paulo
metropolitan region to assess the effectiveness of lockdowns to slow the spread
of COVID-19. Rather than operating under the assumption that the next pandemic
will begin in the same region as the last, the model estimates infection delays
under every possible outbreak scenario, allowing for generalizable insights
into the effectiveness of interventions to delay a region's first case. The
model sheds light on how the effectiveness of lockdowns to slow the spread of
disease is influenced by the interaction of mobility networks and
socio-economic levels. We find that a negative relationship emerges between
network centrality and the infection delay after lockdown, irrespective of
income. Furthermore, for regions across all income and centrality levels,
outbreaks starting in less central locations were more effectively slowed by a
lockdown. Using the Infection Delay Model, this paper identifies and quantifies
a new dimension of disease risk faced by those most central in a mobility
network.",2022-02-08,"Shiv G. Yücel, Rafael H. M. Pereira, Pedro S. Peixoto, Chico Q. Camargo"
Temporal Walk Centrality: Ranking Nodes in Evolving Networks,"We propose the Temporal Walk Centrality, which quantifies the importance of a
node by measuring its ability to obtain and distribute information in a
temporal network. In contrast to the widely-used betweenness centrality, we
assume that information does not necessarily spread on shortest paths but on
temporal random walks that satisfy the time constraints of the network. We show
that temporal walk centrality can identify nodes playing central roles in
dissemination processes that might not be detected by related betweenness
concepts and other common static and temporal centrality measures. We propose
exact and approximation algorithms with different running times depending on
the properties of the temporal network and parameters of our new centrality
measure. A technical contribution is a general approach to lift existing
algebraic methods for counting walks in static networks to temporal networks.
Our experiments on real-world temporal networks show the efficiency and
accuracy of our algorithms. Finally, we demonstrate that the rankings by
temporal walk centrality often differ significantly from those of other
state-of-the-art temporal centralities.",2022-02-08,"Lutz Oettershagen, Petra Mutzel, Nils M. Kriege"
"Understanding the Trustworthiness Management in the Social Internet of
  Things: A Survey","The next generation of the Internet of Things (IoT) facilitates the
integration of the notion of social networking into smart objects (i.e.,
things) in a bid to establish the social network of interconnected objects.
This integration has led to the evolution of a promising and emerging paradigm
of Social Internet of Things (SIoT), wherein the smart objects act as social
objects and intelligently impersonate the social behaviour similar to that of
humans. These social objects are capable of establishing social relationships
with the other objects in the network and can utilize these relationships for
service discovery. Trust plays a significant role to achieve the common goal of
trustworthy collaboration and cooperation among the objects and provide
systems' credibility and reliability. In SIoT, an untrustworthy object can
disrupt the basic functionality of a service by delivering malicious messages
and adversely affect the quality and reliability of the service. In this
survey, we present a holistic view of trustworthiness management for SIoT. The
essence of trust in various disciplines has been discussed along with the Trust
in SIoT followed by a detailed study on trust management components in SIoT.
Furthermore, we analyzed and compared the trust management schemes by primarily
categorizing them into four groups in terms of their strengths, limitations,
trust management components employed in each of the referred trust management
schemes, and the performance of these studies vis-a-vis numerous trust
evaluation dimensions. Finally, we have discussed the future research
directions of the emerging paradigm of SIoT, particularly for trustworthiness
management in SIoT.",2022-02-08,"Subhash Sagar, Adnan Mahmood, Quan Z. Sheng, Jitander Kumar Pabani, Wei Emma Zhang"
"Link Prediction of Artificial Intelligence Concepts using Low
  Computational Power","This paper presents an approach proposed for the Science4cast 2021
competition, organized by the Institute of Advanced Research in Artificial
Intelligence, whose main goal was to predict the likelihood of future
associations between machine learning concepts in a semantic network. The
developed methodology corresponds to a solution for a scenario of availability
of low computational power only, exploiting the extraction of low order
topological features and its incorporation in an optimized classifier to
estimate the degree of future connections between the nodes. The reasons that
motivated the developed methodologies will be discussed, as well as some
results, limitations and suggestions of improvements.",2022-02-07,Francisco Valente
"COVID-19 and Influenza Joint Forecasts Using Internet Search Information
  in the United States","As COVID-19 pandemic progresses, severe flu seasons may happen alongside an
increase in cases in cases and death of COVID-19, causing severe burdens on
health care resources and public safety. A consequence of a twindemic may be a
mixture of two different infections in the same person at the same time,
""flurona"". Admist the raising trend of ""flurona"", forecasting both influenza
outbreaks and COVID-19 waves in a timely manner is more urgent than ever, as
accurate joint real-time tracking of the twindemic aids health organizations
and policymakers in adequate preparation and decision making. Under the current
pandemic, state-of-art influenza and COVID-19 forecasting models carry valuable
domain information but face shortcomings under current complex disease
dynamics, such as similarities in symptoms and public healthcare seeking
patterns of the two diseases. Inspired by the inner-connection between
influenza and COVID-19 activities, we propose ARGOX-Joint-Ensemble which allows
us to combine historical influenza and COVID-19 disease forecasting models to a
new ensemble framework that handles scenarios where flu and COVID co-exist. Our
framework is able to emphasize learning from COVID-related or influenza
signals, through a winner-takes-all ensemble fashion. Moreover, our experiments
demonstrate that our approach is successful in adapting past influenza
forecasting models to the current pandemic, while improving upon previous
COVID-19 forecasting models, by steadily outperforming alternative benchmark
methods, and remaining competitive with publicly available models.",2022-02-05,"Simin Ma, Shaoyang Ning, Shihao Yang"
"Facebook's Architecture Undermines Vaccine Misinformation Removal
  Efforts","Misinformation promotes distrust in science, undermines public health, and
may drive civil unrest. Vaccine misinformation, in particular, has stalled
efforts to overcome the COVID-19 pandemic, prompting social media platforms'
attempts to reduce it. Some have questioned whether ""soft"" content moderation
remedies -- e.g., flagging and downranking misinformation -- were successful,
suggesting that the addition of ""hard"" content remedies -- e.g., deplatforming
and content bans -- is necessary. We therefore examined whether Facebook's
vaccine misinformation content removal policies were effective. Here, we show
that Facebook's policies reduced the number of anti-vaccine posts but also
caused several perverse effects: pro-vaccine content was also removed,
engagement with remaining anti-vaccine content repeatedly recovered to
pre-policy levels, and this content became more misinformative, more
politically polarised, and more likely to be seen in users' newsfeeds. We
explain these results as an unintended consequence of Facebook's design goal:
promoting community formation. Members of communities dedicated to vaccine
refusal appear to seek out misinformation from multiple sources. Community
administrators make use of several channels afforded by the Facebook platform
to disseminate misinformation. Our findings suggest the need to address how
social media platform architecture enables community formation and mobilisation
around misinformative topics when managing the spread of online content.",2022-02-04,"David A. Broniatowski, Jiayan Gu, Amelia M. Jamison, Joseph R. Simons, Lorien C. Abroms"
"Sensor technologies in cancer research for new directions in diagnosis
  and treatment: and exploratory analysis","The goal of this study is an exploratory analysis concerning main sensor
technologies applied in cancer research to detect new directions in diagnosis
and treatments. The study focused on types of cancer having a high incidence
and mortality worldwide: breast, lung, colorectal and prostate. Data of the Web
of Science (WOS) core collection database are used to retrieve articles related
to sensor technologies and cancer research over 1991-2021 period. We utilized
Gephi software version 0.9.2 to visualize the co-word networks of the
interaction between sensor technologies and cancers under study. Results show
main clusters of interaction per typology of cancer. Biosensor is the only type
of sensor that plays an essential role in all types of cancer: breast cancer,
lung cancer, prostate cancer, and colorectal cancer. Electrochemical sensor is
applied in all types of cancer under study except lung cancer. Electrochemical
biosensor is used in breast cancer, lung cancer, and prostate cancer research
but not colorectal cancer. Optical sensor can also be considered one of the
sensor technologies that significantly is used in breast cancer, prostate
cancer, and colorectal cancer. This study shows that this type of sensor is
applied in more diversified approaches. Moreover, the oxygen sensor is mostly
studied in lung cancer and breast cancer due to the usage in breath analysis
for the treatment process. Finally, Cmos sensor is a technology used mainly in
lung cancer and colorectal cancer. Results here suggest new directions for the
evolution of science and technology of sensors in cancer research to support
innovation and research policy directed to new technological trajectories
having a potential of accelerated growth and positive social impact for
diagnosis and treatments of cancer.",2022-02-04,"Mario Coccia, Saeed Roshani, Melika Mosleh"
Unsupervised Behaviour Analysis of News Consumption in Turkish Media,"Clickstream data, which come with a massive volume generated by human
activities on websites, have become a prominent feature for identifying
readers' characteristics by newsrooms after the digitization of news outlets.
Although the nature of clickstream data has a similar logic within websites, it
has inherent limitations in recognizing human behaviours when looking from a
broad perspective, which brings the need to limit the problem in niche areas.
This study investigates the anonymized readers' click activities on the
organizations' websites to identify news consumption patterns following
referrals from Twitter,who incidentally reach but propensity is mainly routed
news content. Methodologies for ensemble cluster analysis with mixed-type
embedding strategies are applied and compared to find similar reader groups and
interests independent of time. Various internal validation perspectives are
used to determine the optimality of the quality of clusters, where the Calinski
Harabasz Index (CHI) is found to give a generalizable result. Our findings
demonstrate that clustering a mixed-type dataset approaches the optimal
internal validation scores, which we define to discriminate the clusters and
algorithms considering applied strategies when embedded by Uniform Manifold
Approximation and Projection (UMAP) and using a consensus function as a key to
access the most applicable hyperparameter configurations in the given ensemble
rather than using consensus function results directly. Evaluation of the
resulting clusters highlights specific clusters repeatedly present in the
separated monthly samples by Adjusted Mutual Information scores greater than
0.5, which provide insights to the news organizations and overcome the
degradation of the modeling behaviours due to the change in the interest over
time.",2022-02-04,"Didem Makaroglu, Altan Cakir, Behcet Ugur Toreyin"
Privacy-Aware Crowd Labelling for Machine Learning Tasks,"The extensive use of online social media has highlighted the importance of
privacy in the digital space. As more scientists analyse the data created in
these platforms, privacy concerns have extended to data usage within the
academia. Although text analysis is a well documented topic in academic
literature with a multitude of applications, ensuring privacy of user-generated
content has been overlooked. Most sentiment analysis methods require emotion
labels, which can be obtained through crowdsourcing, where non-expert
individuals contribute to scientific tasks. The text itself has to be exposed
to third parties in order to be labelled. In an effort to reduce the exposure
of online users' information, we propose a privacy preserving text labelling
method for varying applications, based in crowdsourcing. We transform text with
different levels of privacy, and analyse the effectiveness of the
transformation with regards to label correlation and consistency. Our results
suggest that privacy can be implemented in labelling, retaining the
annotational diversity and subjectivity of traditional labelling.",2022-02-03,"Giannis Haralabopoulos, Ioannis Anagnostopoulos"
Generation Alpha: Understanding the Next Cohort of University Students,"Technology is changing at a blistering pace and is impacting on the way we
consider knowledge as a free commodity, along with the ability to apply skills,
concepts and understandings. Technology is aiding the way the world is
evolving, and its contributions to education are not an exemption. While
technology advances will play a crucial part in future teaching-learning
approaches, educators will also be challenged by the next higher-education
generation, the Alpha Generation. This entrepreneurial generation will embrace
the innovation, progressiveness, and advancement with the expectation that one
in two Generation Alphas will obtain a university degree. In anticipating the
educational challenges and opportunities of the future higher education
environment, this research reflected on Generation Alpha as the next cohort of
university students, considering their preferred learning styles, perceptions
and expectations relating to education. The research employed a theoretical
analysis based on the characteristics and traits that distinguishes Generation
Alpha, spearheaded by technology advances. The empirical investigation
considered three independent studies that were previous conducted by authors
from Slovakia, Hungary, Australia, and Turkey to understand the challenges and
opportunities pertaining to Generation Alpha. The research identified the
influence of social media, social connections, high levels of perceptions and
the Generation Alpha's ability to interpret information as strengths to
consider in future teaching-learning approaches in the higher education
environment. This research concluded with recommendations on how universities
could be transformed to ensure a better learning experience for Generation
Alpha students, aligned with their characteristics, perceptions and
expectations.",2022-02-03,"Rushan Ziatdinov, Juanee Cilliers"
"Governing online goods: Maturity and formalization in Minecraft, Reddit,
  and World of Warcraft communities","Building a successful community means governing active populations and
limited resources. This challenge often requires communities to design formal
governance systems from scratch. But the characteristics of successful
institutional designs are unclear. Communities that are more mature and
established may have more elaborate formal policy systems. Alternatively, they
may require less formalization precisely because of their maturity. Indeed,
scholars often downplay the role that formal rules relative to unwritten rules,
norms, and values. But in a community with formal rules, decisions are more
consistent, transparent, and legitimate. To understand the relationship of
formal institutions to community maturity and governance style, we conduct a
large-scale quantitative analysis applying institutional analysis frameworks of
self-governance scholar Elinor Ostrom to 80,000 communities across 3 platforms:
the sandbox game Minecraft, the MMO game World of Warcraft, and Reddit. We
classify communities' written rules to test predictors of institutional
formalization. From this analysis we extract two major findings. First,
institutional formalization, the size and complexity of an online community's
governance system, is generally positively associated with maturity, as
measured by age, population size, or degree of user engagement. Second, we find
that online communities employ similar governance styles across platforms,
strongly favoring ""weak"" norms to ""strong"" requirements. These findings suggest
that designers and founders of online communities converge on styles of
governance practice that are correlated with successful self-governance. With
deeper insights into the patterns of successful self-governance, we can help
more communities overcome the challenges of self-governance and create for
their members powerful experiences of shared meaning and collective
empowerment.",2022-02-02,"Seth Frey, Qiankun Zhong, Beril Bulat, William D. Weisman, Caitlyn Liu, Stephen Fujimoto, Hannah M. Wang, Charles M. Schweik"
A Longitudinal Dataset of Twitter ISIS Users,"We present a large longitudinal dataset of tweets from two sets of users that
are suspected to be affiliated with ISIS. These sets of users are identified
based on a prior study and a campaign aimed at shutting down ISIS Twitter
accounts. These users have engaged with known ISIS accounts at least once
during 2014-2015 and are still active as of 2021. Some of them have directly
supported the ISIS users and their tweets by retweeting them, and some of the
users that have quoted tweets of ISIS, have uncertain connections to ISIS seed
accounts. This study and the dataset represent a unique approach to analyzing
ISIS data. Although much research exists on ISIS online activities, few studies
have focused on individual accounts. Our approach to validating accounts as
well as developing a framework for differentiating accounts' functionality
(e.g., propaganda versus operational planning) offers a foundation for future
research. We perform some descriptive statistics and preliminary analyses on
our collected data to provide deeper insight and highlight the significance and
practicality of such analyses. We further discuss several cross-disciplinary
potential use cases and research directions.",2022-02-02,"Younes Karimi, Anna Squicciarini, Peter K. Forster, Kira M. Leavitt"
Hierarchical Entity Alignment for Attribute-Rich Event-Driven Graphs,"This paper addresses the problem of entity alignment in attribute-rich
event-driven graphs. Unlike many other entity alignment problems, we are
interested in aligning entities based on the similarity of their actions, i.e.,
entities that participate in similar events are more likely to be the same. We
model the generative process of this problem as a Bayesian model and derive our
proposed algorithm from the posterior predictive distribution. We apply our
Hierarchical Entity AlignmenT (HEAT) algorithm to two datasets, one on
publications and the other on financial transactions, derived from real data
and provided to us by an external collaborator.",2022-02-01,"Elizabeth Hou, Joanna Brown, John Fisher"
"Measuring the Accessibility of Domain Name Encryption and Its Impact on
  Internet Filtering","Most online communications rely on DNS to map domain names to their hosting
IP address(es). Previous work has shown that DNS-based network interference is
widespread due to the unencrypted and unauthenticated nature of the original
DNS protocol. In addition to DNS, accessed domain names can also be monitored
by on-path observers during the TLS handshake when the SNI extension is used.
These lingering issues with exposed plaintext domain names have led to the
development of a new generation of protocols that keep accessed domain names
hidden. DNS-over-TLS (DoT) and DNS-over-HTTPS (DoH) hide the domain names of
DNS queries, while Encrypted Server Name Indication (ESNI) encrypts the domain
name in the SNI extension.
  We present DNEye, a measurement system built on top of a network of
distributed vantage points, which we used to study the accessibility of DoT/DoH
and ESNI, and to investigate whether these protocols are tampered with by
network providers (e.g., for censorship). Moreover, we evaluate the efficacy of
these protocols in circumventing network interference when accessing content
blocked by traditional DNS manipulation. We find evidence of blocking efforts
against domain name encryption technologies in several countries, including
China, Russia, and Saudi Arabia. At the same time, we discover that domain name
encryption can help with unblocking more than 55% and 95% of censored domains
in China and other countries where DNS-based filtering is heavily employed.",2022-02-01,"Nguyen Phong Hoang, Michalis Polychronakis, Phillipa Gill"
"Rewiring What-to-Watch-Next Recommendations to Reduce Radicalization
  Pathways","Recommender systems typically suggest to users content similar to what they
consumed in the past. If a user happens to be exposed to strongly polarized
content, she might subsequently receive recommendations which may steer her
towards more and more radicalized content, eventually being trapped in what we
call a ""radicalization pathway"". In this paper, we study the problem of
mitigating radicalization pathways using a graph-based approach. Specifically,
we model the set of recommendations of a ""what-to-watch-next"" recommender as a
d-regular directed graph where nodes correspond to content items, links to
recommendations, and paths to possible user sessions. We measure the
""segregation"" score of a node representing radicalized content as the expected
length of a random walk from that node to any node representing non-radicalized
content. High segregation scores are associated to larger chances to get users
trapped in radicalization pathways. Hence, we define the problem of reducing
the prevalence of radicalization pathways by selecting a small number of edges
to ""rewire"", so to minimize the maximum of segregation scores among all
radicalized nodes, while maintaining the relevance of the recommendations. We
prove that the problem of finding the optimal set of recommendations to rewire
is NP-hard and NP-hard to approximate within any factor. Therefore, we turn our
attention to heuristics, and propose an efficient yet effective greedy
algorithm based on the absorbing random walk theory. Our experiments on
real-world datasets in the context of video and news recommendations confirm
the effectiveness of our proposal.",2022-02-01,"Francesco Fabbri, Yanhao Wang, Francesco Bonchi, Carlos Castillo, Michael Mathioudakis"
"The collective vs individual nature of mountaineering: a network and
  simplicial approach","Mountaineering is a sport of contrary forces: teamwork plays a large role in
mental fortitude and skills, but the actual act of climbing, and indeed
survival, is largely individualistic. This work studies the effects of the
structure and topology of relationships within climbers on the level of
cooperation and success. It does so using simplicial complexes, where
relationships between climbers are captured through simplexes that correspond
to joint previous expeditions with dimension given by the number of climbers
minus one and weight given by the number of occurrences of the simplex. First,
this analysis establishes the importance of relationships and shows that
chances of failure to summit reduce drastically when climbing with repeat
partners. From a climber-centric perspective, climbers that belong to simplexes
with large dimension were more likely to be successful, across experience
levels. From an expedition-centric perspective, the distribution of
relationships within a group is explored to identify collective human behavior:
from polarized to cooperative. Expeditions containing simplices with large
dimension, and usually low weight, i.e., a large number of people had a small
number of previous joint expeditions, tended to be more cooperative, with more
homogeneity in success amongst climbers. On the other hand, the existence of
small, usually strong, subgroups lead to a polarized style where climbers that
were not a part of the subgroup were less likely to succeed. Lastly, this work
examines the effects of individual features and expedition-wide factors that
may play different roles in individualistic and cooperative expeditions.
Centrality indicates that individual traits of youth and oxygen use while
ascending are strong drivers of success. Of expedition-wide factors, the
expedition size and number of expedition days are found to be strongly
correlated with success rate.",2022-01-31,Sanjukta Krishnagopal
"Glowing Experience or Bad Trip? A Quantitative Analysis of User Reported
  Drug Experiences on Erowid.org","Erowid.org is a website dedicated to documenting information about
psychoactive substances, with over 36,000 user-submitted drug Experience
Reports. We study the potential of these reports to provide information about
characteristic experiences with drugs. First, we assess different kinds of drug
experiences, such as 'addiction' or 'bad trips'. We quantitatively analyze how
such experiences are related to substances and user variables. Furthermore, we
classify positive and negative experiences as well as reported addiction using
information about the consumer, substance, context and location of the drug
experience. While variables based only on objective characteristics yield poor
predictive performance for subjective experiences, we find subjective user
reports can help to identify new patterns and impact factors on drug
experiences. In particular, we found a positive association between addiction
experiences and dextromethorphan, a substance with largely unknown withdrawal
effects. Our research can help to gain a deeper sociological understanding of
drug consumption and to identify relationships which may have clinical
relevance. Moreover, it can show how non-mainstream social media platforms can
be utilized to study characteristics of human behavior and how this can be done
in an ethical way in collaboration with the platform providers.",2022-01-31,"Angelina Mooseder, Momin M. Malik, Hemank Lamba, Earth Erowid, Sylvia Thyssen, Juergen Pfeffer"
MGNN: Graph Neural Networks Inspired by Distance Geometry Problem,"Graph Neural Networks (GNNs) have emerged as a prominent research topic in
the field of machine learning. Existing GNN models are commonly categorized
into two types: spectral GNNs, which are designed based on polynomial graph
filters, and spatial GNNs, which utilize a message-passing scheme as the
foundation of the model. For the expressive power and universality of spectral
GNNs, a natural approach is to improve the design of basis functions for better
approximation ability. As for spatial GNNs, models like Graph Isomorphism
Networks (GIN) analyze their expressive power based on Graph Isomorphism Tests.
Recently, there have been attempts to establish connections between spatial
GNNs and geometric concepts like curvature and cellular sheaves, as well as
physical phenomena like oscillators. However, despite the recent progress,
there is still a lack of comprehensive analysis regarding the universality of
spatial GNNs from the perspectives of geometry and physics. In this paper, we
propose MetricGNN (MGNN), a spatial GNN model inspired by the
congruent-insensitivity property of classifiers in the classification phase of
GNNs. We demonstrate that a GNN model is universal in the spatial domain if it
can generate embedding matrices that are congruent to any given embedding
matrix. This property is closely related to the Distance Geometry Problem
(DGP). Since DGP is an NP-Hard combinatorial optimization problem, we propose
optimizing an energy function derived from spring networks and the
Multi-Dimensional Scaling (MDS) problem. This approach also allows our model to
handle both homophilic and heterophilic graphs. Finally, we propose employing
the iteration method to optimize our energy function. We extensively evaluate
the effectiveness of our model through experiments conducted on both synthetic
and real-world datasets. Our code is available at:
https://github.com/GuanyuCui/MGNN.",2022-01-31,"Guanyu Cui, Zhewei Wei"
"Analyzing Community-aware Centrality Measures Using The Linear Threshold
  Model","Targeting influential nodes in complex networks allows fastening or hindering
rumors, epidemics, and electric blackouts. Since communities are prevalent in
real-world networks, community-aware centrality measures exploit this
information to target influential nodes. Researches show that they compare
favorably with classical measures that are agnostic about the community
structure. Although the diffusion process is of prime importance, previous
studies consider mainly the famous Susceptible-Infected-Recovered (SIR)
epidemic propagation model. This work investigates the consistency of previous
analyses using the popular Linear Threshold (LT) propagation model, which
characterizes many spreading processes in our real life. We perform a
comparative analysis of seven influential community-aware centrality measures
on thirteen real-world networks. Overall, results show that Community-based
Mediator, Comm Centrality, and Modularity Vitality outperform the other
measures. Moreover, Community-based Mediator is more effective on a tight
budget (i.e., a small fraction of initially activated nodes), while Comm
Centrality and Modularity Vitality perform better with a medium to a high
fraction of initially activated nodes.",2022-01-30,"Stephany Rajeh, Ali Yassin, Ali Jaber, Hocine Cherifi"
Identifying Influential Nodes Using Overlapping Modularity Vitality,"It is of paramount importance to uncover influential nodes to control
diffusion phenomena in a network. In recent works, there is a growing trend to
investigate the role of the community structure to solve this issue. Up to now,
the vast majority of the so-called community-aware centrality measures rely on
non-overlapping community structure. However, in many real-world networks, such
as social networks, the communities overlap. In other words, a node can belong
to multiple communities. To overcome this drawback, we propose and investigate
the ""Overlapping Modularity Vitality"" centrality measure. This extension of
""Modularity Vitality"" quantifies the community structure strength variation
when removing a node. It allows identifying a node as a hub or a bridge based
on its contribution to the overlapping modularity of a network. A comparative
analysis with its non-overlapping version using the
Susceptible-Infected-Recovered (SIR) epidemic diffusion model has been
performed on a set of six real-world networks. Overall, Overlapping Modularity
Vitality outperforms its alternative. These results illustrate the importance
of incorporating knowledge about the overlapping community structure to
identify influential nodes effectively. Moreover, one can use multiple ranking
strategies as the two measures are signed. Results show that selecting the
nodes with the top positive or the top absolute centrality values is more
effective than choosing the ones with the maximum negative values to spread the
epidemic.",2022-01-30,"Stephany Rajeh, Marinette Savonnet, Eric Leclercq, Hocine Cherifi"
A Topological Centrality Measure for Directed Networks,"Given a directed network $ G $, we are interested in studying the qualitative
features of $ G $ which govern how perturbations propagate across $ G $.
Various classical centrality measures have been already developed and proven
useful to capture qualitative features and behaviors for undirected networks.
In this paper, we use topological data analysis (TDA) to adapt measures of
centrality to capture both directedness and non-local propagating behaviors in
networks. We introduce a new metric for computing centrality in directed
weighted networks, namely the quasi-centrality measure. We compute these
metrics on trade networks to illustrate that our measure successfully captures
propagating effects in the network and can also be used to identify sources of
shocks that can disrupt the topology of directed networks. Moreover, we
introduce a method that gives a hierarchical representation of the topological
influences of nodes in a directed network.",2022-01-30,Fenghuan He
Modularity-based Backbone Extraction in Weighted Complex Networks,"The constantly growing size of real-world networks is a great challenge.
Therefore, building a compact version of networks allowing their analyses is a
must. Backbone extraction techniques are among the leading solutions to reduce
network size while preserving its features. Coarse-graining merges similar
nodes to reduce the network size, while filter-based methods remove nodes or
edges according to a specific statistical property. Since community structure
is ubiquitous in real-world networks, preserving it in the backbone extraction
process is of prime interest. To this end, we propose a filter-based method.
The so-called ""modularity vitality backbone"" removes nodes with the lower
contribution to the network's modularity. Experimental results show that the
proposed strategy outperforms the ""overlapping nodes ego backbone"" and the
""overlapping nodes and hub backbone."" These two backbone extraction processes
recently introduced have proved their efficacy to preserve better the
information of the original network than the popular disparity filter.",2022-01-30,"Stephany Rajeh, Marinette Savonnet, Eric Leclercq, Hocine Cherifi"
"Rank List Sensitivity of Recommender Systems to Interaction
  Perturbations","Prediction models can exhibit sensitivity with respect to training data:
small changes in the training data can produce models that assign conflicting
predictions to individual data points during test time. In this work, we study
this sensitivity in recommender systems, where users' recommendations are
drastically altered by minor perturbations in other unrelated users'
interactions. We introduce a measure of stability for recommender systems,
called Rank List Sensitivity (RLS), which measures how rank lists generated by
a given recommender system at test time change as a result of a perturbation in
the training data. We develop a method, CASPER, which uses cascading effect to
identify the minimal and systematical perturbation to induce higher instability
in a recommender system. Experiments on four datasets show that recommender
models are overly sensitive to minor perturbations introduced randomly or via
CASPER - even perturbing one random interaction of one user drastically changes
the recommendation lists of all users. Importantly, with CASPER perturbation,
the models generate more unstable recommendations for low-accuracy users (i.e.,
those who receive low-quality recommendations) than high-accuracy ones.",2022-01-29,"Sejoon Oh, Berk Ustun, Julian McAuley, Srijan Kumar"
"Map Equation Centrality: Community-aware Centrality based on the Map
  Equation","To measure node importance, network scientists employ centrality scores that
typically take a microscopic or macroscopic perspective, relying on node
features or global network structure. However, traditional centrality measures
such as degree centrality, betweenness centrality, or PageRank neglect the
community structure found in real-world networks. To study node importance
based on network flows from a mesoscopic perspective, we analytically derive a
community-aware information-theoretic centrality score based on network flow
and the coding principles behind the map equation: map equation centrality. Map
equation centrality measures how much further we can compress the network's
modular description by not coding for random walker transitions to the
respective node, using an adapted coding scheme and determining node importance
from a network flow-based point of view. The information-theoretic centrality
measure can be determined from a node's local network context alone because
changes to the coding scheme only affect other nodes in the same module. Map
equation centrality is agnostic to the chosen network flow model and allows
researchers to select the model that best reflects the dynamics of the process
under study. Applied to synthetic networks, we highlight how our approach
enables a more fine-grained differentiation between nodes than node-local or
network-global measures. Predicting influential nodes for two different
dynamical processes on real-world networks with traditional and other
community-aware centrality measures, we find that activating nodes based on map
equation centrality scores tends to create the largest cascades in a linear
threshold model.",2022-01-29,"Christopher Blöcker, Juan Carlos Nieves, Martin Rosvall"
"Collaborative Learning in General Graphs with Limited Memorization:
  Complexity, Learnability, and Reliability","We consider a K-armed bandit problem in general graphs where agents are
arbitrarily connected and each of them has limited memorizing capabilities and
communication bandwidth. The goal is to let each of the agents eventually learn
the best arm. It is assumed in these studies that the communication graph
should be complete or well-structured, whereas such an assumption is not always
valid in practice. Furthermore, limited memorization and communication
bandwidth also restrict the collaborations of the agents, since the agents
memorize and communicate very few experiences. Additionally, an agent may be
corrupted to share falsified experiences to its peers, while the resource limit
in terms of memorization and communication may considerably restrict the
reliability of the learning process. To address the above issues, we propose a
three-staged collaborative learning algorithm. In each step, the agents share
their latest experiences with each other through light-weight random walks in a
general communication graph, and then make decisions on which arms to pull
according to the recommendations received from their peers. The agents finally
update their adoptions (i.e., preferences to the arms) based on the reward
obtained by pulling the arms. Our theoretical analysis shows that, when there
are a sufficient number of agents participating in the collaborative learning
process, all the agents eventually learn the best arm with high probability,
even with limited memorizing capabilities and light-weight communications. We
also reveal in our theoretical analysis the upper bound on the number of
corrupted agents our algorithm can tolerate. The efficacy of our proposed
three-staged collaborative learning algorithm is finally verified by extensive
experiments on both synthetic and real datasets.",2022-01-29,"Feng Li, Xuyang Yuan, Lina Wang, Huan Yang, Dongxiao Yu, Weifeng Lv, Xiuzhen Cheng"
"Online Change Point Detection for Weighted and Directed Random Dot
  Product Graphs","Given a sequence of random (directed and weighted) graphs, we address the
problem of online monitoring and detection of changes in the underlying data
distribution. Our idea is to endow sequential change-point detection (CPD)
techniques with a graph representation learning substrate based on the
versatile Random Dot Product Graph (RDPG) model. We consider efficient, online
updates of a judicious monitoring function, which quantifies the discrepancy
between the streaming graph observations and the nominal RDPG. This reference
distribution is inferred via spectral embeddings of the first few graphs in the
sequence. We characterize the distribution of this running statistic to select
thresholds that guarantee error-rate control, and under simplifying
approximations we offer insights on the algorithm's detection resolution and
delay. The end result is a lightweight online CPD algorithm, that is also
explainable by virtue of the well-appreciated interpretability of RDPG
embeddings. This is in stark contrast with most existing graph CPD approaches,
which either rely on extensive computation, or they store and process the
entire observed time series. An apparent limitation of the RDPG model is its
suitability for undirected and unweighted graphs only, a gap we aim to close
here to broaden the scope of the CPD framework. Unlike previous proposals, our
non-parametric RDPG model for weighted graphs does not require a priori
specification of the weights' distribution to perform inference and estimation.
This network modeling contribution is of independent interest beyond CPD. We
offer an open-source implementation of the novel online CPD algorithm for
weighted and direct graphs, whose effectiveness and efficiency are demonstrated
via (reproducible) synthetic and real network data experiments.",2022-01-26,"Bernardo Marenco, Paola Bermolen, Marcelo Fiori, Federico Larroca, Gonzalo Mateos"
Handling Bias in Toxic Speech Detection: A Survey,"Detecting online toxicity has always been a challenge due to its inherent
subjectivity. Factors such as the context, geography, socio-political climate,
and background of the producers and consumers of the posts play a crucial role
in determining if the content can be flagged as toxic. Adoption of automated
toxicity detection models in production can thus lead to a sidelining of the
various groups they aim to help in the first place. It has piqued researchers'
interest in examining unintended biases and their mitigation. Due to the
nascent and multi-faceted nature of the work, complete literature is chaotic in
its terminologies, techniques, and findings. In this paper, we put together a
systematic study of the limitations and challenges of existing methods for
mitigating bias in toxicity detection.
  We look closely at proposed methods for evaluating and mitigating bias in
toxic speech detection. To examine the limitations of existing methods, we also
conduct a case study to introduce the concept of bias shift due to
knowledge-based bias mitigation. The survey concludes with an overview of the
critical challenges, research gaps, and future directions. While reducing
toxicity on online platforms continues to be an active area of research, a
systematic study of various biases and their mitigation strategies will help
the research community produce robust and fair models.",2022-01-26,"Tanmay Garg, Sarah Masud, Tharun Suresh, Tanmoy Chakraborty"
Network-Side Digital Contact Tracing on a Large University Campus,"We describe a study conducted at a large public university campus in the
United States which shows the efficacy of network log information for digital
contact tracing and prediction of COVID-19 cases. Over the period of January
18, 2021 to May 7, 2021, more than 216 million client-access-point associations
were logged across more than 11,000 wireless access points (APs). The
association information was used to find potential contacts for approximately
30,000 individuals. Contacts are determined using an AP colocation algorithm,
which supposes contact when two individuals connect to the same WiFi AP at
approximately the same time. The approach was validated with a truth set of 350
positive COVID-19 cases inferred from the network log data by observing
associations with APs in isolation residence halls reserved for individuals
with a confirmed (clinical) positive COVID-19 test result. The network log data
and AP-colocation have a predictive value of greater than 10%; more precisely,
the contacts of an individual with a confirmed positive COVID-19 test have
greater than a 10\% chance of testing positive in the following 7 days
(compared with a 0.79% chance when chosen at random, a relative risk ratio of
12.6). Moreover, a cumulative exposure score is computed to account for
exposure to multiple individuals that test positive. Over the duration of the
study, the cumulative exposure score predicts positive cases with a true
positive rate of 16.5% and missed detection rate of 79% at a specified
operating point.",2022-01-25,"Matthew L. Malloy, Lance Hartung, Steve Wangen, Suman Banerjee"
Link Prediction with Contextualized Self-Supervision,"Link prediction aims to infer the link existence between pairs of nodes in
networks/graphs. Despite their wide application, the success of traditional
link prediction algorithms is hindered by three major challenges -- link
sparsity, node attribute noise and dynamic changes -- that are faced by many
real-world networks. To address these challenges, we propose a Contextualized
Self-Supervised Learning (CSSL) framework that fully exploits structural
context prediction for link prediction. The proposed CSSL framework learns a
link encoder to infer the link existence probability from paired node
embeddings, which are constructed via a transformation on node attributes. To
generate informative node embeddings for link prediction, structural context
prediction is leveraged as a self-supervised learning task to boost the link
prediction performance. Two types of structural context are investigated, i.e.,
context nodes collected from random walks vs. context subgraphs. The CSSL
framework can be trained in an end-to-end manner, with the learning of model
parameters supervised by both the link prediction and self-supervised learning
tasks. The proposed CSSL is a generic and flexible framework in the sense that
it can handle both attributed and non-attributed networks, and operate under
both transductive and inductive link prediction settings. Extensive experiments
and ablation studies on seven real-world benchmark networks demonstrate the
superior performance of the proposed self-supervision based link prediction
algorithm over state-of-the-art baselines, on different types of networks under
both transductive and inductive settings. The proposed CSSL also yields
competitive performance in terms of its robustness to node attribute noise and
scalability over large-scale networks.",2022-01-25,"Daokun Zhang, Jie Yin, Philip S. Yu"
MonLAD: Money Laundering Agents Detection in Transaction Streams,"Given a stream of money transactions between accounts in a bank, how can we
accurately detect money laundering agent accounts and suspected behaviors in
real-time? Money laundering agents try to hide the origin of illegally obtained
money by dispersive multiple small transactions and evade detection by smart
strategies. Therefore, it is challenging to accurately catch such fraudsters in
an unsupervised manner. Existing approaches do not consider the characteristics
of those agent accounts and are not suitable to the streaming settings.
Therefore, we propose MonLAD and MonLAD-W to detect money laundering agent
accounts in a transaction stream by keeping track of their residuals and other
features; we devise AnoScore algorithm to find anomalies based on the robust
measure of statistical deviation. Experimental results show that MonLAD
outperforms the state-of-the-art baselines on real-world data and finds various
suspicious behavior patterns of money laundering. Additionally, several
detected suspected accounts have been manually-verified as agents in real money
laundering scenario.",2022-01-25,"Xiaobing Sun, Wenjie Feng, Shenghua Liu, Yuyang Xie, Siddharth Bhatia, Bryan Hooi, Wenhan Wang, Xueqi Cheng"
A Method to Predict Semantic Relations on Artificial Intelligence Papers,"Predicting the emergence of links in large evolving networks is a difficult
task with many practical applications. Recently, the Science4cast competition
has illustrated this challenge presenting a network of 64.000 AI concepts and
asking the participants to predict which topics are going to be researched
together in the future. In this paper, we present a solution to this problem
based on a new family of deep learning approaches, namely Graph Neural
Networks. The results of the challenge show that our solution is competitive
even if we had to impose severe restrictions to obtain a computationally
efficient and parsimonious model: ignoring the intrinsic dynamics of the graph
and using only a small subset of the nodes surrounding a target link.
Preliminary experiments presented in this paper suggest the model is learning
two related, but different patterns: the absorption of a node by a sub-graph
and union of more dense sub-graphs. The model seems to excel at recognizing the
first type of pattern.",2022-01-24,"Francisco Andrades, Ricardo Ñanculef"
"Identifying the temporal dynamics of densification and sparsification in
  human contact networks","Temporal social networks of human interactions are preponderant in
understanding the fundamental patterns of human behavior. In these networks,
interactions occur locally between individuals (i.e., nodes) who connect with
each other at different times, culminating into a complex system-wide web that
has a dynamic composition. Dynamic behavior in networks occurs not only locally
but also at the global level, as systems expand or shrink due either to:
changes in the size of node population or variations in the chance of a
connection between two nodes. Here, we propose a numerical maximum-likelihood
method to estimate population size and the probability of two nodes connecting
at any given point in time. An advantage of the method is that it relies only
on aggregate quantities, which are easy to access and free from privacy issues.
Our approach enables us to identify the simultaneous (rather than the
asynchronous) contribution of each mechanism in the densification and
sparsification of human contacts, providing a better understanding of how
humans collectively construct and deconstruct social networks.",2022-01-24,"Shaunette T. Ferguson, Teruyoshi Kobayashi"
Understanding and Detecting Hateful Content using Contrastive Learning,"The spread of hate speech and hateful imagery on the Web is a significant
problem that needs to be mitigated to improve our Web experience. This work
contributes to research efforts to detect and understand hateful content on the
Web by undertaking a multimodal analysis of Antisemitism and Islamophobia on
4chan's /pol/ using OpenAI's CLIP. This large pre-trained model uses the
Contrastive Learning paradigm. We devise a methodology to identify a set of
Antisemitic and Islamophobic hateful textual phrases using Google's Perspective
API and manual annotations. Then, we use OpenAI's CLIP to identify images that
are highly similar to our Antisemitic/Islamophobic textual phrases. By running
our methodology on a dataset that includes 66M posts and 5.8M images shared on
4chan's /pol/ for 18 months, we detect 173K posts containing 21K
Antisemitic/Islamophobic images and 246K posts that include 420 hateful
phrases. Among other things, we find that we can use OpenAI's CLIP model to
detect hateful content with an accuracy score of 0.81 (F1 score = 0.54). By
comparing CLIP with two baselines proposed by the literature, we find that CLIP
outperforms them, in terms of accuracy, precision, and F1 score, in detecting
Antisemitic/Islamophobic images. Also, we find that Antisemitic/Islamophobic
imagery is shared in a similar number of posts on 4chan's /pol/ compared to
Antisemitic/Islamophobic textual phrases, highlighting the need to design more
tools for detecting hateful imagery. Finally, we make available (upon request)
a dataset of 246K posts containing 420 Antisemitic/Islamophobic phrases and 21K
likely Antisemitic/Islamophobic images (automatically detected by CLIP) that
can assist researchers in further understanding Antisemitism and Islamophobia.",2022-01-21,"Felipe González-Pizarro, Savvas Zannettou"
"Ensemble of Opinion Dynamics Models to Understand the Role of the
  Undecided in the Vaccination Debate","We present three models used to describe the recruitment of the undecided
population by pro-vax and no-vax factions. Starting from real-world data of
Facebook pages, we compare three opinion dynamics models that catch different
behaviours of the undecided population.
  The first one is a variation of the SIS model, where undecided position is
considered indifferent. Neutrals can be ""infected"" by one of the two extreme
factions, joining their side, and they ""recover"" when they lose interest in the
debate and go back to neutrality.
  The second model is a three parties Voters model: neutral pages represent a
centrist position. They lean their original ideas, that are different from both
the other parties.
  The last is the Bilingual model adapted to the vaccination debate: neutral
individuals are in agreement with both pro-, ad anti-vax factions, with a
position of compromise between the extremes (""bilingualism''). If they have a
one-sided neighbourhood, the convenience to agree with both parties comes out,
and bi-linguists can become mono-linguists.
  Our results depicts an agreement between the three models: anti-vax opinion
propagates more than pro-vax, thanks to an initial strategic position in the
online social network (even if they start with a smaller population). While
most of the pro-vaccines nodes are segregated in their own communities,
no-vaccines ones are entangled at the core of the network, where the majority
of undecided population is located.
  In the last section, we propose and compare some policies that could be
applied on the network to prevent anti-vax overcome: they lead us to conclude
that censoring strategies are not effective, as well as segregating scenarios
based on unfollowing decisions, while the addition of links in the network
favours the containment of the pro-vax domain, reducing the distance between
pro-vaxxers and undecided population.",2022-01-21,"Jacopo Lenti, Giancarlo Ruffo"
"Reputation analysis of news sources in Twitter: Particular case of
  Spanish presidential election in 2019","Fake news are affecting a large proportion of the population even becoming a
danger to the society. Mostly, this disinformation flow take place through
Internet. Being aware of that problem, in this work we propose a synthetic
indicator that measures the user reputation in Twitter in order to analyze the
credibility of the content in this social network. In order to show the
indicator utility, we have analyzed data from some political topics in Spain
from 2019 to 2020 and we have checked that bots plays a decisive role into the
spread of news and, as might be expected, the link among popularity and
reputation reports about the event credibility.",2022-01-21,"Aarón López-García, Rafael Benítez"
"Classic Graph Structural Features Outperform Factorization-Based Graph
  Embedding Methods on Community Labeling","Graph representation learning (also called graph embeddings) is a popular
technique for incorporating network structure into machine learning models.
Unsupervised graph embedding methods aim to capture graph structure by learning
a low-dimensional vector representation (the embedding) for each node. Despite
the widespread use of these embeddings for a variety of downstream transductive
machine learning tasks, there is little principled analysis of the
effectiveness of this approach for common tasks. In this work, we provide an
empirical and theoretical analysis for the performance of a class of embeddings
on the common task of pairwise community labeling. This is a binary variant of
the classic community detection problem, which seeks to build a classifier to
determine whether a pair of vertices participate in a community. In line with
our goal of foundational understanding, we focus on a popular class of
unsupervised embedding techniques that learn low rank factorizations of a
vertex proximity matrix (this class includes methods like GraRep, DeepWalk,
node2vec, NetMF). We perform detailed empirical analysis for community labeling
over a variety of real and synthetic graphs with ground truth. In all cases we
studied, the models trained from embedding features perform poorly on community
labeling. In constrast, a simple logistic model with classic graph structural
features handily outperforms the embedding models. For a more principled
understanding, we provide a theoretical analysis for the (in)effectiveness of
these embeddings in capturing the community structure. We formally prove that
popular low-dimensional factorization methods either cannot produce community
structure, or can only produce ``unstable"" communities. These communities are
inherently unstable under small perturbations.",2022-01-20,"Andrew Stolman, Caleb Levy, C. Seshadhri, Aneesh Sharma"
TweetBoost: Influence of Social Media on NFT Valuation,"NFT or Non-Fungible Token is a token that certifies a digital asset to be
unique. A wide range of assets including, digital art, music, tweets, memes,
are being sold as NFTs. NFT-related content has been widely shared on social
media sites such as Twitter. We aim to understand the dominant factors that
influence NFT asset valuation. Towards this objective, we create a
first-of-its-kind dataset linking Twitter and OpenSea (the largest NFT
marketplace) to capture social media profiles and linked NFT assets. Our
dataset contains 245,159 tweets posted by 17,155 unique users, directly linking
62,997 NFT assets on OpenSea worth 19 Million USD. We have made the dataset
public. We analyze the growth of NFTs, characterize the Twitter users promoting
NFT assets, and gauge the impact of Twitter features on the virality of an NFT.
Further, we investigate the effectiveness of different social media and NFT
platform features by experimenting with multiple machine learning and deep
learning models to predict an asset's value. Our results show that social media
features improve the accuracy by 6% over baseline models that use only NFT
platform features. Among social media features, count of user membership lists,
number of likes and retweets are important features.",2022-01-20,"Arnav Kapoor, Dipanwita Guhathakurta, Mehul Mathur, Rupanshu Yadav, Manish Gupta, Ponnurangam Kumaraguru"
"CUF-Links: Continuous and Ubiquitous FAIRness Linkages for reproducible
  research","Despite much creative work on methods and tools, reproducibility -- the
ability to repeat the computational steps used to obtain a research result --
remains elusive. One reason for these difficulties is that extant tools for
capturing research processes do not align well with the rich working practices
of scientists. We advocate here for simple mechanisms that can be integrated
easily with current work practices to capture basic information about every
data product consumed or produced in a project. We argue that by thus extending
the scope of findable, accessible, interoperable, and reusable (FAIR) data in
both time and space to enable the creation of a continuous chain of continuous
and ubiquitous FAIRness linkages (CUF-Links) from inputs to outputs, such
mechanisms can provide a strong foundation for documenting the provenance
linkages that are essential to reproducible research. We give examples of
mechanisms that can achieve these goals, and review how they have been applied
in practice.",2022-01-20,"Ian Foster, Carl Kesselman"
FreSCo: Mining Frequent Patterns in Simplicial Complexes,"Simplicial complexes are a generalization of graphs that model higher-order
relations. In this paper, we introduce simplicial patterns -- that we call
simplets -- and generalize the task of frequent pattern mining from the realm
of graphs to that of simplicial complexes. Our task is particularly challenging
due to the enormous search space and the need for higher-order isomorphism. We
show that finding the occurrences of simplets in a complex can be reduced to a
bipartite graph isomorphism problem, in linear time and at most quadratic
space. We then propose an anti-monotonic frequency measure that allows us to
start the exploration from small simplets and stop expanding a simplet as soon
as its frequency falls below the minimum frequency threshold. Equipped with
these ideas and a clever data structure, we develop a memory-conscious
algorithm that, by carefully exploiting the relationships among the simplices
in the complex and among the simplets, achieves efficiency and scalability for
our complex mining task. Our algorithm, FreSCo, comes in two flavors: it can
compute the exact frequency of the simplets or, more quickly, it can determine
whether a simplet is frequent, without having to compute the exact frequency.
Experimental results prove the ability of FreSCo to mine frequent simplets in
complexes of various size and dimension, and the significance of the simplets
with respect to the traditional graph patterns.",2022-01-20,"Giulia Preti, Gianmarco De Francisci Morales, Francesco Bonchi"
"""Learn the Facts About COVID-19"": Analyzing the Use of Warning Labels on
  TikTok Videos","During the COVID-19 pandemic, health-related misinformation and harmful
content shared online had a significant adverse effect on society. To mitigate
this adverse effect, mainstream social media platforms employed soft moderation
interventions (i.e., warning labels) on potentially harmful posts. Despite the
recent popularity of these moderation interventions, we lack empirical analyses
aiming to uncover how these warning labels are used in the wild, particularly
during challenging times like the COVID-19 pandemic. In this work, we analyze
the use of warning labels on TikTok, focusing on COVID-19 videos. First, we
construct a set of 26 COVID-19 related hashtags, then we collect 41K videos
that include those hashtags in their description. Second, we perform a
quantitative analysis on the entire dataset to understand the use of warning
labels on TikTok. Then, we perform an in-depth qualitative study, using
thematic analysis, on 222 COVID-19 related videos to assess the content and the
connection between the content and the warning labels. Our analysis shows that
TikTok broadly applies warning labels on TikTok videos, likely based on
hashtags included in the description. More worrying is the addition of COVID-19
warning labels on videos where their actual content is not related to COVID-19
(23% of the cases in a sample of 143 English videos that are not related to
COVID-19). Finally, our qualitative analysis on a sample of 222 videos shows
that 7.7% of the videos share misinformation/harmful content and do not include
warning labels, 37.3% share benign information and include warning labels, and
that 35% of the videos that share misinformation/harmful content (and need a
warning label) are made for fun. Our study demonstrates the need to develop
more accurate and precise soft moderation systems, especially on a platform
like TikTok that is extremely popular among people of younger age.",2022-01-19,"Chen Ling, Krishna P. Gummadi, Savvas Zannettou"
"Small Cohort of Epilepsy Patients Showed Increased Activity on Facebook
  before Sudden Unexpected Death","Sudden Unexpected Death in Epilepsy (SUDEP) remains a leading cause of death
in people with epilepsy. Despite the constant risk for patients and bereavement
to family members, to date the physiological mechanisms of SUDEP remain
unknown. Here we explore the potential to identify putative predictive signals
of SUDEP from online digital behavioral data using text and sentiment analysis.
Specifically, we analyze Facebook timelines of six epilepsy patients deceased
due to SUDEP, donated by surviving family members. We find preliminary evidence
for behavioral changes detectable by text and sentiment analysis tools. Namely,
in the months preceding their SUDEP event patient social media timelines show:
i) increase in verbosity; ii) increased use of functional words; and iii)
sentiment shifts as measured by different sentiment analysis tools. Combined,
these results suggest that social media engagement, as well as its sentiment,
may serve as possible early-warning signals for SUDEP in people with epilepsy.
While the small sample of patient timelines analyzed in this study prevents
generalization, our preliminary investigation demonstrates the potential of
social media data as complementary data in larger studies of SUDEP and
epilepsy.",2022-01-19,"Ian B. Wood, Rion Brattig Correia, Wendy R. Miller, Luis M. Rocha"
Detecting Stance in Tweets : A Signed Network based Approach,"Identifying user stance related to a political event has several
applications, like determination of individual stance, shaping of public
opinion, identifying popularity of government measures and many others. The
huge volume of political discussions on social media platforms, like, Twitter,
provide opportunities in developing automated mechanisms to identify individual
stance and subsequently, scale to a large volume of users. However, issues like
short text and huge variance in the vocabulary of the tweets make such exercise
enormously difficult. Existing stance detection algorithms require either event
specific training data or annotated twitter handles and therefore, are
difficult to adapt to new events. In this paper, we propose a sign network
based framework that use external information sources, like news articles to
create a signed network of relevant entities with respect to a news event and
subsequently use the same to detect stance of any tweet towards the event.
Validation on 5,000 tweets related to 10 events indicates that the proposed
approach can ensure over 6.5% increase in average F1 score compared to the
existing stance detection approaches.",2022-01-19,"Roshni Chakraborty, Maitry Bhavsar, Sourav Kumar Dandapat, Joydeep Chandra"
"Many Ways to Be Lonely: Fine-Grained Characterization of Loneliness and
  Its Potential Changes in COVID-19","Loneliness has been associated with negative outcomes for physical and mental
health. Understanding how people express and cope with various forms of
loneliness is critical for early screening and targeted interventions to reduce
loneliness, particularly among vulnerable groups such as young adults. To
examine how different forms of loneliness and coping strategies manifest in
loneliness self-disclosure, we built a dataset, FIG-Loneliness (FIne-Grained
Loneliness) by using Reddit posts in two young adult-focused forums and two
loneliness related forums consisting of a diverse age group. We provided
annotations by trained human annotators for binary and fine-grained loneliness
classifications of the posts. Trained on FIG-Loneliness, two BERT-based models
were used to understand loneliness forms and authors' coping strategies in
these forums. Our binary loneliness classification achieved an accuracy above
97%, and fine-grained loneliness category classification reached an average
accuracy of 77% across all labeled categories. With FIG-Loneliness and model
predictions, we found that loneliness expressions in the young adults related
forums were distinct from other forums. Those in young adult-focused forums
were more likely to express concerns pertaining to peer relationship, and were
potentially more sensitive to geographical isolation impacted by the COVID-19
pandemic lockdown. Also, we showed that different forms of loneliness have
differential use in coping strategies.",2022-01-19,"Yueyi Jiang, Yunfan Jiang, Liu Leqi, Piotr Winkielman"
Dual Space Graph Contrastive Learning,"Unsupervised graph representation learning has emerged as a powerful tool to
address real-world problems and achieves huge success in the graph learning
domain. Graph contrastive learning is one of the unsupervised graph
representation learning methods, which recently attracts attention from
researchers and has achieved state-of-the-art performances on various tasks.
The key to the success of graph contrastive learning is to construct proper
contrasting pairs to acquire the underlying structural semantics of the graph.
However, this key part is not fully explored currently, most of the ways
generating contrasting pairs focus on augmenting or perturbating graph
structures to obtain different views of the input graph. But such strategies
could degrade the performances via adding noise into the graph, which may
narrow down the field of the applications of graph contrastive learning. In
this paper, we propose a novel graph contrastive learning method, namely
\textbf{D}ual \textbf{S}pace \textbf{G}raph \textbf{C}ontrastive (DSGC)
Learning, to conduct graph contrastive learning among views generated in
different spaces including the hyperbolic space and the Euclidean space. Since
both spaces have their own advantages to represent graph data in the embedding
spaces, we hope to utilize graph contrastive learning to bridge the spaces and
leverage advantages from both sides. The comparison experiment results show
that DSGC achieves competitive or better performances among all the datasets.
In addition, we conduct extensive experiments to analyze the impact of
different graph encoders on DSGC, giving insights about how to better leverage
the advantages of contrastive learning between different spaces.",2022-01-19,"Haoran Yang, Hongxu Chen, Shirui Pan, Lin Li, Philip S. Yu, Guandong Xu"
Covid-19 vaccine hesitancy and mega-influencers,"Covid-19 vaccines are widely available in the United States, yet our Covid-19
vaccination rates have remained far below 100%. Not only that, but CDC data
shows that even in places where vaccine acceptance was proportionally high at
the outset of the Covid-19 vaccination effort, that willingness has not
necessarily translated into high rates of vaccination over the subsequent
months. We model how such a shift could have arisen, using parameters in
agreement with data from the state of Alabama. The simulations suggest that in
Alabama, local interactions would have favored the emergence of tight consensus
around the initial majority view, which was to accept the Covid-19 vaccine. Yet
this is not what happened. We therefore add to our model the impact of
mega-influencers such as mass media, the governor of the state, etc. Our
simulations show that a single vaccine-hesitant mega-influencer, reaching a
large fraction of the population, can indeed cause the consensus to shift
radically, from acceptance to hesitancy. Surprisingly this is true even when
the mega-influencer only reaches individuals who are already somewhat inclined
to agree with them, and under the conservative assumption that individuals give
no more weight to the mega-influencer than they would give to a single one of
their friends or neighbors. Our simulations also suggest that a competing
mega-influencer with the opposite view can shift the mean population opinion
back, but cannot restore the tightness of consensus around that view. Our code
and data are distributed in the ODyN (Opinion Dynamic Networks) library
available at https://github.com/annahaensch/ODyN.",2022-01-19,"Anna Haensch, Natasa Dragovic, Christoph Börgers, Bruce Boghosian"
"Representation Learning on Heterostructures via Heterogeneous Anonymous
  Walks","Capturing structural similarity has been a hot topic in the field of network
embedding recently due to its great help in understanding the node functions
and behaviors. However, existing works have paid very much attention to
learning structures on homogeneous networks while the related study on
heterogeneous networks is still a void. In this paper, we try to take the first
step for representation learning on heterostructures, which is very challenging
due to their highly diverse combinations of node types and underlying
structures. To effectively distinguish diverse heterostructures, we firstly
propose a theoretically guaranteed technique called heterogeneous anonymous
walk (HAW) and its variant coarse HAW (CHAW). Then, we devise the heterogeneous
anonymous walk embedding (HAWE) and its variant coarse HAWE in a data-driven
manner to circumvent using an extremely large number of possible walks and
train embeddings by predicting occurring walks in the neighborhood of each
node. Finally, we design and apply extensive and illustrative experiments on
synthetic and real-world networks to build a benchmark on heterostructure
learning and evaluate the effectiveness of our methods. The results demonstrate
our methods achieve outstanding performance compared with both homogeneous and
heterogeneous classic methods, and can be applied on large-scale networks.",2022-01-18,"Xuan Guo, Pengfei Jiao, Ting Pan, Wang Zhang, Mengyu Jia, Danyang Shi, Wenjun Wang"
Unveiling music genre structure through common-interest communities,"Using a dataset of more than 90,000 metal music reviews written by over 9,000
users in a period of 15 years, we analyse the genre structure of metal music
with the aid of review text information. We model the relationships between
genres using a user-oriented network, based on the written reviews. We then
perform community detection and employ a network ""averaging"" method to obtain
stable genre clusters, in order to analyse the structures of clusters both
locally within each cluster and globally over the entire network. In addition
to identifying the clusters, we use Dependency Parsing and modified Term
Frequency - Inverse Document Frequency to extract significant and unique
features of each cluster. These structures and review text information can
allow us to understand how music audience (fans) perceive similar and different
genres, and also assist in classifying different genres which share
common-interest user communities, offering a more objective way in grouping
music genres. Furthermore, the classification can also help recommendation
engines provide more targeted suggestions of music, and potentially help
musicians to select genre labels for their music, and design music to better
cater to preferences of their audiences based on previous reviews.",2022-01-18,"Zhiheng Jiang, Hoai Nguyen Huynh"
"Hate Speech in the Political Discourse on Social Media: Disparities
  Across Parties, Gender, and Ethnicity","Social media has become an indispensable channel for political communication.
However, the political discourse is increasingly characterized by hate speech,
which affects not only the reputation of individual politicians but also the
functioning of society at large. In this work, we empirically analyze how the
amount of hate speech in replies to posts from politicians on Twitter depends
on personal characteristics, such as their party affiliation, gender, and
ethnicity. For this purpose, we employ Twitter's Historical API to collect
every tweet posted by members of the 117th U.S. Congress for an observation
period of more than six months. Additionally, we gather replies for each tweet
and use machine learning to predict the amount of hate speech they embed.
Subsequently, we implement hierarchical regression models to analyze whether
politicians with certain characteristics receive more hate speech. We find that
tweets are particularly likely to receive hate speech in replies if they are
authored by (i) persons of color from the Democratic party, (ii) white
Republicans, and (iii) women. Furthermore, our analysis reveals that more
negative sentiment (in the source tweet) is associated with more hate speech
(in replies). However, the association varies across parties: negative
sentiment attracts more hate speech for Democrats (vs. Republicans).
Altogether, our empirical findings imply significant differences in how
politicians are treated on social media depending on their party affiliation,
gender, and ethnicity.",2022-01-17,"Kirill Solovev, Nicolas Pröllochs"
OntoDSumm : Ontology based Tweet Summarization for Disaster Events,"The huge popularity of social media platforms like Twitter attracts a large
fraction of users to share real-time information and short situational messages
during disasters. A summary of these tweets is required by the government
organizations, agencies, and volunteers for efficient and quick disaster
response. However, the huge influx of tweets makes it difficult to manually get
a precise overview of ongoing events. To handle this challenge, several tweet
summarization approaches have been proposed. In most of the existing
literature, tweet summarization is broken into a two-step process where in the
first step, it categorizes tweets, and in the second step, it chooses
representative tweets from each category. There are both supervised as well as
unsupervised approaches found in literature to solve the problem of first step.
Supervised approaches requires huge amount of labelled data which incurs cost
as well as time. On the other hand, unsupervised approaches could not clusters
tweet properly due to the overlapping keywords, vocabulary size, lack of
understanding of semantic meaning etc. While, for the second step of
summarization, existing approaches applied different ranking methods where
those ranking methods are very generic which fail to compute proper importance
of a tweet respect to a disaster. Both the problems can be handled far better
with proper domain knowledge. In this paper, we exploited already existing
domain knowledge by the means of ontology in both the steps and proposed a
novel disaster summarization method OntoDSumm. We evaluate this proposed method
with 4 state-of-the-art methods using 10 disaster datasets. Evaluation results
reveal that OntoDSumm outperforms existing methods by approximately 2-66% in
terms of ROUGE-1 F1 score.",2022-01-17,"Piyush Kumar Garg, Roshni Chakraborty, Sourav Kumar Dandapat"
"VaccinEU: COVID-19 vaccine conversations on Twitter in French, German
  and Italian","Despite the increasing limitations for unvaccinated people, in many European
countries there is still a non-negligible fraction of individuals who refuse to
get vaccinated against SARS-CoV-2, undermining governmental efforts to
eradicate the virus. We study the role of online social media in influencing
individuals' opinion towards getting vaccinated by designing a large-scale
collection of Twitter messages in three different languages -- French, German
and Italian -- and providing public access to the data collected. Focusing on
the European context, our VaccinEU dataset aims to help researchers to better
understand the impact of online (mis)information about vaccines and design more
accurate communication strategies to maximize vaccination coverage.",2022-01-17,"Marco Di Giovanni, Francesco Pierri, Christopher Torres-Lugo, Marco Brambilla"
"Rethinking Activity Awareness: The Design, Evaluation & Implication of
  Integrating Activity Awareness into Mobile Messaging","Nowadays, different types of context information are integrated into mobile
messaging to increase expressiveness and awareness, including mobile device
setting, location, activity, and heart rate. Due to low recognition accuracy,
sometimes users cannot accurately infer others' status through activity
awareness. Recently, activity recognition technology has advanced. However, the
user behaviors of activity awareness with improved technology have not been
studied. In this study, we design ActAware, a mobile instant messaging
application that integrates activity awareness based on improved activity
recognition technology, i.e., improved recognition accuracy and the addition of
activity transition notification. We conduct a field study to explore user
behaviors and found that activity awareness allows users to speculate on the
reasons for chat interruption, plan communication, speculate on whether the
chat partner is departing/arriving, and deepen the understanding of living
patterns. Compared with disclosing other types of context information, users
have fewer privacy concerns about disclosing activity information in ActAware.
Based on these findings, we provide design recommendations for mobile messaging
to better support activity awareness.",2022-01-17,"Ling Chen, Miaomiao Dong"
Zero Botnets: An Observe-Pursue-Counter Approach,"Adversarial Internet robots (botnets) represent a growing threat to the safe
use and stability of the Internet. Botnets can play a role in launching
adversary reconnaissance (scanning and phishing), influence operations
(upvoting), and financing operations (ransomware, market manipulation, denial
of service, spamming, and ad click fraud) while obfuscating tailored tactical
operations. Reducing the presence of botnets on the Internet, with the
aspirational target of zero, is a powerful vision for galvanizing policy
action. Setting a global goal, encouraging international cooperation, creating
incentives for improving networks, and supporting entities for botnet takedowns
are among several policies that could advance this goal. These policies raise
significant questions regarding proper authorities/access that cannot be
answered in the abstract. Systems analysis has been widely used in other
domains to achieve sufficient detail to enable these questions to be dealt with
in concrete terms. Defeating botnets using an observe-pursue-counter
architecture is analyzed, the technical feasibility is affirmed, and the
authorities/access questions are significantly narrowed. Recommended next steps
include: supporting the international botnet takedown community, expanding
network observatories, enhancing the underlying network science at scale,
conducting detailed systems analysis, and developing appropriate policy
frameworks.",2022-01-16,"Jeremy Kepner, Jonathan Bernays, Stephen Buckley, Kenjiro Cho, Cary Conrad, Leslie Daigle, Keeley Erhardt, Vijay Gadepally, Barry Greene, Michael Jones, Robert Knake, Bruce Maggs, Peter Michaleas, Chad Meiners, Andrew Morris, Alex Pentland, Sandeep Pisharody, Sarah Powazek, Andrew Prout, Philip Reiner, Koichi Suzuki, Kenji Takahashi, Tony Tauber, Leah Walker, Douglas Stetson"
"Understanding Political Polarization via Jointly Modeling Users,
  Connections and Multimodal Contents on Heterogeneous Graphs","Understanding political polarization on social platforms is important as
public opinions may become increasingly extreme when they are circulated in
homogeneous communities, thus potentially causing damage in the real world.
Automatically detecting the political ideology of social media users can help
better understand political polarization. However, it is challenging due to the
scarcity of ideology labels, complexity of multimodal contents, and cost of
time-consuming data collection process. In this study, we adopt a heterogeneous
graph neural network to jointly model user characteristics, multimodal post
contents as well as user-item relations in a bipartite graph to learn a
comprehensive and effective user embedding without requiring ideology labels.
We apply our framework to online discussions about economy and public health
topics. The learned embeddings are then used to detect political ideology and
understand political polarization. Our framework outperforms the unimodal,
early/late fusion baselines, and homogeneous GNN frameworks by a margin of at
least 9% absolute gain in the area under the receiver operating characteristic
on two social media datasets. More importantly, our work does not require a
time-consuming data collection process, which allows faster detection and in
turn allows the policy makers to conduct analysis and design policies in time
to respond to crises. We also show that our framework learns meaningful user
embeddings and can help better understand political polarization. Notable
differences in user descriptions, topics, images, and levels of retweet/quote
activities are observed. Our framework for decoding user-content interaction
shows wide applicability in understanding political polarization. Furthermore,
it can be extended to user-item bipartite information networks for other
applications such as content and product recommendation.",2022-01-16,"Hanjia Lyu, Jiebo Luo"
"""I Can't Keep It Up."" A Dataset from the Defunct Voat.co News Aggregator","Voat.co was a news aggregator website that shut down on December 25, 2020.
The site had a troubled history and was known for hosting various banned
subreddits. This paper presents a dataset with over 2.3M submissions and 16.2M
comments posted from 113K users in 7.1K subverses (the equivalent of subreddit
for Voat). Our dataset covers the whole lifetime of Voat, from its developing
period starting on November 8, 2013, the day it was founded, April 2014, up
until the day it shut down (December 25, 2020). This work presents the largest
and most complete publicly available Voat dataset, to the best of our
knowledge. Along with the release of this dataset, we present a preliminary
analysis covering posting activity and daily user and subverse registration on
the platform so that researchers interested in our dataset can know what to
expect. Our data may prove helpful to false news dissemination studies as we
analyze the links users share on the platform, finding that many communities
rely on alternative news press, like Breitbart and GatewayPundit, for their
daily discussions. In addition, we perform network analysis on user
interactions finding that many users prefer not to interact with subverses
outside their narrative interests, which could be helpful to researchers
focusing on polarization and echo chambers. Also, since Voat was one of the
platforms banned Reddit communities migrated to, we are confident our dataset
will motivate and assist researchers studying deplatforming. Finally, many
hateful and conspiratorial communities were very popular on Voat, which makes
our work valuable for researchers focusing on toxicity, conspiracy theories,
cross-platform studies of social networks, and natural language processing.",2022-01-15,"Amin Mekacher, Antonis Papasavva"
"Interpretable and Effective Reinforcement Learning for Attacking against
  Graph-based Rumor Detection","Social networks are frequently polluted by rumors, which can be detected by
advanced models such as graph neural networks. However, the models are
vulnerable to attacks and understanding the vulnerabilities is critical to
rumor detection in practice. To discover subtle vulnerabilities, we design a
powerful attacking algorithm to camouflage rumors in social networks based on
reinforcement learning that can interact with and attack any black-box
detectors. The environment has exponentially large state spaces, high-order
graph dependencies, and delayed noisy rewards, making the state-of-the-art
end-to-end approaches difficult to learn features as large learning costs and
expressive limitation of graph deep models. Instead, we design domain-specific
features to avoid learning features and produce interpretable attack policies.
To further speed up policy optimization, we devise: (i) a credit assignment
method that decomposes delayed rewards to atomic attacking actions proportional
to the their camouflage effects on target rumors; (ii) a time-dependent control
variate to reduce reward variance due to large graphs and many attacking steps,
supported by the reward variance analysis and a Bayesian analysis of the
prediction distribution. On three real world datasets of rumor detection tasks,
we demonstrate: (i) the effectiveness of the learned attacking policy compared
to rule-based attacks and current end-to-end approaches; (ii) the usefulness of
the proposed credit assignment strategy and variance reduction components;
(iii) the interpretability of the policy when generating strong attacks via the
case study.",2022-01-15,"Yuefei Lyu, Xiaoyu Yang, Jiaxin Liu, Philip S. Yu, Sihong Xie, Xi Zhang"
What is the mission of innovation?,"Governments and organizations recognize the need to revisit a mission-driven
innovation amidst national and organizational innovation policy formulations.
Notwithstanding a fertile research agenda on mission statements (hereafter
mission(s)), several lines of inquiry remain open, such as crossnational and
multisectorial studies and an examination of research knowledge intensive
institutions. In this article, we identify similarities and differences in the
content of missions from government, private, higher education, and health
research knowledge intensive institutions in a sample of over 1,900
institutions from 89 countries through the deployment of sentiment analysis,
readability, and lexical diversity; semantic networks; and a similarity
computation between document corpus. We found that missions of research
knowledge intensive institutions are challenging to read texts with lower
lexical diversity that favors positive rather than negative words. In stark
contrast to this, the non-profit sector is consonant in multiple dimensions in
its use of Corporate Social Responsibility jargon. The lexical appearance of
research in the missions varies according to mission sectorial context, and
each sector has a cluster specific focus. Utilizing the mission as a strategic
planning tool in higher income regions might serve to explain corpora
similarities shared by sectors and continents.",2022-01-14,Julian D. Cortes
"A Fine-Grained Analysis of Public Opinion toward Chinese Technology
  Companies on Reddit","In the face of the growing global influence and prevalence of Chinese
technology companies, governments worldwide have expressed concern and mistrust
toward these companies. There is a scarcity of research that specifically
examines the widespread public response to this phenomenon on a large scale.
This study aims to fill in the gap in understanding public opinion toward
Chinese technology companies using Reddit data, a popular news-oriented social
media platform. We employ the state-of-the-art transformer model to build a
reliable sentiment classifier. We then use LDA to extract the topics associated
with positive and negative comments. We also conduct content analysis by
studying the changes in the semantic meaning of the companies' names over time.
Our main findings include the following: 1) Notable difference exists in the
proportions of positive comments (8.42%) and negative comments (14.12%); 2)
Positive comments are mostly associated with the companies' consumer products,
such as smartphones, laptops, and wearable electronics. Negative comments have
a more diverse topic distribution (notable topics include criticism toward the
platform, dissatisfaction with the companies' smartphone products, companies'
ties to the Chinese government, data security concerns, 5G construction, and
general political discussions); and 3) Characterization of each technology
company is usually centered around a particular predominant theme related to
the company, while real-world political events may trigger drastic changes in
users' characterization.",2022-01-14,"Enting Zhou, Yurong Liu, Hanjia Lyu, Jiebo Luo"
"This Must Be the Place: Predicting Engagement of Online Communities in a
  Large-scale Distributed Campaign","Understanding collective decision making at a large-scale, and elucidating
how community organization and community dynamics shape collective behavior are
at the heart of social science research. In this work we study the behavior of
thousands of communities with millions of active members. We define a novel
task: predicting which community will undertake an unexpected, large-scale,
distributed campaign.
  To this end, we develop a hybrid model, combining textual cues, community
meta-data, and structural properties. We show how this multi-faceted model can
accurately predict large-scale collective decision-making in a distributed
environment. We demonstrate the applicability of our model through Reddit's
r/place - a large-scale online experiment in which millions of users,
self-organized in thousands of communities, clashed and collaborated in an
effort to realize their agenda.
  Our hybrid model achieves a high F1 prediction score of 0.826. We find that
coarse meta-features are as important for prediction accuracy as fine-grained
textual cues, while explicit structural features play a smaller role.
Interpreting our model, we provide and support various social insights about
the unique characteristics of the communities that participated in the \r/place
experiment.
  Our results and analysis shed light on the complex social dynamics that drive
collective behavior, and on the factors that propel user coordination. The
scale and the unique conditions of the \rp~experiment suggest that our findings
may apply in broader contexts, such as online activism, (countering) the spread
of hate speech and reducing political polarization. The broader applicability
of the model is demonstrated through an extensive analysis of the
WallStreetBets community, their role in r/place and four years later, in the
GameStop short squeeze campaign of 2021.",2022-01-14,"Abraham Israeli, Alexander Kremiansky, Oren Tsur"
"Global-threshold and backbone high-resolution weather radar networks are
  significantly complementary in a watershed","There are several criteria for building up networks from time series related
to different points in geographical space. The most used criterion is the
Global-Threshold (GT). Using a weather radar dataset, this paper shows that the
Backbone (BB) - a local-threshold criterion - generates networks whose
geographical configuration is complementary to the GT networks. We compare the
results for two well-known similarities measures: the Pearson Correlation (PC)
coefficient and the Mutual Information (MI). The extracted backbone network
(miBB), whose number of links is the same as the global MI (miGT), has the
lowest average shortest path and presents a small-world effect. Regarding the
global PC (pcGT) and its corresponding BB network (pcBB), there is a
significant linear relationship: $R2=0.77$ with a slope of $1.15$ (p-value
$<E-7$) for the pcGT network, and $R2=0.68$ with a slope of $0.76$ (p-value
$<E-7$) for the pcBB network. In relation to the MI ones, only the miGT present
a high $R2$ ($0.79$, with slope = $1.95$), whereas the miBB has an $R2$ of only
$0.20$ ($\text{slope} =0.24$). On the one hand, the GT networks present a
sizeable connected component in the central area, close to the main rivers. On
the other hand, the BB networks present a few meaningful connected components
surrounding the watershed and dominating cells close to the outlet, with
significant statistical differences in the altimetry distribution.",2022-01-13,"Aurelienne A. S. Jorge, Iuri da Silva Diniz, Vander L. S. Freitas, Izabelly C. Costa, Leonardo B. L. Santos"
"Feature-rich multiplex lexical networks reveal mental strategies of
  early language learning","Knowledge in the human mind exhibits a dualistic vector/network nature.
Modelling words as vectors is key to natural language processing, whereas
networks of word associations can map the nature of semantic memory. We
reconcile these paradigms - fragmented across linguistics, psychology and
computer science - by introducing FEature-Rich MUltiplex LEXical (FERMULEX)
networks. This novel framework merges structural similarities in networks and
vector features of words, which can be combined or explored independently.
Similarities model heterogenous word associations across
semantic/syntactic/phonological aspects of knowledge. Words are enriched with
multi-dimensional feature embeddings including frequency, age of acquisition,
length and polysemy. These aspects enable unprecedented explorations of
cognitive knowledge. Through CHILDES data, we use FERMULEX networks to model
normative language acquisition by 1000 toddlers between 18 and 30 months.
Similarities and embeddings capture word homophily via conformity, which
measures assortative mixing via distance and features. Conformity unearths a
language kernel of frequent/polysemous/short nouns and verbs key for basic
sentence production, supporting recent evidence of children's syntactic
constructs emerging at 30 months. This kernel is invisible to network
core-detection and feature-only clustering: It emerges from the dual
vector/network nature of words. Our quantitative analysis reveals two key
strategies in early word learning. Modelling word acquisition as random walks
on FERMULEX topology, we highlight non-uniform filling of communicative
developmental inventories (CDIs). Conformity-based walkers lead to accurate
(75%), precise (55%) and partially well-recalled (34%) predictions of early
word learning in CDIs, providing quantitative support to previous empirical
findings and developmental theories.",2022-01-13,"Salvatore Citraro, Michael S. Vitevitch, Massimo Stella, Giulio Rossetti"
"Theme Analysis of Political Facebook Ads in the 2021 Dutch General
  Election","Social media platforms have been trying to be more transparent about the
political ads they run on their platforms, because the Cambridge Analytica
scandal revealed that political campaigns are using social media on a large
scale. One such transparency effort is the Facebook Ad Library, a public
repository of all political ads run on Facebook and Instagram. This library
provides journalist and researchers with data to get a better understanding of
political advertising and microtargeting on Facebook's platforms.
Unfortunately, the Facebook Ad Library only provides estimates and basic
information. This paper analyses political ads in more depth, by examining the
themes that ads are about. We provide a method to match themes to political
Facebook ads and we apply this method to analyse Facebook ad campaigns ran by
Dutch political parties during the 2021 Dutch general election.",2022-01-12,Joren Vrancken
"No Community Can Do Everything: Why People Participate in Similar Online
  Communities","Large-scale quantitative analyses have shown that individuals frequently talk
to each other about similar things in different online spaces. Why do these
overlapping communities exist? We provide an answer grounded in the analysis of
20 interviews with active participants in clusters of highly related
subreddits. Within a broad topical area, there are a diversity of benefits an
online community can confer. These include (a) specific information and
discussion, (b) socialization with similar others, and (c) attention from the
largest possible audience. A single community cannot meet all three needs. Our
findings suggest that topical areas within an online community platform tend to
become populated by groups of specialized communities with diverse sizes,
topical boundaries, and rules. Compared with any single community, such systems
of overlapping communities are able to provide a greater range of benefits.",2022-01-12,"Nathan TeBlunthuis, Charles Kiene, Isabella Brown, Laura Alia Levi, Nicole McGinnis, Benjamin Mako Hill"
"Generating Connected, Simple, and Realistic Cyber Graphs for Smart Grids","Smart grids integrate communication systems with power networks to enable
power grids operation and command through real-time data collection and control
signals. Designing, analyzing, and simulating smart grid infrastructures as
well as predicting the impact of power network failures strongly depend on the
topologies of the underlying power network and communication system. Despite
the substantial impact that the communication systems bring to smart grid
operation, the topology of communication systems employed in smart grids was
less studied. The power community lacks realistic generative communication
system models that can be calibrated to match real-world data. To address this
issue, this paper proposes a framework to generate the underlying topological
graphs for the communication systems deployed in smart grids by mimicking the
topology of real-world smart grids. In this regard, we have updated the
Chung-Lu algorithm to guarantee the communication network connectivity and to
match the degree distribution of a real-world smart grid rather than following
an expected degree distribution. In addition, key characteristics of
communication systems such as diameter, average shortest paths, clustering
coefficients, assortativity, and spectral gap were taken into consideration to
generate the most similar real-world communication network for smart grid
studies. We believe that the proposed algorithm to generate realistic cyber
graphs for smart grid studies will benefit the power community.",2022-01-12,"Osman Boyaci, M. Rasoul Narimani, Katherine Davis, Erchin Serpedin"
"Understanding how people consume low quality and extreme news using web
  traffic data","To mitigate the spread of fake news, researchers need to understand who visit
fake new sites, what brings people to those sites, where visitors come from,
and what content they prefer to consume. In this paper, we analyze web traffic
data from The Gateway Pundit (TGP), a popular far-right website that is known
for repeatedly sharing false information that has made its web traffic
available to the general public. We collect data on 68 million web traffic
visits to the site over a month period and analyze how people consume news via
multiple features. Our traffic analysis shows that search engines and social
media platforms are main drivers of traffic; our geo-location analysis reveals
that TGP is more popular in counties that voted for Trump in 2020; and our
topic analysis shows that conspiratorial articles receive more visits than
factual articles.
  Due to the inability to observe direct website traffic, existing research
uses alternative data source such as engagement signals from social media
posts. To validate if social media engagement signals correlate with actual web
visit counts, we collect all Facebook and Twitter posts with URLs from TGP
during the same time period. We show that all engagement signals positively
correlate with web visit counts, but with varying correlation strengths.
Metrics based on Facebook posts correlate better than metrics based on Twitter.
Our unique web traffic data set and insights can help researchers to better
measure the impact of far-right and fake news URLs on social media platforms.",2022-01-11,"Zhouhan Chen, Haohan Chen, Juliana Freire, Jonathan Nagler, Joshua A. Tucker"
"Investigating internal migration with network analysis and latent space
  representations: An application to Turkey","Human migration patterns influence the redistribution of population
characteristics over the geography and since such distributions are closely
related to social and economic outcomes, investigating the structure and
dynamics of internal migration plays a crucial role in understanding and
designing policies for such systems. We provide an in-depth investigation into
the structure and dynamics of the internal migration in Turkey from 2008 to
2020. We identify a set of classical migration laws and examine them via
various methods for signed network analysis, ego network analysis,
representation learning, temporal stability analysis, community detection, and
network visualization. The findings show that, in line with the classical
migration laws, most migration links are geographically bounded with several
exceptions involving cities with large economic activity, major migration flows
are countered with migration flows in the opposite direction, there are
well-defined migration routes, and the migration system is generally stable
over the investigated period. Apart from these general results, we also provide
unique and specific insights into Turkey. Overall, the novel toolset we employ
for the first time in the literature allows the investigation of selected
migration laws from a complex networks perspective and sheds light on future
migration research on different geographies.",2022-01-10,"Furkan Gürsoy, Bertan Badur"
"A comparison of primary stakeholders'views on the deployment of
  biometric technologies in border management: Case study of SMart mobILity at
  the European land borders","Advances in technology have a substantial impact on every aspect of our
lives, ranging from the way we communicate to the way we travel. The Smart
mobility at the European land borders (SMILE) project is geared towards the
deployment of biometric technologies to optimize and monitor the flow of people
at land borders. However, despite the anticipated benefits of deploying
biometric technologies in border control, there are still divergent views on
the use of such technologies by two primary stakeholders travelers and border
authorities. In this paper, we provide a comparison of travelers and border
authorities views on the deployment of biometric technologies in border
management. The overall goal of this study is to enable us to understand the
concerns of travelers and border guards in order to facilitate the acceptance
of biometric technologies for a secure and more convenient border crossing. Our
method of inquiry consisted of in person interviews with border guards (SMILE
project end users), observation and field visits (to the Hungarian-Romanian and
Bulgarian-Romanian borders) and questionnaires for both travelers and border
guards. As a result of our investigation, two conflicting trends emerged. On
one hand, border guards argued that biometric technologies had the potential to
be a very effective tool that would enhance security levels and make traveler
identification and authentication procedures easy, fast and convenient. On the
other hand, travelers were more concerned about the technologies representing a
threat to fundamental rights, personal privacy and data protection.",2022-01-10,"Mohamed Abomhara, Sule Yildirim Yayilgan, Livinus Obiora Nweke, Zoltan Szekely"
Social Media Networks Attacks and their Preventive Mechanisms: A Review,"We live in a virtual world where actual lifestyles are replicated. The
growing reliance on the use of social media networks worldwide has resulted in
great concern for information security. One of the factors popularizing the
social media platforms is how they connect people worldwide to interact, share
content, and engage in mutual interactions of common interest that cut across
geographical boundaries. Behind all these incredible gains are digital crime
equivalence that threatens the physical socialization. Criminal-minded elements
and hackers are exploiting Social Media Platforms (SMP) for many nefarious
activities to harm others. As detection tools are developed to control these
crimes, hackers' tactics and techniques are constantly evolving. Hackers are
constantly developing new attacking tools and hacking strategies to gain
malicious access to systems and attack social media network thereby making it
difficult for security administrators and organizations to develop and
implement the proper policies and procedures necessary to prevent the hackers'
attacks. The increase in cyber-attacks on the social media platforms calls for
urgent and more intelligent security measures to enhance the effectiveness of
social media platforms. This paper explores the mode and tactics of hackers'
mode of attacks on social media and ways of preventing their activities against
users to ensure secure social cyberspace and enhance virtual socialization.
Social media platforms are briefly categorized, the various types of attacks
are also highlighted with current state-of-the-art preventive mechanisms to
overcome the attacks as proposed in research works, finally, social media
intrusion detection mechanism is suggested as a second line of defense to
combat cybercrime on social media networks",2022-01-10,"Emmanuel Etuh, Francis S. Bakpo, Eneh Agozie H"
"Promoting and countering misinformation during Australia's 2019-2020
  bushfires: A case study of polarisation","During Australia's unprecedented bushfires in 2019-2020, misinformation
blaming arson resurfaced on Twitter using #ArsonEmergency. The extent to which
bots were responsible for disseminating and amplifying this misinformation has
received scrutiny in the media and academic research. Here we study Twitter
communities spreading this misinformation during the population-level event,
and investigate the role of online communities and bots. Our in-depth
investigation of the dynamics of the discussion uses a phased approach --
before and after reporting of bots promoting the hashtag was broadcast by the
mainstream media. Though we did not find many bots, the most bot-like accounts
were social bots, which present as genuine humans. Further, we distilled
meaningful quantitative differences between two polarised communities in the
Twitter discussion, resulting in the following insights. First, Supporters of
the arson narrative promoted misinformation by engaging others directly with
replies and mentions using hashtags and links to external sources. In response,
Opposers retweeted fact-based articles and official information. Second,
Supporters were embedded throughout their interaction networks, but Opposers
obtained high centrality more efficiently despite their peripheral positions.
By the last phase, Opposers and unaffiliated accounts appeared to coordinate,
potentially reaching a broader audience. Finally, unaffiliated accounts shared
the same URLs as Opposers over Supporters by a ratio of 9:1 in the last phase,
having shared mostly Supporter URLs in the first phase. This foiled Supporters'
efforts, highlighting the value of exposing misinformation campaigns. We
speculate that the communication strategies observed here could be discoverable
in other misinformation-related discussions and could inform
counter-strategies.",2022-01-10,"Derek Weber, Lucia Falzon, Lewis Mitchell, Mehwish Nasim"
VGAER: Graph Neural Network Reconstruction based Community Detection,"Community detection is a fundamental and important issue in network science,
but there are only a few community detection algorithms based on graph neural
networks, among which unsupervised algorithms are almost blank. By fusing the
high-order modularity information with network features, this paper proposes a
Variational Graph AutoEncoder Reconstruction based community detection VGAER
for the first time, and gives its non-probabilistic version. They do not need
any prior information. We have carefully designed corresponding input features,
decoder, and downstream tasks based on the community detection task and these
designs are concise, natural, and perform well (NMI values under our design are
improved by 59.1% - 565.9%). Based on a series of experiments with wide range
of datasets and advanced methods, VGAER has achieved superior performance and
shows strong competitiveness and potential with a simpler design. Finally, we
report the results of algorithm convergence analysis and t-SNE visualization,
which clearly depicted the stable performance and powerful network modularity
ability of VGAER. Our codes are available at https://github.com/qcydm/VGAER.",2022-01-08,"Chenyang Qiu, Zhaoci Huang, Wenzhe Xu, Huijia Li"
MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs,"We introduce a novel masked graph autoencoder (MGAE) framework to perform
effective learning on graph structure data. Taking insights from
self-supervised learning, we randomly mask a large proportion of edges and try
to reconstruct these missing edges during training. MGAE has two core designs.
First, we find that masking a high ratio of the input graph structure, e.g.,
$70\%$, yields a nontrivial and meaningful self-supervisory task that benefits
downstream applications. Second, we employ a graph neural network (GNN) as an
encoder to perform message propagation on the partially-masked graph. To
reconstruct the large number of masked edges, a tailored cross-correlation
decoder is proposed. It could capture the cross-correlation between the head
and tail nodes of anchor edge in multi-granularity. Coupling these two designs
enables MGAE to be trained efficiently and effectively. Extensive experiments
on multiple open datasets (Planetoid and OGB benchmarks) demonstrate that MGAE
generally performs better than state-of-the-art unsupervised learning
competitors on link prediction and node classification.",2022-01-07,"Qiaoyu Tan, Ninghao Liu, Xiao Huang, Rui Chen, Soo-Hyun Choi, Xia Hu"
Neighbor2vec: an efficient and effective method for Graph Embedding,"Graph embedding techniques have led to significant progress in recent years.
However, present techniques are not effective enough to capture the patterns of
networks. This paper propose neighbor2vec, a neighbor-based sampling strategy
used algorithm to learn the neighborhood representations of node, a framework
to gather the structure information by feature propagation between the node and
its neighbors. We claim that neighbor2vec is a simple and effective approach to
enhancing the scalability as well as equality of graph embedding, and it breaks
the limits of the existing state-of-the-art unsupervised techniques. We conduct
experiments on several node classification and link prediction tasks for
networks such as ogbn-arxiv, ogbn-products, ogbn-proteins, ogbl-ppa,ogbl-collab
and ogbl-citation2. The result shows that Neighbor2vec's representations
provide an average accuracy scores up to 6.8 percent higher than competing
methods in node classification tasks and 3.0 percent higher in link prediction
tasks. The neighbor2vec's representations are able to outperform all baseline
methods and two classical GNN models in all six experiments.",2022-01-07,Zhiming Lin
"Spatio-Temporal Graph Representation Learning for Fraudster Group
  Detection","Motivated by potential financial gain, companies may hire fraudster groups to
write fake reviews to either demote competitors or promote their own
businesses. Such groups are considerably more successful in misleading
customers, as people are more likely to be influenced by the opinion of a large
group. To detect such groups, a common model is to represent fraudster groups'
static networks, consequently overlooking the longitudinal behavior of a
reviewer thus the dynamics of co-review relations among reviewers in a group.
Hence, these approaches are incapable of excluding outlier reviewers, which are
fraudsters intentionally camouflaging themselves in a group and genuine
reviewers happen to co-review in fraudster groups. To address this issue, in
this work, we propose to first capitalize on the effectiveness of the HIN-RNN
in both reviewers' representation learning while capturing the collaboration
between reviewers, we first utilize the HIN-RNN to model the co-review
relations of reviewers in a group in a fixed time window of 28 days. We refer
to this as spatial relation learning representation to signify the
generalisability of this work to other networked scenarios. Then we use an RNN
on the spatial relations to predict the spatio-temporal relations of reviewers
in the group. In the third step, a Graph Convolution Network (GCN) refines the
reviewers' vector representations using these predicted relations. These
refined representations are then used to remove outlier reviewers. The average
of the remaining reviewers' representation is then fed to a simple fully
connected layer to predict if the group is a fraudster group or not. Exhaustive
experiments of the proposed approach showed a 5% (4%), 12% (5%), 12% (5%)
improvement over three of the most recent approaches on precision, recall, and
F1-value over the Yelp (Amazon) dataset, respectively.",2022-01-07,"Saeedreza Shehnepoor, Roberto Togneri, Wei Liu, Mohammed Bennamoun"
Handling Trust in A Cloud Based Multi Agent System,"Cloud computing is an opened and distributed network that guarantees access
to a large amount of data and IT infrastructure at several levels (software,
hardware...). With the increase demand, handling clients' needs is getting
increasingly challenging. Responding to all requesting clients could lead to
security breaches, and since it is the provider's responsibility to secure not
only the offered cloud services but also the data, it is important to ensure
clients reliability. Although filtering clients in the cloud is not so common,
it is required to assure cloud safety.
  In this paper, by implementing multi agent systems in the cloud to handle
interactions for the providers, trust is introduced at agent level to filtrate
the clients asking for services by using Particle Swarm Optimization and
acquaintance knowledge to determine malicious and untrustworthy clients. The
selection depends on previous knowledge and overall rating of trusted peers.
The conducted experiments show that the model outputs relevant results, and
even with a small number of peers, the framework is able to converge to the
best solution. The model presented in this paper is a part of ongoing work to
adapt interactions in the cloud.",2022-01-05,"Imen Bouabdallah, Hakima Mellah"
Botometer 101: Social bot practicum for computational social scientists,"Social bots have become an important component of online social media.
Deceptive bots, in particular, can manipulate online discussions of important
issues ranging from elections to public health, threatening the constructive
exchange of information. Their ubiquity makes them an interesting research
subject and requires researchers to properly handle them when conducting
studies using social media data. Therefore, it is important for researchers to
gain access to bot detection tools that are reliable and easy to use. This
paper aims to provide an introductory tutorial of Botometer, a public tool for
bot detection on Twitter, for readers who are new to this topic and may not be
familiar with programming and machine learning. We introduce how Botometer
works, the different ways users can access it, and present a case study as a
demonstration. Readers can use the case study code as a template for their own
research. We also discuss recommended practice for using Botometer.",2022-01-05,"Kai-Cheng Yang, Emilio Ferrara, Filippo Menczer"
"Nipping in the Bud: Detection, Diffusion and Mitigation of Hate Speech
  on Social Media","Since the proliferation of social media usage, hate speech has become a major
crisis. Hateful content can spread quickly and create an environment of
distress and hostility. Further, what can be considered hateful is contextual
and varies with time. While online hate speech reduces the ability of already
marginalised groups to participate in discussion freely, offline hate speech
leads to hate crimes and violence against individuals and communities. The
multifaceted nature of hate speech and its real-world impact have already
piqued the interest of the data mining and machine learning communities.
Despite our best efforts, hate speech remains an evasive issue for researchers
and practitioners alike. This article presents methodological challenges that
hinder building automated hate mitigation systems. These challenges inspired
our work in the broader area of combating hateful content on the web. We
discuss a series of our proposed solutions to limit the spread of hate speech
on social media.",2022-01-04,"Tanmoy Chakraborty, Sarah Masud"
"SMART: a Technology Readiness Methodology in the Frame of the NIS
  Directive","An ever shorter technology lifecycle engendered the need for assessing new
technologies w.r.t. their market readiness. Knowing the Technology readiness
level (TRL) of a given target technology proved to be useful to mitigate risks
such as cost overrun, product roll out delays, or early launch failures.
Originally developed for space programmes by NASA, TRL became a de facto
standard among technology and manufacturing companies and even among research
funding agencies. However, while TRL assessments provide a systematic
evaluation process resulting in meaningful metric, they are one dimensional:
they only answer the question if a technology can go into production. Hence
they leave an inherent gap, i.e., if a technology fulfils requirements with a
certain quality. This gap becomes intolerable when this metric is applied
software such as technological cybersecurity measures. With legislation such as
the General Data Protection Regulation4 (GDPR) and the Network and Information
Systems Directive5 (NIS-D) making reference to state of the art when requiring
appropriate protection measures, software designers are faced with the question
how to measure if a technology is suitable to use. We argue that there is a
potential mismatch of legal aim and technological reality which not only leads
to a risk of non-compliance, but also might lead to weaker protected systems
than possible. In that regard, we aim to address the gaps identified with
existing Technology Readiness Assessment (TRA)s and aim to overcome these by
developing standardised method which is suitable for assessing software w.r.t.
its market readiness and quality (in sum maturity).",2022-01-03,"Archana Kumari, Stefan Schiffner, Sandra Schmitz"
Automated Fake News Detection using cross-checking with reliable sources,"Over the past decade, fake news and misinformation have turned into a major
problem that has impacted different aspects of our lives, including politics
and public health. Inspired by natural human behavior, we present an approach
that automates the detection of fake news. Natural human behavior is to
cross-check new information with reliable sources. We use Natural Language
Processing (NLP) and build a machine learning (ML) model that automates the
process of cross-checking new information with a set of predefined reliable
sources. We implement this for Twitter and build a model that flags fake
tweets. Specifically, for a given tweet, we use its text to find relevant news
from reliable news agencies. We then train a Random Forest model that checks if
the textual content of the tweet is aligned with the trusted news. If it is
not, the tweet is classified as fake. This approach can be generally applied to
any kind of information and is not limited to a specific news story or a
category of information. Our implementation of this approach gives a $70\%$
accuracy which outperforms other generic fake-news classification models. These
results pave the way towards a more sensible and natural approach to fake news
detection.",2022-01-01,"Zahra Ghadiri, Milad Ranjbar, Fakhteh Ghanbarnejad, Sadegh Raeisi"
"A Markov Decision Process Framework for Efficient and Implementable
  Contact Tracing and Isolation","Efficient contact tracing and isolation is an effective strategy to control
epidemics. It was used effectively during the Ebola epidemic and successfully
implemented in several parts of the world during the ongoing COVID-19 pandemic.
An important consideration in contact tracing is the budget on the number of
individuals asked to quarantine -- the budget is limited for socioeconomic
reasons. In this paper, we present a Markov Decision Process (MDP) framework to
formulate the problem of using contact tracing to reduce the size of an
outbreak while asking a limited number of people to quarantine. We formulate
each step of the MDP as a combinatorial problem, MinExposed, which we
demonstrate is NP-Hard; as a result, we develop an LP-based approximation
algorithm. Though this algorithm directly solves MinExposed, it is often
impractical in the real world due to information constraints. To this end, we
develop a greedy approach based on insights from the analysis of the previous
algorithm, which we show is more interpretable. A key feature of the greedy
algorithm is that it does not need complete information of the underlying
social contact network. This makes the heuristic implementable in practice and
is an important consideration. Finally, we carry out experiments on simulations
of the MDP run on real-world networks, and show how the algorithms can help in
bending the epidemic curve while limiting the number of isolated individuals.
Our experimental results demonstrate that the greedy algorithm and its variants
are especially effective, robust, and practical in a variety of realistic
scenarios, such as when the contact graph and specific transmission
probabilities are not known. All code can be found in our GitHub repository:
https://github.com/gzli929/ContactTracing.",2021-12-31,"George Li, Arash Haddadan, Ann Li, Madhav Marathe, Aravind Srinivasan, Anil Vullikanti, Zeyu Zhao"
"Uncovering migration systems through spatio-temporal tensor
  co-clustering","A central problem in the study of human mobility is that of migration
systems. Typically, migration systems are defined as a set of relatively stable
movements of people between two or more locations over time. While these
emergent systems are expected to vary over time, they ideally contain a stable
underlying structure that could be discovered empirically. There have been some
notable attempts to formally or informally define migration systems, however
they have been limited by being hard to operationalize, and by defining
migration systems in ways that ignore origin/destination aspects and/or fail to
account for migration dynamics. In this work we propose a novel method,
spatio-temporal (ST) tensor co-clustering, stemming from signal processing and
machine learning theory. To demonstrate its effectiveness for describing stable
migration systems we focus on domestic migration between counties in the US
from 1990-2018. Relevant data for this period has been made available through
the US Internal Revenue Service. Specifically, we concentrate on three
illustrative case studies: (i) US Metropolitan Areas, (ii) the state of
California, and (iii) Louisiana, focusing on detecting exogenous events such as
Hurricane Katrina in 2005. Finally, we conclude with discussion and limitations
of this approach.",2021-12-31,"Zack W. Almquist, Tri Duc Nguyen, Mikael Sorensen, Xiao Fu, Nicholas D. Sidiropoulos"
"Effective and Efficient PageRank-based Positioning for Graph
  Visualization","Graph visualization is a vital component in many real-world applications
(e.g., social network analysis, web mining, and bioinformatics) that enables
users to unearth crucial insights from complex data. Lying in the core of graph
visualization is the node distance measure, which determines how the nodes are
placed on the screen. A favorable node distance measure should be informative
in reflecting the full structural information between nodes and effective in
optimizing visual aesthetics. However, existing node distance measures yield
sub-par visualization quality as they fall short of these requirements.
Moreover, most existing measures are computationally inefficient, incurring a
long response time when visualizing large graphs. To overcome such
deficiencies, we propose a new node distance measure, PDist, geared towards
graph visualization by exploiting a well-known node proximity measure,
personalized PageRank. Moreover, we propose an efficient algorithm Tau-Push for
estimating PDist under both single- and multi-level visualization settings.
With several carefully-designed techniques, Tau-Push offers non-trivial
theoretical guarantees for estimation accuracy and computation complexity.
Extensive experiments show that our proposal significantly outperforms 13
state-of-the-art graph visualization solutions on 12 real-world graphs in terms
of both efficiency and effectiveness (including aesthetic criteria and user
feedback). In particular, our proposal can interactively produce satisfactory
visualizations within one second for billion-edge graphs.",2021-12-30,"Shiqi Zhang, Renchi Yang, Xiaokui Xiao, Xiao Yan, Bo Tang"
"Analytical Models for Motifs in Temporal Networks: Discovering Trends
  and Anomalies","Dynamic evolving networks capture temporal relations in domains such as
social networks, communication networks, and financial transaction networks. In
such networks, temporal motifs, which are repeated sequences of time-stamped
edges/transactions, offer valuable information about the networks' evolution
and function. However, currently no analytical models for temporal graphs exist
and there are no models that would allow for scalable modeling of temporal
motif frequencies over time. Here, we develop the Temporal Activity State Block
Model (TASBM), to model temporal motifs in temporal graphs. We develop
efficient model fitting methods and derive closed-form expressions for the
expected motif frequencies and their variances in a given temporal network,
thus enabling the discovery of statistically significant temporal motifs. Our
TASMB framework can accurately track the changes in the expected motif
frequencies over time, and also scales well to networks with tens of millions
of edges/transactions as it does not require time-consuming generation of many
random temporal networks and then computing motif counts for each one of them.
We show that TASBM is able to model changes in temporal activity over time in a
network of financial transactions, a phone call, and an email network.
Additionally, we show that deviations from the expected motif counts calculated
by our analytical framework correspond to anomalies in the financial
transactions and phone call networks.",2021-12-30,"Alexandra Porter, Baharan Mirzasoleiman, Jure Leskovec"
"Source Detection via Contact Tracing in the Presence of Asymptomatic
  Patients","Inferring the source of a diffusion in a large network of agents is a
difficult but feasible task, if a few agents act as sensors revealing the time
at which they got hit by the diffusion. A main limitation of current source
detection algorithms is that they assume full knowledge of the contact network,
which is rarely the case, especially for epidemics, where the source is called
patient zero. Inspired by recent contact tracing algorithms, we propose a new
framework, which we call Source Detection via Contact Tracing Framework
(SDCTF). In the SDCTF, the source detection task starts at the time of the
first hospitalization, and initially we have no knowledge about the contact
network other than the identity of the first hospitalized agent. We may then
explore the network by contact queries, and obtain symptom onset times by test
queries in an adaptive way. We also assume that some of the agents may be
asymptomatic, and therefore cannot reveal their symptom onset time. Our goal is
to find patient zero with as few contact and test queries as possible.
  We propose two local search algorithms for the SDCTF: the LS algorithm is
more data-efficient, but can fail to find the true source if many asymptomatic
agents are present, whereas the LS+ algorithm is more robust to asymptomatic
agents. By simulations we show that both LS and LS+ outperform state of the art
adaptive and non-adaptive source detection algorithms adapted to the SDCTF,
even though these baseline algorithms have full access to the contact network.
Extending the theory of random exponential trees, we analytically approximate
the probability of success of the LS/ LS+ algorithms, and we show that our
analytic results match the simulations. Finally, we benchmark our algorithms on
the Data-driven COVID-19 Simulator developed by Lorch et al., which is the
first time source detection algorithms are tested on such a complex dataset.",2021-12-29,"Gergely Ódor, Jana Vuckovic, Miguel-Angel Sanchez Ndoye, Patrick Thiran"
"Neural Myerson Auction for Truthful and Energy-Efficient Autonomous
  Aerial Data Delivery","A successful deployment of drones provides an ideal solution for surveillance
systems. Using drones for surveillance can provide access to areas that may be
difficult or impossible to reach by humans or in-land vehicles gathering images
or video recordings of a specific target in their coverage. Therefore, we
introduces a data delivery drone to transfer collected surveillance data in
harsh communication conditions. This paper proposes a Myerson auction-based
asynchronous data delivery in an aerial distributed data platform in
surveillance systems taking battery limitation and long flight constraints into
account. In this paper, multiple delivery drones compete to offer data transfer
to a single fixed-location surveillance drone. Our proposed Myerson
auction-based algorithm, which uses the truthful second-price auction (SPA) as
a baseline, is to maximize the seller's revenue while meeting several desirable
properties, i.e., individual rationality and incentive compatibility while
pursuing truthful operations. On top of these SPA-based operations, a deep
learning-based framework is additionally designed for delivery performance
improvements.",2021-12-29,"Haemin Lee, Sean Kwon, Soyi Jung, Joongheon Kim"
"How Powerful are Interest Diffusion on Purchasing Prediction: A Case
  Study of Taocode","A taocode is a kind of specially coded text-link on Taobao(the world's
biggest online shopping website), through which users can share messages about
products with each other. Analyzing taocodes can potentially facilitate
understanding of the social relationships between users and, more excitingly,
their online purchasing behaviors under the influence of taocode diffusion.
This paper innovatively investigates the problem of online purchasing
predictions from an information diffusion perspective, with taocode as a case
study. Specifically, we conduct profound observational studies on a large-scale
real-world dataset from Taobao, containing over 100M Taocode sharing records.
Inspired by our observations, we propose InfNet, a dynamic GNN-based framework
that models the information diffusion across Taocode. We then apply InfNet to
item purchasing predictions. Extensive experiments on real-world datasets
validate the effectiveness of InfNet compared with 8 state-of-the-art
baselines.",2021-12-29,"Xuanwen Huang, Yang Yang, Ziqiang Cheng, Shen Fan, Zhongyao Wang, Juren Li, Jun Zhang, Jingmin Chen"
Social Sensors in Epidemiological Networks via Graph Eigenvectors,"In this paper, we consider epidemiological networks which are used for
modeling the transmission of contagious diseases through a population.
Specifically, we study the so-called social sensors problem: given an
epidemiological network, can we find a small set of nodes such that by
monitoring disease transmission on these nodes, we can get ahead of the overall
epidemic in the full population? In spite of its societal relevance, there has
not been much statistical work on this problem, and we aim to provide an
exposition that will hopefully stimulate interest in the research community.
Furthermore, by leveraging classical results in spectral graph theory, we
propose a novel method for finding social sensors, which achieves substantial
improvement over existing methods in both synthetic and real-world
epidemiological networks.",2021-12-29,"Shubhajit Sen, Samhita Pal, Srijan Sengupta"
