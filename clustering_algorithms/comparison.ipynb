{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca_embeddings = np.load('embeddings/pca_embeddings.npy')\n",
    "pca_embeddings.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(pca_embeddings)\n",
    "\n",
    "def plot_clusters(labels, title):\n",
    "    plt.scatter(scaled_embeddings[:, 0], scaled_embeddings[:, 1], c=labels, cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "abstracts = pd.read_csv('data/arxiv_abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "cluster_labels_db = np.load('cluster_labels_db.npy')\n",
    "cluster_labels_km = np.load('cluster_labels_km.npy')\n",
    "cluster_labels_hdb = np.load('cluster_labels_hdb.npy')\n",
    "\n",
    "silhouette_km = silhouette_score(scaled_embeddings, cluster_labels_km)\n",
    "silhouette_db = silhouette_score(scaled_embeddings, cluster_labels_db)\n",
    "silhouette_hdb = silhouette_score(scaled_embeddings, cluster_labels_hdb)\n",
    "print(f\"K-means Silhouette Score: {silhouette_km}\")\n",
    "print(f\"DBSCAN Silhouette Score: {silhouette_db}\")\n",
    "print(f\"HDBSCAN Silhouette Score: {silhouette_hdb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_clustered_abstracts(abstracts_path, cluster_labels, output_dir='data'):\n",
    "    \"\"\"\n",
    "    Save abstracts to separate CSV files based on cluster labels.\n",
    "\n",
    "    Parameters:\n",
    "    - abstracts_path: str, path to the CSV file containing abstracts.\n",
    "    - cluster_labels: array-like, cluster labels for each abstract.\n",
    "    - output_dir: str, directory to save the output CSV files.\n",
    "    \"\"\"\n",
    "    # Load abstracts\n",
    "    abstracts = pd.read_csv(abstracts_path)\n",
    "    abstracts['Cluster'] = cluster_labels\n",
    "\n",
    "    # Filter out noise points (-1) and group by cluster\n",
    "    clusters = abstracts[abstracts['Cluster'] != -1].groupby('Cluster')\n",
    "\n",
    "    # Iterate through each cluster and save abstracts\n",
    "    for cluster_id, cluster_data in clusters:\n",
    "        # Save abstracts belonging to this cluster\n",
    "        cluster_filename = f'{output_dir}/cluster_{cluster_id}_abstracts.csv'\n",
    "        cluster_data.to_csv(cluster_filename, index=False)\n",
    "        print(f\"Saved Cluster {cluster_id} abstracts to {cluster_filename}\")\n",
    "\n",
    "    # Optionally, save a single file with all clusters grouped\n",
    "    all_clusters_filename = f'{output_dir}/all_clusters_abstracts.csv'\n",
    "    abstracts.to_csv(all_clusters_filename, index=False)\n",
    "    print(f\"Saved all cluster abstracts to {all_clusters_filename}\")\n",
    "\n",
    "# Assuming cluster_labels_hdb is already defined\n",
    "abstracts_path = 'data/arxiv_abstracts.csv'\n",
    "cluster_labels = cluster_labels_hdb  # Replace with your actual cluster labels\n",
    "\n",
    "# Call the function to save clustered abstracts\n",
    "save_clustered_abstracts(abstracts_path, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "abstracts['Cluster'] = cluster_labels_hdb\n",
    "\n",
    "def clustered_abstracts(abstracts, cluster_labels, title):\n",
    "    # Convert embeddings to a DataFrame if needed\n",
    "    embeddings_df = pd.DataFrame(scaled_embeddings, columns=[f\"Embedding_{i}\" for i in range(scaled_embeddings.shape[1])])\n",
    "\n",
    "    # Add cluster indices to the embeddings DataFrame\n",
    "    embeddings_df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "    # Add cluster indices to the existing abstracts DataFrame\n",
    "    abstracts[\"Cluster\"] = cluster_labels\n",
    "\n",
    "    # Save the updated DataFrame for later use\n",
    "    abstracts.to_csv(f\"data/abstracts_{title}.csv\", index=False)\n",
    "\n",
    "    #cluster distribution\n",
    "    return abstracts[\"Cluster\"].value_counts()\n",
    "\n",
    "print(clustered_abstracts(abstracts, cluster_labels_hdb, \"cluster_hdb\"))\n",
    "print(clustered_abstracts(abstracts, cluster_labels_db, \"cluster_db\"))\n",
    "print(clustered_abstracts(abstracts, cluster_labels_km, \"cluster_km\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
